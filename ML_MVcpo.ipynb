{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mofuoku417/Machine-Learning-Techniques-for-Multivariate-Time-Series-Forecasting-of-Crude-Palm-Oil-Prices/blob/main/ML_MVcpo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43F7rVvutZRy"
      },
      "source": [
        "###Importing Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "OpdmgmMRtbph"
      },
      "outputs": [],
      "source": [
        "import plotly.express as px \n",
        "import matplotlib.dates as mdates\n",
        "from statsmodels.tsa.api import SimpleExpSmoothing\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.rcParams['figure.figsize'] = (10, 5)\n",
        "plt.style.use('fivethirtyeight')\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import explained_variance_score\n",
        "import matplotlib.pyplot as plt\n",
        "from timeit import default_timer as timer\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "from statsmodels.tsa.api import ExponentialSmoothing\n",
        "from statsmodels.tsa.api import ExponentialSmoothing, SimpleExpSmoothing, Holt\n",
        "from statsmodels.tsa.api import SimpleExpSmoothing\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import make_scorer, mean_squared_error\n",
        "from sklearn.svm import SVR\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "X5J8FQk5tqFB"
      },
      "outputs": [],
      "source": [
        "#To compute Mean Directional Accuracy\n",
        "def mda(actual: np.ndarray, predicted: np.ndarray):\n",
        "    \"\"\" Mean Directional Accuracy \"\"\"\n",
        "    return np.mean((np.sign(actual[1:] - actual[:-1]) == np.sign(predicted[1:] - predicted[:-1])).astype(int))\n",
        "\n",
        "#Calculate the Mean Absolute Percentage Error\n",
        "#def MAPE(y_true, y_pred): \n",
        "    #mape = np.mean(np.abs((np.array(y_true) - np.array(y_pred)) / np.array(y_true))) * 100\n",
        "    #return mape\n",
        "\n",
        "def mean_absolute_percentage_error(y_true, y_pred): \n",
        "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
        "\n",
        "def MAPE(y_true, y_pred): \n",
        "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
        "\n",
        "#Calculate the Root Mean Squared Error:\n",
        "def RMSE(y_true, y_pred): \n",
        "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    return rmse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSOpWjm5tJyZ"
      },
      "source": [
        "###Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "sYVz5OJUTOqL",
        "outputId": "8e5576d5-0516-4cec-e5dc-228e51597fed"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-cf6fcddb-e73f-494c-ae59-1fa740ba02f5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>cpo_pri</th>\n",
              "      <th>cno_pri</th>\n",
              "      <th>rps_pri</th>\n",
              "      <th>pno_pri</th>\n",
              "      <th>sbo_pri</th>\n",
              "      <th>wti_spri</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2002-02-01</td>\n",
              "      <td>323.0</td>\n",
              "      <td>455.0</td>\n",
              "      <td>423.45</td>\n",
              "      <td>844.0</td>\n",
              "      <td>468.0</td>\n",
              "      <td>28.67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2002-03-01</td>\n",
              "      <td>345.0</td>\n",
              "      <td>546.0</td>\n",
              "      <td>415.85</td>\n",
              "      <td>799.0</td>\n",
              "      <td>485.0</td>\n",
              "      <td>24.49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2002-04-01</td>\n",
              "      <td>362.0</td>\n",
              "      <td>595.0</td>\n",
              "      <td>410.77</td>\n",
              "      <td>718.0</td>\n",
              "      <td>466.0</td>\n",
              "      <td>22.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2002-05-01</td>\n",
              "      <td>376.0</td>\n",
              "      <td>636.0</td>\n",
              "      <td>414.82</td>\n",
              "      <td>614.0</td>\n",
              "      <td>442.0</td>\n",
              "      <td>21.64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2002-06-01</td>\n",
              "      <td>383.0</td>\n",
              "      <td>738.0</td>\n",
              "      <td>451.04</td>\n",
              "      <td>619.0</td>\n",
              "      <td>429.0</td>\n",
              "      <td>22.30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cf6fcddb-e73f-494c-ae59-1fa740ba02f5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cf6fcddb-e73f-494c-ae59-1fa740ba02f5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cf6fcddb-e73f-494c-ae59-1fa740ba02f5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         Date  cpo_pri  cno_pri  rps_pri  pno_pri  sbo_pri  wti_spri\n",
              "0  2002-02-01    323.0    455.0   423.45    844.0    468.0     28.67\n",
              "1  2002-03-01    345.0    546.0   415.85    799.0    485.0     24.49\n",
              "2  2002-04-01    362.0    595.0   410.77    718.0    466.0     22.06\n",
              "3  2002-05-01    376.0    636.0   414.82    614.0    442.0     21.64\n",
              "4  2002-06-01    383.0    738.0   451.04    619.0    429.0     22.30"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ],
      "source": [
        "df = pd.read_csv(\"https://raw.githubusercontent.com/mofuoku417/multivariate-time-series-prediction-of-crude-palm-oil-price-data-science-approach/main/cleaned_data/preprocessed.csv\")\n",
        " #removed unwanted column\n",
        "df.drop([\"Unnamed: 0\"], axis=1, inplace=True)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "1yRl6UK6fspH"
      },
      "outputs": [],
      "source": [
        "df.index = pd.to_datetime(df['Date'], format='%Y.%m.%d')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "0fXgOn1dnmOj",
        "outputId": "d3cfe1e8-fc06-4fa3-af4e-47b651dc5d1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-5f33841c-27c2-4b29-929f-96dbd5a0fb07\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>cpo_pri</th>\n",
              "      <th>cno_pri</th>\n",
              "      <th>rps_pri</th>\n",
              "      <th>pno_pri</th>\n",
              "      <th>sbo_pri</th>\n",
              "      <th>wti_spri</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2002-02-01</th>\n",
              "      <td>2002-02-01</td>\n",
              "      <td>323.0</td>\n",
              "      <td>455.0</td>\n",
              "      <td>423.45</td>\n",
              "      <td>844.0</td>\n",
              "      <td>468.0</td>\n",
              "      <td>28.67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2002-03-01</th>\n",
              "      <td>2002-03-01</td>\n",
              "      <td>345.0</td>\n",
              "      <td>546.0</td>\n",
              "      <td>415.85</td>\n",
              "      <td>799.0</td>\n",
              "      <td>485.0</td>\n",
              "      <td>24.49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2002-04-01</th>\n",
              "      <td>2002-04-01</td>\n",
              "      <td>362.0</td>\n",
              "      <td>595.0</td>\n",
              "      <td>410.77</td>\n",
              "      <td>718.0</td>\n",
              "      <td>466.0</td>\n",
              "      <td>22.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2002-05-01</th>\n",
              "      <td>2002-05-01</td>\n",
              "      <td>376.0</td>\n",
              "      <td>636.0</td>\n",
              "      <td>414.82</td>\n",
              "      <td>614.0</td>\n",
              "      <td>442.0</td>\n",
              "      <td>21.64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2002-06-01</th>\n",
              "      <td>2002-06-01</td>\n",
              "      <td>383.0</td>\n",
              "      <td>738.0</td>\n",
              "      <td>451.04</td>\n",
              "      <td>619.0</td>\n",
              "      <td>429.0</td>\n",
              "      <td>22.30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5f33841c-27c2-4b29-929f-96dbd5a0fb07')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5f33841c-27c2-4b29-929f-96dbd5a0fb07 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5f33841c-27c2-4b29-929f-96dbd5a0fb07');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                  Date  cpo_pri  cno_pri  rps_pri  pno_pri  sbo_pri  wti_spri\n",
              "Date                                                                         \n",
              "2002-02-01  2002-02-01    323.0    455.0   423.45    844.0    468.0     28.67\n",
              "2002-03-01  2002-03-01    345.0    546.0   415.85    799.0    485.0     24.49\n",
              "2002-04-01  2002-04-01    362.0    595.0   410.77    718.0    466.0     22.06\n",
              "2002-05-01  2002-05-01    376.0    636.0   414.82    614.0    442.0     21.64\n",
              "2002-06-01  2002-06-01    383.0    738.0   451.04    619.0    429.0     22.30"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del df['Date']"
      ],
      "metadata": {
        "id": "eE3cx_r6lIf3"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "NKMPVKV3mnSu",
        "outputId": "58baa94e-7702-4c4a-a270-7b8aa46fb610",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-2574c12e-7b87-4632-9cc4-9c0772032794\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cpo_pri</th>\n",
              "      <th>cno_pri</th>\n",
              "      <th>rps_pri</th>\n",
              "      <th>pno_pri</th>\n",
              "      <th>sbo_pri</th>\n",
              "      <th>wti_spri</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2002-02-01</th>\n",
              "      <td>323.0</td>\n",
              "      <td>455.0</td>\n",
              "      <td>423.45</td>\n",
              "      <td>844.0</td>\n",
              "      <td>468.0</td>\n",
              "      <td>28.67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2002-03-01</th>\n",
              "      <td>345.0</td>\n",
              "      <td>546.0</td>\n",
              "      <td>415.85</td>\n",
              "      <td>799.0</td>\n",
              "      <td>485.0</td>\n",
              "      <td>24.49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2002-04-01</th>\n",
              "      <td>362.0</td>\n",
              "      <td>595.0</td>\n",
              "      <td>410.77</td>\n",
              "      <td>718.0</td>\n",
              "      <td>466.0</td>\n",
              "      <td>22.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2002-05-01</th>\n",
              "      <td>376.0</td>\n",
              "      <td>636.0</td>\n",
              "      <td>414.82</td>\n",
              "      <td>614.0</td>\n",
              "      <td>442.0</td>\n",
              "      <td>21.64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2002-06-01</th>\n",
              "      <td>383.0</td>\n",
              "      <td>738.0</td>\n",
              "      <td>451.04</td>\n",
              "      <td>619.0</td>\n",
              "      <td>429.0</td>\n",
              "      <td>22.30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2574c12e-7b87-4632-9cc4-9c0772032794')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2574c12e-7b87-4632-9cc4-9c0772032794 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2574c12e-7b87-4632-9cc4-9c0772032794');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "            cpo_pri  cno_pri  rps_pri  pno_pri  sbo_pri  wti_spri\n",
              "Date                                                             \n",
              "2002-02-01    323.0    455.0   423.45    844.0    468.0     28.67\n",
              "2002-03-01    345.0    546.0   415.85    799.0    485.0     24.49\n",
              "2002-04-01    362.0    595.0   410.77    718.0    466.0     22.06\n",
              "2002-05-01    376.0    636.0   414.82    614.0    442.0     21.64\n",
              "2002-06-01    383.0    738.0   451.04    619.0    429.0     22.30"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "Xnsa-m4quAR_"
      },
      "outputs": [],
      "source": [
        "#Copy the Dataframe\n",
        "df1 = df.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Target Plot"
      ],
      "metadata": {
        "id": "ILAeiPpPuOhS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,5))\n",
        "plt.grid()\n",
        "plt.plot(df.index, df['cpo_pri'], color = 'blue',  label = 'Test')\n",
        "ax = plt.gca()\n",
        "ax.xaxis.set_major_locator(mdates.MonthLocator(interval=12))\n",
        "ax.xaxis.set_major_formatter(mdates.DateFormatter('%m-%Y'))\n",
        "plt.gcf().autofmt_xdate() # Rotation\n",
        "plt.legend(['Actual Values', 'Crude Palm Oil Price 2002-2021'],loc='best')\n",
        "plt.title('Crude Palm Oil Price')\n",
        "plt.ylabel('Monthly Crude Palm Oil Price')\n",
        "plt.xlabel('Date')"
      ],
      "metadata": {
        "id": "2uKVbItrq5j5",
        "outputId": "aab742c8-7d8c-4d02-f7e7-fd10bf028350",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Date')"
            ]
          },
          "metadata": {},
          "execution_count": 103
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x360 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Visualize Multiple Time Series"
      ],
      "metadata": {
        "id": "OCVQkm3r63vk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from plotly.subplots import make_subplots\n",
        "import plotly.graph_objects as go\n",
        "fig = make_subplots(rows=6, cols=1)\n",
        "fig.add_trace(\n",
        "    go.Scatter(x=df.reset_index()['Date'], y=df.reset_index()['cpo_pri'],name='crude palm oil price'),\n",
        "    row=1, col=1\n",
        ")\n",
        "fig.add_trace(\n",
        "    go.Scatter(x=df.reset_index()['Date'], y=df.reset_index()['cno_pri'],name='coconut oil price'),\n",
        "    row=2, col=1\n",
        ")\n",
        "fig.add_trace(\n",
        "    go.Scatter(x=df.reset_index()['Date'], y=df.reset_index()['rps_pri'],name='rapeseed oil price'),\n",
        "    row=3, col=1\n",
        ")\n",
        "fig.add_trace(\n",
        "    go.Scatter(x=df.reset_index()['Date'], y=df.reset_index()['pno_pri'],name='peanut oil price'),\n",
        "    row=4, col=1\n",
        ")\n",
        "fig.add_trace(\n",
        "    go.Scatter(x=df.reset_index()['Date'], y=df.reset_index()['sbo_pri'],name='soybean oil price'),\n",
        "    row=4, col=1\n",
        ")\n",
        "fig.add_trace(\n",
        "    go.Scatter(x=df.reset_index()['Date'], y=df.reset_index()['wti_spri'],name='west texas intermediate spot price'),\n",
        "    row=4, col=1\n",
        "\n",
        ")\n",
        "fig.update_layout(height=1000, width=1200, title_text=\"Time Series\")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "kHYmlb1c31XU",
        "outputId": "43786077-50da-488b-ce81-71e482683080",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"784469b7-e9a2-412a-b4f5-7d0fa05191e3\" class=\"plotly-graph-div\" style=\"height:1000px; width:1200px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"784469b7-e9a2-412a-b4f5-7d0fa05191e3\")) {                    Plotly.newPlot(                        \"784469b7-e9a2-412a-b4f5-7d0fa05191e3\",                        [{\"name\":\"crude palm oil price\",\"x\":[\"2002-02-01T00:00:00\",\"2002-03-01T00:00:00\",\"2002-04-01T00:00:00\",\"2002-05-01T00:00:00\",\"2002-06-01T00:00:00\",\"2002-07-01T00:00:00\",\"2002-08-01T00:00:00\",\"2002-09-01T00:00:00\",\"2002-10-01T00:00:00\",\"2002-11-01T00:00:00\",\"2002-12-01T00:00:00\",\"2003-01-01T00:00:00\",\"2003-02-01T00:00:00\",\"2003-03-01T00:00:00\",\"2003-04-01T00:00:00\",\"2003-05-01T00:00:00\",\"2003-06-01T00:00:00\",\"2003-07-01T00:00:00\",\"2003-08-01T00:00:00\",\"2003-09-01T00:00:00\",\"2003-10-01T00:00:00\",\"2003-11-01T00:00:00\",\"2003-12-01T00:00:00\",\"2004-01-01T00:00:00\",\"2004-02-01T00:00:00\",\"2004-03-01T00:00:00\",\"2004-04-01T00:00:00\",\"2004-05-01T00:00:00\",\"2004-06-01T00:00:00\",\"2004-07-01T00:00:00\",\"2004-08-01T00:00:00\",\"2004-09-01T00:00:00\",\"2004-10-01T00:00:00\",\"2004-11-01T00:00:00\",\"2004-12-01T00:00:00\",\"2005-01-01T00:00:00\",\"2005-02-01T00:00:00\",\"2005-03-01T00:00:00\",\"2005-04-01T00:00:00\",\"2005-05-01T00:00:00\",\"2005-06-01T00:00:00\",\"2005-07-01T00:00:00\",\"2005-08-01T00:00:00\",\"2005-09-01T00:00:00\",\"2005-10-01T00:00:00\",\"2005-11-01T00:00:00\",\"2005-12-01T00:00:00\",\"2006-01-01T00:00:00\",\"2006-02-01T00:00:00\",\"2006-03-01T00:00:00\",\"2006-04-01T00:00:00\",\"2006-05-01T00:00:00\",\"2006-06-01T00:00:00\",\"2006-07-01T00:00:00\",\"2006-08-01T00:00:00\",\"2006-09-01T00:00:00\",\"2006-10-01T00:00:00\",\"2006-11-01T00:00:00\",\"2006-12-01T00:00:00\",\"2007-01-01T00:00:00\",\"2007-02-01T00:00:00\",\"2007-03-01T00:00:00\",\"2007-04-01T00:00:00\",\"2007-05-01T00:00:00\",\"2007-06-01T00:00:00\",\"2007-07-01T00:00:00\",\"2007-08-01T00:00:00\",\"2007-09-01T00:00:00\",\"2007-10-01T00:00:00\",\"2007-11-01T00:00:00\",\"2007-12-01T00:00:00\",\"2008-01-01T00:00:00\",\"2008-02-01T00:00:00\",\"2008-03-01T00:00:00\",\"2008-04-01T00:00:00\",\"2008-05-01T00:00:00\",\"2008-06-01T00:00:00\",\"2008-07-01T00:00:00\",\"2008-08-01T00:00:00\",\"2008-09-01T00:00:00\",\"2008-10-01T00:00:00\",\"2008-11-01T00:00:00\",\"2008-12-01T00:00:00\",\"2009-01-01T00:00:00\",\"2009-02-01T00:00:00\",\"2009-03-01T00:00:00\",\"2009-04-01T00:00:00\",\"2009-05-01T00:00:00\",\"2009-06-01T00:00:00\",\"2009-07-01T00:00:00\",\"2009-08-01T00:00:00\",\"2009-09-01T00:00:00\",\"2009-10-01T00:00:00\",\"2009-11-01T00:00:00\",\"2009-12-01T00:00:00\",\"2010-01-01T00:00:00\",\"2010-02-01T00:00:00\",\"2010-03-01T00:00:00\",\"2010-04-01T00:00:00\",\"2010-05-01T00:00:00\",\"2010-06-01T00:00:00\",\"2010-07-01T00:00:00\",\"2010-08-01T00:00:00\",\"2010-09-01T00:00:00\",\"2010-10-01T00:00:00\",\"2010-11-01T00:00:00\",\"2010-12-01T00:00:00\",\"2011-01-01T00:00:00\",\"2011-02-01T00:00:00\",\"2011-03-01T00:00:00\",\"2011-04-01T00:00:00\",\"2011-05-01T00:00:00\",\"2011-06-01T00:00:00\",\"2011-07-01T00:00:00\",\"2011-08-01T00:00:00\",\"2011-09-01T00:00:00\",\"2011-10-01T00:00:00\",\"2011-11-01T00:00:00\",\"2011-12-01T00:00:00\",\"2012-01-01T00:00:00\",\"2012-02-01T00:00:00\",\"2012-03-01T00:00:00\",\"2012-04-01T00:00:00\",\"2012-05-01T00:00:00\",\"2012-06-01T00:00:00\",\"2012-07-01T00:00:00\",\"2012-08-01T00:00:00\",\"2012-09-01T00:00:00\",\"2012-10-01T00:00:00\",\"2012-11-01T00:00:00\",\"2012-12-01T00:00:00\",\"2013-01-01T00:00:00\",\"2013-02-01T00:00:00\",\"2013-03-01T00:00:00\",\"2013-04-01T00:00:00\",\"2013-05-01T00:00:00\",\"2013-06-01T00:00:00\",\"2013-07-01T00:00:00\",\"2013-08-01T00:00:00\",\"2013-09-01T00:00:00\",\"2013-10-01T00:00:00\",\"2013-11-01T00:00:00\",\"2013-12-01T00:00:00\",\"2014-01-01T00:00:00\",\"2014-02-01T00:00:00\",\"2014-03-01T00:00:00\",\"2014-04-01T00:00:00\",\"2014-05-01T00:00:00\",\"2014-06-01T00:00:00\",\"2014-07-01T00:00:00\",\"2014-08-01T00:00:00\",\"2014-09-01T00:00:00\",\"2014-10-01T00:00:00\",\"2014-11-01T00:00:00\",\"2014-12-01T00:00:00\",\"2015-01-01T00:00:00\",\"2015-02-01T00:00:00\",\"2015-03-01T00:00:00\",\"2015-04-01T00:00:00\",\"2015-05-01T00:00:00\",\"2015-06-01T00:00:00\",\"2015-07-01T00:00:00\",\"2015-08-01T00:00:00\",\"2015-09-01T00:00:00\",\"2015-10-01T00:00:00\",\"2015-11-01T00:00:00\",\"2015-12-01T00:00:00\",\"2016-01-01T00:00:00\",\"2016-02-01T00:00:00\",\"2016-03-01T00:00:00\",\"2016-04-01T00:00:00\",\"2016-05-01T00:00:00\",\"2016-06-01T00:00:00\",\"2016-07-01T00:00:00\",\"2016-08-01T00:00:00\",\"2016-09-01T00:00:00\",\"2016-10-01T00:00:00\",\"2016-11-01T00:00:00\",\"2016-12-01T00:00:00\",\"2017-01-01T00:00:00\",\"2017-02-01T00:00:00\",\"2017-03-01T00:00:00\",\"2017-04-01T00:00:00\",\"2017-05-01T00:00:00\",\"2017-06-01T00:00:00\",\"2017-07-01T00:00:00\",\"2017-08-01T00:00:00\",\"2017-09-01T00:00:00\",\"2017-10-01T00:00:00\",\"2017-11-01T00:00:00\",\"2017-12-01T00:00:00\",\"2018-01-01T00:00:00\",\"2018-02-01T00:00:00\",\"2018-03-01T00:00:00\",\"2018-04-01T00:00:00\",\"2018-05-01T00:00:00\",\"2018-06-01T00:00:00\",\"2018-07-01T00:00:00\",\"2018-08-01T00:00:00\",\"2018-09-01T00:00:00\",\"2018-10-01T00:00:00\",\"2018-11-01T00:00:00\",\"2018-12-01T00:00:00\",\"2019-01-01T00:00:00\",\"2019-02-01T00:00:00\",\"2019-03-01T00:00:00\",\"2019-04-01T00:00:00\",\"2019-05-01T00:00:00\",\"2019-06-01T00:00:00\",\"2019-07-01T00:00:00\",\"2019-08-01T00:00:00\",\"2019-09-01T00:00:00\",\"2019-10-01T00:00:00\",\"2019-11-01T00:00:00\",\"2019-12-01T00:00:00\",\"2020-01-01T00:00:00\",\"2020-02-01T00:00:00\",\"2020-03-01T00:00:00\",\"2020-04-01T00:00:00\",\"2020-05-01T00:00:00\",\"2020-06-01T00:00:00\",\"2020-07-01T00:00:00\",\"2020-08-01T00:00:00\",\"2020-09-01T00:00:00\",\"2020-10-01T00:00:00\",\"2020-11-01T00:00:00\",\"2020-12-01T00:00:00\",\"2021-01-01T00:00:00\",\"2021-02-01T00:00:00\",\"2021-03-01T00:00:00\"],\"y\":[323.0,345.0,362.0,376.0,383.0,382.0,396.0,402.0,390.0,404.0,382.0,382.0,391.0,396.0,413.0,401.0,410.0,425.0,408.0,392.0,371.0,356.0,362.0,356.0,352.0,333.0,357.0,411.0,404.0,387.0,395.0,434.0,488.0,508.0,494.0,575.0,614.0,616.0,707.0,719.0,655.0,661.0,687.0,625.0,611.0,631.0,655.0,616.0,586.0,615.0,607.0,590.0,535.0,518.0,519.0,562.0,552.0,508.0,476.0,513.0,545.0,532.0,550.0,561.0,567.0,580.0,559.0,562.0,553.0,533.0,498.0,504.0,525.0,547.0,556.0,566.0,621.0,659.0,671.0,688.0,705.0,633.0,661.0,674.0,703.0,694.0,681.0,663.0,632.0,561.0,497.0,509.0,475.0,392.0,319.0,354.0,388.0,381.0,370.0,354.0,348.0,332.0,349.0,372.0,324.0,315.0,312.0,306.0,288.0,255.0,257.0,265.0,254.0,240.0,254.0,251.0,234.0,255.0,330.0,362.0,310.0,277.0,323.0,360.0,374.0,353.0,359.0,360.0,385.0,426.0,422.0,446.0,425.0,427.0,465.0,489.0,486.0,477.0,454.0,443.0,454.0,466.0,458.0,439.0,441.0,515.0,548.0,540.0,527.0,564.0,584.0,575.0,537.0,471.0,455.0,458.0,468.0,451.0,455.0,446.0,419.0,423.0,458.0,458.0,450.0,452.0,455.0,448.0,454.0,468.0,467.0,457.0,459.0,474.0,473.0,476.0,484.0,478.0,499.0,534.0,511.0,514.0,572.0,626.0,638.0,645.0,661.0,743.0,816.0,833.0,855.0,831.0,852.0,926.0,999.0,1002.0,1012.25,1012.25,1012.25,1012.25,1012.25,1012.25,1012.25,964.0,826.0,636.0,581.0,587.0,659.0,656.0,660.0,800.0,873.0,789.0,698.0,746.0,704.0,725.0,763.0,822.0,831.0,830.0,863.0,863.0,855.0,826.0,844.0,944.0,949.0,1012.25],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"name\":\"coconut oil price\",\"x\":[\"2002-02-01T00:00:00\",\"2002-03-01T00:00:00\",\"2002-04-01T00:00:00\",\"2002-05-01T00:00:00\",\"2002-06-01T00:00:00\",\"2002-07-01T00:00:00\",\"2002-08-01T00:00:00\",\"2002-09-01T00:00:00\",\"2002-10-01T00:00:00\",\"2002-11-01T00:00:00\",\"2002-12-01T00:00:00\",\"2003-01-01T00:00:00\",\"2003-02-01T00:00:00\",\"2003-03-01T00:00:00\",\"2003-04-01T00:00:00\",\"2003-05-01T00:00:00\",\"2003-06-01T00:00:00\",\"2003-07-01T00:00:00\",\"2003-08-01T00:00:00\",\"2003-09-01T00:00:00\",\"2003-10-01T00:00:00\",\"2003-11-01T00:00:00\",\"2003-12-01T00:00:00\",\"2004-01-01T00:00:00\",\"2004-02-01T00:00:00\",\"2004-03-01T00:00:00\",\"2004-04-01T00:00:00\",\"2004-05-01T00:00:00\",\"2004-06-01T00:00:00\",\"2004-07-01T00:00:00\",\"2004-08-01T00:00:00\",\"2004-09-01T00:00:00\",\"2004-10-01T00:00:00\",\"2004-11-01T00:00:00\",\"2004-12-01T00:00:00\",\"2005-01-01T00:00:00\",\"2005-02-01T00:00:00\",\"2005-03-01T00:00:00\",\"2005-04-01T00:00:00\",\"2005-05-01T00:00:00\",\"2005-06-01T00:00:00\",\"2005-07-01T00:00:00\",\"2005-08-01T00:00:00\",\"2005-09-01T00:00:00\",\"2005-10-01T00:00:00\",\"2005-11-01T00:00:00\",\"2005-12-01T00:00:00\",\"2006-01-01T00:00:00\",\"2006-02-01T00:00:00\",\"2006-03-01T00:00:00\",\"2006-04-01T00:00:00\",\"2006-05-01T00:00:00\",\"2006-06-01T00:00:00\",\"2006-07-01T00:00:00\",\"2006-08-01T00:00:00\",\"2006-09-01T00:00:00\",\"2006-10-01T00:00:00\",\"2006-11-01T00:00:00\",\"2006-12-01T00:00:00\",\"2007-01-01T00:00:00\",\"2007-02-01T00:00:00\",\"2007-03-01T00:00:00\",\"2007-04-01T00:00:00\",\"2007-05-01T00:00:00\",\"2007-06-01T00:00:00\",\"2007-07-01T00:00:00\",\"2007-08-01T00:00:00\",\"2007-09-01T00:00:00\",\"2007-10-01T00:00:00\",\"2007-11-01T00:00:00\",\"2007-12-01T00:00:00\",\"2008-01-01T00:00:00\",\"2008-02-01T00:00:00\",\"2008-03-01T00:00:00\",\"2008-04-01T00:00:00\",\"2008-05-01T00:00:00\",\"2008-06-01T00:00:00\",\"2008-07-01T00:00:00\",\"2008-08-01T00:00:00\",\"2008-09-01T00:00:00\",\"2008-10-01T00:00:00\",\"2008-11-01T00:00:00\",\"2008-12-01T00:00:00\",\"2009-01-01T00:00:00\",\"2009-02-01T00:00:00\",\"2009-03-01T00:00:00\",\"2009-04-01T00:00:00\",\"2009-05-01T00:00:00\",\"2009-06-01T00:00:00\",\"2009-07-01T00:00:00\",\"2009-08-01T00:00:00\",\"2009-09-01T00:00:00\",\"2009-10-01T00:00:00\",\"2009-11-01T00:00:00\",\"2009-12-01T00:00:00\",\"2010-01-01T00:00:00\",\"2010-02-01T00:00:00\",\"2010-03-01T00:00:00\",\"2010-04-01T00:00:00\",\"2010-05-01T00:00:00\",\"2010-06-01T00:00:00\",\"2010-07-01T00:00:00\",\"2010-08-01T00:00:00\",\"2010-09-01T00:00:00\",\"2010-10-01T00:00:00\",\"2010-11-01T00:00:00\",\"2010-12-01T00:00:00\",\"2011-01-01T00:00:00\",\"2011-02-01T00:00:00\",\"2011-03-01T00:00:00\",\"2011-04-01T00:00:00\",\"2011-05-01T00:00:00\",\"2011-06-01T00:00:00\",\"2011-07-01T00:00:00\",\"2011-08-01T00:00:00\",\"2011-09-01T00:00:00\",\"2011-10-01T00:00:00\",\"2011-11-01T00:00:00\",\"2011-12-01T00:00:00\",\"2012-01-01T00:00:00\",\"2012-02-01T00:00:00\",\"2012-03-01T00:00:00\",\"2012-04-01T00:00:00\",\"2012-05-01T00:00:00\",\"2012-06-01T00:00:00\",\"2012-07-01T00:00:00\",\"2012-08-01T00:00:00\",\"2012-09-01T00:00:00\",\"2012-10-01T00:00:00\",\"2012-11-01T00:00:00\",\"2012-12-01T00:00:00\",\"2013-01-01T00:00:00\",\"2013-02-01T00:00:00\",\"2013-03-01T00:00:00\",\"2013-04-01T00:00:00\",\"2013-05-01T00:00:00\",\"2013-06-01T00:00:00\",\"2013-07-01T00:00:00\",\"2013-08-01T00:00:00\",\"2013-09-01T00:00:00\",\"2013-10-01T00:00:00\",\"2013-11-01T00:00:00\",\"2013-12-01T00:00:00\",\"2014-01-01T00:00:00\",\"2014-02-01T00:00:00\",\"2014-03-01T00:00:00\",\"2014-04-01T00:00:00\",\"2014-05-01T00:00:00\",\"2014-06-01T00:00:00\",\"2014-07-01T00:00:00\",\"2014-08-01T00:00:00\",\"2014-09-01T00:00:00\",\"2014-10-01T00:00:00\",\"2014-11-01T00:00:00\",\"2014-12-01T00:00:00\",\"2015-01-01T00:00:00\",\"2015-02-01T00:00:00\",\"2015-03-01T00:00:00\",\"2015-04-01T00:00:00\",\"2015-05-01T00:00:00\",\"2015-06-01T00:00:00\",\"2015-07-01T00:00:00\",\"2015-08-01T00:00:00\",\"2015-09-01T00:00:00\",\"2015-10-01T00:00:00\",\"2015-11-01T00:00:00\",\"2015-12-01T00:00:00\",\"2016-01-01T00:00:00\",\"2016-02-01T00:00:00\",\"2016-03-01T00:00:00\",\"2016-04-01T00:00:00\",\"2016-05-01T00:00:00\",\"2016-06-01T00:00:00\",\"2016-07-01T00:00:00\",\"2016-08-01T00:00:00\",\"2016-09-01T00:00:00\",\"2016-10-01T00:00:00\",\"2016-11-01T00:00:00\",\"2016-12-01T00:00:00\",\"2017-01-01T00:00:00\",\"2017-02-01T00:00:00\",\"2017-03-01T00:00:00\",\"2017-04-01T00:00:00\",\"2017-05-01T00:00:00\",\"2017-06-01T00:00:00\",\"2017-07-01T00:00:00\",\"2017-08-01T00:00:00\",\"2017-09-01T00:00:00\",\"2017-10-01T00:00:00\",\"2017-11-01T00:00:00\",\"2017-12-01T00:00:00\",\"2018-01-01T00:00:00\",\"2018-02-01T00:00:00\",\"2018-03-01T00:00:00\",\"2018-04-01T00:00:00\",\"2018-05-01T00:00:00\",\"2018-06-01T00:00:00\",\"2018-07-01T00:00:00\",\"2018-08-01T00:00:00\",\"2018-09-01T00:00:00\",\"2018-10-01T00:00:00\",\"2018-11-01T00:00:00\",\"2018-12-01T00:00:00\",\"2019-01-01T00:00:00\",\"2019-02-01T00:00:00\",\"2019-03-01T00:00:00\",\"2019-04-01T00:00:00\",\"2019-05-01T00:00:00\",\"2019-06-01T00:00:00\",\"2019-07-01T00:00:00\",\"2019-08-01T00:00:00\",\"2019-09-01T00:00:00\",\"2019-10-01T00:00:00\",\"2019-11-01T00:00:00\",\"2019-12-01T00:00:00\",\"2020-01-01T00:00:00\",\"2020-02-01T00:00:00\",\"2020-03-01T00:00:00\",\"2020-04-01T00:00:00\",\"2020-05-01T00:00:00\",\"2020-06-01T00:00:00\",\"2020-07-01T00:00:00\",\"2020-08-01T00:00:00\",\"2020-09-01T00:00:00\",\"2020-10-01T00:00:00\",\"2020-11-01T00:00:00\",\"2020-12-01T00:00:00\",\"2021-01-01T00:00:00\",\"2021-02-01T00:00:00\",\"2021-03-01T00:00:00\"],\"y\":[455.0,546.0,595.0,636.0,738.0,702.0,644.0,647.0,638.0,589.0,528.0,494.0,501.0,493.0,496.0,461.0,444.0,439.0,427.0,402.0,418.0,436.0,460.0,455.0,424.0,419.0,464.0,615.0,595.0,573.0,539.0,560.0,599.0,608.0,579.0,596.0,622.0,621.0,706.0,692.0,622.0,636.0,632.0,619.0,616.0,668.0,693.0,686.0,677.0,718.0,750.0,718.0,711.0,738.0,723.0,756.0,778.0,816.0,775.0,742.0,721.0,722.0,760.0,777.0,768.0,768.0,737.0,710.0,654.0,637.0,597.0,567.0,615.0,627.0,616.0,586.0,558.0,559.0,578.0,618.0,723.0,652.0,667.0,667.0,652.0,695.0,752.0,774.0,763.0,745.0,700.0,827.0,874.0,796.0,656.0,684.0,704.0,690.0,703.0,703.0,654.0,591.0,552.0,550.0,481.0,437.0,400.0,371.0,332.0,340.0,367.0,329.0,319.0,285.0,289.0,293.0,295.0,317.0,358.0,363.0,322.0,307.0,330.0,339.0,362.0,376.0,366.0,411.0,420.0,446.0,445.0,443.0,410.0,434.0,457.0,482.0,494.0,477.0,441.0,421.0,440.0,459.0,439.0,421.0,431.0,487.0,515.0,583.0,584.0,642.0,685.0,736.0,716.0,658.0,669.0,627.0,657.0,642.0,659.0,654.0,646.0,646.0,710.0,679.0,647.0,639.0,606.0,550.0,559.0,587.0,582.0,553.0,569.0,591.0,575.0,578.0,583.0,575.0,583.0,606.0,609.0,626.0,656.0,732.0,731.0,763.0,769.0,828.0,894.0,979.0,929.0,910.0,930.0,1010.0,1092.875,1092.875,1092.875,1092.875,1092.875,1092.875,1092.875,1092.875,1092.875,1092.875,1092.875,856.0,719.0,740.0,734.0,673.0,625.0,747.0,843.0,747.0,685.0,747.0,701.0,706.0,729.0,768.0,784.0,798.0,921.0,940.0,932.0,993.0,1031.0,1092.875,1092.875,1092.875],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"name\":\"rapeseed oil price\",\"x\":[\"2002-02-01T00:00:00\",\"2002-03-01T00:00:00\",\"2002-04-01T00:00:00\",\"2002-05-01T00:00:00\",\"2002-06-01T00:00:00\",\"2002-07-01T00:00:00\",\"2002-08-01T00:00:00\",\"2002-09-01T00:00:00\",\"2002-10-01T00:00:00\",\"2002-11-01T00:00:00\",\"2002-12-01T00:00:00\",\"2003-01-01T00:00:00\",\"2003-02-01T00:00:00\",\"2003-03-01T00:00:00\",\"2003-04-01T00:00:00\",\"2003-05-01T00:00:00\",\"2003-06-01T00:00:00\",\"2003-07-01T00:00:00\",\"2003-08-01T00:00:00\",\"2003-09-01T00:00:00\",\"2003-10-01T00:00:00\",\"2003-11-01T00:00:00\",\"2003-12-01T00:00:00\",\"2004-01-01T00:00:00\",\"2004-02-01T00:00:00\",\"2004-03-01T00:00:00\",\"2004-04-01T00:00:00\",\"2004-05-01T00:00:00\",\"2004-06-01T00:00:00\",\"2004-07-01T00:00:00\",\"2004-08-01T00:00:00\",\"2004-09-01T00:00:00\",\"2004-10-01T00:00:00\",\"2004-11-01T00:00:00\",\"2004-12-01T00:00:00\",\"2005-01-01T00:00:00\",\"2005-02-01T00:00:00\",\"2005-03-01T00:00:00\",\"2005-04-01T00:00:00\",\"2005-05-01T00:00:00\",\"2005-06-01T00:00:00\",\"2005-07-01T00:00:00\",\"2005-08-01T00:00:00\",\"2005-09-01T00:00:00\",\"2005-10-01T00:00:00\",\"2005-11-01T00:00:00\",\"2005-12-01T00:00:00\",\"2006-01-01T00:00:00\",\"2006-02-01T00:00:00\",\"2006-03-01T00:00:00\",\"2006-04-01T00:00:00\",\"2006-05-01T00:00:00\",\"2006-06-01T00:00:00\",\"2006-07-01T00:00:00\",\"2006-08-01T00:00:00\",\"2006-09-01T00:00:00\",\"2006-10-01T00:00:00\",\"2006-11-01T00:00:00\",\"2006-12-01T00:00:00\",\"2007-01-01T00:00:00\",\"2007-02-01T00:00:00\",\"2007-03-01T00:00:00\",\"2007-04-01T00:00:00\",\"2007-05-01T00:00:00\",\"2007-06-01T00:00:00\",\"2007-07-01T00:00:00\",\"2007-08-01T00:00:00\",\"2007-09-01T00:00:00\",\"2007-10-01T00:00:00\",\"2007-11-01T00:00:00\",\"2007-12-01T00:00:00\",\"2008-01-01T00:00:00\",\"2008-02-01T00:00:00\",\"2008-03-01T00:00:00\",\"2008-04-01T00:00:00\",\"2008-05-01T00:00:00\",\"2008-06-01T00:00:00\",\"2008-07-01T00:00:00\",\"2008-08-01T00:00:00\",\"2008-09-01T00:00:00\",\"2008-10-01T00:00:00\",\"2008-11-01T00:00:00\",\"2008-12-01T00:00:00\",\"2009-01-01T00:00:00\",\"2009-02-01T00:00:00\",\"2009-03-01T00:00:00\",\"2009-04-01T00:00:00\",\"2009-05-01T00:00:00\",\"2009-06-01T00:00:00\",\"2009-07-01T00:00:00\",\"2009-08-01T00:00:00\",\"2009-09-01T00:00:00\",\"2009-10-01T00:00:00\",\"2009-11-01T00:00:00\",\"2009-12-01T00:00:00\",\"2010-01-01T00:00:00\",\"2010-02-01T00:00:00\",\"2010-03-01T00:00:00\",\"2010-04-01T00:00:00\",\"2010-05-01T00:00:00\",\"2010-06-01T00:00:00\",\"2010-07-01T00:00:00\",\"2010-08-01T00:00:00\",\"2010-09-01T00:00:00\",\"2010-10-01T00:00:00\",\"2010-11-01T00:00:00\",\"2010-12-01T00:00:00\",\"2011-01-01T00:00:00\",\"2011-02-01T00:00:00\",\"2011-03-01T00:00:00\",\"2011-04-01T00:00:00\",\"2011-05-01T00:00:00\",\"2011-06-01T00:00:00\",\"2011-07-01T00:00:00\",\"2011-08-01T00:00:00\",\"2011-09-01T00:00:00\",\"2011-10-01T00:00:00\",\"2011-11-01T00:00:00\",\"2011-12-01T00:00:00\",\"2012-01-01T00:00:00\",\"2012-02-01T00:00:00\",\"2012-03-01T00:00:00\",\"2012-04-01T00:00:00\",\"2012-05-01T00:00:00\",\"2012-06-01T00:00:00\",\"2012-07-01T00:00:00\",\"2012-08-01T00:00:00\",\"2012-09-01T00:00:00\",\"2012-10-01T00:00:00\",\"2012-11-01T00:00:00\",\"2012-12-01T00:00:00\",\"2013-01-01T00:00:00\",\"2013-02-01T00:00:00\",\"2013-03-01T00:00:00\",\"2013-04-01T00:00:00\",\"2013-05-01T00:00:00\",\"2013-06-01T00:00:00\",\"2013-07-01T00:00:00\",\"2013-08-01T00:00:00\",\"2013-09-01T00:00:00\",\"2013-10-01T00:00:00\",\"2013-11-01T00:00:00\",\"2013-12-01T00:00:00\",\"2014-01-01T00:00:00\",\"2014-02-01T00:00:00\",\"2014-03-01T00:00:00\",\"2014-04-01T00:00:00\",\"2014-05-01T00:00:00\",\"2014-06-01T00:00:00\",\"2014-07-01T00:00:00\",\"2014-08-01T00:00:00\",\"2014-09-01T00:00:00\",\"2014-10-01T00:00:00\",\"2014-11-01T00:00:00\",\"2014-12-01T00:00:00\",\"2015-01-01T00:00:00\",\"2015-02-01T00:00:00\",\"2015-03-01T00:00:00\",\"2015-04-01T00:00:00\",\"2015-05-01T00:00:00\",\"2015-06-01T00:00:00\",\"2015-07-01T00:00:00\",\"2015-08-01T00:00:00\",\"2015-09-01T00:00:00\",\"2015-10-01T00:00:00\",\"2015-11-01T00:00:00\",\"2015-12-01T00:00:00\",\"2016-01-01T00:00:00\",\"2016-02-01T00:00:00\",\"2016-03-01T00:00:00\",\"2016-04-01T00:00:00\",\"2016-05-01T00:00:00\",\"2016-06-01T00:00:00\",\"2016-07-01T00:00:00\",\"2016-08-01T00:00:00\",\"2016-09-01T00:00:00\",\"2016-10-01T00:00:00\",\"2016-11-01T00:00:00\",\"2016-12-01T00:00:00\",\"2017-01-01T00:00:00\",\"2017-02-01T00:00:00\",\"2017-03-01T00:00:00\",\"2017-04-01T00:00:00\",\"2017-05-01T00:00:00\",\"2017-06-01T00:00:00\",\"2017-07-01T00:00:00\",\"2017-08-01T00:00:00\",\"2017-09-01T00:00:00\",\"2017-10-01T00:00:00\",\"2017-11-01T00:00:00\",\"2017-12-01T00:00:00\",\"2018-01-01T00:00:00\",\"2018-02-01T00:00:00\",\"2018-03-01T00:00:00\",\"2018-04-01T00:00:00\",\"2018-05-01T00:00:00\",\"2018-06-01T00:00:00\",\"2018-07-01T00:00:00\",\"2018-08-01T00:00:00\",\"2018-09-01T00:00:00\",\"2018-10-01T00:00:00\",\"2018-11-01T00:00:00\",\"2018-12-01T00:00:00\",\"2019-01-01T00:00:00\",\"2019-02-01T00:00:00\",\"2019-03-01T00:00:00\",\"2019-04-01T00:00:00\",\"2019-05-01T00:00:00\",\"2019-06-01T00:00:00\",\"2019-07-01T00:00:00\",\"2019-08-01T00:00:00\",\"2019-09-01T00:00:00\",\"2019-10-01T00:00:00\",\"2019-11-01T00:00:00\",\"2019-12-01T00:00:00\",\"2020-01-01T00:00:00\",\"2020-02-01T00:00:00\",\"2020-03-01T00:00:00\",\"2020-04-01T00:00:00\",\"2020-05-01T00:00:00\",\"2020-06-01T00:00:00\",\"2020-07-01T00:00:00\",\"2020-08-01T00:00:00\",\"2020-09-01T00:00:00\",\"2020-10-01T00:00:00\",\"2020-11-01T00:00:00\",\"2020-12-01T00:00:00\",\"2021-01-01T00:00:00\",\"2021-02-01T00:00:00\",\"2021-03-01T00:00:00\"],\"y\":[423.45,415.85,410.77,414.82,451.04,477.29,521.14,525.01,539.31,593.04,616.49,623.72,585.76,551.92,557.22,607.17,612.27,582.56,553.48,564.09,615.82,620.32,648.67,675.49,704.51,687.6,644.98,700.61,699.96,650.92,667.68,657.92,668.92,684.68,709.72,683.88,647.24,663.64,651.7,652.57,642.01,645.33,654.17,687.82,734.38,727.47,711.64,728.91,716.23,738.57,773.72,828.42,829.91,820.58,809.12,785.73,784.4,822.39,854.31,823.02,790.39,771.51,808.43,844.71,867.68,925.81,958.29,1044.75,1146.97,1252.43,1336.75,1368.63375,1368.63375,1368.63375,1368.63375,1368.63375,1368.63375,1368.63375,1352.83,1238.29,1040.68,974.82,838.02,831.74,802.4,776.9,830.19,947.07,917.18,851.56,884.24,855.36,894.11,933.77,938.29,914.09,900.93,910.08,909.13,862.49,876.07,946.76,1012.94,1032.57,1149.51,1242.32,1368.63375,1368.63375,1368.63375,1368.63375,1368.63375,1368.63375,1368.63375,1368.63375,1350.5,1309.99,1270.51,1273.54,1244.66,1252.78,1287.68,1289.12,1303.59,1234.88,1183.37,1214.67,1230.73,1268.69,1214.2,1184.61,1188.18,1210.92,1216.99,1161.66,1131.82,1116.66,1147.34,1008.78,993.85,983.52,1010.85,1021.7,1007.11,948.01,971.77,1009.95,1011.42,954.94,948.33,892.08,851.75,836.46,859.11,841.33,814.81,777.72,762.51,751.16,747.72,769.95,841.79,809.98,753.56,771.69,809.13,799.62,820.94,781.35,779.88,766.26,808.51,805.59,793.48,767.83,817.52,849.65,914.14,918.26,930.43,890.82,874.38,847.32,839.33,842.05,847.47,905.99,875.36,872.87,897.25,962.98,901.97,848.38,827.48,800.24,793.31,811.49,838.02,848.61,853.67,821.47,850.55,840.39,827.02,859.73,829.7,808.68,805.96,815.84,840.01,845.27,877.48,903.07,908.67,910.73,924.5,941.46,902.34,796.67,758.96,799.83,850.98,890.21,921.55,938.14,927.71,1047.78,1097.63,1138.24,1272.13,1321.88],\"type\":\"scatter\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"},{\"name\":\"peanut oil price\",\"x\":[\"2002-02-01T00:00:00\",\"2002-03-01T00:00:00\",\"2002-04-01T00:00:00\",\"2002-05-01T00:00:00\",\"2002-06-01T00:00:00\",\"2002-07-01T00:00:00\",\"2002-08-01T00:00:00\",\"2002-09-01T00:00:00\",\"2002-10-01T00:00:00\",\"2002-11-01T00:00:00\",\"2002-12-01T00:00:00\",\"2003-01-01T00:00:00\",\"2003-02-01T00:00:00\",\"2003-03-01T00:00:00\",\"2003-04-01T00:00:00\",\"2003-05-01T00:00:00\",\"2003-06-01T00:00:00\",\"2003-07-01T00:00:00\",\"2003-08-01T00:00:00\",\"2003-09-01T00:00:00\",\"2003-10-01T00:00:00\",\"2003-11-01T00:00:00\",\"2003-12-01T00:00:00\",\"2004-01-01T00:00:00\",\"2004-02-01T00:00:00\",\"2004-03-01T00:00:00\",\"2004-04-01T00:00:00\",\"2004-05-01T00:00:00\",\"2004-06-01T00:00:00\",\"2004-07-01T00:00:00\",\"2004-08-01T00:00:00\",\"2004-09-01T00:00:00\",\"2004-10-01T00:00:00\",\"2004-11-01T00:00:00\",\"2004-12-01T00:00:00\",\"2005-01-01T00:00:00\",\"2005-02-01T00:00:00\",\"2005-03-01T00:00:00\",\"2005-04-01T00:00:00\",\"2005-05-01T00:00:00\",\"2005-06-01T00:00:00\",\"2005-07-01T00:00:00\",\"2005-08-01T00:00:00\",\"2005-09-01T00:00:00\",\"2005-10-01T00:00:00\",\"2005-11-01T00:00:00\",\"2005-12-01T00:00:00\",\"2006-01-01T00:00:00\",\"2006-02-01T00:00:00\",\"2006-03-01T00:00:00\",\"2006-04-01T00:00:00\",\"2006-05-01T00:00:00\",\"2006-06-01T00:00:00\",\"2006-07-01T00:00:00\",\"2006-08-01T00:00:00\",\"2006-09-01T00:00:00\",\"2006-10-01T00:00:00\",\"2006-11-01T00:00:00\",\"2006-12-01T00:00:00\",\"2007-01-01T00:00:00\",\"2007-02-01T00:00:00\",\"2007-03-01T00:00:00\",\"2007-04-01T00:00:00\",\"2007-05-01T00:00:00\",\"2007-06-01T00:00:00\",\"2007-07-01T00:00:00\",\"2007-08-01T00:00:00\",\"2007-09-01T00:00:00\",\"2007-10-01T00:00:00\",\"2007-11-01T00:00:00\",\"2007-12-01T00:00:00\",\"2008-01-01T00:00:00\",\"2008-02-01T00:00:00\",\"2008-03-01T00:00:00\",\"2008-04-01T00:00:00\",\"2008-05-01T00:00:00\",\"2008-06-01T00:00:00\",\"2008-07-01T00:00:00\",\"2008-08-01T00:00:00\",\"2008-09-01T00:00:00\",\"2008-10-01T00:00:00\",\"2008-11-01T00:00:00\",\"2008-12-01T00:00:00\",\"2009-01-01T00:00:00\",\"2009-02-01T00:00:00\",\"2009-03-01T00:00:00\",\"2009-04-01T00:00:00\",\"2009-05-01T00:00:00\",\"2009-06-01T00:00:00\",\"2009-07-01T00:00:00\",\"2009-08-01T00:00:00\",\"2009-09-01T00:00:00\",\"2009-10-01T00:00:00\",\"2009-11-01T00:00:00\",\"2009-12-01T00:00:00\",\"2010-01-01T00:00:00\",\"2010-02-01T00:00:00\",\"2010-03-01T00:00:00\",\"2010-04-01T00:00:00\",\"2010-05-01T00:00:00\",\"2010-06-01T00:00:00\",\"2010-07-01T00:00:00\",\"2010-08-01T00:00:00\",\"2010-09-01T00:00:00\",\"2010-10-01T00:00:00\",\"2010-11-01T00:00:00\",\"2010-12-01T00:00:00\",\"2011-01-01T00:00:00\",\"2011-02-01T00:00:00\",\"2011-03-01T00:00:00\",\"2011-04-01T00:00:00\",\"2011-05-01T00:00:00\",\"2011-06-01T00:00:00\",\"2011-07-01T00:00:00\",\"2011-08-01T00:00:00\",\"2011-09-01T00:00:00\",\"2011-10-01T00:00:00\",\"2011-11-01T00:00:00\",\"2011-12-01T00:00:00\",\"2012-01-01T00:00:00\",\"2012-02-01T00:00:00\",\"2012-03-01T00:00:00\",\"2012-04-01T00:00:00\",\"2012-05-01T00:00:00\",\"2012-06-01T00:00:00\",\"2012-07-01T00:00:00\",\"2012-08-01T00:00:00\",\"2012-09-01T00:00:00\",\"2012-10-01T00:00:00\",\"2012-11-01T00:00:00\",\"2012-12-01T00:00:00\",\"2013-01-01T00:00:00\",\"2013-02-01T00:00:00\",\"2013-03-01T00:00:00\",\"2013-04-01T00:00:00\",\"2013-05-01T00:00:00\",\"2013-06-01T00:00:00\",\"2013-07-01T00:00:00\",\"2013-08-01T00:00:00\",\"2013-09-01T00:00:00\",\"2013-10-01T00:00:00\",\"2013-11-01T00:00:00\",\"2013-12-01T00:00:00\",\"2014-01-01T00:00:00\",\"2014-02-01T00:00:00\",\"2014-03-01T00:00:00\",\"2014-04-01T00:00:00\",\"2014-05-01T00:00:00\",\"2014-06-01T00:00:00\",\"2014-07-01T00:00:00\",\"2014-08-01T00:00:00\",\"2014-09-01T00:00:00\",\"2014-10-01T00:00:00\",\"2014-11-01T00:00:00\",\"2014-12-01T00:00:00\",\"2015-01-01T00:00:00\",\"2015-02-01T00:00:00\",\"2015-03-01T00:00:00\",\"2015-04-01T00:00:00\",\"2015-05-01T00:00:00\",\"2015-06-01T00:00:00\",\"2015-07-01T00:00:00\",\"2015-08-01T00:00:00\",\"2015-09-01T00:00:00\",\"2015-10-01T00:00:00\",\"2015-11-01T00:00:00\",\"2015-12-01T00:00:00\",\"2016-01-01T00:00:00\",\"2016-02-01T00:00:00\",\"2016-03-01T00:00:00\",\"2016-04-01T00:00:00\",\"2016-05-01T00:00:00\",\"2016-06-01T00:00:00\",\"2016-07-01T00:00:00\",\"2016-08-01T00:00:00\",\"2016-09-01T00:00:00\",\"2016-10-01T00:00:00\",\"2016-11-01T00:00:00\",\"2016-12-01T00:00:00\",\"2017-01-01T00:00:00\",\"2017-02-01T00:00:00\",\"2017-03-01T00:00:00\",\"2017-04-01T00:00:00\",\"2017-05-01T00:00:00\",\"2017-06-01T00:00:00\",\"2017-07-01T00:00:00\",\"2017-08-01T00:00:00\",\"2017-09-01T00:00:00\",\"2017-10-01T00:00:00\",\"2017-11-01T00:00:00\",\"2017-12-01T00:00:00\",\"2018-01-01T00:00:00\",\"2018-02-01T00:00:00\",\"2018-03-01T00:00:00\",\"2018-04-01T00:00:00\",\"2018-05-01T00:00:00\",\"2018-06-01T00:00:00\",\"2018-07-01T00:00:00\",\"2018-08-01T00:00:00\",\"2018-09-01T00:00:00\",\"2018-10-01T00:00:00\",\"2018-11-01T00:00:00\",\"2018-12-01T00:00:00\",\"2019-01-01T00:00:00\",\"2019-02-01T00:00:00\",\"2019-03-01T00:00:00\",\"2019-04-01T00:00:00\",\"2019-05-01T00:00:00\",\"2019-06-01T00:00:00\",\"2019-07-01T00:00:00\",\"2019-08-01T00:00:00\",\"2019-09-01T00:00:00\",\"2019-10-01T00:00:00\",\"2019-11-01T00:00:00\",\"2019-12-01T00:00:00\",\"2020-01-01T00:00:00\",\"2020-02-01T00:00:00\",\"2020-03-01T00:00:00\",\"2020-04-01T00:00:00\",\"2020-05-01T00:00:00\",\"2020-06-01T00:00:00\",\"2020-07-01T00:00:00\",\"2020-08-01T00:00:00\",\"2020-09-01T00:00:00\",\"2020-10-01T00:00:00\",\"2020-11-01T00:00:00\",\"2020-12-01T00:00:00\",\"2021-01-01T00:00:00\",\"2021-02-01T00:00:00\",\"2021-03-01T00:00:00\"],\"y\":[844.0,799.0,718.0,614.0,619.0,605.0,595.0,616.0,651.0,665.0,644.0,600.0,562.0,565.0,575.0,622.0,621.0,611.0,602.0,623.0,685.0,712.0,773.0,858.0,845.0,807.0,808.0,924.0,993.0,1011.0,1013.0,1030.0,1020.0,1014.0,1017.0,1018.0,1018.0,1029.0,1048.0,1062.0,1054.0,1025.0,990.0,981.0,973.0,965.0,969.0,980.0,981.0,990.0,995.0,988.0,959.0,925.0,911.0,895.0,897.0,904.0,902.0,885.0,879.0,874.0,868.0,868.0,874.0,886.0,896.0,938.0,981.0,1047.0,1096.0,1093.0,1083.0,1083.0,1090.0,1058.0,1055.0,1029.0,949.0,928.0,900.0,891.0,874.0,862.0,852.0,850.0,862.0,861.0,952.71,889.57,752.45,663.89,762.17,836.25,859.8,849.78,848.78,888.15,924.94,765.61,676.08,687.63,733.28,789.81,793.66,783.14,771.62,754.36,760.59,754.58,769.61,806.79,815.71,811.08,780.64,744.85,727.53,727.53,723.02,738.07,749.57,761.6,759.59,771.62,684.39,617.29,598.92,590.24,599.56,645.95,704.52,758.59,794.71,816.19,870.83,952.0,970.03,1016.45,1039.32,1064.23,1147.41,1234.59,1261.43,1299.68,1329.79,1359.2,1388.91,1402.33,1433.0,1433.0,1356.32,1322.77,1322.77,1264.65,1247.11,1234.59,1213.59,1212.54,1225.57,1233.63,1234.59,1234.59,1234.59,1223.04,1212.54,1198.51,1178.95,1165.1,1168.45,1129.08,1036.17,1036.17,1029.16,993.18,961.89,936.96,936.96,957.01,990.51,1041.92,1079.22,1102.31,1102.31,1102.31,1071.64,1016.33,1055.21,1078.17,1169.41,1268.18,1404.95,1472.3,1523.39,1633.34,1829.84,1851.46875,1851.46875,1851.46875,1851.46875,1851.46875,1851.46875,1851.46875,1851.46875,1851.46875,1851.46875,1851.46875,1851.46875,1761.69,1619.87,1543.24,1535.22,1433.0,1406.55,1338.81,1322.77,1310.18,1232.58,1155.42,1151.65,1181.87,1275.53,1287.5,1317.02,1361.62,1366.87,1366.87,1366.87,1383.9,1426.71,1471.32],\"type\":\"scatter\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"},{\"name\":\"soybean oil price\",\"x\":[\"2002-02-01T00:00:00\",\"2002-03-01T00:00:00\",\"2002-04-01T00:00:00\",\"2002-05-01T00:00:00\",\"2002-06-01T00:00:00\",\"2002-07-01T00:00:00\",\"2002-08-01T00:00:00\",\"2002-09-01T00:00:00\",\"2002-10-01T00:00:00\",\"2002-11-01T00:00:00\",\"2002-12-01T00:00:00\",\"2003-01-01T00:00:00\",\"2003-02-01T00:00:00\",\"2003-03-01T00:00:00\",\"2003-04-01T00:00:00\",\"2003-05-01T00:00:00\",\"2003-06-01T00:00:00\",\"2003-07-01T00:00:00\",\"2003-08-01T00:00:00\",\"2003-09-01T00:00:00\",\"2003-10-01T00:00:00\",\"2003-11-01T00:00:00\",\"2003-12-01T00:00:00\",\"2004-01-01T00:00:00\",\"2004-02-01T00:00:00\",\"2004-03-01T00:00:00\",\"2004-04-01T00:00:00\",\"2004-05-01T00:00:00\",\"2004-06-01T00:00:00\",\"2004-07-01T00:00:00\",\"2004-08-01T00:00:00\",\"2004-09-01T00:00:00\",\"2004-10-01T00:00:00\",\"2004-11-01T00:00:00\",\"2004-12-01T00:00:00\",\"2005-01-01T00:00:00\",\"2005-02-01T00:00:00\",\"2005-03-01T00:00:00\",\"2005-04-01T00:00:00\",\"2005-05-01T00:00:00\",\"2005-06-01T00:00:00\",\"2005-07-01T00:00:00\",\"2005-08-01T00:00:00\",\"2005-09-01T00:00:00\",\"2005-10-01T00:00:00\",\"2005-11-01T00:00:00\",\"2005-12-01T00:00:00\",\"2006-01-01T00:00:00\",\"2006-02-01T00:00:00\",\"2006-03-01T00:00:00\",\"2006-04-01T00:00:00\",\"2006-05-01T00:00:00\",\"2006-06-01T00:00:00\",\"2006-07-01T00:00:00\",\"2006-08-01T00:00:00\",\"2006-09-01T00:00:00\",\"2006-10-01T00:00:00\",\"2006-11-01T00:00:00\",\"2006-12-01T00:00:00\",\"2007-01-01T00:00:00\",\"2007-02-01T00:00:00\",\"2007-03-01T00:00:00\",\"2007-04-01T00:00:00\",\"2007-05-01T00:00:00\",\"2007-06-01T00:00:00\",\"2007-07-01T00:00:00\",\"2007-08-01T00:00:00\",\"2007-09-01T00:00:00\",\"2007-10-01T00:00:00\",\"2007-11-01T00:00:00\",\"2007-12-01T00:00:00\",\"2008-01-01T00:00:00\",\"2008-02-01T00:00:00\",\"2008-03-01T00:00:00\",\"2008-04-01T00:00:00\",\"2008-05-01T00:00:00\",\"2008-06-01T00:00:00\",\"2008-07-01T00:00:00\",\"2008-08-01T00:00:00\",\"2008-09-01T00:00:00\",\"2008-10-01T00:00:00\",\"2008-11-01T00:00:00\",\"2008-12-01T00:00:00\",\"2009-01-01T00:00:00\",\"2009-02-01T00:00:00\",\"2009-03-01T00:00:00\",\"2009-04-01T00:00:00\",\"2009-05-01T00:00:00\",\"2009-06-01T00:00:00\",\"2009-07-01T00:00:00\",\"2009-08-01T00:00:00\",\"2009-09-01T00:00:00\",\"2009-10-01T00:00:00\",\"2009-11-01T00:00:00\",\"2009-12-01T00:00:00\",\"2010-01-01T00:00:00\",\"2010-02-01T00:00:00\",\"2010-03-01T00:00:00\",\"2010-04-01T00:00:00\",\"2010-05-01T00:00:00\",\"2010-06-01T00:00:00\",\"2010-07-01T00:00:00\",\"2010-08-01T00:00:00\",\"2010-09-01T00:00:00\",\"2010-10-01T00:00:00\",\"2010-11-01T00:00:00\",\"2010-12-01T00:00:00\",\"2011-01-01T00:00:00\",\"2011-02-01T00:00:00\",\"2011-03-01T00:00:00\",\"2011-04-01T00:00:00\",\"2011-05-01T00:00:00\",\"2011-06-01T00:00:00\",\"2011-07-01T00:00:00\",\"2011-08-01T00:00:00\",\"2011-09-01T00:00:00\",\"2011-10-01T00:00:00\",\"2011-11-01T00:00:00\",\"2011-12-01T00:00:00\",\"2012-01-01T00:00:00\",\"2012-02-01T00:00:00\",\"2012-03-01T00:00:00\",\"2012-04-01T00:00:00\",\"2012-05-01T00:00:00\",\"2012-06-01T00:00:00\",\"2012-07-01T00:00:00\",\"2012-08-01T00:00:00\",\"2012-09-01T00:00:00\",\"2012-10-01T00:00:00\",\"2012-11-01T00:00:00\",\"2012-12-01T00:00:00\",\"2013-01-01T00:00:00\",\"2013-02-01T00:00:00\",\"2013-03-01T00:00:00\",\"2013-04-01T00:00:00\",\"2013-05-01T00:00:00\",\"2013-06-01T00:00:00\",\"2013-07-01T00:00:00\",\"2013-08-01T00:00:00\",\"2013-09-01T00:00:00\",\"2013-10-01T00:00:00\",\"2013-11-01T00:00:00\",\"2013-12-01T00:00:00\",\"2014-01-01T00:00:00\",\"2014-02-01T00:00:00\",\"2014-03-01T00:00:00\",\"2014-04-01T00:00:00\",\"2014-05-01T00:00:00\",\"2014-06-01T00:00:00\",\"2014-07-01T00:00:00\",\"2014-08-01T00:00:00\",\"2014-09-01T00:00:00\",\"2014-10-01T00:00:00\",\"2014-11-01T00:00:00\",\"2014-12-01T00:00:00\",\"2015-01-01T00:00:00\",\"2015-02-01T00:00:00\",\"2015-03-01T00:00:00\",\"2015-04-01T00:00:00\",\"2015-05-01T00:00:00\",\"2015-06-01T00:00:00\",\"2015-07-01T00:00:00\",\"2015-08-01T00:00:00\",\"2015-09-01T00:00:00\",\"2015-10-01T00:00:00\",\"2015-11-01T00:00:00\",\"2015-12-01T00:00:00\",\"2016-01-01T00:00:00\",\"2016-02-01T00:00:00\",\"2016-03-01T00:00:00\",\"2016-04-01T00:00:00\",\"2016-05-01T00:00:00\",\"2016-06-01T00:00:00\",\"2016-07-01T00:00:00\",\"2016-08-01T00:00:00\",\"2016-09-01T00:00:00\",\"2016-10-01T00:00:00\",\"2016-11-01T00:00:00\",\"2016-12-01T00:00:00\",\"2017-01-01T00:00:00\",\"2017-02-01T00:00:00\",\"2017-03-01T00:00:00\",\"2017-04-01T00:00:00\",\"2017-05-01T00:00:00\",\"2017-06-01T00:00:00\",\"2017-07-01T00:00:00\",\"2017-08-01T00:00:00\",\"2017-09-01T00:00:00\",\"2017-10-01T00:00:00\",\"2017-11-01T00:00:00\",\"2017-12-01T00:00:00\",\"2018-01-01T00:00:00\",\"2018-02-01T00:00:00\",\"2018-03-01T00:00:00\",\"2018-04-01T00:00:00\",\"2018-05-01T00:00:00\",\"2018-06-01T00:00:00\",\"2018-07-01T00:00:00\",\"2018-08-01T00:00:00\",\"2018-09-01T00:00:00\",\"2018-10-01T00:00:00\",\"2018-11-01T00:00:00\",\"2018-12-01T00:00:00\",\"2019-01-01T00:00:00\",\"2019-02-01T00:00:00\",\"2019-03-01T00:00:00\",\"2019-04-01T00:00:00\",\"2019-05-01T00:00:00\",\"2019-06-01T00:00:00\",\"2019-07-01T00:00:00\",\"2019-08-01T00:00:00\",\"2019-09-01T00:00:00\",\"2019-10-01T00:00:00\",\"2019-11-01T00:00:00\",\"2019-12-01T00:00:00\",\"2020-01-01T00:00:00\",\"2020-02-01T00:00:00\",\"2020-03-01T00:00:00\",\"2020-04-01T00:00:00\",\"2020-05-01T00:00:00\",\"2020-06-01T00:00:00\",\"2020-07-01T00:00:00\",\"2020-08-01T00:00:00\",\"2020-09-01T00:00:00\",\"2020-10-01T00:00:00\",\"2020-11-01T00:00:00\",\"2020-12-01T00:00:00\",\"2021-01-01T00:00:00\",\"2021-02-01T00:00:00\",\"2021-03-01T00:00:00\"],\"y\":[468.0,485.0,466.0,442.0,429.0,414.0,434.0,425.0,439.0,456.0,429.0,409.0,421.0,418.0,437.0,436.0,444.0,433.0,438.0,448.0,448.0,461.0,505.0,483.0,489.0,491.0,536.0,589.0,602.0,577.0,586.0,584.0,594.0,571.0,560.0,600.0,672.0,642.0,706.0,693.0,674.0,663.0,652.0,610.0,595.0,611.0,626.0,616.0,614.0,638.0,623.0,579.0,554.0,548.0,538.0,582.0,591.0,563.0,549.0,565.0,569.0,528.0,517.0,514.0,534.0,527.0,541.0,541.0,541.0,550.0,535.0,544.0,555.0,611.0,676.0,622.0,625.0,634.0,652.0,662.0,671.0,629.0,612.0,592.0,615.0,614.0,614.0,591.0,541.63,482.36,444.36,442.68,421.5,405.88,391.4,412.37,413.93,399.53,387.31,374.67,369.79,357.94,363.49,366.24,337.97,330.17,339.3,328.92,312.49,314.02,316.78,320.57,304.81,303.78,327.63,326.01,295.17,286.89,421.36,427.49,385.09,373.03,390.69,396.87,389.18,364.92,359.21,370.86,399.89,456.81,489.63,502.75,505.67,528.57,582.0,591.03,540.72,522.43,522.52,540.9,549.24,545.85,531.41,515.69,558.02,608.26,630.62,637.36,656.97,682.08,689.43,672.46,627.96,581.74,605.08,604.65,601.6,583.49,561.19,552.06,519.98,495.73,543.69,545.88,537.98,560.15,561.26,550.08,545.16,578.62,558.93,537.66,535.83,533.27,540.6,540.44,588.29,600.55,630.01,632.18,602.35,614.71,675.67,698.12,697.33,715.04,719.03,753.7,788.7,835.55,887.12,921.79,970.08875,970.08875,970.08875,970.08875,970.08875,970.08875,970.08875,970.08875,970.08875,970.08875,970.08875,970.08875,970.08875,942.53,825.64,745.55,789.89,747.64,730.71,809.08,889.62,892.92,846.3,903.15,858.18,897.0,932.38,939.91,920.55,909.19,911.07,902.83,859.49,860.28,910.82,970.08875,970.08875,970.08875],\"type\":\"scatter\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"},{\"name\":\"west texas intermediate spot price\",\"x\":[\"2002-02-01T00:00:00\",\"2002-03-01T00:00:00\",\"2002-04-01T00:00:00\",\"2002-05-01T00:00:00\",\"2002-06-01T00:00:00\",\"2002-07-01T00:00:00\",\"2002-08-01T00:00:00\",\"2002-09-01T00:00:00\",\"2002-10-01T00:00:00\",\"2002-11-01T00:00:00\",\"2002-12-01T00:00:00\",\"2003-01-01T00:00:00\",\"2003-02-01T00:00:00\",\"2003-03-01T00:00:00\",\"2003-04-01T00:00:00\",\"2003-05-01T00:00:00\",\"2003-06-01T00:00:00\",\"2003-07-01T00:00:00\",\"2003-08-01T00:00:00\",\"2003-09-01T00:00:00\",\"2003-10-01T00:00:00\",\"2003-11-01T00:00:00\",\"2003-12-01T00:00:00\",\"2004-01-01T00:00:00\",\"2004-02-01T00:00:00\",\"2004-03-01T00:00:00\",\"2004-04-01T00:00:00\",\"2004-05-01T00:00:00\",\"2004-06-01T00:00:00\",\"2004-07-01T00:00:00\",\"2004-08-01T00:00:00\",\"2004-09-01T00:00:00\",\"2004-10-01T00:00:00\",\"2004-11-01T00:00:00\",\"2004-12-01T00:00:00\",\"2005-01-01T00:00:00\",\"2005-02-01T00:00:00\",\"2005-03-01T00:00:00\",\"2005-04-01T00:00:00\",\"2005-05-01T00:00:00\",\"2005-06-01T00:00:00\",\"2005-07-01T00:00:00\",\"2005-08-01T00:00:00\",\"2005-09-01T00:00:00\",\"2005-10-01T00:00:00\",\"2005-11-01T00:00:00\",\"2005-12-01T00:00:00\",\"2006-01-01T00:00:00\",\"2006-02-01T00:00:00\",\"2006-03-01T00:00:00\",\"2006-04-01T00:00:00\",\"2006-05-01T00:00:00\",\"2006-06-01T00:00:00\",\"2006-07-01T00:00:00\",\"2006-08-01T00:00:00\",\"2006-09-01T00:00:00\",\"2006-10-01T00:00:00\",\"2006-11-01T00:00:00\",\"2006-12-01T00:00:00\",\"2007-01-01T00:00:00\",\"2007-02-01T00:00:00\",\"2007-03-01T00:00:00\",\"2007-04-01T00:00:00\",\"2007-05-01T00:00:00\",\"2007-06-01T00:00:00\",\"2007-07-01T00:00:00\",\"2007-08-01T00:00:00\",\"2007-09-01T00:00:00\",\"2007-10-01T00:00:00\",\"2007-11-01T00:00:00\",\"2007-12-01T00:00:00\",\"2008-01-01T00:00:00\",\"2008-02-01T00:00:00\",\"2008-03-01T00:00:00\",\"2008-04-01T00:00:00\",\"2008-05-01T00:00:00\",\"2008-06-01T00:00:00\",\"2008-07-01T00:00:00\",\"2008-08-01T00:00:00\",\"2008-09-01T00:00:00\",\"2008-10-01T00:00:00\",\"2008-11-01T00:00:00\",\"2008-12-01T00:00:00\",\"2009-01-01T00:00:00\",\"2009-02-01T00:00:00\",\"2009-03-01T00:00:00\",\"2009-04-01T00:00:00\",\"2009-05-01T00:00:00\",\"2009-06-01T00:00:00\",\"2009-07-01T00:00:00\",\"2009-08-01T00:00:00\",\"2009-09-01T00:00:00\",\"2009-10-01T00:00:00\",\"2009-11-01T00:00:00\",\"2009-12-01T00:00:00\",\"2010-01-01T00:00:00\",\"2010-02-01T00:00:00\",\"2010-03-01T00:00:00\",\"2010-04-01T00:00:00\",\"2010-05-01T00:00:00\",\"2010-06-01T00:00:00\",\"2010-07-01T00:00:00\",\"2010-08-01T00:00:00\",\"2010-09-01T00:00:00\",\"2010-10-01T00:00:00\",\"2010-11-01T00:00:00\",\"2010-12-01T00:00:00\",\"2011-01-01T00:00:00\",\"2011-02-01T00:00:00\",\"2011-03-01T00:00:00\",\"2011-04-01T00:00:00\",\"2011-05-01T00:00:00\",\"2011-06-01T00:00:00\",\"2011-07-01T00:00:00\",\"2011-08-01T00:00:00\",\"2011-09-01T00:00:00\",\"2011-10-01T00:00:00\",\"2011-11-01T00:00:00\",\"2011-12-01T00:00:00\",\"2012-01-01T00:00:00\",\"2012-02-01T00:00:00\",\"2012-03-01T00:00:00\",\"2012-04-01T00:00:00\",\"2012-05-01T00:00:00\",\"2012-06-01T00:00:00\",\"2012-07-01T00:00:00\",\"2012-08-01T00:00:00\",\"2012-09-01T00:00:00\",\"2012-10-01T00:00:00\",\"2012-11-01T00:00:00\",\"2012-12-01T00:00:00\",\"2013-01-01T00:00:00\",\"2013-02-01T00:00:00\",\"2013-03-01T00:00:00\",\"2013-04-01T00:00:00\",\"2013-05-01T00:00:00\",\"2013-06-01T00:00:00\",\"2013-07-01T00:00:00\",\"2013-08-01T00:00:00\",\"2013-09-01T00:00:00\",\"2013-10-01T00:00:00\",\"2013-11-01T00:00:00\",\"2013-12-01T00:00:00\",\"2014-01-01T00:00:00\",\"2014-02-01T00:00:00\",\"2014-03-01T00:00:00\",\"2014-04-01T00:00:00\",\"2014-05-01T00:00:00\",\"2014-06-01T00:00:00\",\"2014-07-01T00:00:00\",\"2014-08-01T00:00:00\",\"2014-09-01T00:00:00\",\"2014-10-01T00:00:00\",\"2014-11-01T00:00:00\",\"2014-12-01T00:00:00\",\"2015-01-01T00:00:00\",\"2015-02-01T00:00:00\",\"2015-03-01T00:00:00\",\"2015-04-01T00:00:00\",\"2015-05-01T00:00:00\",\"2015-06-01T00:00:00\",\"2015-07-01T00:00:00\",\"2015-08-01T00:00:00\",\"2015-09-01T00:00:00\",\"2015-10-01T00:00:00\",\"2015-11-01T00:00:00\",\"2015-12-01T00:00:00\",\"2016-01-01T00:00:00\",\"2016-02-01T00:00:00\",\"2016-03-01T00:00:00\",\"2016-04-01T00:00:00\",\"2016-05-01T00:00:00\",\"2016-06-01T00:00:00\",\"2016-07-01T00:00:00\",\"2016-08-01T00:00:00\",\"2016-09-01T00:00:00\",\"2016-10-01T00:00:00\",\"2016-11-01T00:00:00\",\"2016-12-01T00:00:00\",\"2017-01-01T00:00:00\",\"2017-02-01T00:00:00\",\"2017-03-01T00:00:00\",\"2017-04-01T00:00:00\",\"2017-05-01T00:00:00\",\"2017-06-01T00:00:00\",\"2017-07-01T00:00:00\",\"2017-08-01T00:00:00\",\"2017-09-01T00:00:00\",\"2017-10-01T00:00:00\",\"2017-11-01T00:00:00\",\"2017-12-01T00:00:00\",\"2018-01-01T00:00:00\",\"2018-02-01T00:00:00\",\"2018-03-01T00:00:00\",\"2018-04-01T00:00:00\",\"2018-05-01T00:00:00\",\"2018-06-01T00:00:00\",\"2018-07-01T00:00:00\",\"2018-08-01T00:00:00\",\"2018-09-01T00:00:00\",\"2018-10-01T00:00:00\",\"2018-11-01T00:00:00\",\"2018-12-01T00:00:00\",\"2019-01-01T00:00:00\",\"2019-02-01T00:00:00\",\"2019-03-01T00:00:00\",\"2019-04-01T00:00:00\",\"2019-05-01T00:00:00\",\"2019-06-01T00:00:00\",\"2019-07-01T00:00:00\",\"2019-08-01T00:00:00\",\"2019-09-01T00:00:00\",\"2019-10-01T00:00:00\",\"2019-11-01T00:00:00\",\"2019-12-01T00:00:00\",\"2020-01-01T00:00:00\",\"2020-02-01T00:00:00\",\"2020-03-01T00:00:00\",\"2020-04-01T00:00:00\",\"2020-05-01T00:00:00\",\"2020-06-01T00:00:00\",\"2020-07-01T00:00:00\",\"2020-08-01T00:00:00\",\"2020-09-01T00:00:00\",\"2020-10-01T00:00:00\",\"2020-11-01T00:00:00\",\"2020-12-01T00:00:00\",\"2021-01-01T00:00:00\",\"2021-02-01T00:00:00\",\"2021-03-01T00:00:00\"],\"y\":[28.67,24.49,22.06,21.64,22.3,23.82,27.84,29.62,29.49,26.71,27.14,29.02,30.25,29.41,26.24,28.92,31.03,33.23,30.84,26.02,24.29,26.33,27.04,28.36,25.21,25.93,26.57,26.15,27.15,27.47,29.96,30.63,33.59,31.32,33.28,36.9,37.59,42.64,37.3,32.25,35.69,36.86,41.04,40.94,39.25,46.36,48.74,52.85,53.48,51.91,49.45,50.11,54.11,51.62,52.32,56.57,55.55,56.08,58.66,57.01,50.14,46.67,45.91,46.93,41.73,45.32,45.77,47.31,46.96,50.3,54.06,53.14,57.51,60.38,64.54,62.71,63.18,64.68,67.94,71.51,80.36,86.12,84.58,77.92,72.35,57.58,45.0,30.88,31.54,30.62,36.45,37.77,43.33,49.67,45.52,49.81,47.69,51.14,52.3,50.99,54.91,55.84,59.89,63.02,58.65,61.73,59.81,59.42,57.61,58.94,61.35,67.44,66.94,65.6,73.53,76.15,70.59,66.9,68.28,60.18,62.25,63.04,71.52,74.8,77.66,77.31,80.41,78.47,73.99,65.75,71.61,75.9,73.44,69.0,67.62,67.3,71.32,71.35,71.67,70.65,72.99,72.64,80.03,80.06,79.57,73.69,69.69,71.43,69.69,73.76,72.76,73.9,74.16,77.43,76.02,72.38,72.33,66.6,60.79,48.06,40.77,44.6,44.1,50.51,53.13,53.33,46.31,38.49,40.49,41.15,39.72,34.23,29.05,27.41,34.04,36.12,41.29,43.42,40.39,39.92,40.3,45.28,42.12,49.34,49.44,50.17,46.41,47.65,43.89,40.23,40.5,40.68,41.82,43.86,48.32,48.95,52.22,50.36,50.88,54.03,59.21,57.82,60.61,58.88,60.21,61.61,49.86,43.02,45.12,48.41,51.45,56.83,54.4,48.42,51.29,49.29,51.75,48.84,51.61,53.83,51.82,46.32,27.02,15.2,26.2,34.03,35.5,35.81,33.59,33.57],\"type\":\"scatter\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.875,1.0]},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.0,1.0]},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.7,0.825]},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.0,1.0]},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.525,0.65]},\"xaxis4\":{\"anchor\":\"y4\",\"domain\":[0.0,1.0]},\"yaxis4\":{\"anchor\":\"x4\",\"domain\":[0.35,0.475]},\"xaxis5\":{\"anchor\":\"y5\",\"domain\":[0.0,1.0]},\"yaxis5\":{\"anchor\":\"x5\",\"domain\":[0.175,0.3]},\"xaxis6\":{\"anchor\":\"y6\",\"domain\":[0.0,1.0]},\"yaxis6\":{\"anchor\":\"x6\",\"domain\":[0.0,0.125]},\"title\":{\"text\":\"Time Series\"},\"height\":1000,\"width\":1200},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('784469b7-e9a2-412a-b4f5-7d0fa05191e3');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot an area chart\n",
        "ax = df.plot.area(fontsize=12);\n",
        "\n",
        "# Additional customizations\n",
        "ax.set_xlabel('Date');\n",
        "ax.legend(fontsize=12);"
      ],
      "metadata": {
        "id": "5DFQAUdQxK4F",
        "outputId": "358a4594-7429-41e9-9197-0abafbd9bea5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        }
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Visualize Correlation Matrices"
      ],
      "metadata": {
        "id": "BIEeJqnWyp5k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_corr = df.corr()\n",
        "\n",
        "sns.heatmap(df_corr)\n",
        "plt.xticks(rotation=90)\n",
        "plt.yticks(rotation=0) "
      ],
      "metadata": {
        "id": "vxxxhcVgn6L1",
        "outputId": "188b99d6-c850-4b1c-ed61-25655583b5e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0.5, 1.5, 2.5, 3.5, 4.5, 5.5]),\n",
              " <a list of 6 Text major ticklabel objects>)"
            ]
          },
          "metadata": {},
          "execution_count": 90
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 2 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Clustered Heatmaps"
      ],
      "metadata": {
        "id": "RTvFRP2xzl7u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get correlation matrix of the meat DataFrame: corr_meat\n",
        "corr_df = df.corr(method='pearson')\n",
        "\n",
        "# Customize the heatmap of the corr_meat correlation matrix\n",
        "fig = sns.clustermap(corr_df,\n",
        "               row_cluster=True,\n",
        "               col_cluster=True,\n",
        "               figsize=(10, 10));\n",
        "\n",
        "plt.setp(fig.ax_heatmap.xaxis.get_majorticklabels(), rotation=90);\n",
        "plt.setp(fig.ax_heatmap.yaxis.get_majorticklabels(), rotation=0);"
      ],
      "metadata": {
        "id": "yb3t6o1vxkpv",
        "outputId": "005c33a5-eedd-45a1-938f-9800d3d79cd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 767
        }
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 4 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "g-ckpAYoEi1H"
      },
      "outputs": [],
      "source": [
        "#Copy the Dataframe\n",
        "df1 = df.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKNZU-NmnKcA"
      },
      "source": [
        "##Traditional Forecasting Technique"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyWvLjmq2EJ5"
      },
      "source": [
        "####Split into train and test set"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.reset_index('Date', inplace=True)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "tGq4PFC08Oiw",
        "outputId": "80ba37bc-780d-490f-f5ae-b6061712bf78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-81ada451-ba7c-4a61-978b-09121f19245c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>cpo_pri</th>\n",
              "      <th>cno_pri</th>\n",
              "      <th>rps_pri</th>\n",
              "      <th>pno_pri</th>\n",
              "      <th>sbo_pri</th>\n",
              "      <th>wti_spri</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2002-02-01</td>\n",
              "      <td>323.0</td>\n",
              "      <td>455.0</td>\n",
              "      <td>423.45</td>\n",
              "      <td>844.0</td>\n",
              "      <td>468.0</td>\n",
              "      <td>28.67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2002-03-01</td>\n",
              "      <td>345.0</td>\n",
              "      <td>546.0</td>\n",
              "      <td>415.85</td>\n",
              "      <td>799.0</td>\n",
              "      <td>485.0</td>\n",
              "      <td>24.49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2002-04-01</td>\n",
              "      <td>362.0</td>\n",
              "      <td>595.0</td>\n",
              "      <td>410.77</td>\n",
              "      <td>718.0</td>\n",
              "      <td>466.0</td>\n",
              "      <td>22.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2002-05-01</td>\n",
              "      <td>376.0</td>\n",
              "      <td>636.0</td>\n",
              "      <td>414.82</td>\n",
              "      <td>614.0</td>\n",
              "      <td>442.0</td>\n",
              "      <td>21.64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2002-06-01</td>\n",
              "      <td>383.0</td>\n",
              "      <td>738.0</td>\n",
              "      <td>451.04</td>\n",
              "      <td>619.0</td>\n",
              "      <td>429.0</td>\n",
              "      <td>22.30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-81ada451-ba7c-4a61-978b-09121f19245c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-81ada451-ba7c-4a61-978b-09121f19245c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-81ada451-ba7c-4a61-978b-09121f19245c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        Date  cpo_pri  cno_pri  rps_pri  pno_pri  sbo_pri  wti_spri\n",
              "0 2002-02-01    323.0    455.0   423.45    844.0    468.0     28.67\n",
              "1 2002-03-01    345.0    546.0   415.85    799.0    485.0     24.49\n",
              "2 2002-04-01    362.0    595.0   410.77    718.0    466.0     22.06\n",
              "3 2002-05-01    376.0    636.0   414.82    614.0    442.0     21.64\n",
              "4 2002-06-01    383.0    738.0   451.04    619.0    429.0     22.30"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qgb-TgCecj-E",
        "outputId": "1fb026d1-f68b-484b-e6ba-8da433c988be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "176 days of training months \n",
            " 54 months of testing data \n"
          ]
        }
      ],
      "source": [
        "df.set_index('Date', inplace=True)\n",
        "split_date = '2016-09' #'2017-06' \n",
        "df_training = df.loc[df.index <= split_date]\n",
        "df_test = df.loc[df.index > split_date]\n",
        "print(f\"{len(df_training)} days of training months \\n {len(df_test)} months of testing data \")\n",
        "df_training_len = 184"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dPOcfKUbpZNt"
      },
      "outputs": [],
      "source": [
        "#X = cleaned_data['cpo_pri']\n",
        "#test = X.iloc[-46:]\n",
        "#train = X.iloc[:-46]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "oRr44hrrpjLx"
      },
      "outputs": [],
      "source": [
        "#X = df['cpo_pri']\n",
        "#test = X.iloc[-46:]\n",
        "#train = X.iloc[:-46]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRkTkpx4jVab"
      },
      "source": [
        "###Plot the Data: Train Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "se6tU1Q-yZsN",
        "outputId": "9ea581d5-cf31-46b4-b3f8-ebbfe1ffe048"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x360 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.figure(figsize=(20,5))\n",
        "plt.title(\"Train and Test Data Split\")\n",
        "plt.plot(df_training.index, df_training['cpo_pri'], label='Train')\n",
        "plt.plot(df_test.index,df_test['cpo_pri'], label='Test')\n",
        "ax = plt.gca()\n",
        "ax.xaxis.set_major_locator(mdates.MonthLocator(interval=12))\n",
        "ax.xaxis.set_major_formatter(mdates.DateFormatter('%m-%Y'))\n",
        "plt.gcf().autofmt_xdate() # Rotation\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0c09g-pjGb1"
      },
      "source": [
        "###Nave Forecast\n",
        "\n",
        "We apply the naive forecast to establish a baseline for model accuracy. First, the naive method predicts the time df by continuing the last value. Then, the last value of the last season of the forecast is used according to the seasonal pattern."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "cUJ1yQOH1ozO"
      },
      "outputs": [],
      "source": [
        "y_hat = df_test.copy()\n",
        "nd = np.asarray(df_training.cpo_pri)\n",
        "y_hat['naive'] = nd[len(nd)-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "id": "cCTuF8A4yaFk",
        "outputId": "b72a1228-cf27-48a1-acd4-1db982b9bc9e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABRkAAAFECAYAAACj2Tm8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3gU1foH8O/MbnbTs5SQJkkooRMUJLQLht6EXAQFxX65CCgqKnBRLBQFvCpFEVSuBfSHXiIgRYoYlRYIihCVEmoIEFKAFFJ3d+b3R242md0kpE929/t5Hp6Hc+bMzHtSML4557xCRkaGDCIiIiIiIiIiIqJqEtUOgIiIiIiIiIiIiOwbk4xERERERERERERUI0wyEhERERERERERUY0wyUhEREREREREREQ1wiQjERERERERERER1QiTjERERERERERERFQjTDISERER2bGpU6fCYDAgMTFR7VCIiIiIyIkxyUhERERUywwGAwwGAzp06IDc3NwyxwwaNMghk4P79u2zzL+8P/Hx8WqH2eAYDAZ07txZ7TCIiIiIqk2rdgBEREREjurq1at4//33MXv27Dp7x+uvv44ZM2YgMDCwzt5RHc2bN8dDDz1U5jU/P796joaIiIiI6hqTjERERER1wNvbGzqdDitWrMBjjz0Gf3//OnmPv79/nT27JoKDgzFnzhy1wyAiIiKiesLt0kRERER1wNXVFXPmzEFOTg4WLlxY6fu2bduGyZMno1u3bggMDERgYCD69euHDz/8EGaz2Wa89ZmMR44cgcFgwPjx48t9R2RkJBo1aoSLFy8q+vfu3YsJEyagVatW8PX1RadOnfDiiy8iJSWl0vFXVXZ2NhYuXIju3bvDz88PwcHBGDVqFLZv324zNjExEQaDASNHjkRycjKefvpptG3bFo0bN8a2bduqPY+MjAwsXLgQvXv3RmBgIJo3b45evXph7ty5yMjIsIw7duwYZs+ejT59+iA0NBR+fn7o2rUr5syZg5s3b9o8t7CwEB999BHuuecetGjRAv7+/ujUqRPGjRuHLVu2ACjZXg4ASUlJim3lU6dOrdHHloiIiKg+cSUjERERUR157LHH8PHHH+P//u//MGXKFHTq1Om298ybNw+iKFqSjFlZWdi7dy9efvllHD16FGvWrKnw/u7du6NNmzb48ccfkZaWBl9fX8X1kydP4tixY5ZEWbFly5bhjTfeQKNGjTBkyBD4+fnhr7/+wn/+8x/s2LEDP/zwA4KCgqr1cShPZmYmhg8fjhMnTiA8PBxTpkxBZmYmNm/ejIkTJ2LOnDllbjW/efMmBg8eDG9vb0RFRUGWZTRq1Kha87h48SJGjRqFpKQkhIeH4/HHHwcAnDt3DmvWrMEDDzxgSQJ+8cUX2LZtG/r06YPIyEhIkoRjx45h1apV2LNnD2JiYuDl5WV59rRp0xAdHY127drh/vvvh4eHB5KTk3H06FFs27YNo0ePRnBwMGbPno0lS5bA29tbkVjkGY1ERERkT4SMjAxZ7SCIiIiIHInBYECzZs2QkJCAXbt2Yfz48YiMjMTmzZstYwYNGoRff/0Vx48fR0hIiKX/woULaNGiheJ5kiRh2rRp+Prrr/HDDz+ge/fulmtTp07F+vXrFc8pTrS9+eabePrppxXPeu2117BixQqsXLkSEydOBAAcOHAA9957L+6++25s2LDBklQDgK+//hpTpkzBqFGjsG7dutvOfd++fRg1alS5ZzJ2794dgwYNAgC88MIL+PTTTzFx4kR88MEHEAQBAHDlyhUMGDAAqamp+PHHH9G1a1cARSsZu3TpAgAYP348Vq5cCa225Hfm1ZnHkCFDEBcXh5dffhmzZs1SxJqRkQGtVgtPT08AwKVLlxAUFASNRqMYt3btWjz77LOW8zGBogRqaGgounTpgj179ijiBIDr16+jSZMmlrbBYEDz5s3xxx9/3PZjTERERNQQcbs0ERERUR0aOnQoIiMj8fPPP2PXrl23HW+dYAQAURQxZcoUAEBMTMxtnzF+/HhoNBqsX79e0W82m/Hf//4XHh4eiIqKsvSvXr0asixj6dKlisQcAEyYMAHh4eH4/vvvkZ2dfdt3F0tKSsKSJUts/uzZswcAYDQa8fXXX8Pd3R3z58+3JBgBICgoCC+88AJkWcbatWttnq3T6bBw4UKbxF1V53Hs2DHExcWhQ4cOeOmll2zeYzAYLAlGoOicSesEIwA88sgj8Pb2VnxuBEGALMvQ6XRl3lM6wUhERETkCLhdmoiIiKiOLViwAPfccw9ee+01DBo0qMykU7EbN25gxYoV2L17NxITE5GTk6O4npycfNv3BQQEoH///tizZw/i4+MRHh4OoChBee3aNTz44IOK5Nnhw4eh1WqxdetWbN261eZ5hYWFMJvNOHfuHO68885KzblPnz5lnqtYLCEhAbm5ubj77rvLTLhFRkYCAI4fP25zLTg42GYbeHXmceTIEQDAgAEDIIq3/9270WjEZ599ho0bN+LUqVPIysqCJEmW66U/N97e3hg2bBh27tyJPn364N5770WvXr3QvXt3xceeiIiIyFEwyUhERERUxzp37oyHHnoIX375JT777DNMmjSpzHEZGRno378/EhMT0a1bN0yYMAGNGjWCRqNBZmYmVq9ejYKCgkq9c+LEidizZw/Wr19vSTIWr2y03sZ848YNmEwmLFmypMJn3rp1q1LvroysrCwAQLNmzcq87ufnB6Bo27G18u6p6jyKnx0QEFCpmJ944gls27YNoaGhGDFiBPz8/KDT6QAAq1atsvncfPbZZ1ixYgWio6Px9ttvAwBcXFwwbNgwLFy4ULFNnoiIiMjeMclIREREVA/mzp2LTZs2YfHixXjggQfKHLNu3TokJiZi9uzZmDNnjuJaXFwcVq9eXen3jRgxAgaDAdHR0ViwYAFu3bqF77//HiEhIfjb3/6mGOvt7Q2j0YikpKSqT6yavL29AQCpqallXi+uBF08rrTSW6utn1mVefj4+ACo3OrQ33//Hdu2bUNkZCSio6MVW7UlScKKFSts7nFzc8Ps2bMxe/ZsJCcnIzY2Fhs2bMDWrVtx6tQpHDx4EC4uLpWKlYiIiKih45mMRERERPXA398fzz77LNLT0/Hee++VOeb8+fMAgNGjR9tcO3DgQJXep9frMXbsWKSlpWH37t3YtGkT8vPzMWHCBJskXffu3ZGdnV2vRUfatGkDd3d3nDhxAtevX7e5/ssvvwBApbdnA1WfR3EBnZiYGMW257IUf26GDx9ucxbkb7/9hry8vArvDwgIwH333Yf169cjIiICZ86cwalTpyzXRVG8bQxEREREDRmTjERERET1ZPr06QgMDMSqVatw7do1m+vBwcEAgP379yv6jx8/jqVLl1b5fcXVo9evX4/169dDEAQ8+OCDNuOKK1A///zzuHLlis31/Px8xMbGVvn9FXFxccH48eORm5uLefPmQZZly7Xk5GQsXboUgiDg4YcfrvQzqzqPO++8Ez169MCJEyfwzjvv2IzPzMy0bK0u73OTlpZWZtGY9PR0/Pnnnzb9BQUFlm3a7u7ulv7GjRsjPT39tslKIiIiooaK26WJiIiI6om7uzvmzp2LadOm4fLlyzbXJ0yYgBUrVmDOnDnYt28fWrVqhXPnzmHXrl0YNWoUNm7cWKX3de3aFe3bt8eOHTtgMpnQp08fhIaG2ozr168fFixYgNdffx3dunXD4MGDERoaivz8fCQlJeHgwYMIDg62SbDV1Ouvv47Y2FisXbsW8fHxiIyMRGZmJjZv3oybN29i1qxZuPvuuyv9vOrM46OPPsK9996Lt956C9u3b0ffvn0BABcuXEBMTAx27dqF8PBwdO3aFT179sTWrVsxZMgQ9OzZE6mpqdizZw/CwsJsznW8evUq+vXrhw4dOqBjx44ICgpCTk4OYmJicO7cOYwePRqtWrWyjO/fvz82bNiAsWPHonfv3tDr9ejUqROGDx9ew48yERERUf1gkpGIiIioHk2YMAGrV69GfHy8zbWAgADs2LEDb7zxBg4dOoSYmBiEhYXh3XffxT333FPlJCNQVOTl1Vdftfy9PNOnT0fPnj2xevVqxMbGYufOnfD09ERAQAAeeOABjBkzpsrvvh2DwYBdu3Zh+fLl2LJlCz788EPo9XqEh4fjqaeeKnPb+O1UdR6hoaHYu3cv3n//fWzbtg2ffPIJ9Ho97rjjDvzzn/+0rGDUaDRYv349Fi5ciN27d+Ojjz5CQEAAHn30Ubz00kvo0aOH4rnBwcF4+eWXsW/fPhw4cADp6enw8fFBy5Yt8dxzz9l8LhYtWgRRFPHzzz/j0KFDkCQJDz74IJOMREREZDeEjIwM+fbDiIiIiIiIiIiIiMrGMxmJiIiIiIiIiIioRphkJCIiIiIiIiIiohphkpGIiIiIiIiIiIhqhElGIiIiIiIiIiIiqhEmGYmIiIiIiIiIiKhGmGQkIiIiIiIiIiKiGmGSsQE7c+aM2iHUG2eaK8D5Ojpnmq8zzRXgfB2ZM80V4HwdnTPN15nmCjjXfJ1prgDn6+icab7ONFeA87XGJCMRERERERERERHVCJOMREREREREREREVCNMMhIREREREREREVGNMMlIRERERERERERENaJVO4C6YjKZkJOTo3YYNeLq6orMzEy1w6gX9jZXDw8PaLUO++1DRERERERERFQlDpklMZlMyM7OhsFggCAIaodTbXq9Hq6urmqHUS/saa6yLCMjIwNeXl5MNBIRERERERERwUGTjDk5OXafYKSGSxAEGAwGZGVlwcfHR+1wiIiIiIiInJJ4+QI08YeBgvz6f7neFaY7e0EODKn/dxM1UA6ZZATABCPVKX59ERERERERqUPIvAFd9Bpo9+2AIMuqxaHb9Dly31gNOShUtRiIGpJKFX45cOAAJkyYgPbt28NgMOCrr75SXJdlGYsWLUK7du3g7++PkSNH4uTJk4oxGRkZmDx5MoKDgxEcHIzJkycjIyNDMeavv/7CiBEj4O/vj/bt22PJkiWQVfwHg4iIiIiIiIgaCJMRLt9/DfdZD8Nl7/eqJhgBQCjMh27HN6rGQA2Ddt8OuL02Gbr1H0JzLBbIs+8aIdVVqSRjTk4OOnTogMWLF8PNzc3m+vLly7Fy5UosWbIEMTEx8PX1xZgxY5CdnW0ZM2nSJMTHxyM6OhrR0dGIj4/HU089ZbmelZWFMWPGoFmzZoiJicHixYvx/vvv44MPPqiFaRIRERERERGR3bmVCc3J3+Gy+1u4v/wE9N+shpCfq3ZUFtojP6uzXZsaFM2Jo9AkJkC3879wWzoHLru/VTskVVRqu/SQIUMwZMgQAMC0adMU12RZxqpVq/D8888jKioKALBq1SqEhYUhOjoaTzzxBE6fPo09e/Zg586diIiIAAAsXboUw4cPx5kzZxAWFoYNGzYgLy8Pq1atgpubGzp06ICEhAR8+OGHeOaZZ7g9lYiIiIiIiMgJaI4fhssP30JMOgcx43qFY6WAYJgiIgHUX85A+9MWiFk3AQBCfh60R/fD1GtQvb2fGhhZhubk74ouc/s7VQpGXTU+kzExMREpKSkYMGCApc/NzQ29e/fG4cOH8cQTTyAuLg6enp7o0aOHZUzPnj3h4eGBw4cPIywsDHFxcejVq5dipeTAgQPx5ptvIjExEaGhoTUN1SlNnToVN27cwDffcAk3ERERERERNWzClYtwXTYHgiRVOE5290DhmCdgHPB3QFvP5SastklrD+xiktGJCSlXIN5Mt7RlnR5Si3YqRqSeGn8npqSkAAB8fX0V/b6+vkhOTgYApKamokmTJorViIIgoGnTpkhNTbWMCQwMtHlG8bXykoxnzpyx6XN1dYVer6/ehFTi7+9f4fUHHngAK1asqPJz582bB1mWkZ/f8Jdv20OMpWVlZVm+fqujrK9dR8b5Oi5nmivA+ToyZ5orwPk6OmearzPNFXCu+TrTXAHOt5j/L9/Bo4IEoywISL+rH67dEwWThxdw4UJdhVgu1+bt0L5UW/Pnr7hw9AhMXoZy73Gmz68zzRUArv+yCx6l2tlBLXHuYqJq8ajJ7qtLh4WF2fRlZmbC1dVVhWiq7/Tp05a/79q1C88++yzi4+MtyVJXV1fFnIxGI1xcXG77XHv5OOTn59tNrMW8vb3RvHnzat1bfEyAs+B8HZczzRXgfB2ZM80V4HwdnTPN15nmCjjXfJ1prgDnW5pr9GVFW9a6QAoMhhTUAlLzljDd1QdugSFoUR+BlicsDOadX0Fz6SwAQJBltLl2DsauE8oc7kyfX2eaK1A034AbVxV9+m59HPZjcLsEco2TjH5+fgCAtLQ0RcIlLS0NzZo1AwA0a9YM169fhyzLltWMsiwjPT1dMSYtLU3x7OJ28ZiaMHx2pcbPqIqMJ4KqNL744wgAPj4+AIrm7erqisTERLRt2xZr1qzBF198gSNHjmD+/PkYN24cZs6cidjYWNy4cQOhoaF45pln8PDDD1ueZb1deuTIkWjXrh18fHzw+eefQxRFTJgwAfPnz4coVqoOEBEREREREVHtMxZCc+6Eoit30ReQmwWWc4N6TH2GWpKMQNGWaePw8QDrSTiXMs9jvEulYNRX46xSSEgI/Pz88NNPP1n68vPzERsbazmDMSIiArdu3UJcXJxlTFxcHHJychRjYmNjFVtmf/rpJwQEBCAkJKSmYTqEefPmYdKkSTh06BBGjhyJ/Px8dOnSBV9//TUOHTqEKVOmYMaMGfjll18qfM6GDRug0Wiwe/du/Pvf/8aqVauwcePGepoFERERERERkS3xwmkIxkJLW2rsC9k3QMWIymfqOQByqYU6mssXIJZKOpJz0F+/BjHzhqUt610hhbZVMSJ1VSrJeOvWLcTHxyM+Ph6SJOHy5cuIj49HUlISBEHA1KlTsXz5cmzZsgUnTpzAtGnT4OHhgXHjxgEA2rZti0GDBmHGjBmIi4tDXFwcZsyYgaFDh1qWkI4bNw5ubm6YNm0aTpw4gS1btmDZsmWYNm0aK0v/z+TJkxEVFYXQ0FAEBQUhMDAQzz77LMLDwxEaGorHH38co0aNQnR0dIXPadu2LV555RW0bt0aY8aMQd++fW+bmCQiIiIiIiKqS5rT8Yq2uW2XBrsyUDY0gblzhKJPe2C3StGQWrwSTyva5jad678QUQNSqSTj77//jn79+qFfv37Iy8vDokWL0K9fP7z11lsAgOeeew5Tp07FzJkz0b9/f1y7dg0bN26El5eX5Rlr1qxBp06dMHbsWIwdOxadOnXCRx99ZLnu4+ODTZs2ITk5Gf3798fMmTPx9NNP45lnnqnlKduvu+5SLrk1m81455130Lt3b7Ro0QJBQUHYunUrLl++XM4TinTs2FHR9vf3t9mqTkRERERERFSfNKePKdrmtl1UiqRyTH2GKNra2D2A2aRSNKQGT+skoxNvlQYqeSZj3759kZGRUe51QRAwZ84czJkzp9wxBoMBH3/8cYXv6dixI3bs2FGZkKqsqmckNkQeHh6K9vvvv48PPvgAixcvRocOHeDp6Yn58+ffNmFoXTBGEATIslzr8RIRERERERFVitkEzZk/lV1tw1UKpnJMd/WB7OYBIS8HACBm3YTmz19h7tJT5cioXsiybZKxnXMnGVnpw47FxsZi2LBhmDBhAsLDw9GiRQucPcszIIiIiIiIiMi+iJfOQsjPs7QlLwPkgGAVI6oEnR6miEhFl/bALnVioXonXrkIl5xsS1t2dYcU6phVpSuLSUY71rp1a+zduxexsbFISEjAzJkzcenSJbXDIiIiIiIiIqoS6/MYpbbhDfY8xtKMfYYq2tqj+4FSiSdyXDZVpduGAxrnPY8RYJLRrs2cORNdu3bF/fffjxEjRsDd3R3333+/2mERERERERERVYnm9HFFu6Gfx1hMCusEqVQFbMFohPbXvSpGRPVFc8rqDNF2d6oUScPh3CnWBioqKgoZGRnIz88HAISEhJR5JqbBYMCXX35Z4bNWrVqlaG/fvv22Y4iIiIiIiIjqjSRBc/oPRZe5nX0kGSGKMPUeDN13ay1dmvOnYLpnpIpBUZ2TJNsko5MXfQG4kpGIiIiIiIiIVCReuQghJ8vSlt09Id3RQsWIqsYc2kbRFtKSVYqE6ot4+QKEW6W/Zj0ghbRWMaKGgUlGIiIiIiIiIlKNzVbpNp0BUaNSNFUnNw1QtMV0JhkdneaU1XmMbbrY1ddsXeF2aSIiIiIiIiJSjWhV9MVezmMsJvn6K9pCegogSYDIdV0OQ5IgJp2DJj4O2j/iIJ79U3GZW6WLMMlIREREREREROqQ5TKKvoSrFEw1uXlA9vC2bPkWzCYIGemQGzdTOTCqDWJCPFw/XgSxgm3w5vYs+gJwuzQRERERERERqURIuQIx84alLetdIYW0qeCOhslmNWPaNZUiodrm+tm7FScYQ9pAat6qHiNquJhkJCIiIiIiIiJV2KxibN0J0NrfpkvZ1+pcRhZ/cQhC1k2IVxPLvCYFhiCl11DkzXybW+P/x/6+c4mIiIiIiIjIIWhO2flW6f+RrJKMrDDtGMSk84q2ZGiCwr8/BnOn7pB9A3D1zBmEeRlUiq7hYZKRiIiIiIiIiFShSbBOMtpX0ZdiEitMOyTxsjLJaO50N0z9R6sUTcPH9ZxEREREREREVO+E9GsQ01MsbVnrAqllOxUjqj7Z6kxGkWcyOgTx8gVFW7qjpUqR2AcmGYmIiIiIiIio3mlOxyvaUsv2gE6vUjQ1w+3SjklMOqdoM8lYMSYZGwiDwWDzx9/f3/L3qVOnVvvZixYtQq9evWoxWiIiIiIiIqKaEc+dULTt9TxGAJCb+Cnaws00wGRUKRqqFZIZ4pWLyq7mTDJWhGcyNhCnT5+2/H3Xrl149tlnER8fD72+6Lc4rq6uaoVGREREREREVOs01knG1h1UiqQW6PSQDE0gZlwHAAiyDOF6KmS/IJUDo+oSUq9CKCywtGUvH8g+jVWMqOFzmiSj52OR9fq+W1/8XKXxfn4lv/Xw8fEBADRr1sySXNyxYwcWL16MU6dOwc/PD/fffz9mz54NnU4HANiyZQsWL16M8+fPw9XVFR06dMDnn3+OH374AUuWLAFQtFoSAFauXImJEyfWdIpERERERERE1VNYYLMV1dzSjpOMAOSmAcD/koxAUfEXM5OMdsu6srS5eStAEFSKxj44TZLRnv3444+YPHkyFi1ahD59+iApKQkvvPACCgoKsHDhQqSkpOAf//gHXnvtNYwePRo5OTn49ddfAQD33XcfTp48iV27dmHbtm0AAG9vbzWnQ0RERERERE5OvJgAwWy2tCXfQMDboGJENSf5+kNz9k9LW2DxF7umsaosLd3RQqVI7AeTjHbgnXfewfTp0/Hwww8DAFq0aIE33ngDTz31FBYsWIDk5GQYjUZERUUhODgYANChQ8lvgDw8PKDVahWrJYmIiIiIiIjUYrNVulV7lSKpPbJV8ReRxV/smvVKRhZ9uT0mGe3A8ePHcfToUSxfvtzSJ0kS8vLykJKSgs6dOyMyMhK9e/dG//79ERkZiaioKDRt2lTFqImIiIiIiIjKJp47qWhLrex7qzTACtOORrReydi8lUqR2A+nSTJW9YzEhkSSJMyePRt///vfba41bdoUGo0GmzZtwpEjRxATE4N169Zh3rx52L59Ozp37qxCxERERERERETl05xXJhkdciVjOpOMdqsgD0LqVUtTFgRIQaHqxWMnnCbJaM+6dOmChIQEtGxZ/tJcQRAQERGBiIgIzJ49Gz179sSmTZvQuXNn6HQ6mEuddUFERERERESkFm12BsTrKZa2rHWBFNxaxYhqh9TUX9HmmYz2S7x8EYIsW9pys0BA76piRPaBSUY7MGvWLIwfPx7NmzfHmDFjoNVqcfLkSfz222+YP38+jhw5gp9//hkDBw6Er68v4uPjceXKFbRt2xYAEBwcjKSkJBw7dgzNmzeHp6cn9Hq9yrMiIiIiIiIiZ+Rx9YKiLYW0Blx0KkVTe+TGvpBFEYIkAQDErJtAQZ7KUVF1cKt09YhqB0C3N3DgQPz3v//F/v37MXDgQAwcOBBLly7FHXfcAaCoWvThw4cxfvx4dOvWDXPnzsXMmTMxfvx4AMDo0aMxePBgREVFoVWrVoiOjlZzOkREREREROTE3K8ok4zmlvZ/HiMAQKOF3LiZoktITylnMDVkNklGVpauFK5kbICioqKQkZGB/Px8S9+AAQMwYMCAMse3bdu2wsShXq/H2rVraz1OIiIiIiIioqryuGKVwHGA8xiLSb4BENNLtkmLacmAB4uy2hvrytJmVpauFK5kJCIiIiIiIqL6IZnhnnxR0WV2gMrSxWyKv7DCtP2RZWi4XbpamGQkIiIiIiIionohXkmEprDA0pa9fGwSc/bMpvhLOou/2Bsh8waE7ExLW9bpITdznK/RusTt0kRERERERERUL8RzJxRtc6sOgCCoFE3ts5uVjAX5cPlpK4QbqTD2HwU5IFjtiBoM663SUlALQNSoFI19YZKRiIiIiIiIiOqFxjrJ2NJxzmMEyljJ2ECTjLrNX0D3/XoAgPbYQeS++ZlDVPiuDbaVpXkeY2VxuzQRERERERER1QvrlYySA53HCJSxkjG9ASYZZRkue7dbmmLKFWjO/qViQA2LzUpGVpauNK5kJCIiIiIiIqK6l5cD8WqipSkLAswt26kYUO2TfRpDdnGBYDQCAITcHGjyclSOSklIvgThVpaiTzx/Eub2d6kUUfUJKZeh/+/HEFKu2FyTvRvB1HsQTD0HAlqXSj/TdiUji75UFpOMRERERERERFTnNBdOQ5BlS1sOCAbcPVWMqA6IIuSm/hCSkyxduox0FQOypUn4w7bv/CkYVYilRkxGuL03B+K1pHKHaP/6FdK3/4Fx2AMw3jMScHWv+JlmE8SrF5Vdd3C7dGVxuzQRERERERERVV/uLbj8sBGaIz8DpZKI1myKvjjYeYzFpKbKLdO6zOsqRVI2zRnbJKN4/qQKkdSMy8/bKkwwFhNvpEH/fyvh8cJ46DZ9BhgLyx0rpFyxrEIFAMmnEeBtqENAyEAAACAASURBVJV4nQFXMhIRERERERFR9WRnwH3+NIipVwEAhYPGoPCR58ocqjmnTGSZWzvWeYzFrM9l1NvBSkbxRhqEm+mQGzVVIaJqyM+Fy3drq3SLkJMN3eYvIF44jfwZi8qsaq6xOY+RW6WrgklGB7Vo0SJs2bIFsbGxaodCREREREREjkgyw3X1m5YEIwDo9myC1CYcph79FUOFrJvQJMQrb3fUlYxWScaGtF1ayLiu+HyVJl44BXOjv9VzRNXjsisaYtZNS1vW6ZE3898l26GNhdAe2A2Xvd9DsFq5qD1+CNqDP8DUZ4jNc1lZuma4XboBmTp1KgwGA95++21F/759+2AwGHD9euWXWE+fPh3bt2+//cAaSExMhMFgsPnz0EMP1el769qiRYvQq1cvtcMgIiIiIiJq0HSbPof2zyM2/frP3oFQOpFVWADX5XMh5GRbumRXN4et2iv5+ivaDSnJKJaxirGY5vypeoykBrIyoPt+vaLLOPR+SG3CIQW3LvrTqgMKH30eue99g8LRj0C2OvtT9/UqoNTXYzFWlq4ZJhkbGFdXV7z//vtIT6/ZP0Kenp5o3LhxLUVVsW+//RanT5+2/Pnwww+r/Syj0e6OmiUiIiIiInI6mt8PQrdlXZnXhLwcuH44DzAZAVmG/j9vQ3P2L8UY46D7AI1jbq6UmzbcJGNZW6WL2cu5jLqt6yDk51nasoc3CkdMKHOs7N0IhWP/gdw3VkN2KakwLWbdhO7b/ygHm4wQExMUXawsXTVOk2TMiRlWr3+qq2/fvmjevLnNasbSzGYznnnmGYSHh8Pf3x9du3bF8uXLIUmSZUzp1XgxMTHw9fXFjRs3FM+ZP38+evfubWkfPnwYI0aMQEBAANq3b48XXngBWVnKsvZlady4Mfz8/Cx/DIaiQ1ELCgrwr3/9C2FhYfDz88OgQYMU27eLV2ju3r0bw4YNg6+vL3788UfIsozly5fjzjvvhL+/P3r37o1vvvlG8c7k5GT885//RIsWLRAQEIC//e1v2Lt3LwDgwoULePDBB9GmTRsEBgaiX79+2Llzp+L+LVu2oHfv3vD390doaChGjBiB1NRUfPXVV1iyZAlOnjxpWZn51Vdf3fZjQERERERE5CyElMtw/fhNRZ/solO0NRdOQ/ffj+Hy3Vq4HPpRcS2rRXsUjnmizuNUi/V2aX3G9QoL4tSnipKMmgungFJ5hYZISEuGy4/fKfoKRz982yrlst8dKBw5UdHnEvMdxOLVm2YTXFctgHgjreQeQYQUGFI7gTsJp0ky2gtRFPHGG2/gs88+w8WLF8scI0kSAgIC8Pnnn+Pw4cN49dVX8e677+LLL78sc/w999yDJk2aYPPmzZY+WZaxYcMGjB8/HgDw119/4b777sPw4cOxf/9+rFu3Dn/88QeeeeaZas/ltddew6ZNm/DBBx9g79696NChA8aNG4dr164pxr3xxhv417/+hSNHjuDuu+/GwoULsW7dOrzzzjs4dOgQZsyYgRkzZmDXrl0AgJycHIwcORKXLl3CV199hYMHD2LWrFmW5926dQuDBw/Gpk2bsH//fowePRqPPPIIEhKKfiORkpKCf/zjH3jwwQdx+PBhfP/995gwoei3Hvfddx+eeeYZhIWFWVZm3nfffdX+GBARERERETmUgny4vv86hNwcS5csish76d8wdeurGKrbtQH6TZ8p+qSAYFwcOwXQOuYqRgCAhzfk4rMBAYimQgiZNyq4oZ7k5UK8dFbRJetdLX8XcnMgpFyu76iqRLfxUwhmk6UtNfGDcUBUpe41jnwQkl+QpS3IMvRfvAeYTNCveRvaX/cqxpvv7gvo9LUTuJNw4O9q+zVkyBD06NEDixYtwhdffGFz3cXFBa+88oqlHRISguPHj+Pbb7/Fo48+ajNeo9Hgvvvuw4YNG/Dkk08CAA4dOoQrV65g3LhxAIAVK1ZgzJgxmD59uuW+d999F/369UNaWhp8fX3LjXfEiBEQxZJ89YYNG9ClSxd8+umnWLFiBYYOHQoAWLp0Kfbu3Ys1a9Zg7ty5lvGzZ89GZGQkXF1dkZOTg5UrV2Ljxo2WVZahoaH47bffsGbNGgwdOhTR0dFITU3FDz/8gCZNmgAAWrQoOSehc+fO6Ny5s6X90ksvYefOnfjuu+8wc+ZMJCcnw2g0IioqCsHBwQCADh1Kqpp5eHhAq9XCz8+v3DkTERERERE5HbMJ+jVLoEk6p+guHD8VUrsuyG/eEu4XEyBeTynzdtnTG3kzFsGclVsf0apHECD5Big+TkL6NciGJioGBWjOnYAgl6xUlAJDIDVupjhXU3P+FEwBwWqEpyCkXIbL3h0QrqcAru6Q3T0AjRba2D2KcYX3PVn5RKBOj4JHnofbOzMtXZqLCXCbNwUaq+Sr5N8cBeVUSafyMcnYQM2bNw+DBw/GsWPHyrz+6aefYu3atUhKSkJ+fj6MRiOaN29e7vMeeOABrFq1CpcuXUJwcDA2bNiAPn36ICioKIt//PhxnD9/Hps2bbLcI/9vOfeFCxcqTDJ+8skniiRdQEAAzp07B6PRiJ49e1r6NRoNIiIicOqU8jDZu+66y/L306dPIz8/H+PGjYNQqpy80Wi0JATj4+PRsWNHS4LRWk5ODpYsWYJdu3bh2rVrMJlMyM/PR8eOHQEUJSEjIyPRu3dv9O/fH5GRkYiKikLTpk3LnSMREREREZFTMxnhumqBzWovY0R/GIcWLV6Bhxfyp74Kt7eehWC17VbWaJE3fQFkvyAg60x9Ra0a2dcfKJVkFNOSIbXuqGJEtlulzWGdIfs0AkolGcXzJ4Eyqi7XFyEtGbot66Ddv9Pma8ia+Y4WMPUeVKXnmzt3h7F7JFyO/Gzps0kwNvVD3qx3IfvUT50LR+I0SUaPATtvP6gB6datG0aOHInXXnsNM2fOVFzbuHEj5syZgwULFiAiIgLe3t745JNPsG3btnKfd+edd6JNmzaIjo7G9OnTsXnzZsybN89yXZIkPProo5g2bZrNvQEBATZ9pQUFBaFly8qXdS+dPASKVg6WjgMA1q9fb5M01VZyOf2rr76KPXv2YMGCBWjVqhXc3d0xZcoUFBYWla3XaDTYtGkTjhw5gpiYGKxbtw7z5s3D9u3bFSsgiYiIiIiICEXVoT94HdrjhxTdUmAICp6cCZT6fzwprBMKx/4D+g2fKMYWPPEipHZd6iXchkBqqvz/aCH9Wjkj6494xirJ2KYzZA8vRZ9aFaaF6ynQbfkS2n3fQzCbK3VP4f2TAVFT5XcVPvQ0tH8cVhSPKSYZmiBv1nuQmzSr8nPJiZKM9ujll19Gv3798OOPykNyY2Nj0a1bN0yePNnSd+HChds+74EHHsCGDRvQvn175ObmIiqq5NyCLl264OTJk1VKFlakRYsW0Ol0OHTokGUrs9lsRlxcnGWLdlnatm0LvV6PpKQk3HPPPWWOCQ8PxzfffIPr16+XuZrx0KFDmDBhgmV++fn5uHDhAlq1KqkKJQgCIiIiEBERgdmzZ6Nnz57YtGkTOnfuDJ1OB3Ml/1EjIiIiIiJyaAV5cF32CrQnjiq6pab+yHthMeDmbnOLccSDEC+dg8vhGMiCgMIxT8DUd3h9RdwgyFbFX8Q0lZOMJhM0Z08ousxtOttsNRYvnQWMhYBVIZ+6pD2wG/pP/w3BZKz0PabOETB36Xn7gWWQG/uicMyT0K9fqez38ilawVjq3EaqGiYZG7AWLVrg8ccfx+rVqxX9rVu3xvr16/HDDz+gZcuW+Pbbb3Hw4EH4+PhU+Lz7778fCxcuxJtvvolhw4bB29vbcu25557D4MGDMWPGDDz++OPw8vJCQkICdu7ciWXLllU5dg8PDzz55JN444030KRJE4SEhODDDz9EWloaJk2aVO59Xl5emD59Ol599VXIsow+ffrg1q1b+PXXXyGKIh5//HGMGzcOS5cuxUMPPYTXX38dgYGBOHHiBDw9PdGvXz+0atUK27Ztw4gRI+Di4oIlS5agoKDA8o4jR47g559/xsCBA+Hr64v4+HhcuXIFbdu2BQAEBwcjKSkJx44dQ/PmzeHp6Qm9noe9EhERERGRk8m9Bbf3/gXNmT8V3ZJ/86JkTHmrvUQRBVNfhXHo/ZBd3SAHhdZ9rA2M1Eh5HJeQdVOlSIqIiWcgFOZb2pKhSVEiVBAgNfGznKMpmIwQk85DatmufgIzFkL/5fIyE4ySf3MYB40pWimbl1NUmCYvB5JvAIwDoxQraKv82sFjoD24G5rEoq37srsH8ma+45Rfq7WJScYGbtasWVi/fr2i74knnsAff/yBSZMmQZZljB49Gk8//XS51aWLBQcHo2fPnoiNjcXLL7+suNapUyd8//33WLhwIe69916YzWaEhoZi5MiR1Y69eDv2008/jczMTISHhyM6Ohr+/v4V3vfKK6/A19cXH3zwAV588UV4eXmhc+fOeO65okNXPTw8sH37dsydOxcTJkyA0WhE69at8dZbbwEA3nzzTUyfPh0jRoyAwWDA1KlTFUlGb29vHD58GB9//DEyMzMRFBSEmTNnWiptjx49Glu3bkVUVBQyMzOxcuVKTJw40TZQIiIiIiIiB+b60Zs2CUbzHS2QP/Od2xcxEQRIrdrXYXQNm+xlULTVTjJqrLdKh3W2JOmklu0UxXo050/WW5JRkxCvqFQOAFKzQBT+/XGYeg4ANHWUttJokTfz39B/+x+goACFoyZCDgypm3c5ESEjI0NWO4jalpmZedtVffYgPz8frq6utx/oAOxxrjX5Ojtz5gzCwsJqOaKGi/N1XM40V4DzdWTONFeA83V0zjRfZ5or4Fzzdaa5Ag1zvsKVi/B4+XFFnzmkDfJmvg1YJdCqqiHOt7YJVxPhMecxS1tqFojcf/+favG4rngV2t/2WdoFE6fDOGQsAMDl+6+h/6ZkB6Wxz1AUTJ5TrfdU9XOr++oD6HZHW9qm7vcgf+qrdZdcrGXO8LVc2u3max+fNSIiIiIiIiKqN5qEeEXbfEcL5M1+F7AqFEJlk72tVzJmqBQJAFmGaF1Zuk1J0VOz1apFzfmT9RIWAGjjDyvaxp6D7CbBSLbE2niI2WzGwoULER4eDj8/P4SHh2PhwoUwmUyWMbIsY9GiRWjXrh38/f0xcuRInDyp/MLNyMjA5MmTERwcjODgYEyePBkZGSp+IxIRERERERE5IY1VUsrUcxATjFXh7gVZLEm5CPm5QGFBBTfUHSHlMsTsktyK7OoGqXlJ0VcptA1koSRWMfkSkHurfuK6llQSl0YLc8dudf5eqju1kmRctmwZ1qxZgyVLliAuLg6LFy/GJ598gvfee88yZvny5Vi5ciWWLFmCmJgY+Pr6YsyYMcjOzraMmTRpEuLj4xEdHY3o6GjEx8fjqaeeqo0QiYiIiIiIiKiSrJOMpVe+USWIou25jNmZqoRi87ls1VG5WtDVHVKQ8jxCzYXTdR6X9rhyFaO5bXiZ1crJftRKkjEuLg7Dhg3D8OHDERISghEjRmD48OH47bffABStYly1ahWef/55REVFoUOHDli1ahVu3bqF6OiivfenT5/Gnj17sGzZMkRERCAiIgJLly7Frl27cObMmdoIk4iIiIiIiIhuQ7iRCjH9mqUta10gtWirYkT2yTbJqM5OzcokjKWWyiI94vlTdRoTAGjiDyna5i496/ydVLdqZaN7z5498Z///AcJCQlo06YNTp06hX379mHGjBkAgMTERKSkpGDAgAGWe9zc3NC7d28cPnwYTzzxBOLi4uDp6YkePXoonuvh4YHDhw+Xe7BkWQlIV1dX6PX62pia6vLz828/yEHY21yzsrKQmppa7fudLXnO+TouZ5orwPk6MmeaK8D5Ojpnmq8zzRVwrvk601yBhjVfw19xaFGqneMfgjOJl2r1HQ1pvnWltVaP0hvMr576C9lGod7jaHPuFFxKtZPcDMi2+vg38WiM4FLtvD+O4EK7iGq9rzKfW7GwAJ1P/K7oO+fjjwI7/Lpwhq/lyqqVJOPzzz+PW7duoUePHtBoNDCZTHjppZcwadIkAEBKSlEpdF9fX8V9vr6+SE5OBgCkpqaiSZMmEISSbzhBENC0adMKEzllJR8zMzOh1+sVz7JH9lhxubrsba6yLMPb2xvNmzev1v2sQOXYnGm+zjRXgPN1ZM40V4DzdXTONF9nmivgXPN1prkCDW++utjtynaX7rUaX0Obb13R+wUAF0tqUdzh6Q6TCvN2u6VcQRnQNQL+vgGKPlEHYMeXlrZ3yuVqfY4q+7nV/H4QormkjofkG4jgnn0BO8vjOMvXcrHbJVRrZbv0xo0b8fXXX2PNmjX45ZdfsHr1aqxZswZr166tjcdXmYeHBzIyMiDLsirvJ8cmyzIyMjLg4eGhdihERERERES1TnOG5zHWBtm7kaKtynbpgnyIWTctTVkUITf2tRkmBbWA7KKztMWMdAg3qr9z73a0x2MVbVOXHnaXYCRbtbKS8bXXXsMzzzyDsWPHAgA6duyIpKQkLF26FI8++ij8/PwAAGlpaYqVX2lpaWjWrBkAoFmzZrh+/TpkWbasQJRlGenp6ZYxlZ6UVgsvLy9kZWXVxvRUk5WVBW9vb7XDqBf2NlcvLy9otbXy7UNERERERNRw5N6CmHRe0WVu3UmlYOyb7OWjaAtZ9Z9kFEqdrQkAcuNmyqIvxbRaSCFh0Jz9y9IlXjwDc+Oq5WMqRZahsS76Es7zGB1BrWRJcnNzodFoFH0ajQaSJAEAQkJC4Ofnh59++gldu3YFULQ9NjY2FvPnzwcARERE4NatW4iLi7OcyxgXF4ecnBzFOY2VpdVq4ePjc/uBDVhqamq1t+PaG2eaKxERERERUUOlOfsXhFK7As1BoYCn/SwIaUgawkpG0SrJKDX1L3es2TrJeOkszF371H5MVy5ALLVKUtbpYW5/Z62/h+pfrSQZhw0bhmXLliEkJATt2rVDfHw8Vq5ciQkTJgAoOltx6tSpeO+99xAWFobWrVvjnXfegYeHB8aNGwcAaNu2LQYNGoQZM2Zg2bJlAIAZM2Zg6NChTrW/nYiIiIiIiEgt1pWIJW6Vrjab6tKlti3XFzEtWdGWrc5iLE0KUeZeNIlnYKyDmDTHrapKt78L0DlG8V5nVytJxrfffhtvvvkmXnzxRaSnp8PPzw+PPfYYZs2aZRnz3HPPIS8vDzNnzkRGRga6deuGjRs3wsurpNbSmjVrMGvWLMu26+HDh+Ptt9+ujRCJiIiIiIiI6Dask4zmNuEqRWL/ZG+rJGN2Zr3HYL1duqKVjFJwa0VbvHS2TmLSWm2VNnXpVSfvofpXK0lGLy8vLF68GIsXLy53jCAImDNnDubMmVPuGIPBgI8//rg2QiIiIiIiIiKiqjAWQjx/UtHFoi/VZ7NdWo2VjNZnMlaUZAwKhSyKEP539J2Yfg3IyQY8vMq9p8pysiFaFxYKj6i955OqaqW6NBERERERERHZNzHxDARjoaUtNfaF3MRPxYjsm03hFxXOZBSstktLFWyXhk4PKTBE0SUmnavVeLR//mpJYgKAOTC0wi3cZF+YZCQiIiIiIiIi263SYZ0BQVApGgfg7gm5VCVnoSAfKMir1xCqspIRsN0yrUk8U6vxaOKtzmO8k1WlHQmTjERERERERETEoi+1TRDKKP5Sj6sZ83Ih3MqyNGWNFnKjJhXeYl38pVbPZczLgfbofkWXObxH7T2fVMckIxEREREREZGzkyRorM/KY5KxxtQs/mKzirFJM0DUVHhPXRZ/cflpK4TcnJJ3eRmKVsuSw2CSkYiIiIiIiMjJCdeSlKve3Dwg3dFCxYgcg+1Kxvor/mJTWboSZx+ag1sp2uKVRMBkrHkwxkK47Nqg7Bp8H6CtlXrE1EAwyUhERERERETk5DSn4xVtc1in2656o9uzXclYf9ulRauiL7c7jxEA4OkDqXEzS1MwmyBeuWgzTEi5DM2Jo0CpQkEV0R7YDTHjekkselcYB/69UveS/WDKmIiIiIiIiMjJ2RR94VbpWiF7N1K06/NMRpuVjJVJMqLoXEbxRqqlLSaeVZzVqDnyM9w+eAMAYOrQFfkvvQ1oKkgvSWbodnyj6DJGjgI8vSsVD9kPrmQkIiIiIiIicnI25zHyrLxaYbNdWs2VjJXYLg3c5lxGSYL+69WWpvbEUWiOHqjweZrf9kO8llQSh0YD49D7KxUL2RcmGYmIiIiIiIicmJBxXZGQkjVaSC3bqRiR47DZLm0HKxnNVklGTeIZy9/FhD9sCsq47NlU/sNkGbrt6xVdpl6DiorQkMNhkpGIiIiIiIjIiYnnTijaUkgYoNOrFI1jUXUlo3V16cquZAwpYyWjJAEAXA7sshmvPXUM4uXzZT5Lc/J3aC6cUvQVjniwUnGQ/WGSkYiIiIiIiMiJac6dVLTNrTqoFInjsV3JWE/VpXOyIeTeKonDxcXmfMjyyE39Ibt7WNpCfm7RqsjCAmjjfi7zHpc9m8vut17FeFcfyEGhlYqD7A+TjEREREREREROTDyvTDJKrdqrFInjsVnJWE/bpW1WMTbxB8RKpoAEocxzGbW/7YeQn1vmLdoDu4GcbOU9iWeg/fOIoq/w3ocqFwPZJSYZiYiIiIiIiJyVZLbZzmpuySRjbbGpLp2dAchynb9XSLM6j9G3cucxFivrXEZtGVulLe8rzFdupZZl6DZ/oXxmm3BIrTtWKQ6yL0wyElGDI8sytlzMw78OZ2BfcoHa4RAREREROSzxSiKE/DxLW/bygdwsUMWIHIyrGySti6UpGAuBUh/vumKzkrGSRV+KWa9k1MQfhubPXxV9xu6RirbLns2AXHR2ozbmO2iP7ldcLxzJsxgdHZOMRNSgXMs14/4fruPRn25g9YkcjNmVjj9uGNUOi4iIiIjIIVkXfTG3bA8IgkrROCBBgMndS9lVD8VfbCpLV7Loi2W8dZLxYgKE/yUQAcAc3AqFjzwLWaO19Ikpl+F1/gTEM39C/9X7ivvNIWEwd+lZpRjI/jDJSEQNxtbEPPTenIo9V0pWL5pkYF1CjopRERERERE5Ls15Fn2payYPqyRjPRR/EdOSFe0qr2QMClUkEK2Z+gyF7NMYpohIRb///u1w/eB1CGZzybtd3ZE/ZS6T106ASUYiUl22UcLT+2/ikZgbuFEg2VyPucIt00REREREdcF6JaPE8xhrne1Kxsw6f6fNSsYqJhmhdYFUThVoWRRh6jkQAGAcNEZxzTPpLMSM64q+/H/OgRwYUrX3k11ikpGIVJVRIGHg1jR8dabsKmUAcDbLhMRsUz1GRWRfDl4rwKxDGYg+nwu5lg4SN0p1fyA5ERERqSwvF+KVi4ouc8t26sTiwIzWSca6XskoyxDTrVYyVnG7NGC7ZbqYuXMEZEOTojGtOsAc2qbcZxTeOxHmu/tW+d1kn5hkJCJVRZ/PRUKmMoHoIgJ+bsp/nriakahs6xJyMHJHOj4+mYNJv9zEdxfza/Q8WZYx+1AGAtddxdjfXLHhXC6keqiASERERPVPc/E0hFL/nZcCggGrrb1Uczbbpev6TMacLGUxH50rZC9DlR8jhZSdZDT1GVrSEASb1YyWcR3vRuHYJ6v8XrJfTDISkap+S1cWdWnro8Wee30xub2nov/HKzVLnBA5orUJOZh+IAOlU4Drz5W/Krgy/u9sLj46mQOjBFzKE/HPvTcxeFsaDqUw0U9ERORoxLNWRV9acat0XbDZLp1Vt0lGMa2MrdLVOA/RHBxm0ye7e8B0V29Fn6nHAMie3lbv9EP+tFcBUVPl95L9YpKRiFR1/Hqhov12TwO6NNFhYJBe0b83uYDbN4lK+fx0Dp49YPsDamxKAczV/F65WSDhtSNZNv2/pRsx7Pt0PPbTdR5dQERE5EA0562TjCz6UhfqeyWjYLNVuornMf6PFNzKps8UMQDQKf9fDTo9Coc9UPI+nR750xcAnj7Vei/ZLyYZiUg1eSYZpzOUCYsuTVwAAOFNXNDUteSfqCyjjN/SlAlJImf12akcPH+w7B9Oswpl/HnTWOa125n3ayaul1F8qdh3F/Pxt+9SEX2+ZqsliYiIqAGQZYjnlJWlJSYZ60SDWMlYHe6ekPyCFF3GPkPKHGoc+SAKHnkOaXf3R97cDyBVcE4jOS4mGYlINSdvGmEuteAqxFMDg77onyVRENA/UPkbsh8reS7jiZtGfHLyFs5kVi/RQtSQ/efULcyIrfgH0wPXqp6QP5JaiC8SlMnDFm62Ccdso4xJv9zE0/tvIsdYfkKSiIiIGjbhegrEzBuWtqzTQ7qjhYoROS6blYx1XPjFurK0XN0kI4DCUQ9b/m7sHgkprFPZA0UNjIPG4PKwhyCF2G6zJufAJCMRqeb4dWUSsHgVY7EBQa6KdkwlzmU8cK0AA7amYuahTPTZnIqEDCYayXGs/OsWXozNVPTpRGB4c+X3yoFrVTs/0STJeDFWebZja28tvrwrH9uHN8WdVt+bAPDVmVz035qGP27we4yIiMgeaaxXMYa2BTRalaJxbDYrGet4u7RolWSUqrldGgBMfYcjZ9EXyH3lfRRMmVutsx3JeTDJSESqsT6PsUsTnaI9wGol49F0I27km8t9XlahhCn7bqJ4SKEErDmVUzvBEqnsnePZeCXONsG4bkATzL5T+YPrwZSCKlWEXnMqB/FWycJ3evlAJwJ9/PWIGeWLf/f0gd7q3O6ETBMGbUvF56f5fUZERGRvxPPKJCOLvtSdMrdLV+FntaoS0qxXMgbU6HlyYAikNp0BLZPQVDEmGYlINcetkhrhVqul/Nw16NS4pE8G8PPV8ldozT2SiaRbyiTkD5dZlZrsmyzLmP9bJhYeVRZk0WuArwY2wdDmrujc2AXeupLfKt8skHHyZuUKtFzLNeNNq2ePbeGGyMCS1ZGiIOCf7T3x473N0MZH1OY6MAAAIABJREFU+cNlgRl4/mAGPjpxq6pTIyIiIhVpzrGydH2RdHrIupKfrQSzCciro1/SynKtrmQkqgomGYlIFUZJxl83Kt4uDQADrc9lLCfJuDspH2sTbItRXMg241wmq+GSfZJlGf86nIn34pUJPHetgP8OaoLBdxT9sKoRBfRqplwJXJkt07Is4+W4TGQbS36T7uUi4M2IsisBdmrsgp9G+eLhMHeba7MPZ2JdAlc0EhER2QWTCeLFBEUXi77ULdnboGjXVfEXITsDQmHJQgvZ1Q3w8K6TdxFZY5KRiFRxKsOEwlI1IwLcRTRz09iMGxCkTDLGXMmHbLW14GaBhGcPlH948g+VOMuRqKHJNUl4en8GPjqpTNx5uQj4dkgT3BOoPIexj7/ye+VASsVJxpsFEibG3MDGC3mK/le6esPf3fZ7sZiHi4gP/tYIa+5pBDeN8kyeZw9k4FtWniYiImrwxKRzEIwlRxdJhqaQGzdTMSLHJ3s3UrTr6lxGIS1Z0ZaaBvAcRao3TDISkSrirc5jDLc6j7FYTz893LUl/1FMzpVwMkO5MnHmoQxcyyu/yu0ebpkmO3M4pQB9v0vF/51VJuwMOgHfDW2KXn56m3usk4wHrxXaJOSLxf7v+d9fUn5vhDd2waR2HpWKcVxLd3w5sDF0pX6SkAE8tfcmdlzKK/c+IiIiUp/1eYwSt0rXOdlLuVOkripMW2+VrkllaaKqYpKRiFRxu8rSxfQaAX/zVyYgfyy1MnHzhTxEn1cmNP4e6qZo779WgDxT3R2sTFRb8k0yXjuSieE70nEuS3m+qK+riG3DfdHVt+yEfJcmLvAslZBPy5eQYHVUgFmS8faxLIzckY7LOcrne+sErOzbCFqx8r/pHhjkik8jG6P0gkaTDDz20w38fJXJfSIiooZKc9b6PEZula5rtisZM8sZWTOCzXmMNSv6QlQVTDISkSrirZOMjctOMgLAgCDlttCYKwVIyDDird+z8NxB5W8AOzd2wcf9GuEOj5LtnvnmokQjUUN2LL0QkVtTseLPW5CscuKhXhpsH95UUQjJmlYU0MPP+lzGkhXDBWYZ4/dcx1u/Z9s8v2tTF/wyqhk6V/D88twb4obVfRuhdGqyUAIeibmBqznlV4MnIiIilcgyi76oQPayPpOx6isZNX/+Cpfd30Jz7GBRMrH0rhWTEeK5k9D8dVT5Xq5kpHrE+uNEVO/Mkow/KlH0pdhAq3MZf7pagIhNqTbjdCKwum8j6DQCBt+hx2enS7aa7r6cbymSUVUpuWb8ddOI7s108HLh72ao9p3PMmH0rnRkFdquuH2yrQfmd/eGZyW+9vr46/HjlZKE+oFrBXjyf9uf343Pxp4rtsn26Z088WpXb+g01T+r5/7/Z+++45so+D+Afy6X2SZp2qaD1bLKaNllyRaQrYh7TwRBUfBxP/p73AN9FBQciNtHH31QERBFtuyyocxCoVCgu2n2vPv9UWhyGW3apiPN9/16+Xp5l7v0jqbJ5Xvf0SkKFhePx7a5ewsZHDxe3luBT0fE1fl5CSGEEBJinAuybxZAVJhftYpnRODad2nCg4oM9R38It7wG+Rfvy98TkU0uDYdABED0ZkTgj6bV9BkadKYKMhICGl0p/VOmDzKl+NkIrSJDjxoorNajHZKFueN1WdFPd9XjYzLmVhj28gFQca69mXcX2LH9WtKUGHn0SaKxcbrEvwOqCGkPt45aPAJMLaJYvHhMI1PJm91hvpkMtrA8zxy9S4sOGQQPKaVi/Dx8Ng6B9+93dMlGqVWDi/v1Vet+/G0BTO625EZoMSbEEIIIY3IboP841ch3rdVsNrVrTcgj2qig4ocPpmMtRz8Ilm/3GcdYzGBPZVd7X5cm/a1+jmE1Ael5BBCGp2/foxMNRPPGIbBmNa+gy6ukIqAJ3upMKeHsmrdiNYyeCZ+nTG4cNqrP11NDA4O928qQ8Xl4M8FswsLDhtq2IuQ2rlkdmGZ10TmWzspsO36xFoFGAGgr1YqmPhcYOGQq3fhyZ06wTT3RIUIW6YmhizAeMWcHkqka4T3L5/bVRFwAA0hhBBCGonJAMU7T/kEGPloFex3zmmig4osvpmMtSiXNujA5p+p9c90jJgEPrldrfcjpK4oyEgIaXTBDn3xdEea8O4qA2BkKxk+GKrBydta4YVMNViPgRUqiQhDvCbwrr1Qu2zGp3dW4KxBmD35zQkzdLbAk6wJqa0lR41weLykOqpYfDQsFhpZ7T+ipSyDgYnCrMFndumw8aKwTPq1ATFoFRX6jFyxiMGbg4STE7OK7fjlDE2bJoQQQpoKU3QRijceA3vykGA9F5cI8wuLwLXr2ERHFlnqM/iFPXFY+FwyOXhFtM92XKwWjgGjYLv9EZhfXgLbg0/X7WAJqSMqlyaENLpDtejHeMXARBl+HBuPNeetSIsRY1oHBZJrCJKMbSvD5kvu4Mq6fCseTldWs4fbL7lm/HDK7LPe6OTx1QkT5vZSBfU8hFTH6ODwxQmTYN3sDKUgYF5bQ5Olwte9Vx/GEa1kuLmjwnu3kBnZWo6J7eT447w7qP+vPXpMTJEjSkz3NgkhhJBGwbnAHt4DyYbfwB7cCYYX3iR3tWkP65PzwcclNtEBRp76DH5hTxwQLDtGToH9jkfAlBVBlH8GcDnBpXYBH0+/T9K0KMhICGlUPM/jYKmwIXHv+OD6tY1vJ8f4dsGXd17TVo4Xd7v7w20tsMHs5GoMdJwzOjF3R+AeKZ8cNWJ2hrJegzIIAYDvcsxV5fhAZX9S76zd2hqaLAPgv6xfIgLeHRxTbXuCUHhtQAzWXbBWZWjmm1xYlG3E033UDfpzCSGEkIhnMUGy4TdINqyAqKTA7yauLj1hmfsGEE03zRsTrxJWezDGCoDjAFHNN2HZ4wcFy65uvQGGAR+fBFd8UkiPk5D6oJQCQkijyjO6BEEVtYRBe1XDDFLpGiNGW4+BMlYXsPWS78Q1Ty6Ox8y/ywVDOKQiIEos7HP3v1zfLEdCasPJ8fj4iFGw7oFu0fXO9svUSiEL8Cf1eA8Vumhqzhyur04xYszsLswaXnDYiIum6oc3EUIIIaTu2CN7EPX8/ZD9tCRggNHZbygsT71LAcamIJWB9xiww7hcgNlYzQ6XmQwQnT8tWOXq2ivUR0dISFCQkRDSqLz7MfaMl0DUQFlVDMPgmra168v43iEDdhQKA5Ev9Y/B3V7ZZYuyjTTMgtTLqjwr8jwmpktFwIzuvr11aksuZtDfzzTnVCWLf/RuvC8UT/ZWId6jr6TZyePlvcH3HiKEEEJIkKxmSL9ZAMX8JyEqK/K7iSulE6wPPg3rnFcAaeCBiqRheQ9/EelKa9yHPXkYjMf3DlfbjoAyppo9CGk6FGQkhDSqQ16l0r3iGjaraqzXdN51+YGDjJsv2vDWAWGZ6Zg2MjycHo1ZGUp4tsk7pnNivVevO0KCxfM8PswWvtZu7RSFREVosnorS6aF5g/WQCFuvBJ/jUyEf/YTlkf/eNqCkzpHgD0IIYQQUluiE4cQ9cJ0SNcv93mMl0jhGDYe5hcXw/LKUjhHTAJEDVNBRILDaZMFy+zRfTXuwx4X9mN0desd0mMiJJQoyEgIaVS+k6WD68dYVyNbyyDxeKc7Y3DhdIXTZ7vsMgfu3lAKl0dyolYuwkfDYiFiGLRXiTE1VTgs44PsIMobCPFjZ5Ede0uEfwuP9AhuKFEwJnr1Lp2SUrt+pqFyT5copMcK2z+vpeA8IYQQEhLijSugePNxiIovCtbzDAP7xFthWrAMtoeeA9c5A2jgfswkOK5egwTL4r1/17gPe8JPP0ZCmikKMhJCGk3l0JfaT5auD6VEhCFJwqyux7aXo9TqLlM9b3Ti5rUl0DuE5c+LhmmQ5DHB+rGewiDQ35dsOFBSfY9HQvxZ5BWgHtdWhm4h7JXYVyvFK/3VSFGymJIix6JhsSF77toQixjcnSYsAd9eQEFGQgghpL6YsiLIvvtQUEYLAFxSG1ie/wD222YBShq41tw4+48QLItOHK5+yrTFBNHZHMEqrisFGUnzRUFGQkijKbBwKLZyVcsKlkFaTMMPuR/nlcG1rcCOq1cW40iZAzobh5vXluKSmRNs82p/NSa0E2Yu9tVKMTRZmHm5+AhlM5LaOaN3YvU5Ydn+oz1C3yvxsZ4qHLo5Gd+NiYdG1nQf90O8/mZ2FNqpnykhhBBST+K9W8E4hTfv7dfcAPOrS8F16dlER0Vqwie0gis1rWqZ4Tmw+7YF3J49mQ2Gd39P4Vqnglc3zc1jQoJBQUZCSIO5ZHbh1b0VmHtEhsG/FiLz50LB4z3ixBCLGr504/6uUT7BzHNGF8b9Xoxr/yzBcZ2wfHpm92g8GqB0dY7X+l/OWHDO6Ft+DQB5BieuX1OC4b8V4Z0DepRZabIuAX4+Y4FniK1XnATDkxu2bUBT6hErgVri/jsvs3E44adlASGEEEKCx+7dIli23fAA7Hc9BsgUAfYgzYUzc7hgWbxnc8Bt2RNe/Rgpi5E0cxRkJIQ0CCfH46a/SvDvQ0ZsK2dxXOeE2SnMXmrofoxXRIlF+GOSFkOShD/P5ORxuEx4B/i6VDneGBgDJkDfmnFt5ejqEbB08cBre/U+23E8j3s2lmHTRRsOlznw+n4DMn4qxJM7dMjVU4Alkq3MswiW7+saHfD11hKwIgaDvf72thdQmwFCCCGkzowVPn36nINHN9HBkNpyDhgpWGaP7gNMBr/bssepHyMJLxRkJIQ0iBVnLThSXn0wbVJK4w2i0MpZLB+vxQNdowNuc1WSFEtGxIGtJrtSxDA+WY4/5Vqwo1DYZ+6n0xaf/pMWF4+lx03I/LkQd64vpSm7EeiswSl4XTAAJjfi30FT8e6Lur2Q+jISQgghdSXevx0M5y6hdbXtAD6pbRMeEakNvnUquFYpVcuMywXxgR2+G9osEJ09IVjl6tanoQ+PkHoJWZCxoKAADz/8MDp16oSkpCQMGjQIW7durXqc53m8+eab6NatG5KTkzF58mQcO3ZM8Bw6nQ4zZsxASkoKUlJSMGPGDOh0ulAdIiGkkfA8H3DycrSYQUasGG8PisHoNo0bXJGyDN4bosF7V2kg9oojdokR4/sx8ZB7P+DH7Z2jkOE1MfepnRVwcZWZmlYX8No+3+zGK3gAv5+zYsyqYmQVUbAlkqzyymIcnCQVDBdqqa7yyWS0UV9GQgghpI7Ee4Sl0q7MEQG2JM2V9wAY8R7fKdNszhEwLne7JS6pLXhNfIMfGyH1EZIgo06nw/jx48HzPH766Sfs2rUL8+fPR0JCQtU2CxcuxOLFi/H2229jw4YNSEhIwLRp02AwuNOCp0+fjkOHDmHZsmVYtmwZDh06hJkzZ4biEAkhjWhrgR0HvLL4fh4Xj9zbk5F/Vytsuz4JM9P99zxsDA90i8byCVokKyrfAjurxfjfNfGIDXI4hljEYP5gjWBddpkDX54wAQB+vCRGvsl9QSAVAW38BJIMDh43/lWKXZTVFTFW5gkHvlybGhl9k/pqpZB7/AlcNHPIM1KPUkIIIaTWrGawR3YLVjkzhzXRwZC68g4ysoezAJvwZjR73KsfI5VKkzAQkiDjBx98gOTkZHz66afIzMxE+/btMXLkSHTt2hVAZVbTxx9/jLlz52Lq1KlIT0/Hxx9/DKPRiGXLlgEATpw4gXXr1mHBggUYOHAgBg4ciPfffx9r1qxBTk5OdT+eENLMLMoW9hQZEefEmDZyxMnZZtN7bliyDAdvTsbWqYnYOjURqaraTbkemizDTR2FAaLX9ulxUufAl+clgvUPdVfiwM1JWDIiFj3jhI9dCTTupEBji1dgdmFXkbAX4bWpLb9UGqjMIh6Q4JvNSAghhJDaYQ9ngXG4b+Zz2mRwKZ2b8IhIXXCpaeC0yVXLjMMO9tAuwTbefTdp6AsJB4xOp6t3vdKgQYMwZswYXLp0CVu2bEFycjLuuecePPTQQ2AYBmfPnkWfPn2wYcMG9OvXr2q/W265BXFxcfjkk0/w7bff4rnnnsP58+erghA8z6Nt27Z4++23cdddd/n92RSAJKR5yTUzuHWfMPi2pKcVfWO4AHuEryIbg5v2ymHh3IFTtZiH3uleVrE8fu1vQczl2CLPA0vOSbDUKxCpEPFYmGFrkf9OpNL/Lokx/7Q70NZd6cI3fSIn0LYkT4LPPF731yU58WIaDYAhhBBCaiP1188QdySrarlo0FhcuObWJjwiUldt1v6ExF1rq5bLMgYib9pDACqDjr3efRwil7vHffact+GIiWv04yTEW1paWsDHape6E8DZs2fx+eefY/bs2Zg7dy4OHz6MZ555BgAwY8YMFBYWAoCgfPrK8qVLlwAARUVFiI+PF2Q5MQwDrVaLoqKigD+7upMLdzk5OS36/DxF0rkCLft8F24tB2CuWu6fIEEftblFnm8agGc4A17ymC7tGWAEgKf7xaB/urAR97tdgIQDery5353xaeEYzDumwP+uiceQZOGQjOasJb+W/anP+e46XQLAHVS8pWss0tJUITqyhhHK3++UaBs+O19StZxtliEtLTUkzx0K9Fpu2eh8W65IOlcgss43ks4VCPJ8nQ5E5x4RrFKOvS4s/53o9wuI+OsAjyBj7OlsSNunAhIp2GP7BQFGLqEV2vcf1GjHWx/0u23Zakr0C0m5NMdx6N27N/71r3+hd+/euOuuuzBz5kwsXbo0FE9PCAkTBWYXfjptFqyb00OFZlIh3SBmZSjRSe1/cEeKksWM7v57Tz7TR41/9hUGmExOHtM3l8HqpIEYLU2Z1YWtXuXBkVIqfcWARIlg4FKuwYVLZurLSAghhASLPboPjMVUtcypY8F1zmjCIyL1wXXOAOeRmchYzWCP7AWjK4V48++CbalUmoSLkAQZk5KSqvovXtGlSxfk5+dXPQ4AxcXFgm2Ki4uRmJgIAEhMTERpaalg2iTP8ygpKanahhDSvH12zAi7R7VvexWLKSktO5AiYxm8NUjj97F/ZaohYwNHWJ/qo8b/ZaoF6y6aOWy6ZA2wBwlXq89b4fKIHadrxOgcIwm8QwsUJRahr1Z4zjuoLyMhJIzwPI/5B/RI/c9FDPm1EF+fMMHB0Y1B0njEe7cKll19hwIi/ze7SRgQieDKHC5YJft8PqLm3gzJjnWC9TT0hYSLkAQZBw8ejFOnTgnWnTp1Cu3atQMApKamIikpCRs3bqx63Gq1YseOHRg0qDLld+DAgTAajcjKcveXyMrKgslkqtqGENJ8GR0cPj9uEqx7JEMJVtSC0xgvu6atHBPaCYOp/bQS3NCh5snBT/RS4Y7OUYJ1K85SkJHjeXx61IhhvxXhng2lKAzzjLeVZ4XTAqe0j4yp0t6GJAlbAewopJ6MhJDw8fo+A97Yb0CFncdRnROPb9eh/8+F+C7HBCcFG0lD41xg9wmDjE6vABUJP95TpkX6cjC8sEc7z4jgSu8HQsJBSIKMs2fPxu7du/Huu+8iNzcXy5cvx5IlSzB9+nQAlb0VZ82ahYULF2LFihU4evQoZs+ejejoaNx0000AgK5du2Ls2LGYN28esrKykJWVhXnz5mH8+PERVd9OSLj6LscMnd19gR0rY3yCZy3Z24NikKSofEtViHj8+ypN0JO0b+0kDDj9cd4S0ZkR5TYOt68vwzO7KpBd5sCKPCtuWlsKoyM8h+Lo7Rw2XhRm7F2XGqFBRq9+o9toqjohJEx8edyEdw8ZfNbnGV14dKsOA38pxC+5Zj97EhIaolNHINKXVy3zimi40vs24RGRUHB17Q0+Wh3wcZ5hYJ92H/j4pEY8KkLqLiSDX/r164f//Oc/eOWVV/DOO++gbdu2eP7556uCjADw+OOPw2Kx4KmnnoJOp0NmZiZ++eUXqFTunmRLly7F008/jRtvvBEAMHHiRMyfPz8Uh0gIaUAujsdHR4yCddO7KREtCcl9jLCQqhJjy9RE7Ci0I9ZwAX210pp3umxosgyxMgbltsrAYrmNx7YCG0a1btml5v7sKbbjvo1lyDcJMxcPlzkw4+9yfDc6DqIwa/L5V75V0Eagg4pFRmxIPn7DzqBEKRgAV0LoR8udKLdxiJVFznsFIST8rD5nwT926qrdJtfgwgOby1Fq4/BQgH7MhNSHd6m0s/dgQBL89SZppsRiOIZcA+nanwWrXSmd4bxqLJyDRoOPp/ZxJHyE7FvO+PHjMX78+ICPMwyD5557Ds8991zAbTQaDZYsWRKqQyKENJLDZQ6cM7qDQjIWeKh7dBMeUdNIVLCY2l6BnJzaZSGKRQwmpSjwnxx3BsTKPGtEBRl5nsenx0x4cXcFAiUsrj5nxct79Hh5QEzjHlw9rcwTlkpfm6oIOsu1pdHIROgRJ8HhMkfVuh2FNkxKiczMTkJI87e7yI4HN5XDs8BAwTKY2l6On89YfD6zXt2rx62doqCW0s0TEkI8D/HeLYJVVCrdcthvfACM0w6mIB9cl55wDB4DvnVqUx8WIXVCn36EkHrbUyzsqza2jRyJCmpCXRvek4ZX5VnA8S2/ZPqEzoG39usx+NciPLvLN8DonQy7MNuIb08Ke382Z2VWF9bme5VKR2g/xiuuShJmXWwvoL6MhJDm6XSFE7etK4XFY3KXiAG+GBWLT0bEYe+NSbi3SxTEHveN9A4e34TR5xQJD6L8MxAVX6pa5iUSuHoNbMIjIiGliIbtvn/A+uz7sN/wAAUYSViLzHotQkhI7fYKMg5KpNKN2hrVSg6VhIHBUflFptDCIavIjsFegzKCYXFWTr88b3JhWnsFJqXIm1XmXLHFha9PmvHLGTOOljsDbjcrPRoz05UY/3sxCi3u6OO87Tq0imIRJxPhmM6B4zonzuidaKtkcW+XaHSPbfqpzS6OxzcnzXh1nx5mp/vLaesoEfppm/74mtLQZBmWHHN/Ad9BfRkJIc2QycHh5rUlKLUJ7379e7AGEy9nX6coxVg4NBatoli8dcDdr/GToybMTFdCEgHD70jjYPdvEyy70jMBeeT0PieEhA8KMhJC6s07k7F/AgUZa0suZjCubWXp1RUr8ix1CjK+sLuiatL3slwLRrWW4a1BMeimadrgFs/z+C7HjBd2V6DCHjhLUy1hsGhYbFXG3w9j4jHpj2JYL1fkO3ngprWlfvf99KgJt3ZS4Nm+arRXNc1H3PYCG57ZVSEoCb7iuvaKsOspGWremYwHSh0wOjgoI6iHKyGk+fvqpBm5BmF/4Cd7qXB/N992MNO7R2PBYUPV51S+yYXfzlpwU0cKApHQEO8TBhmd/YY10ZEQQkj16IqeEFIvZVYXTuvdF+EsA/SJ8EytuvIuo12ZZwVfy5LpUqvLp5x400Ubhi4vwjM7ddDZmmZC8xm9E1PXlGLONl3AAKOYASalyLHpukTBv0W/BCk+GR4X1M/hAfz3tAUDfinEUzt0KDC7atwnVI6WO3DPhlJM+qPEb4Cxs1qMx3qo/OwZWRIVLNJi3AFgF08l04SQ5sXB8fgoWzjQ7pZOCvyzn//3cK2cxe2dhQHFD7ONtf4MJ8QfprwE7JnjgnWuPlc10dEQQkj1KMhICKmXPcXCYEqPOAmixPTWUhdj2sgg92hled7owsFS32BVdb7LMQsmGV/h4oFPj5mQ+XMhthY0Xnmqk+PxwWEDhiwvwt+XfH8uywBXt5bhg6EanLwtGd+PiUdHtW8G4vUdFHihnzron+vggM+Om9D/50Ksv2Ct1znU5KTOgQc3lWHo8iKsyPP9WVFiBi/0U2Pr1ES0jqZepQAwPFmYodvQvyNCCKmNZbkWXPC4SSVngTcGxlTbemR2hhKejx4sdWAr3UAhIcAe2CFYdnXsDl4T30RHQwgh1aNyaUJIvXj3YxxApdJ1ppSIMLqNHKvPuQMuK/Ms6KMN7t+U43l8eaL6ZvOlNg53ri/FgZuSEStr2GCw2cnhzvVl2HjRN7ioYBk83UeFu7tEQSsPLvD2j15KGOwcFmYbwQDooGLRLVaCdI0EiQoRvjhhwnGdsMej0cnj7g1lWDVBi34hfm3mGZx4fb8ey3Itgqmjnm7qqMDL/WPQhoKLAqPbyPCFx2vV32uEEEJCYU+xHR8dMUIrF+H+rjX37eX5yptjnu5Ki67xsyotRoIJ7eT447z7M3zRESOGt6p92xNCPIm9+jE6+w5poiMhhJCaUZCREFIv1I8xtK5LVXgFGa14MTMmqH03XLDhrEf/KBkLvH+VBm8dMOCc0b2+ws7jv6fMmJWhrPNxlts4zNuuw4kSGWbzJtyVFiXI8LA6+YABxlGtZVgwRFPrnokMw+DlATF4rq8aPACFWJhR8mC3aPyUa8Gb+/WC8zU7edyyrhRrJyegg58sybo4VeHAuN9LUBag/LxPvARvDIzBkGT6cunPiFYyiJnK/poAcLLCifNGJ9op6bKEEBI6BWYXblhTAv3loWpLjpkwoZ0cc3sqA/Y8/ivfhmMeN6xEDPBoj+A+L+f0UAqCjGvOW3FC50DXJu6JTMKYzQL26F7BKle/oU10MIQQUjOqaSSE1BnH89hLmYwhNaGdHJ6xs5MVThzXBVcyvfS4MIvx+vYK3JEWjaxpSbini7BX1FcnTPXqFfXQ5jIsP2vBMSOLOdt0mLNNB5ur8vlsLh53bSj1CTBqpAwWD9Pg13Hx9RrKIhczPgFGAGBFDG7vHIU9NyThn32FfbNKrBxu/KsEJdb692i0OHncu7HMb4AxI1aM/4yOw8ZrEyjAWA21VIQBXlPoN1ygbEZCSGi9fUBfFWC84s/zVkxYXYKJq4uxLt+3VcMCryzG69srgv7MuipJikyvvtQfHTEG2JqQmrGH94BxuK8DuYRW4Np0aMIjIoSQ6lGQkRBSZycrnIKL91gZg45qKgutD41MhJGthcGplWctAbZ2O2d04i+vL0sPXp6AKRczeL6vWhC8PFHhxI6he/geAAAgAElEQVTCuvWKWn/BinVeAaHvcsyY8kcxzhmduGdDqc/j6bFi7JqWhDvToqvtaRUKUpbBU33UmNdTmHmSa3DhtnWlMDvrN/zmmV06HCkXlmV314jx9dVx2DI1EZNTFQ1+ji3BmDZywTL1ZSSEhNKpCge+OWkO+PiOQjtuWluKWVvKYXRUfi5kFdl8Phsf7xl81j/DMD5Zj/89bUaRpfGGkJGWxW+pNF1jEEKaMQoyEkLqbHeRbxYjBVfq79pU4ZTp34KYMv31CZOgL2DPOIkgqzQ5isWkFGFQ56sa+jf64+J4vLi7wu9ju4sd6LesEGvyhQHG7hoxVkzQIimqcQPQ/5epxi2dhP+We4odeGBTOZyBmijWYHUR6/Ol9YYOCmy7PhFT2ysgotd/0Ma0EQbTN12y1fn3Qggh3l7dp4fL4y3FTwI8AOCHU2ZcvbIYh0rtWHhYmHV4dWsZesfXrkLj2lQFUpTuzzubC/j8eO0/b0kL5XJC8utXkH36BkR5OdVvy7kgPug19KUvlUoTQpo3CjISQuqM+jE2jEkpcsGEyuwyB/5vjz5goNHu4n0CXw92880YvL9rtGD5tzwLympZPvz9KTOOemXxeXJ6HWKXGDF+m6ANerhLKDEMg0VDYzHSq+n+n+eteHO/vtbPd0LnwJunhK/xTmoWC4ZoKLhYB73jJYjzGD6kt/u2XyCEkLrYW2zHb2eF2dFLRsTit/FajG7t28oip8KJsauKBT2RgdplMV4hFjGYlS7cb1VezRUJJDLIvvsQsuVfQbL9LyhemQ1R7vGA24pOHQVjcN/Y5aOUcHXp1RiHSQghdUZBRkJIndFk6YaRqGB9SqY/zDbihd3+A40r8ywotrpLgNUSBjd1VPhsN7K1DO1VwuyK708FLiXzZnJweMMrODcq3umTkXZFZ3VlBmOioulK6KUsg29GxyEjVthPa/ERIwrNwQdYzU4O920sg5VzBxPlLPDV1fFQS+mjtC5EDIOrvV7n62nKNCGknniex0t7hBn3feIluL6DAiNby/DLeC02XpuAbhrh54KdAzw/YXvHS3xuUgXrts5RgpuFR8qdVDJNwBTkQ7xxpXvZ6YB88b8Ao/8KEfH+7YJlZ+/BgJgGpBFCmjf6ZkQIqRODg8Mxj4w2BkA/CjKGzFuDYqCRCrPjFh8x4rmsCp9Ao3cZ1q2do6CU+L69ixgG93URZjN+dcIc9ACYxUeMuGR2BzNlLPBEBwd+GhuPx7x6UHVUsVgxQYvkRi6R9idGKsKycVokKdz/JlYXsCjIZvw8z+MfOyoE00YB4O1BGvSMo4mh9THaK0C9gfoyEkLqacNFG7YUCG+CvtxfLcg476uVYsO1CbjXayiap7k9lXVuARMrE6Gv1wCYzXQTJeJJf/sGDC/sCy0qKYT80zcAzrdftHc/RlffIQ16fIQQEgoUZCSE1Mm+Yofgjn9XjRgxlNEVMt00Evw2QYtYmfALzidHTXhqZwW2XLJh9TkLPjtmxHavJvVXBr74c2daFDzjj6f0Tp8vY/4Uml0+vapmpSvRSs6DFTF4ZUAMvrk6DsOSpbilkwK/T0pA6+imDzBe0SqKxRO9hBOnvzhuQmkQ5eKLso34wSvj85aOCp+J3aT2RnsNf9lX4kC5n6ndhBASDI7n8a89woz7q1vLMLK13GfbKLEIC4fG4ouRsVBLhJ+17VWsT3/k2vLO1N5IQcaIxlw6B/GOdX4fEx/aBcnK74TbF5yH6NK5qmWeZeHsObBBj5EQQkKBIgKEkDrx7seYSVmMIdc7XooVExIEfesAYOlxE679swR3rC/DUzuFJTZDk6XopgmcXZegYDElRfjFKZgBMG/u18Pk0XAxTibCPK+g3XXtFVg1MQFLRsShVTPIYPR2T5doQTajycnjoxqyGX/Ps+D/vL6wdokR470hGhpyFAKtolike5Syczxl+xBC6u7nXAuyyxyCdf/KVFe7zw0do/D31EQMvHwdIxEBC4ZoIBbV7z3eO7C56WLNQ9xIy+Uvi1Hw+K9fQpV7tGpZvM8ri7FbHyCq9j1CCSGksVGQkRBSJ9SPsXH0jJNgxQQt4mXBvV1PryaL8Yr7vAbArMyzoLiaXlHHdQ58kyPM5Hu2jyrsMlcVYgZzvMq6lxwzBcycO1hqx0N/lwsydpUsj29Hx/ktRyd1M8Yrm3E9lUwTQurAwfF4bZ/wptCNHRToo635+qS9Sow1k7XYOS0RObe1wig/mY+1NShRiiiPkdYXzRxOVgQenEZaLubCWYh3rhess93+CHhVjHsbnkfq8s8gWfM/yD6fD8mfPwq2p6nShJBwQd+SCCHV4nke+0vsyNU7BetosnTj6REnwcqJWmjl1b9lZ8SKMTml5vKuEa2k6KR2Zxo6uOoHwLyyVw/OI9LWSc3i/iCCmc3R/V2jBQFbg4PHJ0d9sxkvmV24fV0pzB7ZmywDvNXNhq7VZIqS2vMeHLThgq0q24fjefx21oLX9upx2Cs7iRBCPG0vsCHP6L5hJmaAf/arPovRE8Mw6KaRQBPkTb2ayFgGQ5KE10abKFM7IkmXfw3GI4vV1bYjHONuhHXWi+A9qiIkZiNk3y+G5O/VEFWUC57DSf0YCSFhgoKMhJCAHByPuzeU4eqVxej3cyGez9LByfHIM7pQ4jHNOFrMoLuGpt01pPRYCf6YpMXEdnL0iJPgqiQpxreV4eaOCjzQNRqv9Fdj+XgtpGzN5V2M3wEwJnB+yriOlDmw+pwws+yl/jGQ1LOMrKlES0Q+2YyfHDWiwu5+PZudHO5YX4qLZmGG4zuDNRgUS/0CQ21wogwKj9ftBbMLJyqcyDM4MfXPEty7sQzvHjJg8upinKYsIEJIAFlFwpufN3RQoKO6aa9NRlJfxognOp8L8e5NgnX2afcBIhFcGf1hn3Z/jc/h6tgdvDa5YQ6QEEJCjKIChBC/eJ7HnK3lWOURYProiAnHyp2Y2E5YRtRPKwEbpkGncJIWI8EPY+ND8lx3pEXh1X16XImtnTG48HOuBTd3Eg4zee+QQbCcqZVgSkr9y8ia0oPdo7Ew24ByW2VQtcLO47NjJkxtL8evZyz4X64FOV7BrIfTo/FAt2jk5DTFEbdscjGDoclSrLvg/vL9QlYFdhbaYfTIJNU7eLx1QI/PRsY1xWESQpq5PSXCbOchybIAWzaeq1vLAbhLuLcV2ODg+LC9UUdqT7r8K2EWY0onuPoNq1p2XHsX2NNHIT640+/+rpROsN3/jwY/TkIICRUKMhJC/Hp9nwH/PW3xWb/xos3nTvyARCqVDjfxchY3dFAIfsev7dNjantFVTbk6Qonfj0rfA38o7cq7AeeqCQizE5X4vX97gDqm/v1Pr28rhjXVobXB8T4fYyExug2ckGQ0fP/PS3LteDJ3g4qWSeECPA8j73NsI1LRqwYCXIRii9Xfxgcle1mrkpq+gAoaXiivByI9/wtWGefdj8g8igmFIlgnfV/kP30KWwnsyFr2x5cSufL/3UCH0M31ggh4YXKpQkhPr48bsK7Xhls1WkOF/Kk9p7uo4ZHT3rkGV340mPS9ILDBkEvxnSNGBPahXcW4xUz0pVQS90n7wow8DNdI8bSkXGUqdvAvPsyBsIDmH8g+PcmQkhkaK5tXBiGwSivkmnqyxghnA7IvlkoWOVK7eJ/gIsiCrZ75yHnvmdhm/UiHJNvh6vnAAowEkLCEgUZCSECf5yz4B87dYJ18TIRBiQEzhyiIGN46qgW+0yafuegAQYHh3yjE/89LRwG80RvFURhnsV4RYxUhIfTlQEfZxngulQ5fh2vhTrMpmiHoy4xYrSNZn3WR4sZ3JkmLOH/5YwFx8ppCAwhxM17GF2fZtTGhYKMEYjnIftmAdhT2YLV9hvuA1rIdRQhhATS9Lf4CCHNxp5iOx7YVC7IXlOwDH68Jh494yR4cocO3+YIA0+pShaJCt/gAAkPT/VW4YdTZpgu974rsXJYnG1EuY2Dw2PGSQcVi+vb1zy5OpzMSlfi25MmXLo84EXEAMOTZZjWQYFrU+WIl9PrurEwDIObOyrw/mH3pO8hSVJ8NDwWKUoWB0rsOFJe2SfzSjbjl1dThgchoZJT4cCzuypQbOHQOUaMbhoxumkkSI8Vo4NK3GwCdoF4BxkHNKObn5V9Gd32FNtRYecQQzewWizJul8h2fy7YJ2zxwC4el/VREdECCGNh4KMhBAAgMXJ494NZbB41I2KGOCLUbFVmYofDNWgR5wEz2dVVJWX3t45yt/TkTCRFMVidoYS7xx0l6Auyjb6lA/P66WCuJl/yaytWJkIf05KwLJcC7RyESamyClg3oSe6qOC0cnjWLkDN3SIwn1do6oyZ5/tq8bdG8qqtl1+1oKnyh1Ij6XejITUV7mNw9Q/S3Dx8g2XQ2XCTGGVhME9XaIxr5cS2mZ688U7yJjZjIKMraNZdI0R48TlgWIuvnIAzKSUlnXjLiIZ9WCsZsHkZ/boPki/XyTYjEtsDeusFymLkRASESjISAgBAPyVb8UFs0uw7t+DNZjocRHMMAxmpisxMFGK73LM6KBiMb1b4JJTEh7m9FDii+MmlNoqv2B6TvQFgNZRItzaqWUGk1NVYvyjt6qpD4MAiBKL8M5gjd/HpqTI0TNOgsOXgx88gLcP6PH11aGZtk5IpOJ5Ho9vK68KMPpjcPBYfMSIr0+Y8EgPJR7JUDarNhJ2DjhUKgyMNrc2LiNby6qCjEDlED0KMoY/ydY1kP2wGK5O6XAOuhqujt0hX/QSGM7998TLFbA+/jqgVDfhkRJCSONpPlcIhJAm9XuecIrw3WlRuL9btN9t+2ql+PdVGjzaQwW5mO7Khju1VFRtoG1ODxVkLP2eSdNhGAbP9hG+Rn87a0V2GfVmJKQ+vs0xY0WeNahtjU4ebx8woM+yQnx42AAHF2BiViPLMYlg94iRto1m0SqqeWVcXk19GcOaweE/CC/O2gAAYE8fhez7xYh67VEwJn3V4zzDwDrzBXBtOzTKcRJCSHNAmYyEENhdPP7MF37JuI3KoCPKg92i8fFRI84bhdms8TIR7ulCrwXS9CalyNE7XoKDHhlLb+3X47sxlM1ISF2cutyH0VOfeAnu7RKNYzoHjuucOFRqh84uDCaW2Ti8uEePrYV2fD86rsn7NR42CHMmMqsZVNdUhrWSgWVQ1Yokp8KJfKMTbZX0Vayp2Fw8vj1pwim9E0qJCGoJA7VUBJWEgdXF47jOiePlDhzTOZFvcuHMHa0QK3O/1pjiSygZdgYYJq/mpwDQvQpsCO6YWgMwna/7OYUbOt+WK5LOFfB/vtGj/2ySY2kO6JONEIItBTboPb5EaOUiDE5sXqVGpGHJWAb/7KvGw1vKBetnZygRLaGkd9L0rmQz3r7e3Ztx1TkrcvVOdFTT5QwhtWF38Zi+uRxmj/YYUWIGS0fGonOMO0hncfL4/LgR7x0yoswmzOZac96Ktw8a8Hzfpi0DzfYKMja3UmkAUElEGJAgxc4id+/ITZdsuCuN3ruaQrmNwx3rS7Gj0F7zxpcdK3dgSLI7I5Ux6qvZmhBCIhd9cySEYJVXqfSkFHmTZyaQxndzRwV6xrm/XMbKGDwYoGSekKYwoV1lNqOnrQVUdkhIbb2xX48DXn0M3xoUIwgwAoBCzODRHiocuCkJz/ZRQSURXhu8c8CAdfnBlVsHctbgxIESO1x1LL8+EgZBRgAY5VUy/dERI4otrgBbCzm5ymDv9WtK8MIJKfKNzpp3amHOGZ24a30p+v9ciJErijDlj2Lcsb4UM/8uw0t7KnCoNLiA4VmDE+N+L65VgBEAjumEfy9ch6612p8QQiIFBRkJiXAujsfv54RfEKZQM/KIxIoYfD8mDlNS5BjZSoYfx8ZDI6OPCdJ8MAyDie2EpWn7imv3RZGQSPf3JRsWHjYK1l2XKsfdaYFbY6ilIjzbV42d05KQIHd/LvAAHvq7DOfqEPTS2znM2VqOPssKMWplMQb+WoivT5hgcwUfbCyxupBvdR8Py8DnRkRzMaaN8L3raLkTk/4owflq/u14nsdf560YurwI/9hRgU0XbVhTLMakP0pw0RRcgLIlyCqyYczKYqw6Z8UpvRMHSx3YWmDH6nNW/HjaggWHjRi5ohhztpZXG7jdV2zHNauKkVNRu9crywDFlsDDkQghhLhRjj4hEW53sR1FHhdOKgmDkV5320nkaKcUU4870qx5ZyntKaHhL4QEi+N5PLtTB88wXpsoFguHxoJhaq5gaBPN4vNRcbh+TQmuJB6W23jct7EMf0xKCHpI2OaLVjyyVYd8j0DZab0Lj2/X4Y39eszOUOK+rtGIqWGK9d5i4d9/jzgJosTN8+ZY/wQJxrWV4a98d/Z1ToUTE1eXYPn4eJ8s0qPlDvwzqwIb/QyJOWd0YdqaEvw+SQutvOGH3PC8/8BvMK+Z+lqWa8YjW8thqyGmyqNykNFvZy14pq8aM7pHQyJi4OJ4FFg4bCuwYe52naBFAAAMTpRiVGsZ9A4OBjsPvYMDzwNdYiToFitGN40EaTFiv6/tUPdcy8nJQVpaWkifszmj8225Iulcgcg735pQkJGQCLfKa6rkuLZymiRMCGm2Mr2CjEfLHTA5OOodSkgQ/sq34qjOncXFAPhkRKxgoEVNRrSS4cV+ary8192Tbl9JZUDs3as01e5rcnB4aY8enx03Bdym0MLhX3v0+PchAxYO0WBah8AZlnu8Mpmba6k0UBmQ+3JUHO7eUIYNHoHDfJMLE1aX4OX+alw0uXDs8sCR4xVOVFdBfqLCiRv/KsWKCVpBMNbB8SiycGgdJap3ENDg4DB9cznW51vhFZuDVAQMS5ZhTg8lRrWWBf2zTA4Odg7QSJlq9+F5Hp+dE2PJufKA2/ijd/D4Z1YFPso2gmGAS2YXAiXH3thBgY+Gx9J1LyGEhBAFGQmJYDzPY9U5YT/GKak1TMkjhJAmFCsToaOKRa6hMq2F44GDpcKG/IQQ/7zLpG/ooMDwVrX/23m8pxK7iuz487z7RuXS4yZ004jxYLdov8GjrQU2zNlajjOG4Mp89XYeD24uB8swuK69/zYu3kHGTG3zLJW+Iloiwg9j4zHj7zL8dtb9b1di5fDIVl21+zIAOseIBaW+B0sduG1dKR7NUGJ3sR27iuw4UOKAxcWjs1qM5/qqMK2DAqI6Bhtf2qPHmvP+e27aOWDDRRs2XLShd7wEj/dQYmp7BVgRA57nUWLlcMHkwlmDC0fKHTh6+b+zBhd4AGkxYtyTFoXb06IE2Zg2F4/1F6z46oQJf+X7Bo2f6KXElBQF9A4Oenvlz/n4qNGnBPqCufrX2dyeSvxfprrO/zaEEEL8oyAjIREsu9yJsx4X+zIWGNuWgoyEkOatf4IUuQb3DZK9xXYKMhJSg52FNp9hF4/3VNbpuUQMg0+Gx2LkiiLkGd3XEU/urMDqc1b8+yoNOlye+q6zcXhpTwW+Omn2eR4GwCMZStzfNRqfnzDi6xNmmDxS5jgemL65DD9J4zGqtfD6hON57C0Rns+AxOabyXiFjGXwxcg4zJXo8G2O77+JP8OTpXh9YAy6xEhw3crzyNK5g3I7Cu3YUVjms88pvRMPbi7H+4eNeLGfGuPaBp9tCFQOWvnmZOCMU08HSx14YHM52u7RQywCLppcsNfQwjCnwokX9+jxyj49JqcoMK6tDH9fsmH1OSv0Dt/UQ6kI+GBoLG7r7JvZeldaFJYcM2L+AYPffT2JGODdwRo8QIPtCCGkQVBtESERzHuq9KjWcqio5JAQ0sx5l0zvKaHhLyTybLlkw9sH9DhcFlxf0gVeWYxj2sjQK77uQTmNTIRvRsdB5tUScMNFG65aXoh3Dujx21kLBv9a6DfA2EHFYvUkLV4bGINOMWK8MVCD7FuS8WwfFUQesTA7B9y5vgy7i4R/56cqnNDb3QGlGCmDTurwyJ9gRQw+GKrBoxnVB3l7xEnw/Zg4rJigRa94KeRiBu92t2FgLcrCs8scuHVdKSauLsGBWrxXvnfQAEctZ53kX85crCnA6MnBAcvPWjB7qw7/PW3xGySMl4nw2wSt3wAjAEjZyinoe25Mwt1pUfAOpcbLROgVJ8GNHRT4Y6KWAoyEENKAwuOTmBDSILyDjFNSKIuRENL8eQcZvYc/ENLS/XTajJl/l4MHMP+AAT+Mice4doE/w4+VOwSlzQDweE9VvY+jd7wUnwyPxcy/ywWBJasLeH2/IeB+D3WLxkv91T69VGNllVOs2ylZQfmwycnj5rUl+H1iAjLiKkuid/uUSkvDqvSVYRi8OkCNtBgxvj5pQrSYQbdYCdI1lQNHumsk0PjplalggZ+uiceUP0uQHWSAGQB2Ftkx6Y8S/DU5AT3iqi8rP2tw4juvLMtFwzS4K80dnNtTbMeCQwb8fs6K4OeBV2avihgE7JPorVecBN+MjkN7Vc1fWxMVLD4cFouX+quRU+FEgpxF62gWCnH4vC4IISTcUZCRkAh1Ru/EkXJ3/xoRA0ykICMhJAz0jJNAKkJVUCPf5EKh2YWkqIafskpIU8upcGDedveEaBcPPLi5DH9OcgfgvC08LAz4ZWolGJ4cmtLiaR2ikBErwRM7dNhaUH2mXFqMGAuHaGpsb3BnWjQq7Dyez6qoWqez87h+TQm6asS4YHLhgknYc69/GJRKe2MYBvd2jca9XWuXWaeRifDruHg8urUcu4rsaK8SY2CiFIMSpRiQKIXDBbyxX4+fzwhvJpudPB7dWo51UxIgFgUOvL170CAY9NJBxeK2TsIswv4JUnw3Jh4ndQ58kG3Ej6fNgsxHtYRBm2gWbaJZdNGIkR4rQUasBF1ixDA7efxwyoyvT5pwWu/bOzFBLsLU9goMkJTi5szWtQ4ex8tZxDfC1G1CCCG+KMhISITyzmK8KkkqaLxNCCHNlYxl0DNOgr0l7iyePcV2TE71PxyCkJbC6uRx/6ZyQd9CADA4eNy2vhTrpyQgUSH8LD9vdGJZrvAz//GeqnpPHvbURSPBygla/Pe0BS9kVaDUJqyXFTPA3J4qPNlbBXmQWWWzM5TQ2TnMP+AOkBZbORQHCGT214ZfkLE+EhQsfrxGG/Dxz0fF4fGedry+T481+e5p1gdKHViUbcTcXv4zWc/onfjhlDCL8ek+6oBByS4aCRYNi8Ur/dU4WeFEjFSENtEs1NLA7XeiJcBjPVWY00OJrQV2fJtjwrFyJ/ppJbihgwJDk2UQixjk5BSHVXYqIYQQ6slISMRadU5YNnUtfTknhISRfl4l0/uoLyOJAC/urghYInve6MKd60th9QpAfnTEKMhKS4sRY0pq6CsXGIbB7Z2jsPuGRNyd5s5666eVYNN1iXghUx10gPGK5/qoMKN7zVl+sTIGg5MiK8gYjF7xUvx4jRbTvKZzv3lAj5M6/6+j+QcNglLmzmoxbu5Y8zVinJzF4CQZusdKqg0wemIYBsNbybBkRBy2TE3EwqGxGNlaXm2WJSGEkOaNgoyERKBTFQ5keTVQn0yl0oSQMNLfe/gL9WUkLdyKsxZ8dlw47TdRIbyU313swKPbysFfDhKVWV342mvoypweygbNDouTV/bFO3ZrMrZOTcT6KTX3AAyEYRi8NSgGdwQY+KGSMOilcuHLUXFBB7Yi0fzBMYjz6O9ocwGPbtXBxQkD0qcqHPjxtHcWo4qCfoQQQoJG5dKkxdPZOHx70gQpy+DuLlGIEtNF6EdHTIIm3ZlaCdop6e2AEBI+vEsj95fYwfE8ldaRsMbxPF7eo8fGiza0V1Vmhl2VJIVGKsKcbeWCbdurWGy8NhEPbCrDxovucthluRYcL5bBkV2Ic0YXLB5paa2iRLi1k/+AXai1imLRKgR9UkUMg8XDNLipowIXTC60imKrev2ppSLk5OQgrTXdKK1OgoLF/MExmL7Z/RrKKrZjyTETZnlMuJ5/0ADPuGOXGDFu7ECVLoQQQoJHUQXSop3QOXDT2lKcN1Y2lf7hlBm/jItHXAT3Hiy2uPD9KWEmxMPpygBbE0JI89RRzUIjZaCzV34j1jt45FQ40VVTt4wpQpqDL46bsDDbCAA4VObAijyr3+0kIuDLUXGIlYnw5ag4jPu9GCcr3MPcsg0sAKfPfrPTlZCx4ReIZxgGo9tQILE+buygwM+5FvzhMWX8lb16pMeKkWd0YUeh3ad35zN9VGApi5EQQkgtUEoXabG2Fdgw7vfiqgAjUNnsesqfJSiy+E6yixRLj5tg9Tj9ttEsrqe71ISQMMMwDDJ9SqapLyMJXy6Ox+IjxqC2fal/DPpezubVyET4cWy8oBzWnziZqNZTjEnLwTAM3huigVrqDhpaXDymrinFY9t0+OGUWZDF2F0jxvXt6fqQEEJI7VCQkYQNq5OH3cXXvCGAZblmTFtTggq77/ZHy52Y/EcJLpgiL9BodnJYekyYxTgrQwkJ3aUmhIQh7yDjvhLqy0jC19oLVpwx1HxtMr6dHLPThcHCDmoxvhsdh2g/g1WUYgZXJUnx/RjqWxjpWkWxeGNgTFDbPtNHTVmMhBBCao3KpUlY+PakCS/v1cPi5HFHWhRe7q/221uR53ksPGzES3v11T5fToUTk1YX47cJWrRXhcefwUWTC/89bUacTITrUuV1Kvn+4ZQZpTaualktZXBPl8bpzUQIIaGWqaVMRtJyfHJUeBNwcKIUiQoRdhbZUWSp/OzuGSfBR8M0YPz0Hh2SLMO26xOxrcAGY0khBqW1RapKDI2U8bs9iUx3do7CL7kWbPDo4+lJIgJmdldiansqTyeEEFJ74RFdIRHtw2wDXtztDhp+dsyETRdtWDIitqpUCAB2FNrwxj49thT4fsl8vq8Ku4vsWHvBfUGVZ3Rh8uoSLJ8Qj7SY5t3Dy+LkMfmP4qoMh6d3AtemKnBPl2gMbyUNatCBi+OxOFtYhnV/l2ioJJTVQAgJT9YDmIUAACAASURBVJkJwvfuI2UOWJw8FH6yuQhpzo6VO7DJK+jz1qAY9NFKwfM8zhpcqLBz6KaRQF7N67u9Soz2KjFy4EKaVxCeEKCybHrx8FjcsrYUh8scUEsYDEyUYlCiFIOTZMhMkNCQREIIIXXWIJ8g7733HjQaDZ566qmqdTzP480330S3bt2QnJyMyZMn49ixY4L9dDodZsyYgZSUFKSkpGDGjBnQ6XQNcYgkhHiex7p8K97ar8eRstCVqvE8j/kH9IIA4xU5FU5cs6oY7x40YGehDdPWlGDi6hKfAKNEBCwZEYun+6jx3Zh4TEkR3pW9YHZhwu8l2NfMs1/+yheWUNk54OczFkxdU4LMnwuxKNtQYyn56vNW5Ho8h0QEzKSBL4SQMKaVs2ivcmd1O3ngUGnzfj8nxJ8lx4Q3AQcnStHncpCQYRh0UIvRRyutNsBISLBaRbHYfF0Czt7RCmfuaIVl47R4qo8aw1vJKMBICCGkXkL+KbJ792589dVXyMjIEKxfuHAhFi9ejLfffhsbNmxAQkICpk2bBoPBULXN9OnTcejQISxbtgzLli3DoUOHMHPmzFAfIgnCOaMTHxw2YPTKIqT85yJm/l2GUqtvnyCLk8cjW3W4aW0p3jpgwJhVRcgq8l9+URs8z+OVvXq8sd8QcBsnD7y2T48Jq0uw0U/Jh1rK4OdxWtzSqbIcWMYy+OrqONzcUdjEutTG4do/S7D+gv8Jjs3BqjxLwMfOGFx4Ybcet6wrhdnJBdxukVcW400do9A6OnKnbBNCWgafkmnqy0jCTLmNw39PCT/nH6abgKSBiRgGGpmI+i4SQggJqZAGGSsqKvDQQw9h0aJF0Gg0Vet5nsfHH3+MuXPnYurUqUhPT8fHH38Mo9GIZcuWAQBOnDiBdevWYcGCBRg4cCAGDhyI999/H2vWrEFOTk4oD5MEUGh2YfERI8auKkKv/xXi//bosa/EAb2dx4+nLRiyvAhr892BuHNGJyauLsb3p8xV66wu4L6NZSiux/Rmjufx7K4KvH9YGBSLEjNBT7kb2UqGdZMTMKKVTLBeLGLwyfBY3J0m7ENocvK4dW0pfjxtRnNjd/FYk19zAHTTRRtuX1fmN9C4q9CGXUXC7J5HM+gLDCEk/HkPf9nbzDPTCfH27UkTLB7VCG2iWExJpX54hBBCCAk/IQ0yXgkijhgxQrA+Ly8PhYWFGD16dNU6hUKBIUOGYNeuXQCArKwsKJVKDBo0qGqbwYMHIzo6umob0nB+OGVG358L8c+sCuwp9p8FUmjhcPPaUjy5Q4c/z1swakUxDpT6bnvRzOGBTWVwcsFNggYABwesv2DFvO3l6P5jAT71moCsljD4ZVw8vro6Dt+PiYNW7v+lOzRZit8navHbBC26aPz3WWRFDD4YqsETvYRBNicPzPy7HB9mB86ebApbCmzQe0zJ1spFWD4+Hjd2UMB7SOTmSzbcurYUJoc70Hi6wukzCGdsGxky4pp3H0pCCAlGf6++jBRkJOHEyfFY4nXNM717NMSUXUYIIYSQMBSywS9ff/01cnNzsWTJEp/HCgsLAQAJCQmC9QkJCbh06RIAoKioCPHx8YLpdwzDQKvVoqioKODPbelZjg19fg4OeP+MBP+7FHzAaelxE5YeN1W7zZYCO55Yl4c5HaovW8u3MvjqvATrShQwuUr9bhMj5vFBuhXx+nPI0QNpAL7rBbyWI8PW8spy395qFx5OcaC/xgwYdMgJIk54uxpgOorxXq4EPNyvuxd363GmoBSzUhu25C7Y3+1/TkkAuH8/Q2PsaGM6j2fbANMTgMey5cgxu6ONWwrsuG5lPh5o58D/LoqxuYwVnB8ATIutQE5OeUjOI1gt/W/VWySdbySdK0Dn29woXADLKODiK9/n8owuZB3NQWwd7qM093MNNTrfprehhEW+yV11IRPxGCYuQE5OQb2fuzmeb0OJpHMFIut8I+lcATrfli6SzjeSzhWIvPOtTkiCjDk5OXjllVfw559/QiJp3OyotLS0Rv15jSknJ6dBz6/A7ML9m8qwo9B/1segRCmmdVCgxMrhvUMGVJeYOClFjgo7h20eg1e+uSDB2C5JuM5PifM5oxPvHjTg+xwznNU8b4JchOXjtT5Zd2kAVmUAx3UOsAzQWS0WBKiD9WIakNHOjJlbyuGR/IcvzkswoH0ibu8cFXjnegj2d+vieGzdWwDAfXB39UpCWtvKMqo0AH92cmHqmlJkewzd2VvBYm+F/36LveIkuKN/6zr9e9VVQ7+Wm5tIOt9IOleAzre56nmySJBZX6psi4EpwbXX0Nk4TN9cht2FVoxso8DD6UpclSRt1PfIphAuv9tQaa7n+3hOMQD3tdOtnaMxIL1tvZ+3uZ5vQ4ikcwUi63wj6VwBOt+WLpLON5LOFYjM861OSIKMWVlZKC0txeDBg6vWuVwubN++HV988QV27twJACguLka7du2qtikuLkZiYiIAIDExEaWlpeB5vurCnud5lJSUVG1Das/i5PH7OQuyyxyQsQzUUhHUEgYMA7y2V48Ci7B/n5wFnu6jxs0dFWindL88xreVY8bfZYIJxwDAAHihnxrzeilRYuUwckURLpndz/nI1nLwAFSSy79TAL/nWfFtjkkQ1POmFDOYlCLHP/upkaoK/DLtFqAkujZu6BiFeDmLuzaUwuBwRzznbi9HlxixT7+vxrS72I4ij9+RSsL49JmMl7NYMT4eU9eU4nAN071TlCw+HKZp8V+eCSGRZUCCVBBk3FVkx8Qgg4zPZ1Vg3QUbAAYr8qxYkWdF73gJHk5X4oYOCshYer8kDeNQqR3bvW70zuxO/ZIJIYQQEr5CEmScPHky+vbtK1j3yCOPoFOnTnjiiSfQuXNnJCUlYePGjejXrx8AwGq1YseOHXjllVcAAAMHDoTRaERWVlZVX8asrCyYTCZBn0YSnOwyB74+acJPp82osAfXG7GdksW3V8ehj9Y3qDYgUYotUxPxfFYFvjlZORxFI2Xw+ag4jGlTmVWXqGDx9dVxmPxHSVUA0eDgce/GsqB+fqJChEnt5JicqsCIVrJG/WI3srUMv47XYsofxbgyRNvmAu5cX4qN1yWiVVTTTGFelScc+DKurdzvv0ucnMWKCVpM/bMEh/wEGnvFSTCnhxLXd1BAQn2eCCEtzOAkKT7zaOOxM0CGvrcTOgf+62fg18FSB2ZtKcdLeyrwYqYad3aOopszJKRcHI9ndlUI1g1PllK/ZEIIIYSEtZAEGTUajWCaNABERUUhNjYW6enpAIBZs2bhvffeQ1paGjp37ox3330X0dHRuOmmmwAAXbt2xdixYzFv3jwsWLAAADBv3jyMHz8+olJP64Pnefwv14JPjxqxt6R2/QSvbi3D5yNjEScPHExTSkT4YGgsZqUrcaTcgbFt5NDIhJNHBibK8PqAGDztdeFcnU5qFvcmm/HIVR3ANmEArH+CFB8MjcWMv929CgssHO5aX4rfJyZALm7cY+N5HivzLIJ116YGzsyJlYmwYoIWt68vrSqBH9dWhkcyVBjRquWX/hFCItfgJGGG974SO6xOvsb37Tf266ttBVJo4fDoVh2+zzHj/SEadA1B9jwhALD4iNGnXc2sDMpiJIQQQkh4C9ngl5o8/vjjsFgseOqpp6DT6ZCZmYlffvkFKpWqapulS5fi6aefxo033ggAmDhxIubPn99YhxjWzM7KL0K/nLHUvLGXeT2VeKGfOugAX/dYCbpX01H/oe7R2FNsx0//3959xzdV738cfyXpSro3q6yyKTLKKluGLC9DBOG6cKGAoPBjiZOreAEF9CqIcgFFEEWGRRCRWVHLngKCQAtSoYO2tKW7ye8PbtKmA1rakuacz/Px8A9Ok/p995ucfPM53/P9Xrx9W+q46ZjWyp1Hgg1EXThv0wKj2YhgA78n5vCf39Msxw4n5PDyb0l80tX7nhbqfk/K5VJa/u3pzjroXcv5Ns8AL2ctP/T349j1HAL0Omq62mYGphBC3Es1XXXUdtNx+X/nzGwjHL2eTVhgyefMYwnZhEdbzxZv5+/IofgcCtcdf4vNpkt4HC+FuPN/Ld3RV9JFJ5PJxK6/szCaoGcN5yrxuSjyxabnMXVfMr9cy2ZAbRfe7+h1VxcgTyfl8M6RFKtjD9Rypn+QS0U1VQghhBDCJiqtyLhlyxarf2s0Gl555RVeeeWVEp/j5eVV7O7U4vb+Ssvl0Z2Jxd4mC+DrrOXh+nrcnbSkZhtJyTGRkm1EAzzRyJUHKnhQq9Fo+LiLN8GeDhyIyy4yS8TVQcMDQS6MamCokrfuvhnqwZmkHLbHZFmOfX0hgzruDsxo5X7PCo2bC81i7FHDBTdHbQmPzqfRaGhdzC3vQgihZB0Dnbicln/e3Bd7+yLj7EJFniauRn4a6E9Uah6fnk7ji3M3LctnAOQY4f0TqayPSuezbj60C6jY86zJZOKFvUl8c+FWhscbGvioi3eF/j/E3TsQl8WTuxMt606v+jOdPBMsLuM6x9l5Jp7/OYnsAutSeztr+E/ne3shUwghhBCiMtyzmYyickTGZvHErkTiM4vuotKjhjNPNjIwoPa9X7jeSadheiuPe/r/rCg6rYal3X3osyWeP2/kWo7PPZbKlZt5LAzzwuke/D0LFxkfrC0zHIQQoiRhAc6svZB/3oyMzWIS7sU+NjI2y+pCEsDYutloNBrqezgwt6MXY5u7MSUy+X+bwuSLSs1j0I8JfNnTh961Ku68vPj0TUuBEeDLP9OZ1srdahM2ce+ZTCZWnE1n+v7kIhvWrTmfToiPI+PLcJvzvGOpRTZpWxDmRTUbrf0shBBCCFGR7jwtSlRZK8/dZNCPCUUKjM28HDgwNIDv+voxtJ5Bdsa8C17OWr7q5YOHk/XfbvWf6QzZlkBipvUu22eSclhyOo3PTqdxoUBh8m5FpeRyKin/92g1MECKjEIIUaKOgdYzC/fFZWM0FV1w0WQy8fZh61mMYYFOhHlZf5bWdXfg2z6+fN7Dh2p66+FSRp6JUTuvszGq6KYxdyMyNos3DhZdy3jdHZYdEdbOJOUw/3gqEX9n3vnBpZCZa+LFX5OZHFm0wGj2+sEb7Iop3f/vYFw2C06mWh17uL6eofUM5W2qEEIIIUSVIJfH7ZDJZGLe8VT+fTS1yM8G1nZhSTdv3EtxW624vYaejqzp5cs/d1632qH7t9hsem+O58PO3hyKz+bbi+mcTipYWLzBfT6ODK2nZ2g9PXXdy/42KzyLsVOgE7632ZRHCCHUrrGXA15OGpL/d75OyTZxJim3yG69u//O4rdCG2683sYDTWpykd+p0WgYUk/P/TWdeftwCv8tsIN1jhGe3pNESraJJxu73nW74zLyeGp3InnFbECz9kI6L7dwk9toS+Fccg59t8STknPrD/lNb1/6lmM5mNQcI4N/TOBIMRvpueiw3EpvNMFTexLZ9WAAwZ4OlrZsjM7gaEION7KNpPxvqZr4jDyrJWSq6bW819GryO8XQgghhLBXUmS0MyaTibcOpfBhgY1JzKa2dOeV1u5o5ctIhelczZntA/15ZMd1olLzZy9eTM3jHz8mlPi8E4k5nEjMYdbhFFr6OtK5mhPt/Z1pH+BEjVJsxrL5svWsiAdvs6u0EEII0Go0dAh0Zttf+efPfXFZVkVGk8nE24XWYuxV05lO1Zz5s+h1OwtPJy3vh3nRyNOBafvzZxyagJd+S+ZGtpEJIWUvBuYaTTyzJ5FrGcVPkzuTnMvvSbm08JFdre/k9YM3LAVGgP/8nlquIuM7h1OKFBjdHDQs6uqNXqfhkR3XLRsE3ci+NbN1RLCBDVGFLzyW7OMu3ng7y0VhIYQQQiiHjGzsiNFkYtr+G0UKjHqdhs97+PBqGw8pMFaCRl6O7HzQn06Bd7fI//HrOSw+dZPRexJptvYaIWuv8fafTlxJK/5LyKboDPbHWc+yGSi3SgshxB2FFdqMZV+hGYubL2dytFDh6LU2pV8/eEwzNz7t5k3hVUjeOJRC+41xzD6Swpmk4jdhK87sIynsvWbdRtdCuxV/e6FibslWsoi/s9h2xXrtzN+uZXM1Pa+EZ9ze9cw8Vp6z/rs38HBgxz/8GVxXzwNBLrzV1vp1c+5GLu8cSSl1gfGpxoYKXdNTCCGEEKIqkCKjncgzmpj4azJLz9y0Ou7hqOG7vr4MqScz3SqTj4uOjX39GNWg+HWTtBq4v4YzXas5cacy75WbeWyKdeD+7+OJTrX+MnIpNZcJvyZZHesQ4CQL/wshRCkUXpcxskCR0Wgy8e9Csxj/UceF1n5lu4D0SLCBL3v64FxoUvqfN3J573gqYd/FEbYxloUnUrlZ0kJ+wA+XM1h40vqiYddqTrwfZn377LqL6cWuLSluMZpMvF7MepYmIDz67ta0/OzMTTIK3L9ew6Bl5z/8aeKVP6N0YogbI+qXfeyl08CgOi68087zrtomhBBCCFGVSeXCDuQaTbywN6nIAvDezho2PuBHqzJ+QRJ3x1mnYXEXL5p6OfDvo6lk5Jlo7+/Ew/X1DKmnJ0B/6xtnbHoemy5lsCEqg32x2ZT01TA+08jw7df5aaA/3s5acowmno1ItFr/0VELczrIFxEhhCiN1n5OOOsg638T2K7czOOvtFyC3BzYFJ3J6eT8CzsaYGbr0s9iLGhAbT3f9vHjnzuuk5Zb9Cx/JjmXWYdT2BCVwYYHfPHXW1ckt1/J5Ok9iVbHqum1LOvhg6uDhimRGm7+7/f+nW7kl2vZdKvufFdtVbq1FzI4kVj87NGNURm80Kz0Oz8D3MwxFrmgO7a5G55O1tflNRoNH3b25s+U3CKzY7Ua6FbdmSF19TTwdMDDUYOHkxZ3Rw3ujlqcZEM+IYQQQiiUFBntwKzDKUUKjAF6Ld/19aOZt6zTdC9pNBomtnBndGNXTFDkSwdAoEHHc03deK6pG3EZeeyLzeZgfDYH4rI5mpBNdoGJLX/eyOWfO6+z8QE/5hxL4WC89ReVt9p6lnmWjRBCqJWzTkMbPyerGYz7YrOpYdAx55j1LMaH6+tpWo7P0G7VnfnpQX9mHU5h55VMiqk1cjIxh/4/JLCxr69lRvqm6AyeiUi02q1Yp4EV9/tYLlYNrOPC2gv5n/vfXkiXImMxMnJNvFNodmpB++OyLUXm0lr1ZzqJWfmd4+mkYXQJG/voHTSs6eXLuL1JHL2eTXNvRx6qZ+AfdVyKFJaFEEIIIdRAioxV3M6YTD4qtAZjTYOO8H6+NPCUAqOteBRTXCxOgF7HoLp6BtW9dUtVVp6J8b9Yz0qNjM1m8LaEIusw9g1yYVyzu9+xVAgh1CgssFCRMS4brQb+KDCLUauBaa3cy/3/aubtyDe9fUnKMrL5UgYbozKIuJpltVP0+ZRc+m25VWg8dj2HsXuTiuwkPbeDJ2GB+UXEEfUNVkXG8OgM3uvohYuDzIAraMnpNK7czF930UkLtd0cOJ+S39ffRWUwoUXp+jrHaOLjU9ZjrmebuOLuWPJnfjWDjg19/crYciGEEEIIZZI1Gauw69nwws/W6/PVMGjZMsBPCox2ylmnYVEXb1p7WC9GX7jAWMOgZXEXrzLvVCqEEGrXMcB6xt+v17KYe8x66+jh9fU0rMDPUW9nLY83cmVDXz/OjqxGr5rWbYhJz6PPlnie/7logXF+mCfPNrW+pbdHDWf8XfKHaCk5JrZdyUTkS8jMY8EJ6359rqkbTzexvji3oQzrMm6MyuCvtPzPZ2cdPF/G262FEEIIIdRMioxVlNFk4q1zzsRn5t+yo9XAf7v7UNddJqDaM2edhveaZtHQs/h+NPezr4vcaiWEEGXVPsB6A64/knM5dyN/ZptOA9Na3t1ajKXh56JjTS9fhtS13hTkRrbJao1erQYWdfHimSZFi1gOWg0PFdrQTXaZtjb3aCqpOfl/US8nDVNaujOkrt6q/48m5BCVcucdn00mEx+etC5a/rOBwXILuxBCCCGEuDMpMlZRi35PY1+y9cB2Wkt3OlWTNZmUwNMRvu3jazVTxWxGK+lnIYS4W17OWpp6l3wx7pFgA8ElXOSpKE46Dcu6e/NEI0OxP3fQwH+7efNow5KXxHgk2Pq5P13JJDmr5N2q1eRiSi4rzlpvzjK1lQfezlpquOoIK7TL+MZSzGbcGZPFqSTrjYEmhJT/lnohhBBCCDWRImMVdCQ+m1mHrRcyDwt0YkpLGewqSV13B77p7Yu+wC6T3ao783/3ST8LIUR5FFzfsCBdBa3FWBo6rYYPO3kxMcR6pqKTFr6434eH6hdfgDRr7edIsEf+xcZsI2yIKv2tv0q2ISrDaqOduu46ni1wm3ThWaDrL955FugHhWYxDqrrQn0PuXNECCGEEKIspMhYBa2LSrcaPHs5aVjazRsHrazPpzRt/J346UF/HgnW81KIG2t6+aCTfhZCiHLpGOBU7PFHGxru6ZIjGo2GWW09mNvBEx9nLfXddXzbx5eBdfSleu7wQoXIqfuSGbc3iejUO9/+q2T7Y7Os/j0hxA3nAhfsBtXVU/Cj9FRSLtHpJX+2HonP5pdr1msjv1zKzWKEEEIIIUQ+KTJWQbPbebIwzAtn7a1K40ddvKnlJlfTlaqFjyOfdvNhVjtPXG+zg6UQQojS6RhYtMjooMEmM8U1Gg3PN3Pj4j+rc+ThanSv4VLq544odMt0ngm+Op9O2/WxTPw1iUsqLDYaTSYOxFsXBDsXWmIkQK+jW3XrY9sTSl5bcVmhW6+7VXemtV/xhWohhBBCCFEyqVxVQRqNhqeauFI98yp/aAP5RylmPAghhBDiliA3B2q56rhyM3+n4McbGahjZxun1fdw4LGGBlb9aX27b64JVp5LZ+W5dGq56mjm7UAzb0eaejvSxs+xQnfOrmrOJudyIzv/dg9PJw2Nillj86F6evb8nT/jcXu8AyaTCY3GekZjao6R7wrdhj6+uewoLYQQQghxN+xrtK0ywa4m+jWU23WEEEKIsnq4vp4PTqYB4O6oYbKdrnf7n85e9KzhzJxjqVa7ZJtduZnHlZt5/HQlv6DW1MuBofX0PFRPTwOFFRwPxFnPYuwQ4IRWU/RW6H/U0TP5t2TL8jNRGVpOJ+XS3Mf677ExKoObBdaoqWHQ0rumbL4mhBBCCHE35N5MIYQQQijO1JbuTGvlzshgPRse8CPITpcd0Wo0PFTfQOSQAD7r5m21GUxJziTn8u7RVNpuiKNreBwf/Z5KZsHFnu3YvkJFxvYBxRcEvZ219CxULFx7oegGMKvOWR/7ZwNXWRtZCCGEEOIuSZFRCCGEEIrj6qhlZmsPlnTzoV0JG8HYE51Ww4hgA/uHBrK4ixetfB1xKEUt7GRiDq8fTGHQjwmk5hgrv6GV7ECc9aYvHW7Tt0PrWa9pufzsTZKy8v8GZ5Nziqzv+Fij2+/6LYQQQgghSiZFRiGEEEIIO+Gg1fDPhq7sGRRAzOM1+GXwrRmOL7dwo1t1Z3QlFB4PxGczYvt10uy40BifkceFlPx1NnUaaONX8u3gg+q44OucP9RNzTGx6Pc0y78Lr3XZtZrTPd19XAghhBBCaWQkJYQQQghhh5x1GkJ8HAkpsM5gQmYe30dnsjE6g1+uZWEscJd0ZGw2j+y4ztrevjZobfntL3Sr9H2+jrg6lny93NVRy8QWbrx5KMVybMnpNMY1d8XdScvX562LjI81cq3YBgshhBBCqIzMZBRCCCGEUAg/Fx1PNXFlUz8/To+oRmihmX6/Xstm1M5EMvNK+AVVWOFNX9r73/k2+GebuOLnkj/cTcs1sehUGtv+yiQ+M39Wp4eThkF19BXXWCGEEEIIFZIioxBCCCGEAlUz6Fj/gB+tfK0LjT9fzWLKGWe72wym8EzGjoF3LjK6Omp5KcTN6tinp2+y6FSa1bGH6xnQl2aRSyGEEEIIUSIpMgohhBBCKJSXs5aNff1o4WNdaNyfrGPCr0k2alXZZeWZOJpQup2lC3u6iSs+jvkF1bRcE5Gx1r/rcdnwRQghhBCi3KTIKIQQQgihYN7OWsL7+tLc23op7m8vZnCsUOGuqjqWkE12gT1rarnqqOmqK9VzXR21PF4zp8SfN/d2KDLbUwghhBBClJ0UGYUQQgghFM7HRUd4Pz8ae1oXGt8/nmqjFpVN4fUYOwTc+VbpgoZVz8Xfpfhh72MNXdFo5FZpIYQQQojykiKjEEIIIYQK+LnomN3e0+rY5suZnE4qeZZfVbGvnEVGvQ5eauFW5LiTFh4Jlg1fhBBCCCEqghQZhRBCCCFUoldN5yK3Bi84UbVnM5pMpqI7S5exyAi31mYM0FsPfQfU1uPjUrrbroUQQgghxO1JkVEIIYQQQiU0Gg1TWrpbHdsQlcH5G1V3NmNUah7xmfkLMro6aAjxKfsaigYHLdMKZNcAzzdzrYgmCiGEEEIIwOHODxFCCCGEEEoxoLYLwQYjF9JvXWs2mmDBiTQWd/Uu8Tmx6XksPXOT32KzaOvvxOT73PFyvjfXqvfFZln9O9TfCQft3a2h+EwTV3JN8Ou1LIbW1RMWWLodqoUQQgghxJ1JkVEIIYQQQkW0Gg1PB+Xw6tn8Ats3F9KZ3sqdOu7WQ8OLKbl89HsqX51PJyvv1rHfYrNZcz6d2e09GV5fX+mbppR305eCNBoNLzRz44VmRddnFEIIIYQQ5SNFRiGEEEIIlenll8fyqzoupNyqHOaZYN7xVJ5v6krMzTxibubx67Vswi9lYDQVfX58ppExPyex+s905od50sCz7Lcvl9b+CiwyCiGEEEKIyiNFRiGEEEIIldFpYPJ97oz/JdlybPWf6az+M71Mvyfiahadw+P4v/vcmXyfe4m3Mf/0VyYbozPwdtbQ1MuRpt6ONPZywN3x9rdcJ2cZOZOca/m3BmjrL0VGIYQQQoiqSIqMQgghhBAqNCLYwNxjqVxOcYzZZgAAIABJREFUyyvV44PcdPSq4cyaC/m3TgNk5cG7R1PZF5vN8h4+Vms15hhNvHnoBotP3Szxdw6tq2dqK/diC44f/W6983VTL4d7thakEEIIIYQoGxmlCSGEEEKokKNWw6QW7nd8XDMvBz7r5s2RYYF80Nmb3wYH0r160Q1Tdv2dRc/v4zibfGun6riMPIZsSyixwAjwV1oe//k9jWHbrpOSbbT62dfn05l/Is3qWPcaslGLEEIIIURVJTMZhRBCCCFU6olGBo5fz2btxQw0QE1XndV/YYFOdK/ubLW5S7CnA9/19eXbixm8euAG8Zn5xcGLqXn03hzPjNYeLPo9lb/TjcX8X4s6EJ/NsJ8SWPeAH55OWiJjs5j4a5LVY/xdtEwIuXNRVAghhBBC2IYUGYUQQgghVEqn1fBBZ28WdPJCA6XeKVqj0TAi2ED36s48viuRA/H5m7Ok5ph49cCNIs+p5arjkWA9527kciYpl4upuVabyhyMz+GhbQks6OTFYzsTKTix0VkHq3v5UMNVd7dRhRBCCCFEJZMioxBCCCGEymlLWVwsLNCg4/v+fkyOTL7tpjHdqjuzvIc3fi75RcLkLCPDtydwMD7HcuxwQg49NsVTeEPrjzt70z5AbpUWQgghhKjKZE1GIYQQQghx15x1Gj7u7MW/23uiK6ZWOSHEjQ0P+FoVGAG8nLWsf8CP9oV2iy5cYJzWyp3hwYYKbrUQQgghhKhoUmQUQgghhBDlotFoGNvcjfUP+OL7v92f3Rw0rOjhzdvtPHHQFj9T0sNJy/q+vnQMcCr25w/V0/NKK1mHUQghhBDCHsjt0kIIIYQQokL0qOHCqRHVOJSQTWtfR1wd73w9291Ry7cP+DJi+3UiY/PXdgz1c2RRF+9SrxMphBBCCCFsS2YyCiGEEEKICuPioKFLNedSFRjN3B21fNvHl+H19ThqoXt1Z9b09kXvIAVGIYQQQgh7ITMZhRBCCCGEzbk5alna3Yel3W3dEiGEEEIIcTdkJqMQQgghhBBCCCGEEKJcpMgohBBCCCGEEEIIIYQoFykyCiGEEEIIIYQQQgghyqVCiowLFizg/vvvJygoiODgYB555BFOnz5t9RiTycS///1vmjRpQrVq1Rg4cCBnzpyxekxycjJjxoyhdu3a1K5dmzFjxpCcnFwRTRRCCCGEEEIIIYQQQlSSCiky/vLLLzzzzDNs27aNTZs24eDgwJAhQ0hKSrI85sMPP2TRokXMnTuXXbt24e/vz9ChQ0lNTbU85tlnn+XEiROsW7eOdevWceLECZ5//vmKaKIQQgghhBBCCCGEEKKSVMju0hs2bLD696effkrt2rXZt28f/fv3x2Qy8cknn/Dyyy8zePBgAD755BMaNmzIunXreOqppzh79iw7duzgxx9/pH379gAsXLiQ/v378+eff9KwYcOKaKoQQgghhBBCCCGEEKKCVcqajGlpaRiNRry8vAC4dOkSsbGx9OzZ0/IYvV5Pp06d2L9/PwAHDhzAzc2NDh06WB7TsWNHXF1dLY8RQgghhBBCCCGEEEJUPZrk5GRTRf/S0aNHc+HCBfbs2YNOp2P//v307duXkydPEhQUZHnc+PHjuXr1Khs2bGD+/PmsXLmS48ePW/2uli1b8uSTTzJ58uSKbqYQQgghhBBCCCGEEKICVMjt0gXNnDmTffv28eOPP6LT6Sr61wshhBBCCCGEEEIIIaqYCr1d+pVXXmH9+vVs2rSJunXrWo4HBgYCEB8fb/X4+Ph4AgICAAgICOD69euYTPkTK00mEwkJCZbHCCGEEEIIIYQQQgghqp4KKzJOnz7dUmBs1KiR1c/q1KlDYGAgu3fvthzLzMwkMjLSsgZj+/btSUtL48CBA5bHHDhwgJs3b1qt0yiEEEIIIYQQQgghhKhaKuR26SlTpvDNN9+watUqvLy8iI2NBcDV1RU3Nzc0Gg1jx45lwYIFNGzYkAYNGvD+++/j6urKww8/DEDjxo3p3bs3kyZN4oMPPgBg0qRJ9O3bV3aWFkIIIYQQQgghhBCiCquQjV/Mu0gXNn36dF555RXg1q3Pc+bM4fPPPyc5OZnQ0FDef/99mjVrZnl8cnIy06ZNY+vWrQD079+fefPmlfj7hRBCCCGEEEIIIYQQtlcpu0sLIYQQQgghhBBCCCHUo0I3fhFCCKXLysqydRPumQsXLpCbm2vrZgghhBBCgVJTU23dhHvm1KlTZGdn27oZQghR6XQzZsx4y9aNUJPExERSUlLQ6XQ4OjpiMpnQaDS2blaliYuLIyoqCpPJhJubm62bU6liYmJYuXIlvr6++Pj4KL5vo6OjeeGFF3Bzc6NBgwa2bk6lu3TpEi+//DLXrl0jJCQER0dHWzep0pj7dsmSJfTo0QN/f39bN6lSxcTEsG3bNtLT0/H09MTJycnWTapUcXFxJCQk4ODggJOTk+LPVVevXuXChQsAiv8cSk1NxWg0qmJ8AZCQkEBsbCwajQYXFxdbN6fSXbt2jZMnT5KXl6f4pYT+/vtvFixYgLu7OzVq1FD86zk6OpoRI0bg5ORESEiIrZtT6aKjoxk/fjznz5+nadOmuLq62rpJlSY6OpqxY8cye/Zs2rVrR926dW3dpEp15coVvv32W5KTk3F2dsbd3V3R799r165x6dIlNBqNol/HZjKmUq6KHFPJTMZ7xGQyMX36dPr06cPw4cPp168f586dU+yL1WQyMW3aNLp168bYsWPp1KkTu3fvxmRS5t35iYmJPPLII8yaNYvdu3eTl5en6L6dNGkSrVu3xsPDg06dOtm6SZVu4cKFhIWFYTKZaNq0KXl5ebZuUqUw921oaChxcXFcvnwZg8Fg62ZVqhkzZtChQweWL1/OP/7xD2bNmkVCQoKtm1Vppk2bRseOHXnuuefo3r07ERERip6d+8orr9CuXTvGjRtHx44d+eqrr0hOTgZQ3OfR66+/Ts+ePfn1118BFPsZBPljqh49evD444/TtWtX9u7di9FotHXTKoV5TNW5c2dmzpxJWFgYX375JRkZGbZuWqVIT09n0qRJLFq0iPDwcHJyctBoNIp7z4L1526tWrXo27evrZtUacz9t3jxYrp06YKDgwM9evRQ7EVbk8nE5MmTCQ0NJT09nfT0dNzd3S0/U6KZM2fSoUMHwsPDeeqpp5g0aRJXrlxR7OfRjBkzaN++PVOmTKFjx46sXbtWsWMMkDGVUlXGmEqKjPfAsWPH6NOnD0eOHGHBggVMmDABg8HAiy++CCjvTbl//366devGsWPHWLFiBZ988gmdOnXitddeU+wb1MXFBU9PT5o2bUp4eDgnT560dZMqRUREBPXr1+fw4cPs2bOHzz77DA8PD0B5r2OzK1eusGPHDj766CO++OILevXqZRkkKsl//vMf6tSpw8mTJ9mxYwerV6+mVq1aRERE2LppleaNN97g8OHDfPfdd4SHh/Paa6/x888/Exsba+umVTij0cjkyZM5ceIEa9euZf78+YSFhTFx4kS+/vprWzevUqxatYqIiAi+/vprvvzyS0aOHMmHH37IggULAOUMGGNiYnj66actr93w8HDi4+Nt3axKc/r0aQYMGMCRI0dYunQp//73v7nvvvuYPHmyInMfP36cXr16ceLECdasWcPq1asZNWoUCxcuVOytlwaDgcTERNq1a8fhw4fZsWMHoJz3rNmBAweoX78+hw4dYvfu3SxfvlzRM1Q1Gg3Jycls3bqV9957jy+++IKuXbvi7e1t66ZVuGXLlhEUFMTx48f56aefCA8PJzg4mF27dgHKey0DzJ8/n/3797NhwwY2bdrE/Pnz+euvvzh9+rStm1YpZs2axbFjx1i/fj1Lly7lySefZOHChXz88ceA8vpYxlTKVFljKiky3gM//vgjfn5+fPPNN3Tv3p3hw4ezcOFCTp48qcjZjGfPnqV///6sXbuWsLAwQkJCGDZsGG5ubmRmZtq6eZXi3LlzuLq6smrVKi5cuMAPP/xgubKjpFlvBw8exM3NjWnTptGyZUuOHj3K8uXL2b17t2JPwF9++SXZ2dkMGzaMffv28eKLLzJz5ky+++47kpKSABQxe2bfvn3Mnj2bHTt20Lp1awAyMjIs2ZRURDaZTNy4cYPffvuN3r1707ZtW5ycnBg8eDA6nY6AgABbN7FCmUwmrly5QmRkJKNHj6Zt27a0aNGCjz/+mLy8PBYvXsyRI0ds3cwKt3XrVoKCgujSpQvBwcHMmTOHhx56iE2bNlmKFkp47964cQN/f3/ee+89PvroIzZu3Mhvv/2mqPdsQXv27MHd3Z3PP/+csLAwunbtymeffUZ0dDR//fWXrZtX4WJiYhg4cCArV66kffv21KhRg5EjR6LX6xU3foRb56vLly/j7e3NwoULyc3N5fvvv+fatWsAilonOCoqCjc3N0aPHs19993HoUOH+PDDD9m4cSNRUVG2bl6l+Pbbb7l+/TqjRo0iMjKSMWPGMG7cOJYsWUJ0dDSgjPPyqVOneP/999m5cyehoaEkJSXh7OxMRkaGIs/Nubm57N69m5YtW9KhQwcA+vTpg06no0mTJpbHKSV7UlISe/bsYcCAAbRr145atWrxxhtv4OrqyieffMLevXsBZbyWzWRMpYzXbmGVNaaSImMlKDwA6tevH2PGjMHHx8dyLCkpiYCAAMt6WPascN5Bgwbx5JNPWq7GXr9+nUWLFlGvXj2++eYbu17kuXBWc9+5urqSlZVF7dq1GTZsGJs3byYmJoa0tDR0Op0tmlohCucdNWoU7du3Z8mSJYwaNYonnniCNWvWMHr0aAYMGGCZUm6vCuY1f1BqtVqaNGnCypUreeaZZ3B0dOTPP//kzTffZNq0aZbH2JvCfbt69Woef/xxy8+qV69OnTp12L9/vy2aV+EK5tVoNKSlpZGWlkZGRgZpaWkkJSUxbtw49Ho98+bNIzIy0oatLb/CeVNTU7lw4YKlgAyQnZ1NUFAQRqORZcuW2aKZFc58Ts7IyECj0VC7dm2rnw8bNoyQkBA++OADwD7fu2bmC1j16tXjxRdfpH379gwePJg2bdrw3//+l0uXLtm4hRXL/Jru168fzz//PDVr1rT8LDY2lho1atj1521h5v7t1q0bjz76qOXiR0JCAm+++Sa1atVi6dKliujnguNg87pmCQkJ1K9fnyFDhnD69GkOHz7MzZs3FdHH5tdy3759GTJkCIsWLWLkyJE89dRTbN++nSlTpvDggw/y1Vdf2bilFcNkMln62NnZGT8/P7799lvGjh2Lj48PRqORzz//nDFjxgD2fV42zy5esGABI0eOBG71t7e3N0FBQZw4cUJRt/6bc6SmpuLs7MyNGze4du0a8fHxjB49mvT0dN555x3Wr18P2P9sN/N3g5SUFKKiomjatKnVz6tVq0ZAQADvvfceYL+v5cLFwvT0dMWOqQpnrVu3rqLHVIXz9u3bt1LGVPb3Sqji3nnnHR577DFeeukljh49SnZ2Nq1ataJnz55A/qDRfDuev7+/XZ9wi8vr5eVleaFu376dBg0a4OTkhMFgYM6cOTz77LMcPHjQxi0vu8JZzWsEARw6dMjSt2+//TZGo5GxY8cSFBRkubpjbwrnzcrKombNmvTq1cuyZt2aNWtYtWoVx48fx9PTk//85z+cP3/exi2/O4Xzmr8E3Lhxg+PHj7Nz505ee+01Fi5cyLfffsvUqVM5fvw4X3zxBWBfV2dLei2bX8MODg5kZWVRr1494uPjSUtLU9R5KjMzk5o1azJ48GC2b9/OY489Rv369XFycuLxxx/nxIkTTJs2jZUrV9q66XeluPdu8+bNadSoEW+++SZnz54F4M0338TJyYmwsDAuXrxoWcjb3nz++eds2rQJwPLlTa/X4+fnR2RkJHFxcZbHNmjQgH79+pGUlMS2bdts1eS7VjCrefCn1+sJCgqyvH/nzp3LoUOH+PHHH+1+vc2CeR0cHDCZTNSvX59evXoB+WOqmJgYUlNTCQoKsllbK0Jx/evm5ka1atUAiIyMpGHDhjg5OdGyZUu++eYbXnjhBTZv3myzNt+twu/bgo4ePYpWq8XBwYGxY8cSGBjIrFmzqFWrluU59qa417KXlxd9+vQhICCA3Nxcvv76a1atWsW5c+do27Ytq1evttsLXoX719zH6enpZGRksG7dOp599lnmzJnDkiVLeP/997ly5Qrz588H7GtGVMGsxW0cZ34vt2zZkpiYGBITE+16TFXcZ663tzfDhg3jr7/+YuzYsTRq1AidTserr75KVlYW77zzDgsXLgTsq2/BOq9Wq8VoNFKnTh1at27N3Llz2b17NwCvvfYaly9fZtiwYSQlJbFv3z5bNvuuLVy4kEmTJvGvf/2L6OhojEYjBoMBHx8fxY2pCmc1mUwYDAbFjqmK69vg4OBKGVNJkbGCXL9+nf79+/PDDz/QoUMHDh48yPjx4y3rFJhPqOYPlT179tChQwdcXV3tqjhhdqe85ky1atVi69atbNmyhQULFvDDDz9w6tQpu1qfo6Ss5oEQQGZmJl26dAFg8+bN/P3335w9e5YXXniB3r1726rpd+VOeYcMGcK4ceN46623CAkJISAgAC8vL959911+/vlnu7ttuqS85quQ48aN4+zZs2zatMnqimX//v1p1qwZp0+fxmg02sWA8U59a74CaTKZcHZ2xtfXl7///huDwaCo85Q575QpU9i2bRt169blqaeeYv369YwePZq1a9fStGlT9u7da1drnpWU13yF+cMPP+TgwYOMHDmSmjVr8tNPP7Fo0SLGjh3LkSNH7O4K9P79++nZsyeTJk1i48aNllvtzBcIJk2axJkzZ4oMfLt27UpWVpZluQN7UFLWgu9LnU6H0WikadOmjBw5kmXLlvHHH3/YqMXlU1Lewszn3YiICNq0aYOfn59dnqtK078ATZo0sazvNnPmTL7//nuMRiNHjhyxmy/upcmq0WgsOyxv2rSJyMhIYmJiGDZsGIMHD7ZFs+9aSXnN/RUWFsb48eOZNWsWzZs3x8PDA51Ox/Tp07lw4QIxMTE2bH3Z3em8PHLkSM6fP89PP/1Ey5YtLc9r27YtgwcP5sCBA2RnZ9vF51Fp37fm85SrqytpaWnk5eUp6jxlLkyMGjWKLVu2EBoayogRI1i7di0PPfQQy5YtY/Dgwfzwww9kZGTYRd/Cnd+7ixYtIiMjg5dffpmaNWuybds2li1bxpgxY+xy6Y5du3bRqlUrNm3ahIuLC19//TXPPfecpVg6efJkxYypSsp64MABy2OUNKYqKW/hSV8VOaayj3e5HTh06BAJCQl89dVXTJo0iYiICAYOHMhnn33G3r170Wq15OXlWU6shw4dshSfNBoNR44c4eLFi7aMUCZ3yqvRaCxvzI4dO1qeV6dOHdLS0uyqEHW7rOZNMaKjo/nxxx/p378/L774IjNmzCA0NJSYmBjOnTtn4wRlU1Le//73v0RERGAwGBg6dCiNGzcG8k9I9erVIzMzk6tXr9qy+WVWUt5ly5YRERFBrVq1LLfwFJyl6evry+XLl8nJybGbAVNp3rcFb7Pt2rUrly9fttudAW/Xt3v37sXR0ZGcnBwuXLhgdZ7y9PQkNjaW7Oxsu1rSoqS8n376KREREYSGhrJ9+3bmz5/PmjVrOHz4MLVq1SIvLw93d3dSUlJsHaHUkpOT2bBhAyEhIfzrX//i1KlT7Ny5EwBHR0fy8vKoU6cOo0ePZu7cuVYDwzp16nDjxg272UU8OTmZ9evXF5u1pPfl7NmzSUxMZOPGjcTFxbF582a7me1WlrwFx1TmO0Y0Gg379u2z+rJQlZUlr7e3N+3atbP8OzAwkGvXrnHz5k27+By63fvWPG6EWwvRR0RE0K9fPyZOnMj06dMZOHAgiYmJ/PLLL4B93D1wu741f4F1dHSkb9++NG/eHMh/TderV4+kpCS7+uJ+u/51cHAgJycHLy8vpk6dCmD1BdfFxYXo6GhcXV3t4nO3LO9bc5bu3btz5coV4uPj7e6W6Tv1rZlWq+XcuXM0btzY8lp2cHDg6tWrlnVk7SH3nfLm5uZSo0YNNm3axPLly1m/fj0HDx6kYcOG5ObmYjQa7WrW2++//86iRYt4+OGH2bFjB3PnzuXw4cNcvnzZMn6qW7euIsZUt8tqngRV+DVqz2OqsuStyDFV1R+RVHHmAVFcXBwpKSlUr14duPUl54knniAsLIwpU6YA+dPlT5w4wfXr1+ncuTPnzp1j0KBBDBgwgMTERNuEKIOy5C1uwBseHk6jRo0YNGjQvWv0XSpNVvOafDVr1uTvv/+mUaNG7Nmzh3HjxjFz5kw2b95c7i3g75Wy5C1ud+UNGzYQGhpqOSlVdXfK27FjR0ve119/nVq1arFq1Sr27NkD3Lqdy9HRkf79+9uk/WVRlvdtwcGi+XaukmYRVVVlyevt7c3p06c5f/68ZbOmo0ePcvPmTcvtA1W9wFqavOYvdfXr16dnz55069bN8vyNGzfSsmVLq1klVZ1er2fAgAE8/fTTTJgwgcaNG7NlyxaOHTsG5PfZu+++i8lkYvbs2ZaF2Hft2oW/vz/du3e3WfvLQq/XM3DgwBKzFhwMmy9oGgwGpk6dyrJly+jTpw/PPvus3WxCVpa8AH/99Rfnz5+nW7dunD9/nkGDBjF48GC7Wf+5rHkL2r59O9WqVWP48OH3qrnlcqf3rVnDhg3JycmhcePG7Nmzh/HjxzNu3DjOnTvHzp07yc3NrfLnZbhz35ozFHeL7YYNG2jWrBkDBgy4p20ujzv1r/l7wbhx4wgLCyM8PJx169aRlZXFqVOnSEpKok+fPkDV/9wty/vWnCU3N5c6deoU6X97cKe+NZlMaDQadDodFy9e5PLly5ax48mTJ4mKiqJ37964uLjYRe7SvpZ9fX0JDQ21ulC9du1aQkJC6Ny5s03afje0Wi2+vr488cQT6HQ6srKy0Ov1NGnShN9//93yOCWMqW6X9eTJk0D+e1MJY6qy5IWKG1PpZsyY8VZFBlGD9evXW3YT9vDwQKPRsH//fs6fP0/r1q0t6xF6enri4+PDmjVr8Pf3p0WLFgDs2LGDQ4cOERcXx/jx42nbti1btmyhXr16toxVovLmPXXqFDdu3GDOnDl8+OGHjBo1ioEDB1bJD5myZl29ejX16tVj6NChDBw4kEcffRRvb28AateuTd26dRkxYgSOjo62jFWi8vbtiRMnSE5OZs6cOXz++ec8++yzdOnSxTLYqGruJq+3tzdt2rShRYsWHDlyhPfee4/IyEjmzp1L7969ee6556rkDJLy9K151nVAQABvv/02gwYNomHDhjZOdHt327ctW7bEw8ODd999l4iICPbu3ctbb71F7969mTRpUpXdZKCseb/++mtL/5p3b42OjmbevHl88803TJw4kZCQELt477q7u+Po6EhQUBA1atQAbs36WblyJc7OzoSGhuLk5EROTo5l7bpffvmF999/n19//ZUPPviAIUOGMHLkyCr/3i1NVkdHR6t+02q1REdHs2HDBo4cOcKwYcPYuHEj9913ny1jlehu88KtgXFkZCSbN28mOTmZl156idDQUH744QerHU2rkvL27/Hjx7l+/Trz5s1j3rx5DB06lOHDhyvitWwutnl5eTFixAgeeeQRy5iqWrVqBAcH89hjjxVblKsKytu3x44dIz4+nnnz5rFkyRKeeOIJ+vTpUyXPyXB3/ZudnY1Op6Nly5Zcu3aNt99+m19++YV58+bRvXt3Xn755Sr5uVvevoVbBanXXnuN+++/nzZt2tgqSqncTd6cnBx0Oh2BgYEsXrzYsivvv/71L3r06MErr7xSJfsW7u61XLB/Y2JiOHXqFAsXLmTFihWMHTuW0NDQKj+mMhgMuLm5ERgYyAMPPICvry+QP/N40aJFjBgxgmbNmpGbm2vXY6qyZC3IXsdUZc1rfq1W1JhKioxlcPDgQQYMGMBvv/3Gjh072LBhA0lJSXTp0gU/Pz8++ugjgoKCaNWqlWU2kMFg4Pz581y8eJHBgwej0Wj46KOP+PXXX9Hr9XzxxReMGTMGZ2dnG6crqqLyLl26lLfeeouMjAyWLVvGkCFDqtwJtzxZz507x7Bhw/Dz87PkMq/RFxISYjUzrKqoqL5dvHgxr7/+Ojk5OSxbtsxyxV1J/RsVFcWgQYOoW7cuffv2pXPnzlSvXp2ZM2fy6KOPVrkP1IroW/MgMDExEaPRyMCBA/H09LRlrBLdbd4///yT6OhoBg0aRJs2bahTpw5eXl5oNBrmz5/PY489ViUHwxX13j1w4ADz588nJiaG5cuXW90WUZUUlzclJYVOnTpZ3ntGo5EaNWoQFRVFREQE9evXp169epb+q127Nn369KF9+/b4+/vzxhtvMGrUKLt475Y2a8F+S01NZdq0aRw6dIgffvihyhZlypvXnHn58uVERETg7e1t2aHWXsZUd9O/X375JXPmzCE9PZ1ly5bx8MMPK+q1DLfOWZ6enkXGVA0aNLCbMdXd9O2KFSt4++23yczMtKxjV9XOyVAx5+WAgAD69etHnz59aNSoEVOmTKmSn7sV1bdGoxGj0YiDgwODBg3Cy8vLVpFuqyL6tlGjRrRo0YKgoCCcnZ2ZM2cOjz/+eJXrW6i4/j1z5gxLliwhOjqaFStW0K9fP8B+xlSdO3fGwcHBao35uLg4Vq1axXPPPUdAQIDl72HvY6rSZC0oLS2NqVOn2u2YqrR5K3pMJUXGMnjnnXcIDAwkPDycfv36YTAYeOedd2jQoAFhYWHExMTw9ddf07VrV8vtam5ubmzdupWMjAweeughNBoNvr6+9O/fn7feesuyY2BVVN68w4YNAyA4OJiePXsybdo0AgMDbRmpRBWV1ayqfagUVlF5GzZsSK9evZg+fXqRk3JVUp68mZmZPPyZal+2AAANoklEQVTww5hMJlxcXKhXrx6tWrXC39/fxqmKVxF9a76a5e7uTu/evatsgREq7rzcvHlzunTpYtnps6qqqPdujRo16Ny5MxMmTKiy52UoPu/bb79NkyZNLFdVjUYjWq2W++67j9WrV5OZmUnbtm3R6/VcvHgRb29v9Ho9DRo0oG3btnb13i1L1qioKLy9vdHpdHTu3JkpU6ZU2axQ/rznz5/Hx8eHOnXq0LlzZ7scU91N3saNG9O9e3cmT55cZd+7FfVaNn8psscx1d30bZMmTejZsydTpkypsn0LFde/cOuzqEmTJvj5+dkyUokqKqv5VuIuXbpU2QIjlD/vhQsX8PHxoW7durRr147u3bsr+nPIPMbw9fWlc+fOjB071q7fuxqNxnI3065du/jxxx+ZPHkyLi4uwK0NBg0GgyLGVHfKmpiYiF6vR6fT0alTJ7sfU90pb3x8PK6urhU2pqpaJecqyHxLzrVr19i0aRODBw/GwcGB4OBgxo0bx1NPPcVrr71GXFycZZ2CTz/91GoNs9zcXMsMGYDOnTvz4IMP2iLOHVVkXrOaNWvStm3bex3ljioja1VWGXlr1apFhw4d7nWUUqnovFX5S46askLF5q1qV16LUxnvXb1eX2WX6ChN3ldffdWST6fTkZeXR0BAAE888QSRkZEsXbqUoUOHMn78eG7evGnDNLdXkVnHjRtHWloaDg4OVbbYVpF5J0yYQGpqKg0aNKiyOw5XdN60tDT8/Pyq5PqpFf1aruqb2VTGa9nf35/WrVvbMFXJKqN/qyo1ZYWKzfviiy+qKu/48eNJS0tDr9dbbq2uasqa1/wdYOvWrXTr1g1PT08uXbrE448/ziuvvEJGRoatotxRRWadMWMGGRkZ6HQ6xYypbpf31Vdf5ebNmxU2pqq6n942Zt4AwNwZbm5u+Pv7c+nSJeDWVQ2dTsfrr79Obm4uixcvxtHRkdmzZ/PHH38wfPhwli9fzvTp09m1axdDhw61WZbSUFNeNWUFyavkvGrKCpJX8ubnzcrKYtWqVZbj5mLEgw8+SFRUFHPmzMFgMLBq1SpcXV1tkOb2Kiurm5ubDdLcWWXlLW4TsqpATf2rpvctyGtZyf2rpqwgeZV8Xoa7z6vVasnKyiI2NpYHHniA2bNn065dO9LT05kzZw56vd42gW5DTVmh8vJW5HtXbpcuZPfu3UycOJEtW7bw22+/4ebmRp06dUhJSeHUqVP89ddf9OjRA4PBYNltyGg08umnn/Lyyy/TpEkTQkNDuXz5MsePH+fy5cssXryYrl272jpasdSUV01ZQfIqOa+asoLklbzF512yZAkvvfSS5XbK8PBw+vbtS0hICGvWrGH8+PEYDAZbx7OipqwgeZWcV01ZQfIqOa+asoLklby3zwu3Nm1966232LRpE3FxcaxcuZL/+7//q3JFNzVlBfvKKzMZ/yctLY0pU6bwzDPP0KFDB7p168Yff/zBzJkziY+Px8/Pj9DQUC5dusT3338P5G9f36NHD1xdXYmIiACgRYsWfPbZZ3z++eds27aN9u3b2yxXSdSUV01ZQfIqOa+asoLklby3z2swGPj5558tv6927dosXLiQ3bt306pVK5tkKomasoLkVXJeNWUFyavkvGrKCpJX8t45r3kM6eDgQN26dVmxYgUHDx4kLCzMZrmKo6asYJ95q94WbTaye/du/vjjD7766is6duwIQLt27XjttdfYv38/Dz74II899hh79uzh+++/p02bNoSEhAC3FkFNTU0tcr9+Vb31AdSVV01ZQfKCcvOqKStIXpC8d8pbcIH11q1bV9n1zNSUFSQvKDevmrKC5AXl5lVTVpC8IHlLm7d58+YcPXrUZlnuRE1ZwT7zykzG/3FwcODRRx+lTZs2lkU0g4ODOXfuHB4eHgB4eHgwZswYbt68yUsvvcSpU6e4evUq27dvp3Xr1lV6N6nC1JRXTVlB8oJy86opK0hekLxKyaumrCB5Qbl51ZQVJC8oN6+asoLkBcl7p7xVdYOTwtSUFewzr+pnMppMJjQaDb1798bR0dHq+I0bN/D19bU6wfTu3RsvLy9eeukl/vnPf5KVlYXBYGDp0qV2scuwmvKqKStI3oLHlZZXTVlB8hY8LnntO6+asoLkLXhcaXnVlBUkb8HjSsurpqwgeQsel7z2nVdNWcG+86q+yGjeladgx5mPnzt3Di8vLxo2bGj1s7Zt27J161ZiY2OJiYmhR48e96q55aamvGrKCpK34HGl5VVTVpC8BY9L3lvsNa+asoLkLXhcaXnVlBUkb8HjSsurpqwgeQsel7y32GteNWUF+86rmiLjlStXqFWrVpHjeXl56HS6Yp+zfv16WrRoYVk488aNG3h4eKDRaHBzc8PDw6NIx1YVasqrpqwgec2UmFdNWUHymknefPaaV01ZQfKaKTGvmrKC5DVTYl41ZQXJayZ589lrXjVlBWXmVfyajOvWraNbt2488cQTDBw4kPDwcOBWpxmNRkvHhYeHc+jQIQCMRiM3btzg4MGDDB48GICPP/6YunXrsmzZMiB/x56qRk151ZQVJK+S86opK0heyaucvGrKCpJXyXnVlBUkr5LzqikrSF7Jq5y8asoKys6r2JmMSUlJvPHGG+zYsYNJkybh5eXFjh07eP755+nduzeurq4AnD59mkmTJnH+/Hk++OAD4FbHXL16FW9vb6KioujUqRNJSUmsWLGCIUOG2DJWidSUV01ZQfIqOa+asoLklbzKyaumrCB5lZxXTVlB8io5r5qyguSVvMrJq6asoI68ii0yHj58mNOnT7N69WratGkDwAMPPMCBAwf45ptvePrpp0lMTGTq1Kncd999rFy50mrhzH379vH777/z5ptvMmHCBGbOnGmrKKWiprxqygqSF5SbV01ZQfKC5FVKXjVlBckLys2rpqwgeUG5edWUFSQvSF6l5FVTVlBHXkUVGSMjI6lZsya1a9emYcOGjBkzhhYtWlg9xmQy4e/vD4CPjw8rV67E19e3yO8yGAxMnTqViRMn4ubmdk/aX1ZqyqumrCB5lZxXTVlB8kpe5eRVU1aQvErOq6asIHmVnFdNWUHySl7l5FVTVlBfXkUUGSMiIpg4cSJGo5GsrCx69uzJCy+8wCOPPGJ5TF5eHhkZGWRnZ1tVggt3nHmr8IceeggHh6r551FTXjVlBcmr5LxqygqSV/IqJ6+asoLkVXJeNWUFyavkvGrKCpJX8ionr5qygvrymtl+VchyiomJYfbs2QwfPpwtW7bwwQcfcOLECd58800uXrwIQE5ODjqdjmPHjuHq6kr79u1L/H3mrcKrasepKa+asoLkVXJeNWUFySt5lZNXTVlB8io5r5qyguRVcl41ZQXJK3mVk1dNWUF9eQuy+yLjuXPnOH78OCNHjqR27doMGDCAWbNmkZuby+zZswFwdHQEYOvWrbRq1cry3GvXrhEdHW2LZt81NeVVU1aQvErOq6asIHklr3LyqikrSF4l51VTVpC8Ss6rpqwgeSWvcvKqKSuoL29Bdl9kTEpKIjg4mNzcXMuxnj17MmjQIPbv38+uXbsAuHnzJgcOHKBfv34YjUbefvttmjZtys6dO23V9LuiprxqygqSF5SbV01ZQfKC5AVl5FVTVpC8oNy8asoKkheUm1dNWUHyguQFZeRVU1ZQX96C7L7I2LRpUy5cuMDZs2ctx3Q6Hffffz/Nmzdn3bp1ACQkJJCdnc2ZM2do2bIl33//PeHh4TzzzDO2avpdUVNeNWUFyQvKzaumrCB5QfKCMvKqKStIXlBuXjVlBckLys2rpqwgeUHygjLyqikrqC9vQYooMnbv3p0lS5aQnJxsOd6oUSOCgoK4du0acGtHn6ioKFatWsWECRM4cOAA3bp1s1Wz75qa8qopK0heMyXmVVNWkLxmktf+86opK0heMyXmVVNWkLxmSsyrpqwgec0kr/3nVVNWUF/egnQzZsx4y9aNKK+mTZvy7rvvEhgYSEhIiGUxzGPHjrFr1y6ef/55dDodwcHBrFy5ktDQUBu3uHzUlFdNWUHyKjmvmrKC5JW8ysmrpqwgeZWcV01ZQfIqOa+asoLklbzKyaumrKC+vGaKKDIGBASQnZ3NkiVL8PDwoFGjRmRmZvLpp5/So0cP7r//fgICAmjXrp2tm1oh1JRXTVlB8io5r5qyguSVvMrJq6asIHmVnFdNWUHyKjmvmrKC5JW8ysmrpqygvrxmmuTkZJOtG1FRpk6dSnh4ODVr1iQhIQGDwcCKFSto1qyZrZtWKdSUV01ZQfIqOa+asoLklbzKoaasIHmVnFdNWUHyKjmvmrKC5JW8yqGmrKC+vIoqMmZlZfHHH39w8uRJnJycGDFihK2bVKnUlFdNWUHyKjmvmrKC5JW8yqGmrCB5lZxXTVlB8io5r5qyguSVvMqhpqygvryKKjIKIYQQQgghhBBCCCHuPbvfXVoIIYQQQgghhBBCCGFbUmQUQgghhBBCCCGEEEKUixQZhRBCCCGEEEIIIYQQ5SJFRiGEEEIIIYQQQgghRLlIkVEIIYQQQgghhBBCCFEuUmQUQgghhBBCCCGEEEKUixQZhRBCCCGEEEIIIYQQ5SJFRiGEEEIIIYQQQgghRLlIkVEIIYQQQgghhBBCCFEu/w8TmeOuhMCUKQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1440x360 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.figure(figsize=(20,5))\n",
        "plt.plot(df_training.index, df_training['cpo_pri'], label='Train')\n",
        "plt.plot(df_test.index,df_test['cpo_pri'], label='Test')\n",
        "plt.plot(y_hat.index,y_hat['naive'], label='Naive Forecast')\n",
        "ax = plt.gca()\n",
        "ax.xaxis.set_major_locator(mdates.MonthLocator(interval=12))\n",
        "ax.xaxis.set_major_formatter(mdates.DateFormatter('%m-%Y'))\n",
        "plt.gcf().autofmt_xdate() # Rotation\n",
        "plt.legend(loc='best')\n",
        "plt.title(\"Naive Forecast\")\n",
        "plt.savefig('/content/UNF.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yMBuQzLlOIH"
      },
      "source": [
        "####Evaluate the Naive Forecast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSL0GgGckrXq",
        "outputId": "7d6a3288-8704-436b-f654-e36afe3c3c42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EVS_NF value of Naive Forecast is: 0.0\n",
            "MAE value of Naive Forecast is: 309.39\n",
            "MDA value of the SVR Model is: 0.96\n",
            "MAPE value Naive of Forecast is 36.37\n",
            "MSE value of Naive Forecast is: 122394.69\n",
            "RMSE value of Naive Forecast is: 349.85\n"
          ]
        }
      ],
      "source": [
        "EVS_NF = explained_variance_score(df_test['cpo_pri'], y_hat['naive'])\n",
        "print('EVS_NF value of Naive Forecast is:', EVS_NF.round(2))\n",
        "\n",
        "MAE_NF = mean_absolute_error(df_test['cpo_pri'], y_hat['naive'])\n",
        "print('MAE value of Naive Forecast is:', MAE_NF.round(2))\n",
        "\n",
        "MDA_NF = mda(df_test['cpo_pri'], y_hat['naive'])\n",
        "print('MDA value of the SVR Model is:', round(MDA_NF,2))\n",
        "\n",
        "MAPE_NF = MAPE(df_test['cpo_pri'], y_hat['naive'])\n",
        "print('MAPE value Naive of Forecast is', round(MAPE_NF,2))\n",
        "\n",
        "MSE_NF = mean_squared_error(df_test['cpo_pri'], y_hat['naive'])\n",
        "print('MSE value of Naive Forecast is:', round(MSE_NF, 2))\n",
        "\n",
        "RMSE_NF = math.sqrt(mean_squared_error(df_test['cpo_pri'], y_hat['naive']))\n",
        "print('RMSE value of Naive Forecast is:',  round(RMSE_NF,2))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Simple Exponential Smoothing Forecast (SES)"
      ],
      "metadata": {
        "id": "bvmBhR98DIAr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Applying Grid Search to get Optimal Parameters of Simple Exponential Smoothing Model"
      ],
      "metadata": {
        "id": "Sqd9FtvKGEIY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resu = []\n",
        "temp_df = pd.DataFrame()\n",
        "for i in [0 , 0.10, 0.20, 0.30, 0.40, 0.50, 0.60, 0.70, 0.80, 0.90,1]:\n",
        "    print(f'Fitting for smoothing level= {i}')\n",
        "    fit_v = SimpleExpSmoothing(np.asarray(df_training[\"cpo_pri\"])).fit(i)\n",
        "    fcst_pred_v= fit_v.forecast(54)\n",
        "    rmse = np.sqrt(metrics.mean_squared_error(df_test[\"cpo_pri\"], fcst_pred_v))\n",
        "    df3 = {'smoothing parameter':i, 'RMSE': rmse}\n",
        "    temp_df = temp_df.append(df3, ignore_index=True)\n",
        "temp_df.sort_values(by=['RMSE']).head(3)"
      ],
      "metadata": {
        "id": "r3EbuHCyDWwC",
        "outputId": "bb9f016a-b197-4545-dfcf-182d92ef259d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        }
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting for smoothing level= 0\n",
            "Fitting for smoothing level= 0.1\n",
            "Fitting for smoothing level= 0.2\n",
            "Fitting for smoothing level= 0.3\n",
            "Fitting for smoothing level= 0.4\n",
            "Fitting for smoothing level= 0.5\n",
            "Fitting for smoothing level= 0.6\n",
            "Fitting for smoothing level= 0.7\n",
            "Fitting for smoothing level= 0.8\n",
            "Fitting for smoothing level= 0.9\n",
            "Fitting for smoothing level= 1\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-657d689d-6ff3-4f25-8245-efdc2d116f51\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>smoothing parameter</th>\n",
              "      <th>RMSE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1.0</td>\n",
              "      <td>349.849531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.9</td>\n",
              "      <td>350.119375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.8</td>\n",
              "      <td>350.451144</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-657d689d-6ff3-4f25-8245-efdc2d116f51')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-657d689d-6ff3-4f25-8245-efdc2d116f51 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-657d689d-6ff3-4f25-8245-efdc2d116f51');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "    smoothing parameter        RMSE\n",
              "10                  1.0  349.849531\n",
              "9                   0.9  350.119375\n",
              "8                   0.8  350.451144"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The least RMSE was achieved with smoothing_level equal to 0.1. Next we utilize it in the same value and train the model."
      ],
      "metadata": {
        "id": "ZmvShlx7HVB6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fitSES = SimpleExpSmoothing(np.asarray(df_training[\"cpo_pri\"])).fit(smoothing_level = 1,optimized= False)\n",
        "SES_gs_pred = fitSES.forecast(54)"
      ],
      "metadata": {
        "id": "VyXrOdZ0DW1I"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test[\"cpo_pri\"]"
      ],
      "metadata": {
        "id": "JtRqgAJcHtlQ",
        "outputId": "86b0eb7d-5b18-4df7-9c5b-b8eec9ab6d4a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Date\n",
              "2016-10-01     484.00\n",
              "2016-11-01     478.00\n",
              "2016-12-01     499.00\n",
              "2017-01-01     534.00\n",
              "2017-02-01     511.00\n",
              "2017-03-01     514.00\n",
              "2017-04-01     572.00\n",
              "2017-05-01     626.00\n",
              "2017-06-01     638.00\n",
              "2017-07-01     645.00\n",
              "2017-08-01     661.00\n",
              "2017-09-01     743.00\n",
              "2017-10-01     816.00\n",
              "2017-11-01     833.00\n",
              "2017-12-01     855.00\n",
              "2018-01-01     831.00\n",
              "2018-02-01     852.00\n",
              "2018-03-01     926.00\n",
              "2018-04-01     999.00\n",
              "2018-05-01    1002.00\n",
              "2018-06-01    1012.25\n",
              "2018-07-01    1012.25\n",
              "2018-08-01    1012.25\n",
              "2018-09-01    1012.25\n",
              "2018-10-01    1012.25\n",
              "2018-11-01    1012.25\n",
              "2018-12-01    1012.25\n",
              "2019-01-01     964.00\n",
              "2019-02-01     826.00\n",
              "2019-03-01     636.00\n",
              "2019-04-01     581.00\n",
              "2019-05-01     587.00\n",
              "2019-06-01     659.00\n",
              "2019-07-01     656.00\n",
              "2019-08-01     660.00\n",
              "2019-09-01     800.00\n",
              "2019-10-01     873.00\n",
              "2019-11-01     789.00\n",
              "2019-12-01     698.00\n",
              "2020-01-01     746.00\n",
              "2020-02-01     704.00\n",
              "2020-03-01     725.00\n",
              "2020-04-01     763.00\n",
              "2020-05-01     822.00\n",
              "2020-06-01     831.00\n",
              "2020-07-01     830.00\n",
              "2020-08-01     863.00\n",
              "2020-09-01     863.00\n",
              "2020-10-01     855.00\n",
              "2020-11-01     826.00\n",
              "2020-12-01     844.00\n",
              "2021-01-01     944.00\n",
              "2021-02-01     949.00\n",
              "2021-03-01    1012.25\n",
              "Name: cpo_pri, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZ-LnNetoKrZ"
      },
      "source": [
        "##Machine Learning Techniques"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Support Vector Regression"
      ],
      "metadata": {
        "id": "1U5ra8VaIlxB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load Dataframe again to get fresh perspective\n",
        "df1"
      ],
      "metadata": {
        "id": "vnpYH6VDIqGQ",
        "outputId": "b18706c4-26b2-4178-ea85-40f072c1828f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        }
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b92fd6dd-6f71-4d04-b4b2-075350c65906\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cpo_pri</th>\n",
              "      <th>cno_pri</th>\n",
              "      <th>rps_pri</th>\n",
              "      <th>pno_pri</th>\n",
              "      <th>sbo_pri</th>\n",
              "      <th>wti_spri</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2002-02-01</th>\n",
              "      <td>323.00</td>\n",
              "      <td>455.000</td>\n",
              "      <td>423.45</td>\n",
              "      <td>844.00</td>\n",
              "      <td>468.00000</td>\n",
              "      <td>28.67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2002-03-01</th>\n",
              "      <td>345.00</td>\n",
              "      <td>546.000</td>\n",
              "      <td>415.85</td>\n",
              "      <td>799.00</td>\n",
              "      <td>485.00000</td>\n",
              "      <td>24.49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2002-04-01</th>\n",
              "      <td>362.00</td>\n",
              "      <td>595.000</td>\n",
              "      <td>410.77</td>\n",
              "      <td>718.00</td>\n",
              "      <td>466.00000</td>\n",
              "      <td>22.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2002-05-01</th>\n",
              "      <td>376.00</td>\n",
              "      <td>636.000</td>\n",
              "      <td>414.82</td>\n",
              "      <td>614.00</td>\n",
              "      <td>442.00000</td>\n",
              "      <td>21.64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2002-06-01</th>\n",
              "      <td>383.00</td>\n",
              "      <td>738.000</td>\n",
              "      <td>451.04</td>\n",
              "      <td>619.00</td>\n",
              "      <td>429.00000</td>\n",
              "      <td>22.30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-11-01</th>\n",
              "      <td>826.00</td>\n",
              "      <td>993.000</td>\n",
              "      <td>1047.78</td>\n",
              "      <td>1366.87</td>\n",
              "      <td>860.28000</td>\n",
              "      <td>34.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-12-01</th>\n",
              "      <td>844.00</td>\n",
              "      <td>1031.000</td>\n",
              "      <td>1097.63</td>\n",
              "      <td>1366.87</td>\n",
              "      <td>910.82000</td>\n",
              "      <td>35.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-01-01</th>\n",
              "      <td>944.00</td>\n",
              "      <td>1092.875</td>\n",
              "      <td>1138.24</td>\n",
              "      <td>1383.90</td>\n",
              "      <td>970.08875</td>\n",
              "      <td>35.81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-02-01</th>\n",
              "      <td>949.00</td>\n",
              "      <td>1092.875</td>\n",
              "      <td>1272.13</td>\n",
              "      <td>1426.71</td>\n",
              "      <td>970.08875</td>\n",
              "      <td>33.59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-03-01</th>\n",
              "      <td>1012.25</td>\n",
              "      <td>1092.875</td>\n",
              "      <td>1321.88</td>\n",
              "      <td>1471.32</td>\n",
              "      <td>970.08875</td>\n",
              "      <td>33.57</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>230 rows  6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b92fd6dd-6f71-4d04-b4b2-075350c65906')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b92fd6dd-6f71-4d04-b4b2-075350c65906 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b92fd6dd-6f71-4d04-b4b2-075350c65906');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "            cpo_pri   cno_pri  rps_pri  pno_pri    sbo_pri  wti_spri\n",
              "Date                                                                \n",
              "2002-02-01   323.00   455.000   423.45   844.00  468.00000     28.67\n",
              "2002-03-01   345.00   546.000   415.85   799.00  485.00000     24.49\n",
              "2002-04-01   362.00   595.000   410.77   718.00  466.00000     22.06\n",
              "2002-05-01   376.00   636.000   414.82   614.00  442.00000     21.64\n",
              "2002-06-01   383.00   738.000   451.04   619.00  429.00000     22.30\n",
              "...             ...       ...      ...      ...        ...       ...\n",
              "2020-11-01   826.00   993.000  1047.78  1366.87  860.28000     34.03\n",
              "2020-12-01   844.00  1031.000  1097.63  1366.87  910.82000     35.50\n",
              "2021-01-01   944.00  1092.875  1138.24  1383.90  970.08875     35.81\n",
              "2021-02-01   949.00  1092.875  1272.13  1426.71  970.08875     33.59\n",
              "2021-03-01  1012.25  1092.875  1321.88  1471.32  970.08875     33.57\n",
              "\n",
              "[230 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create fake temperature\n",
        "df = pd.DataFrame({'temp':np.random.rand(500)})\n",
        "\n",
        "# define function for create N lags\n",
        "def create_lags(df, N):\n",
        "    for i in range(N):\n",
        "        df['Lag' + str(i+1)] = df.temp.shift(i+1)\n",
        "    return df\n",
        "\n",
        "# create 10 lags\n",
        "df = create_lags(df,10)\n",
        "\n",
        "# the first 10 days will have missing values. can't use them.\n",
        "df = df.dropna()\n",
        "\n",
        "# create X and y\n",
        "y = df.temp.values\n",
        "X = df.iloc[:, 1:].values\n",
        "\n",
        "# Train on 70% of the data\n",
        "train_idx = int(len(df) * .7)\n",
        "\n",
        "# create train and test data\n",
        "X_train, y_train, X_test, y_test = X[:train_idx], y[:train_idx], X[train_idx:], y[:train_idx]\n",
        "\n",
        "# fit and predict\n",
        "clf = SVR()\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "clf.predict(X_test)"
      ],
      "metadata": {
        "id": "2bn6u_0aJc_q",
        "outputId": "fd7dfab6-6339-44e7-a0c5-87d00d8cf278",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.59213242, 0.68194836, 0.22007801, 0.78343255, 0.63999073,\n",
              "       0.48614684, 0.71415414, 0.48937708, 0.53500163, 0.38754619,\n",
              "       0.5119702 , 0.41182524, 0.35842651, 0.53974173, 0.55129725,\n",
              "       0.43695411, 0.55533552, 0.44016285, 0.30244846, 0.48079808,\n",
              "       0.80952515, 0.39562405, 0.51360407, 0.41095743, 0.3173061 ,\n",
              "       0.57190412, 0.46111244, 0.38518769, 0.28492203, 0.56450504,\n",
              "       0.51349917, 0.5113216 , 0.38030239, 0.74630842, 0.74307073,\n",
              "       0.60644611, 0.47735305, 0.43753564, 0.57376153, 0.41951887,\n",
              "       0.75749382, 0.82450291, 0.2767825 , 0.84322941, 0.49811819,\n",
              "       0.48272307, 0.44060672, 0.49515193, 0.62052647, 0.29417526,\n",
              "       0.61121887, 0.63504435, 0.31360346, 0.45473057, 0.6790068 ,\n",
              "       0.232219  , 0.54427352, 0.43994054, 0.23038832, 0.39262782,\n",
              "       0.52951244, 0.62704805, 0.54451343, 0.49631602, 0.63786874,\n",
              "       0.74969264, 0.48491795, 0.45609465, 0.55069631, 0.48819037,\n",
              "       0.69097789, 0.46866021, 0.39322052, 0.67882029, 0.53722219,\n",
              "       0.21451282, 0.64519436, 0.63391388, 0.43281596, 0.80169991,\n",
              "       0.4706209 , 0.35880733, 0.3651842 , 0.24579961, 0.64012002,\n",
              "       0.55920917, 0.24317187, 0.67329091, 0.51823523, 0.43141023,\n",
              "       0.84830006, 0.55107011, 0.33974921, 0.59719413, 0.35192279,\n",
              "       0.30802532, 0.58161789, 0.77765649, 0.63960669, 0.52863317,\n",
              "       0.29597307, 0.65398387, 0.39886372, 0.30908574, 0.6418171 ,\n",
              "       0.70297734, 0.36456429, 0.2846203 , 0.68228252, 0.59424833,\n",
              "       0.37629332, 0.67789039, 0.63542065, 0.45653178, 0.8008111 ,\n",
              "       0.63195047, 0.29755966, 0.68968025, 0.67093982, 0.51448143,\n",
              "       0.44601322, 0.59661392, 0.49461989, 0.5444443 , 0.45617907,\n",
              "       0.4866479 , 0.51486217, 0.44602176, 0.18610376, 0.41597308,\n",
              "       0.42765859, 0.58111935, 0.18866185, 0.50425933, 0.53668867,\n",
              "       0.3850301 , 0.53337253, 0.50542543, 0.43595823, 0.64173068,\n",
              "       0.44503328, 0.67504682, 0.66312245, 0.47724831, 0.43428322,\n",
              "       0.47565758, 0.58813203])"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ztNFSL02tyxU"
      },
      "outputs": [],
      "source": [
        "df.set_index('index',inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "u5j5AAecxY0O",
        "outputId": "e8d7d2ab-6fe9-4754-bc49-2f9a7ff66850"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-68afd045-8860-444b-a5dc-f8d4b521c3c9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cpo_pri</th>\n",
              "      <th>cno_pri</th>\n",
              "      <th>rps_pri</th>\n",
              "      <th>pno_pri</th>\n",
              "      <th>sbo_pri</th>\n",
              "      <th>wti_spri</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2002-02-28</th>\n",
              "      <td>323.0</td>\n",
              "      <td>455.0</td>\n",
              "      <td>423.45</td>\n",
              "      <td>844.0</td>\n",
              "      <td>468.0</td>\n",
              "      <td>28.67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2002-03-31</th>\n",
              "      <td>345.0</td>\n",
              "      <td>546.0</td>\n",
              "      <td>415.85</td>\n",
              "      <td>799.0</td>\n",
              "      <td>485.0</td>\n",
              "      <td>24.49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2002-04-30</th>\n",
              "      <td>362.0</td>\n",
              "      <td>595.0</td>\n",
              "      <td>410.77</td>\n",
              "      <td>718.0</td>\n",
              "      <td>466.0</td>\n",
              "      <td>22.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2002-05-31</th>\n",
              "      <td>376.0</td>\n",
              "      <td>636.0</td>\n",
              "      <td>414.82</td>\n",
              "      <td>614.0</td>\n",
              "      <td>442.0</td>\n",
              "      <td>21.64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2002-06-30</th>\n",
              "      <td>383.0</td>\n",
              "      <td>738.0</td>\n",
              "      <td>451.04</td>\n",
              "      <td>619.0</td>\n",
              "      <td>429.0</td>\n",
              "      <td>22.30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-68afd045-8860-444b-a5dc-f8d4b521c3c9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-68afd045-8860-444b-a5dc-f8d4b521c3c9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-68afd045-8860-444b-a5dc-f8d4b521c3c9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "            cpo_pri  cno_pri  rps_pri  pno_pri  sbo_pri  wti_spri\n",
              "index                                                            \n",
              "2002-02-28    323.0    455.0   423.45    844.0    468.0     28.67\n",
              "2002-03-31    345.0    546.0   415.85    799.0    485.0     24.49\n",
              "2002-04-30    362.0    595.0   410.77    718.0    466.0     22.06\n",
              "2002-05-31    376.0    636.0   414.82    614.0    442.0     21.64\n",
              "2002-06-30    383.0    738.0   451.04    619.0    429.0     22.30"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "id": "JVgleiyxkrbk",
        "outputId": "afd2a6e2-bfe4-448b-99ea-b82bc0d6b384"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-130-daf965498905>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msplit_date\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'2018-02'\u001b[0m \u001b[0;31m#old '2017-06'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0msplit_date\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0msplit_date\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{len(df_training)} days of training data \\n {len(df_test)} days of testing data \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/ops/common.py\u001b[0m in \u001b[0;36mnew_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/arraylike.py\u001b[0m in \u001b[0;36m__le__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__le__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__le__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cmp_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__gt__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36m_cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m    877\u001b[0m             \u001b[0;31m# Both are immutable so if ._range attr. are equal, shortcut is possible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cmp_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 879\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cmp_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_arith_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   6059\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6060\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6061\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomparison_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6062\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6063\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36mcomparison_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_numeric_v_string_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0;31m# GH#36377 going through the numexpr path would incorrectly raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0minvalid_comparison\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/ops/invalid.py\u001b[0m in \u001b[0;36minvalid_comparison\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mtyp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Invalid comparison between dtype={left.dtype} and {typ}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Invalid comparison between dtype=int64 and str"
          ]
        }
      ],
      "source": [
        "split_date = '2018-02' #old '2017-06'\n",
        "df_training = df.loc[df.index <= split_date]\n",
        "df_test = df.loc[df.index > split_date]\n",
        "print(f\"{len(df_training)} days of training data \\n {len(df_test)} days of testing data \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "blzvB_WAlaYR"
      },
      "outputs": [],
      "source": [
        "# ADD time features to our model\n",
        "def create_time_features(df, target=None):\n",
        "    \"\"\"\n",
        "    Creates time df features from datetime index\n",
        "    \"\"\"\n",
        "    df['date'] = df.index\n",
        "    X = df.drop(['date'], axis=1)\n",
        "    if target:\n",
        "        y = df[target]\n",
        "        X = X.drop([target], axis=1)\n",
        "        return X, y\n",
        "\n",
        "    return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XNXpQ0n7lad-"
      },
      "outputs": [],
      "source": [
        "x = df[['cno_pri', 'rps_pri', 'pno_pri', 'sbo_pri', 'wti_spri']]\n",
        "y = df[['cpo_pri']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "XVefSkYVkrfe",
        "outputId": "146713ed-9928-453f-d2c3-6b3c99ebe5e0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-571b6543-f173-4c40-bf85-12c968d18e6b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cpo_pri</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>323.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>345.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>362.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>376.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>383.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>225</th>\n",
              "      <td>826.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>226</th>\n",
              "      <td>844.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>227</th>\n",
              "      <td>944.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>228</th>\n",
              "      <td>949.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>229</th>\n",
              "      <td>1012.25</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>230 rows  1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-571b6543-f173-4c40-bf85-12c968d18e6b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-571b6543-f173-4c40-bf85-12c968d18e6b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-571b6543-f173-4c40-bf85-12c968d18e6b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     cpo_pri\n",
              "0     323.00\n",
              "1     345.00\n",
              "2     362.00\n",
              "3     376.00\n",
              "4     383.00\n",
              "..       ...\n",
              "225   826.00\n",
              "226   844.00\n",
              "227   944.00\n",
              "228   949.00\n",
              "229  1012.25\n",
              "\n",
              "[230 rows x 1 columns]"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEPs6dUjrtV3"
      },
      "source": [
        "###Apply Scaling Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EkmiAWXCrpDr",
        "outputId": "3b001dc8-2d10-4e46-8e32-a8d56baf7a3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MinMaxScaler()\n",
            "MinMaxScaler()\n"
          ]
        }
      ],
      "source": [
        "scaler_x = MinMaxScaler()   \n",
        "scaler_y = MinMaxScaler()\n",
        "print(scaler_x.fit(x))       \n",
        "xscale=scaler_x.transform(x)\n",
        "print(scaler_y.fit(y))               \n",
        "yscale=scaler_y.transform(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGCub_UNsK-H"
      },
      "source": [
        "###Split Data into Train, Test Sets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z35VTmO4rpTZ"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(xscale, yscale, test_size=0.2, random_state=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDajW-mNM26J"
      },
      "source": [
        "###Support Vector Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sL6lXmY_O-8q"
      },
      "source": [
        "####Create a GridSearchCV Object and fit it to the Training Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tmnIvx9Ne9q",
        "outputId": "4e971858-d7fe-4a34-fca3-77411903bd2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 10 folds for each of 96 candidates, totalling 960 fits\n",
            "[CV 1/10] END C=0.1, epsilon=0.0001, gamma=1, kernel=rbf;, score=-0.007 total time=   0.0s\n",
            "[CV 2/10] END C=0.1, epsilon=0.0001, gamma=1, kernel=rbf;, score=-0.004 total time=   0.0s\n",
            "[CV 3/10] END C=0.1, epsilon=0.0001, gamma=1, kernel=rbf;, score=-0.006 total time=   0.0s\n",
            "[CV 4/10] END C=0.1, epsilon=0.0001, gamma=1, kernel=rbf;, score=-0.005 total time=   0.0s\n",
            "[CV 5/10] END C=0.1, epsilon=0.0001, gamma=1, kernel=rbf;, score=-0.006 total time=   0.0s\n",
            "[CV 6/10] END C=0.1, epsilon=0.0001, gamma=1, kernel=rbf;, score=-0.007 total time=   0.0s\n",
            "[CV 7/10] END C=0.1, epsilon=0.0001, gamma=1, kernel=rbf;, score=-0.006 total time=   0.0s\n",
            "[CV 8/10] END C=0.1, epsilon=0.0001, gamma=1, kernel=rbf;, score=-0.004 total time=   0.0s\n",
            "[CV 9/10] END C=0.1, epsilon=0.0001, gamma=1, kernel=rbf;, score=-0.007 total time=   0.0s\n",
            "[CV 10/10] END C=0.1, epsilon=0.0001, gamma=1, kernel=rbf;, score=-0.004 total time=   0.0s\n",
            "[CV 1/10] END C=0.1, epsilon=0.0001, gamma=1, kernel=poly;, score=-0.008 total time=   0.0s\n",
            "[CV 2/10] END C=0.1, epsilon=0.0001, gamma=1, kernel=poly;, score=-0.007 total time=   0.0s\n",
            "[CV 3/10] END C=0.1, epsilon=0.0001, gamma=1, kernel=poly;, score=-0.006 total time=   0.0s\n",
            "[CV 4/10] END C=0.1, epsilon=0.0001, gamma=1, kernel=poly;, score=-0.011 total time=   0.0s\n",
            "[CV 5/10] END C=0.1, epsilon=0.0001, gamma=1, kernel=poly;, score=-0.016 total time=   0.0s\n",
            "[CV 6/10] END C=0.1, epsilon=0.0001, gamma=1, kernel=poly;, score=-0.009 total time=   0.0s\n",
            "[CV 7/10] END C=0.1, epsilon=0.0001, gamma=1, kernel=poly;, score=-0.009 total time=   0.0s\n",
            "[CV 8/10] END C=0.1, epsilon=0.0001, gamma=1, kernel=poly;, score=-0.002 total time=   0.0s\n",
            "[CV 9/10] END C=0.1, epsilon=0.0001, gamma=1, kernel=poly;, score=-0.009 total time=   0.0s\n",
            "[CV 10/10] END C=0.1, epsilon=0.0001, gamma=1, kernel=poly;, score=-0.008 total time=   0.0s\n",
            "[CV 1/10] END C=0.1, epsilon=0.0001, gamma=1, kernel=linear;, score=-0.008 total time=   0.0s\n",
            "[CV 2/10] END C=0.1, epsilon=0.0001, gamma=1, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 3/10] END C=0.1, epsilon=0.0001, gamma=1, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 4/10] END C=0.1, epsilon=0.0001, gamma=1, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 5/10] END C=0.1, epsilon=0.0001, gamma=1, kernel=linear;, score=-0.006 total time=   0.0s\n",
            "[CV 6/10] END C=0.1, epsilon=0.0001, gamma=1, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 7/10] END C=0.1, epsilon=0.0001, gamma=1, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 8/10] END C=0.1, epsilon=0.0001, gamma=1, kernel=linear;, score=-0.003 total time=   0.0s\n",
            "[CV 9/10] END C=0.1, epsilon=0.0001, gamma=1, kernel=linear;, score=-0.006 total time=   0.0s\n",
            "[CV 10/10] END C=0.1, epsilon=0.0001, gamma=1, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 1/10] END C=0.1, epsilon=0.0001, gamma=0.1, kernel=rbf;, score=-0.010 total time=   0.0s\n",
            "[CV 2/10] END C=0.1, epsilon=0.0001, gamma=0.1, kernel=rbf;, score=-0.006 total time=   0.0s\n",
            "[CV 3/10] END C=0.1, epsilon=0.0001, gamma=0.1, kernel=rbf;, score=-0.010 total time=   0.0s\n",
            "[CV 4/10] END C=0.1, epsilon=0.0001, gamma=0.1, kernel=rbf;, score=-0.008 total time=   0.0s\n",
            "[CV 5/10] END C=0.1, epsilon=0.0001, gamma=0.1, kernel=rbf;, score=-0.011 total time=   0.0s\n",
            "[CV 6/10] END C=0.1, epsilon=0.0001, gamma=0.1, kernel=rbf;, score=-0.016 total time=   0.0s\n",
            "[CV 7/10] END C=0.1, epsilon=0.0001, gamma=0.1, kernel=rbf;, score=-0.007 total time=   0.0s\n",
            "[CV 8/10] END C=0.1, epsilon=0.0001, gamma=0.1, kernel=rbf;, score=-0.007 total time=   0.0s\n",
            "[CV 9/10] END C=0.1, epsilon=0.0001, gamma=0.1, kernel=rbf;, score=-0.014 total time=   0.0s\n",
            "[CV 10/10] END C=0.1, epsilon=0.0001, gamma=0.1, kernel=rbf;, score=-0.009 total time=   0.0s\n",
            "[CV 1/10] END C=0.1, epsilon=0.0001, gamma=0.1, kernel=poly;, score=-0.035 total time=   0.0s\n",
            "[CV 2/10] END C=0.1, epsilon=0.0001, gamma=0.1, kernel=poly;, score=-0.029 total time=   0.0s\n",
            "[CV 3/10] END C=0.1, epsilon=0.0001, gamma=0.1, kernel=poly;, score=-0.040 total time=   0.0s\n",
            "[CV 4/10] END C=0.1, epsilon=0.0001, gamma=0.1, kernel=poly;, score=-0.051 total time=   0.0s\n",
            "[CV 5/10] END C=0.1, epsilon=0.0001, gamma=0.1, kernel=poly;, score=-0.067 total time=   0.0s\n",
            "[CV 6/10] END C=0.1, epsilon=0.0001, gamma=0.1, kernel=poly;, score=-0.093 total time=   0.0s\n",
            "[CV 7/10] END C=0.1, epsilon=0.0001, gamma=0.1, kernel=poly;, score=-0.040 total time=   0.0s\n",
            "[CV 8/10] END C=0.1, epsilon=0.0001, gamma=0.1, kernel=poly;, score=-0.044 total time=   0.0s\n",
            "[CV 9/10] END C=0.1, epsilon=0.0001, gamma=0.1, kernel=poly;, score=-0.073 total time=   0.0s\n",
            "[CV 10/10] END C=0.1, epsilon=0.0001, gamma=0.1, kernel=poly;, score=-0.067 total time=   0.0s\n",
            "[CV 1/10] END C=0.1, epsilon=0.0001, gamma=0.1, kernel=linear;, score=-0.008 total time=   0.0s\n",
            "[CV 2/10] END C=0.1, epsilon=0.0001, gamma=0.1, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 3/10] END C=0.1, epsilon=0.0001, gamma=0.1, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 4/10] END C=0.1, epsilon=0.0001, gamma=0.1, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 5/10] END C=0.1, epsilon=0.0001, gamma=0.1, kernel=linear;, score=-0.006 total time=   0.0s\n",
            "[CV 6/10] END C=0.1, epsilon=0.0001, gamma=0.1, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 7/10] END C=0.1, epsilon=0.0001, gamma=0.1, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 8/10] END C=0.1, epsilon=0.0001, gamma=0.1, kernel=linear;, score=-0.003 total time=   0.0s\n",
            "[CV 9/10] END C=0.1, epsilon=0.0001, gamma=0.1, kernel=linear;, score=-0.006 total time=   0.0s\n",
            "[CV 10/10] END C=0.1, epsilon=0.0001, gamma=0.1, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 1/10] END C=0.1, epsilon=0.0001, gamma=0.01, kernel=rbf;, score=-0.031 total time=   0.0s\n",
            "[CV 2/10] END C=0.1, epsilon=0.0001, gamma=0.01, kernel=rbf;, score=-0.024 total time=   0.0s\n",
            "[CV 3/10] END C=0.1, epsilon=0.0001, gamma=0.01, kernel=rbf;, score=-0.036 total time=   0.0s\n",
            "[CV 4/10] END C=0.1, epsilon=0.0001, gamma=0.01, kernel=rbf;, score=-0.046 total time=   0.0s\n",
            "[CV 5/10] END C=0.1, epsilon=0.0001, gamma=0.01, kernel=rbf;, score=-0.060 total time=   0.0s\n",
            "[CV 6/10] END C=0.1, epsilon=0.0001, gamma=0.01, kernel=rbf;, score=-0.085 total time=   0.0s\n",
            "[CV 7/10] END C=0.1, epsilon=0.0001, gamma=0.01, kernel=rbf;, score=-0.036 total time=   0.0s\n",
            "[CV 8/10] END C=0.1, epsilon=0.0001, gamma=0.01, kernel=rbf;, score=-0.039 total time=   0.0s\n",
            "[CV 9/10] END C=0.1, epsilon=0.0001, gamma=0.01, kernel=rbf;, score=-0.066 total time=   0.0s\n",
            "[CV 10/10] END C=0.1, epsilon=0.0001, gamma=0.01, kernel=rbf;, score=-0.060 total time=   0.0s\n",
            "[CV 1/10] END C=0.1, epsilon=0.0001, gamma=0.01, kernel=poly;, score=-0.042 total time=   0.0s\n",
            "[CV 2/10] END C=0.1, epsilon=0.0001, gamma=0.01, kernel=poly;, score=-0.031 total time=   0.0s\n",
            "[CV 3/10] END C=0.1, epsilon=0.0001, gamma=0.01, kernel=poly;, score=-0.048 total time=   0.0s\n",
            "[CV 4/10] END C=0.1, epsilon=0.0001, gamma=0.01, kernel=poly;, score=-0.061 total time=   0.0s\n",
            "[CV 5/10] END C=0.1, epsilon=0.0001, gamma=0.01, kernel=poly;, score=-0.078 total time=   0.0s\n",
            "[CV 6/10] END C=0.1, epsilon=0.0001, gamma=0.01, kernel=poly;, score=-0.111 total time=   0.0s\n",
            "[CV 7/10] END C=0.1, epsilon=0.0001, gamma=0.01, kernel=poly;, score=-0.047 total time=   0.0s\n",
            "[CV 8/10] END C=0.1, epsilon=0.0001, gamma=0.01, kernel=poly;, score=-0.053 total time=   0.0s\n",
            "[CV 9/10] END C=0.1, epsilon=0.0001, gamma=0.01, kernel=poly;, score=-0.085 total time=   0.0s\n",
            "[CV 10/10] END C=0.1, epsilon=0.0001, gamma=0.01, kernel=poly;, score=-0.080 total time=   0.0s\n",
            "[CV 1/10] END C=0.1, epsilon=0.0001, gamma=0.01, kernel=linear;, score=-0.008 total time=   0.0s\n",
            "[CV 2/10] END C=0.1, epsilon=0.0001, gamma=0.01, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 3/10] END C=0.1, epsilon=0.0001, gamma=0.01, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 4/10] END C=0.1, epsilon=0.0001, gamma=0.01, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 5/10] END C=0.1, epsilon=0.0001, gamma=0.01, kernel=linear;, score=-0.006 total time=   0.0s\n",
            "[CV 6/10] END C=0.1, epsilon=0.0001, gamma=0.01, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 7/10] END C=0.1, epsilon=0.0001, gamma=0.01, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 8/10] END C=0.1, epsilon=0.0001, gamma=0.01, kernel=linear;, score=-0.003 total time=   0.0s\n",
            "[CV 9/10] END C=0.1, epsilon=0.0001, gamma=0.01, kernel=linear;, score=-0.006 total time=   0.0s\n",
            "[CV 10/10] END C=0.1, epsilon=0.0001, gamma=0.01, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 1/10] END C=0.1, epsilon=0.0001, gamma=0.001, kernel=rbf;, score=-0.041 total time=   0.0s\n",
            "[CV 2/10] END C=0.1, epsilon=0.0001, gamma=0.001, kernel=rbf;, score=-0.030 total time=   0.0s\n",
            "[CV 3/10] END C=0.1, epsilon=0.0001, gamma=0.001, kernel=rbf;, score=-0.046 total time=   0.0s\n",
            "[CV 4/10] END C=0.1, epsilon=0.0001, gamma=0.001, kernel=rbf;, score=-0.059 total time=   0.0s\n",
            "[CV 5/10] END C=0.1, epsilon=0.0001, gamma=0.001, kernel=rbf;, score=-0.076 total time=   0.0s\n",
            "[CV 6/10] END C=0.1, epsilon=0.0001, gamma=0.001, kernel=rbf;, score=-0.108 total time=   0.0s\n",
            "[CV 7/10] END C=0.1, epsilon=0.0001, gamma=0.001, kernel=rbf;, score=-0.046 total time=   0.0s\n",
            "[CV 8/10] END C=0.1, epsilon=0.0001, gamma=0.001, kernel=rbf;, score=-0.052 total time=   0.0s\n",
            "[CV 9/10] END C=0.1, epsilon=0.0001, gamma=0.001, kernel=rbf;, score=-0.083 total time=   0.0s\n",
            "[CV 10/10] END C=0.1, epsilon=0.0001, gamma=0.001, kernel=rbf;, score=-0.078 total time=   0.0s\n",
            "[CV 1/10] END C=0.1, epsilon=0.0001, gamma=0.001, kernel=poly;, score=-0.042 total time=   0.0s\n",
            "[CV 2/10] END C=0.1, epsilon=0.0001, gamma=0.001, kernel=poly;, score=-0.031 total time=   0.0s\n",
            "[CV 3/10] END C=0.1, epsilon=0.0001, gamma=0.001, kernel=poly;, score=-0.048 total time=   0.0s\n",
            "[CV 4/10] END C=0.1, epsilon=0.0001, gamma=0.001, kernel=poly;, score=-0.061 total time=   0.0s\n",
            "[CV 5/10] END C=0.1, epsilon=0.0001, gamma=0.001, kernel=poly;, score=-0.078 total time=   0.0s\n",
            "[CV 6/10] END C=0.1, epsilon=0.0001, gamma=0.001, kernel=poly;, score=-0.111 total time=   0.0s\n",
            "[CV 7/10] END C=0.1, epsilon=0.0001, gamma=0.001, kernel=poly;, score=-0.047 total time=   0.0s\n",
            "[CV 8/10] END C=0.1, epsilon=0.0001, gamma=0.001, kernel=poly;, score=-0.053 total time=   0.0s\n",
            "[CV 9/10] END C=0.1, epsilon=0.0001, gamma=0.001, kernel=poly;, score=-0.085 total time=   0.0s\n",
            "[CV 10/10] END C=0.1, epsilon=0.0001, gamma=0.001, kernel=poly;, score=-0.080 total time=   0.0s\n",
            "[CV 1/10] END C=0.1, epsilon=0.0001, gamma=0.001, kernel=linear;, score=-0.008 total time=   0.0s\n",
            "[CV 2/10] END C=0.1, epsilon=0.0001, gamma=0.001, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 3/10] END C=0.1, epsilon=0.0001, gamma=0.001, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 4/10] END C=0.1, epsilon=0.0001, gamma=0.001, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 5/10] END C=0.1, epsilon=0.0001, gamma=0.001, kernel=linear;, score=-0.006 total time=   0.0s\n",
            "[CV 6/10] END C=0.1, epsilon=0.0001, gamma=0.001, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 7/10] END C=0.1, epsilon=0.0001, gamma=0.001, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 8/10] END C=0.1, epsilon=0.0001, gamma=0.001, kernel=linear;, score=-0.003 total time=   0.0s\n",
            "[CV 9/10] END C=0.1, epsilon=0.0001, gamma=0.001, kernel=linear;, score=-0.006 total time=   0.0s\n",
            "[CV 10/10] END C=0.1, epsilon=0.0001, gamma=0.001, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 1/10] END C=0.1, epsilon=0.001, gamma=1, kernel=rbf;, score=-0.007 total time=   0.0s\n",
            "[CV 2/10] END C=0.1, epsilon=0.001, gamma=1, kernel=rbf;, score=-0.004 total time=   0.0s\n",
            "[CV 3/10] END C=0.1, epsilon=0.001, gamma=1, kernel=rbf;, score=-0.006 total time=   0.0s\n",
            "[CV 4/10] END C=0.1, epsilon=0.001, gamma=1, kernel=rbf;, score=-0.005 total time=   0.0s\n",
            "[CV 5/10] END C=0.1, epsilon=0.001, gamma=1, kernel=rbf;, score=-0.006 total time=   0.0s\n",
            "[CV 6/10] END C=0.1, epsilon=0.001, gamma=1, kernel=rbf;, score=-0.007 total time=   0.0s\n",
            "[CV 7/10] END C=0.1, epsilon=0.001, gamma=1, kernel=rbf;, score=-0.005 total time=   0.0s\n",
            "[CV 8/10] END C=0.1, epsilon=0.001, gamma=1, kernel=rbf;, score=-0.004 total time=   0.0s\n",
            "[CV 9/10] END C=0.1, epsilon=0.001, gamma=1, kernel=rbf;, score=-0.007 total time=   0.0s\n",
            "[CV 10/10] END C=0.1, epsilon=0.001, gamma=1, kernel=rbf;, score=-0.004 total time=   0.0s\n",
            "[CV 1/10] END C=0.1, epsilon=0.001, gamma=1, kernel=poly;, score=-0.008 total time=   0.0s\n",
            "[CV 2/10] END C=0.1, epsilon=0.001, gamma=1, kernel=poly;, score=-0.007 total time=   0.0s\n",
            "[CV 3/10] END C=0.1, epsilon=0.001, gamma=1, kernel=poly;, score=-0.006 total time=   0.0s\n",
            "[CV 4/10] END C=0.1, epsilon=0.001, gamma=1, kernel=poly;, score=-0.012 total time=   0.0s\n",
            "[CV 5/10] END C=0.1, epsilon=0.001, gamma=1, kernel=poly;, score=-0.016 total time=   0.0s\n",
            "[CV 6/10] END C=0.1, epsilon=0.001, gamma=1, kernel=poly;, score=-0.010 total time=   0.0s\n",
            "[CV 7/10] END C=0.1, epsilon=0.001, gamma=1, kernel=poly;, score=-0.009 total time=   0.0s\n",
            "[CV 8/10] END C=0.1, epsilon=0.001, gamma=1, kernel=poly;, score=-0.002 total time=   0.0s\n",
            "[CV 9/10] END C=0.1, epsilon=0.001, gamma=1, kernel=poly;, score=-0.009 total time=   0.0s\n",
            "[CV 10/10] END C=0.1, epsilon=0.001, gamma=1, kernel=poly;, score=-0.008 total time=   0.0s\n",
            "[CV 1/10] END C=0.1, epsilon=0.001, gamma=1, kernel=linear;, score=-0.008 total time=   0.0s\n",
            "[CV 2/10] END C=0.1, epsilon=0.001, gamma=1, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 3/10] END C=0.1, epsilon=0.001, gamma=1, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 4/10] END C=0.1, epsilon=0.001, gamma=1, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 5/10] END C=0.1, epsilon=0.001, gamma=1, kernel=linear;, score=-0.006 total time=   0.0s\n",
            "[CV 6/10] END C=0.1, epsilon=0.001, gamma=1, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 7/10] END C=0.1, epsilon=0.001, gamma=1, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 8/10] END C=0.1, epsilon=0.001, gamma=1, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 9/10] END C=0.1, epsilon=0.001, gamma=1, kernel=linear;, score=-0.006 total time=   0.0s\n",
            "[CV 10/10] END C=0.1, epsilon=0.001, gamma=1, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 1/10] END C=0.1, epsilon=0.001, gamma=0.1, kernel=rbf;, score=-0.010 total time=   0.0s\n",
            "[CV 2/10] END C=0.1, epsilon=0.001, gamma=0.1, kernel=rbf;, score=-0.006 total time=   0.0s\n",
            "[CV 3/10] END C=0.1, epsilon=0.001, gamma=0.1, kernel=rbf;, score=-0.010 total time=   0.0s\n",
            "[CV 4/10] END C=0.1, epsilon=0.001, gamma=0.1, kernel=rbf;, score=-0.008 total time=   0.0s\n",
            "[CV 5/10] END C=0.1, epsilon=0.001, gamma=0.1, kernel=rbf;, score=-0.012 total time=   0.0s\n",
            "[CV 6/10] END C=0.1, epsilon=0.001, gamma=0.1, kernel=rbf;, score=-0.016 total time=   0.0s\n",
            "[CV 7/10] END C=0.1, epsilon=0.001, gamma=0.1, kernel=rbf;, score=-0.007 total time=   0.0s\n",
            "[CV 8/10] END C=0.1, epsilon=0.001, gamma=0.1, kernel=rbf;, score=-0.007 total time=   0.0s\n",
            "[CV 9/10] END C=0.1, epsilon=0.001, gamma=0.1, kernel=rbf;, score=-0.014 total time=   0.0s\n",
            "[CV 10/10] END C=0.1, epsilon=0.001, gamma=0.1, kernel=rbf;, score=-0.009 total time=   0.0s\n",
            "[CV 1/10] END C=0.1, epsilon=0.001, gamma=0.1, kernel=poly;, score=-0.035 total time=   0.0s\n",
            "[CV 2/10] END C=0.1, epsilon=0.001, gamma=0.1, kernel=poly;, score=-0.029 total time=   0.0s\n",
            "[CV 3/10] END C=0.1, epsilon=0.001, gamma=0.1, kernel=poly;, score=-0.040 total time=   0.0s\n",
            "[CV 4/10] END C=0.1, epsilon=0.001, gamma=0.1, kernel=poly;, score=-0.051 total time=   0.0s\n",
            "[CV 5/10] END C=0.1, epsilon=0.001, gamma=0.1, kernel=poly;, score=-0.067 total time=   0.0s\n",
            "[CV 6/10] END C=0.1, epsilon=0.001, gamma=0.1, kernel=poly;, score=-0.093 total time=   0.0s\n",
            "[CV 7/10] END C=0.1, epsilon=0.001, gamma=0.1, kernel=poly;, score=-0.040 total time=   0.0s\n",
            "[CV 8/10] END C=0.1, epsilon=0.001, gamma=0.1, kernel=poly;, score=-0.044 total time=   0.0s\n",
            "[CV 9/10] END C=0.1, epsilon=0.001, gamma=0.1, kernel=poly;, score=-0.073 total time=   0.0s\n",
            "[CV 10/10] END C=0.1, epsilon=0.001, gamma=0.1, kernel=poly;, score=-0.067 total time=   0.0s\n",
            "[CV 1/10] END C=0.1, epsilon=0.001, gamma=0.1, kernel=linear;, score=-0.008 total time=   0.0s\n",
            "[CV 2/10] END C=0.1, epsilon=0.001, gamma=0.1, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 3/10] END C=0.1, epsilon=0.001, gamma=0.1, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 4/10] END C=0.1, epsilon=0.001, gamma=0.1, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 5/10] END C=0.1, epsilon=0.001, gamma=0.1, kernel=linear;, score=-0.006 total time=   0.0s\n",
            "[CV 6/10] END C=0.1, epsilon=0.001, gamma=0.1, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 7/10] END C=0.1, epsilon=0.001, gamma=0.1, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 8/10] END C=0.1, epsilon=0.001, gamma=0.1, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 9/10] END C=0.1, epsilon=0.001, gamma=0.1, kernel=linear;, score=-0.006 total time=   0.0s\n",
            "[CV 10/10] END C=0.1, epsilon=0.001, gamma=0.1, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 1/10] END C=0.1, epsilon=0.001, gamma=0.01, kernel=rbf;, score=-0.031 total time=   0.0s\n",
            "[CV 2/10] END C=0.1, epsilon=0.001, gamma=0.01, kernel=rbf;, score=-0.024 total time=   0.0s\n",
            "[CV 3/10] END C=0.1, epsilon=0.001, gamma=0.01, kernel=rbf;, score=-0.036 total time=   0.0s\n",
            "[CV 4/10] END C=0.1, epsilon=0.001, gamma=0.01, kernel=rbf;, score=-0.046 total time=   0.0s\n",
            "[CV 5/10] END C=0.1, epsilon=0.001, gamma=0.01, kernel=rbf;, score=-0.060 total time=   0.0s\n",
            "[CV 6/10] END C=0.1, epsilon=0.001, gamma=0.01, kernel=rbf;, score=-0.085 total time=   0.0s\n",
            "[CV 7/10] END C=0.1, epsilon=0.001, gamma=0.01, kernel=rbf;, score=-0.036 total time=   0.0s\n",
            "[CV 8/10] END C=0.1, epsilon=0.001, gamma=0.01, kernel=rbf;, score=-0.039 total time=   0.0s\n",
            "[CV 9/10] END C=0.1, epsilon=0.001, gamma=0.01, kernel=rbf;, score=-0.066 total time=   0.0s\n",
            "[CV 10/10] END C=0.1, epsilon=0.001, gamma=0.01, kernel=rbf;, score=-0.060 total time=   0.0s\n",
            "[CV 1/10] END C=0.1, epsilon=0.001, gamma=0.01, kernel=poly;, score=-0.042 total time=   0.0s\n",
            "[CV 2/10] END C=0.1, epsilon=0.001, gamma=0.01, kernel=poly;, score=-0.031 total time=   0.0s\n",
            "[CV 3/10] END C=0.1, epsilon=0.001, gamma=0.01, kernel=poly;, score=-0.048 total time=   0.0s\n",
            "[CV 4/10] END C=0.1, epsilon=0.001, gamma=0.01, kernel=poly;, score=-0.061 total time=   0.0s\n",
            "[CV 5/10] END C=0.1, epsilon=0.001, gamma=0.01, kernel=poly;, score=-0.078 total time=   0.0s\n",
            "[CV 6/10] END C=0.1, epsilon=0.001, gamma=0.01, kernel=poly;, score=-0.111 total time=   0.0s\n",
            "[CV 7/10] END C=0.1, epsilon=0.001, gamma=0.01, kernel=poly;, score=-0.047 total time=   0.0s\n",
            "[CV 8/10] END C=0.1, epsilon=0.001, gamma=0.01, kernel=poly;, score=-0.053 total time=   0.0s\n",
            "[CV 9/10] END C=0.1, epsilon=0.001, gamma=0.01, kernel=poly;, score=-0.085 total time=   0.0s\n",
            "[CV 10/10] END C=0.1, epsilon=0.001, gamma=0.01, kernel=poly;, score=-0.080 total time=   0.0s\n",
            "[CV 1/10] END C=0.1, epsilon=0.001, gamma=0.01, kernel=linear;, score=-0.008 total time=   0.0s\n",
            "[CV 2/10] END C=0.1, epsilon=0.001, gamma=0.01, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 3/10] END C=0.1, epsilon=0.001, gamma=0.01, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 4/10] END C=0.1, epsilon=0.001, gamma=0.01, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 5/10] END C=0.1, epsilon=0.001, gamma=0.01, kernel=linear;, score=-0.006 total time=   0.0s\n",
            "[CV 6/10] END C=0.1, epsilon=0.001, gamma=0.01, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 7/10] END C=0.1, epsilon=0.001, gamma=0.01, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 8/10] END C=0.1, epsilon=0.001, gamma=0.01, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 9/10] END C=0.1, epsilon=0.001, gamma=0.01, kernel=linear;, score=-0.006 total time=   0.0s\n",
            "[CV 10/10] END C=0.1, epsilon=0.001, gamma=0.01, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 1/10] END C=0.1, epsilon=0.001, gamma=0.001, kernel=rbf;, score=-0.041 total time=   0.0s\n",
            "[CV 2/10] END C=0.1, epsilon=0.001, gamma=0.001, kernel=rbf;, score=-0.030 total time=   0.0s\n",
            "[CV 3/10] END C=0.1, epsilon=0.001, gamma=0.001, kernel=rbf;, score=-0.047 total time=   0.0s\n",
            "[CV 4/10] END C=0.1, epsilon=0.001, gamma=0.001, kernel=rbf;, score=-0.059 total time=   0.0s\n",
            "[CV 5/10] END C=0.1, epsilon=0.001, gamma=0.001, kernel=rbf;, score=-0.076 total time=   0.0s\n",
            "[CV 6/10] END C=0.1, epsilon=0.001, gamma=0.001, kernel=rbf;, score=-0.108 total time=   0.0s\n",
            "[CV 7/10] END C=0.1, epsilon=0.001, gamma=0.001, kernel=rbf;, score=-0.046 total time=   0.0s\n",
            "[CV 8/10] END C=0.1, epsilon=0.001, gamma=0.001, kernel=rbf;, score=-0.052 total time=   0.0s\n",
            "[CV 9/10] END C=0.1, epsilon=0.001, gamma=0.001, kernel=rbf;, score=-0.083 total time=   0.0s\n",
            "[CV 10/10] END C=0.1, epsilon=0.001, gamma=0.001, kernel=rbf;, score=-0.078 total time=   0.0s\n",
            "[CV 1/10] END C=0.1, epsilon=0.001, gamma=0.001, kernel=poly;, score=-0.042 total time=   0.0s\n",
            "[CV 2/10] END C=0.1, epsilon=0.001, gamma=0.001, kernel=poly;, score=-0.031 total time=   0.0s\n",
            "[CV 3/10] END C=0.1, epsilon=0.001, gamma=0.001, kernel=poly;, score=-0.048 total time=   0.0s\n",
            "[CV 4/10] END C=0.1, epsilon=0.001, gamma=0.001, kernel=poly;, score=-0.061 total time=   0.0s\n",
            "[CV 5/10] END C=0.1, epsilon=0.001, gamma=0.001, kernel=poly;, score=-0.078 total time=   0.0s\n",
            "[CV 6/10] END C=0.1, epsilon=0.001, gamma=0.001, kernel=poly;, score=-0.111 total time=   0.0s\n",
            "[CV 7/10] END C=0.1, epsilon=0.001, gamma=0.001, kernel=poly;, score=-0.047 total time=   0.0s\n",
            "[CV 8/10] END C=0.1, epsilon=0.001, gamma=0.001, kernel=poly;, score=-0.053 total time=   0.0s\n",
            "[CV 9/10] END C=0.1, epsilon=0.001, gamma=0.001, kernel=poly;, score=-0.085 total time=   0.0s\n",
            "[CV 10/10] END C=0.1, epsilon=0.001, gamma=0.001, kernel=poly;, score=-0.080 total time=   0.0s\n",
            "[CV 1/10] END C=0.1, epsilon=0.001, gamma=0.001, kernel=linear;, score=-0.008 total time=   0.0s\n",
            "[CV 2/10] END C=0.1, epsilon=0.001, gamma=0.001, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 3/10] END C=0.1, epsilon=0.001, gamma=0.001, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 4/10] END C=0.1, epsilon=0.001, gamma=0.001, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 5/10] END C=0.1, epsilon=0.001, gamma=0.001, kernel=linear;, score=-0.006 total time=   0.0s\n",
            "[CV 6/10] END C=0.1, epsilon=0.001, gamma=0.001, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 7/10] END C=0.1, epsilon=0.001, gamma=0.001, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 8/10] END C=0.1, epsilon=0.001, gamma=0.001, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 9/10] END C=0.1, epsilon=0.001, gamma=0.001, kernel=linear;, score=-0.006 total time=   0.0s\n",
            "[CV 10/10] END C=0.1, epsilon=0.001, gamma=0.001, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 1/10] END C=1, epsilon=0.0001, gamma=1, kernel=rbf;, score=-0.006 total time=   0.0s\n",
            "[CV 2/10] END C=1, epsilon=0.0001, gamma=1, kernel=rbf;, score=-0.003 total time=   0.0s\n",
            "[CV 3/10] END C=1, epsilon=0.0001, gamma=1, kernel=rbf;, score=-0.003 total time=   0.0s\n",
            "[CV 4/10] END C=1, epsilon=0.0001, gamma=1, kernel=rbf;, score=-0.003 total time=   0.0s\n",
            "[CV 5/10] END C=1, epsilon=0.0001, gamma=1, kernel=rbf;, score=-0.005 total time=   0.0s\n",
            "[CV 6/10] END C=1, epsilon=0.0001, gamma=1, kernel=rbf;, score=-0.002 total time=   0.0s\n",
            "[CV 7/10] END C=1, epsilon=0.0001, gamma=1, kernel=rbf;, score=-0.003 total time=   0.0s\n",
            "[CV 8/10] END C=1, epsilon=0.0001, gamma=1, kernel=rbf;, score=-0.004 total time=   0.0s\n",
            "[CV 9/10] END C=1, epsilon=0.0001, gamma=1, kernel=rbf;, score=-0.004 total time=   0.0s\n",
            "[CV 10/10] END C=1, epsilon=0.0001, gamma=1, kernel=rbf;, score=-0.003 total time=   0.0s\n",
            "[CV 1/10] END C=1, epsilon=0.0001, gamma=1, kernel=poly;, score=-0.006 total time=   0.0s\n",
            "[CV 2/10] END C=1, epsilon=0.0001, gamma=1, kernel=poly;, score=-0.005 total time=   0.0s\n",
            "[CV 3/10] END C=1, epsilon=0.0001, gamma=1, kernel=poly;, score=-0.006 total time=   0.0s\n",
            "[CV 4/10] END C=1, epsilon=0.0001, gamma=1, kernel=poly;, score=-0.006 total time=   0.0s\n",
            "[CV 5/10] END C=1, epsilon=0.0001, gamma=1, kernel=poly;, score=-0.021 total time=   0.0s\n",
            "[CV 6/10] END C=1, epsilon=0.0001, gamma=1, kernel=poly;, score=-0.006 total time=   0.0s\n",
            "[CV 7/10] END C=1, epsilon=0.0001, gamma=1, kernel=poly;, score=-0.009 total time=   0.0s\n",
            "[CV 8/10] END C=1, epsilon=0.0001, gamma=1, kernel=poly;, score=-0.002 total time=   0.0s\n",
            "[CV 9/10] END C=1, epsilon=0.0001, gamma=1, kernel=poly;, score=-0.010 total time=   0.0s\n",
            "[CV 10/10] END C=1, epsilon=0.0001, gamma=1, kernel=poly;, score=-0.009 total time=   0.0s\n",
            "[CV 1/10] END C=1, epsilon=0.0001, gamma=1, kernel=linear;, score=-0.007 total time=   0.0s\n",
            "[CV 2/10] END C=1, epsilon=0.0001, gamma=1, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 3/10] END C=1, epsilon=0.0001, gamma=1, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 4/10] END C=1, epsilon=0.0001, gamma=1, kernel=linear;, score=-0.003 total time=   0.0s\n",
            "[CV 5/10] END C=1, epsilon=0.0001, gamma=1, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 6/10] END C=1, epsilon=0.0001, gamma=1, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 7/10] END C=1, epsilon=0.0001, gamma=1, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 8/10] END C=1, epsilon=0.0001, gamma=1, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 9/10] END C=1, epsilon=0.0001, gamma=1, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 10/10] END C=1, epsilon=0.0001, gamma=1, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 1/10] END C=1, epsilon=0.0001, gamma=0.1, kernel=rbf;, score=-0.008 total time=   0.0s\n",
            "[CV 2/10] END C=1, epsilon=0.0001, gamma=0.1, kernel=rbf;, score=-0.004 total time=   0.0s\n",
            "[CV 3/10] END C=1, epsilon=0.0001, gamma=0.1, kernel=rbf;, score=-0.005 total time=   0.0s\n",
            "[CV 4/10] END C=1, epsilon=0.0001, gamma=0.1, kernel=rbf;, score=-0.004 total time=   0.0s\n",
            "[CV 5/10] END C=1, epsilon=0.0001, gamma=0.1, kernel=rbf;, score=-0.007 total time=   0.0s\n",
            "[CV 6/10] END C=1, epsilon=0.0001, gamma=0.1, kernel=rbf;, score=-0.004 total time=   0.0s\n",
            "[CV 7/10] END C=1, epsilon=0.0001, gamma=0.1, kernel=rbf;, score=-0.005 total time=   0.0s\n",
            "[CV 8/10] END C=1, epsilon=0.0001, gamma=0.1, kernel=rbf;, score=-0.003 total time=   0.0s\n",
            "[CV 9/10] END C=1, epsilon=0.0001, gamma=0.1, kernel=rbf;, score=-0.005 total time=   0.0s\n",
            "[CV 10/10] END C=1, epsilon=0.0001, gamma=0.1, kernel=rbf;, score=-0.004 total time=   0.0s\n",
            "[CV 1/10] END C=1, epsilon=0.0001, gamma=0.1, kernel=poly;, score=-0.013 total time=   0.0s\n",
            "[CV 2/10] END C=1, epsilon=0.0001, gamma=0.1, kernel=poly;, score=-0.014 total time=   0.0s\n",
            "[CV 3/10] END C=1, epsilon=0.0001, gamma=0.1, kernel=poly;, score=-0.015 total time=   0.0s\n",
            "[CV 4/10] END C=1, epsilon=0.0001, gamma=0.1, kernel=poly;, score=-0.013 total time=   0.0s\n",
            "[CV 5/10] END C=1, epsilon=0.0001, gamma=0.1, kernel=poly;, score=-0.025 total time=   0.0s\n",
            "[CV 6/10] END C=1, epsilon=0.0001, gamma=0.1, kernel=poly;, score=-0.021 total time=   0.0s\n",
            "[CV 7/10] END C=1, epsilon=0.0001, gamma=0.1, kernel=poly;, score=-0.014 total time=   0.0s\n",
            "[CV 8/10] END C=1, epsilon=0.0001, gamma=0.1, kernel=poly;, score=-0.009 total time=   0.0s\n",
            "[CV 9/10] END C=1, epsilon=0.0001, gamma=0.1, kernel=poly;, score=-0.024 total time=   0.0s\n",
            "[CV 10/10] END C=1, epsilon=0.0001, gamma=0.1, kernel=poly;, score=-0.018 total time=   0.0s\n",
            "[CV 1/10] END C=1, epsilon=0.0001, gamma=0.1, kernel=linear;, score=-0.007 total time=   0.0s\n",
            "[CV 2/10] END C=1, epsilon=0.0001, gamma=0.1, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 3/10] END C=1, epsilon=0.0001, gamma=0.1, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 4/10] END C=1, epsilon=0.0001, gamma=0.1, kernel=linear;, score=-0.003 total time=   0.0s\n",
            "[CV 5/10] END C=1, epsilon=0.0001, gamma=0.1, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 6/10] END C=1, epsilon=0.0001, gamma=0.1, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 7/10] END C=1, epsilon=0.0001, gamma=0.1, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 8/10] END C=1, epsilon=0.0001, gamma=0.1, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 9/10] END C=1, epsilon=0.0001, gamma=0.1, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 10/10] END C=1, epsilon=0.0001, gamma=0.1, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 1/10] END C=1, epsilon=0.0001, gamma=0.01, kernel=rbf;, score=-0.010 total time=   0.0s\n",
            "[CV 2/10] END C=1, epsilon=0.0001, gamma=0.01, kernel=rbf;, score=-0.006 total time=   0.0s\n",
            "[CV 3/10] END C=1, epsilon=0.0001, gamma=0.01, kernel=rbf;, score=-0.009 total time=   0.0s\n",
            "[CV 4/10] END C=1, epsilon=0.0001, gamma=0.01, kernel=rbf;, score=-0.007 total time=   0.0s\n",
            "[CV 5/10] END C=1, epsilon=0.0001, gamma=0.01, kernel=rbf;, score=-0.011 total time=   0.0s\n",
            "[CV 6/10] END C=1, epsilon=0.0001, gamma=0.01, kernel=rbf;, score=-0.014 total time=   0.0s\n",
            "[CV 7/10] END C=1, epsilon=0.0001, gamma=0.01, kernel=rbf;, score=-0.007 total time=   0.0s\n",
            "[CV 8/10] END C=1, epsilon=0.0001, gamma=0.01, kernel=rbf;, score=-0.007 total time=   0.0s\n",
            "[CV 9/10] END C=1, epsilon=0.0001, gamma=0.01, kernel=rbf;, score=-0.013 total time=   0.0s\n",
            "[CV 10/10] END C=1, epsilon=0.0001, gamma=0.01, kernel=rbf;, score=-0.009 total time=   0.0s\n",
            "[CV 1/10] END C=1, epsilon=0.0001, gamma=0.01, kernel=poly;, score=-0.042 total time=   0.0s\n",
            "[CV 2/10] END C=1, epsilon=0.0001, gamma=0.01, kernel=poly;, score=-0.031 total time=   0.0s\n",
            "[CV 3/10] END C=1, epsilon=0.0001, gamma=0.01, kernel=poly;, score=-0.048 total time=   0.0s\n",
            "[CV 4/10] END C=1, epsilon=0.0001, gamma=0.01, kernel=poly;, score=-0.061 total time=   0.0s\n",
            "[CV 5/10] END C=1, epsilon=0.0001, gamma=0.01, kernel=poly;, score=-0.078 total time=   0.0s\n",
            "[CV 6/10] END C=1, epsilon=0.0001, gamma=0.01, kernel=poly;, score=-0.111 total time=   0.0s\n",
            "[CV 7/10] END C=1, epsilon=0.0001, gamma=0.01, kernel=poly;, score=-0.047 total time=   0.0s\n",
            "[CV 8/10] END C=1, epsilon=0.0001, gamma=0.01, kernel=poly;, score=-0.053 total time=   0.0s\n",
            "[CV 9/10] END C=1, epsilon=0.0001, gamma=0.01, kernel=poly;, score=-0.085 total time=   0.0s\n",
            "[CV 10/10] END C=1, epsilon=0.0001, gamma=0.01, kernel=poly;, score=-0.080 total time=   0.0s\n",
            "[CV 1/10] END C=1, epsilon=0.0001, gamma=0.01, kernel=linear;, score=-0.007 total time=   0.0s\n",
            "[CV 2/10] END C=1, epsilon=0.0001, gamma=0.01, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 3/10] END C=1, epsilon=0.0001, gamma=0.01, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 4/10] END C=1, epsilon=0.0001, gamma=0.01, kernel=linear;, score=-0.003 total time=   0.0s\n",
            "[CV 5/10] END C=1, epsilon=0.0001, gamma=0.01, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 6/10] END C=1, epsilon=0.0001, gamma=0.01, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 7/10] END C=1, epsilon=0.0001, gamma=0.01, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 8/10] END C=1, epsilon=0.0001, gamma=0.01, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 9/10] END C=1, epsilon=0.0001, gamma=0.01, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 10/10] END C=1, epsilon=0.0001, gamma=0.01, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 1/10] END C=1, epsilon=0.0001, gamma=0.001, kernel=rbf;, score=-0.031 total time=   0.0s\n",
            "[CV 2/10] END C=1, epsilon=0.0001, gamma=0.001, kernel=rbf;, score=-0.024 total time=   0.0s\n",
            "[CV 3/10] END C=1, epsilon=0.0001, gamma=0.001, kernel=rbf;, score=-0.036 total time=   0.0s\n",
            "[CV 4/10] END C=1, epsilon=0.0001, gamma=0.001, kernel=rbf;, score=-0.046 total time=   0.0s\n",
            "[CV 5/10] END C=1, epsilon=0.0001, gamma=0.001, kernel=rbf;, score=-0.059 total time=   0.0s\n",
            "[CV 6/10] END C=1, epsilon=0.0001, gamma=0.001, kernel=rbf;, score=-0.084 total time=   0.0s\n",
            "[CV 7/10] END C=1, epsilon=0.0001, gamma=0.001, kernel=rbf;, score=-0.035 total time=   0.0s\n",
            "[CV 8/10] END C=1, epsilon=0.0001, gamma=0.001, kernel=rbf;, score=-0.039 total time=   0.0s\n",
            "[CV 9/10] END C=1, epsilon=0.0001, gamma=0.001, kernel=rbf;, score=-0.066 total time=   0.0s\n",
            "[CV 10/10] END C=1, epsilon=0.0001, gamma=0.001, kernel=rbf;, score=-0.060 total time=   0.0s\n",
            "[CV 1/10] END C=1, epsilon=0.0001, gamma=0.001, kernel=poly;, score=-0.042 total time=   0.0s\n",
            "[CV 2/10] END C=1, epsilon=0.0001, gamma=0.001, kernel=poly;, score=-0.031 total time=   0.0s\n",
            "[CV 3/10] END C=1, epsilon=0.0001, gamma=0.001, kernel=poly;, score=-0.048 total time=   0.0s\n",
            "[CV 4/10] END C=1, epsilon=0.0001, gamma=0.001, kernel=poly;, score=-0.061 total time=   0.0s\n",
            "[CV 5/10] END C=1, epsilon=0.0001, gamma=0.001, kernel=poly;, score=-0.078 total time=   0.0s\n",
            "[CV 6/10] END C=1, epsilon=0.0001, gamma=0.001, kernel=poly;, score=-0.111 total time=   0.0s\n",
            "[CV 7/10] END C=1, epsilon=0.0001, gamma=0.001, kernel=poly;, score=-0.047 total time=   0.0s\n",
            "[CV 8/10] END C=1, epsilon=0.0001, gamma=0.001, kernel=poly;, score=-0.053 total time=   0.0s\n",
            "[CV 9/10] END C=1, epsilon=0.0001, gamma=0.001, kernel=poly;, score=-0.085 total time=   0.0s\n",
            "[CV 10/10] END C=1, epsilon=0.0001, gamma=0.001, kernel=poly;, score=-0.080 total time=   0.0s\n",
            "[CV 1/10] END C=1, epsilon=0.0001, gamma=0.001, kernel=linear;, score=-0.007 total time=   0.0s\n",
            "[CV 2/10] END C=1, epsilon=0.0001, gamma=0.001, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 3/10] END C=1, epsilon=0.0001, gamma=0.001, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 4/10] END C=1, epsilon=0.0001, gamma=0.001, kernel=linear;, score=-0.003 total time=   0.0s\n",
            "[CV 5/10] END C=1, epsilon=0.0001, gamma=0.001, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 6/10] END C=1, epsilon=0.0001, gamma=0.001, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 7/10] END C=1, epsilon=0.0001, gamma=0.001, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 8/10] END C=1, epsilon=0.0001, gamma=0.001, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 9/10] END C=1, epsilon=0.0001, gamma=0.001, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 10/10] END C=1, epsilon=0.0001, gamma=0.001, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 1/10] END C=1, epsilon=0.001, gamma=1, kernel=rbf;, score=-0.006 total time=   0.0s\n",
            "[CV 2/10] END C=1, epsilon=0.001, gamma=1, kernel=rbf;, score=-0.003 total time=   0.0s\n",
            "[CV 3/10] END C=1, epsilon=0.001, gamma=1, kernel=rbf;, score=-0.003 total time=   0.0s\n",
            "[CV 4/10] END C=1, epsilon=0.001, gamma=1, kernel=rbf;, score=-0.003 total time=   0.0s\n",
            "[CV 5/10] END C=1, epsilon=0.001, gamma=1, kernel=rbf;, score=-0.005 total time=   0.0s\n",
            "[CV 6/10] END C=1, epsilon=0.001, gamma=1, kernel=rbf;, score=-0.002 total time=   0.0s\n",
            "[CV 7/10] END C=1, epsilon=0.001, gamma=1, kernel=rbf;, score=-0.003 total time=   0.0s\n",
            "[CV 8/10] END C=1, epsilon=0.001, gamma=1, kernel=rbf;, score=-0.004 total time=   0.0s\n",
            "[CV 9/10] END C=1, epsilon=0.001, gamma=1, kernel=rbf;, score=-0.004 total time=   0.0s\n",
            "[CV 10/10] END C=1, epsilon=0.001, gamma=1, kernel=rbf;, score=-0.003 total time=   0.0s\n",
            "[CV 1/10] END C=1, epsilon=0.001, gamma=1, kernel=poly;, score=-0.006 total time=   0.0s\n",
            "[CV 2/10] END C=1, epsilon=0.001, gamma=1, kernel=poly;, score=-0.005 total time=   0.0s\n",
            "[CV 3/10] END C=1, epsilon=0.001, gamma=1, kernel=poly;, score=-0.006 total time=   0.0s\n",
            "[CV 4/10] END C=1, epsilon=0.001, gamma=1, kernel=poly;, score=-0.007 total time=   0.0s\n",
            "[CV 5/10] END C=1, epsilon=0.001, gamma=1, kernel=poly;, score=-0.021 total time=   0.0s\n",
            "[CV 6/10] END C=1, epsilon=0.001, gamma=1, kernel=poly;, score=-0.006 total time=   0.0s\n",
            "[CV 7/10] END C=1, epsilon=0.001, gamma=1, kernel=poly;, score=-0.009 total time=   0.0s\n",
            "[CV 8/10] END C=1, epsilon=0.001, gamma=1, kernel=poly;, score=-0.002 total time=   0.0s\n",
            "[CV 9/10] END C=1, epsilon=0.001, gamma=1, kernel=poly;, score=-0.010 total time=   0.0s\n",
            "[CV 10/10] END C=1, epsilon=0.001, gamma=1, kernel=poly;, score=-0.009 total time=   0.0s\n",
            "[CV 1/10] END C=1, epsilon=0.001, gamma=1, kernel=linear;, score=-0.007 total time=   0.0s\n",
            "[CV 2/10] END C=1, epsilon=0.001, gamma=1, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 3/10] END C=1, epsilon=0.001, gamma=1, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 4/10] END C=1, epsilon=0.001, gamma=1, kernel=linear;, score=-0.003 total time=   0.0s\n",
            "[CV 5/10] END C=1, epsilon=0.001, gamma=1, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 6/10] END C=1, epsilon=0.001, gamma=1, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 7/10] END C=1, epsilon=0.001, gamma=1, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 8/10] END C=1, epsilon=0.001, gamma=1, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 9/10] END C=1, epsilon=0.001, gamma=1, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 10/10] END C=1, epsilon=0.001, gamma=1, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 1/10] END C=1, epsilon=0.001, gamma=0.1, kernel=rbf;, score=-0.008 total time=   0.0s\n",
            "[CV 2/10] END C=1, epsilon=0.001, gamma=0.1, kernel=rbf;, score=-0.004 total time=   0.0s\n",
            "[CV 3/10] END C=1, epsilon=0.001, gamma=0.1, kernel=rbf;, score=-0.005 total time=   0.0s\n",
            "[CV 4/10] END C=1, epsilon=0.001, gamma=0.1, kernel=rbf;, score=-0.004 total time=   0.0s\n",
            "[CV 5/10] END C=1, epsilon=0.001, gamma=0.1, kernel=rbf;, score=-0.007 total time=   0.0s\n",
            "[CV 6/10] END C=1, epsilon=0.001, gamma=0.1, kernel=rbf;, score=-0.004 total time=   0.0s\n",
            "[CV 7/10] END C=1, epsilon=0.001, gamma=0.1, kernel=rbf;, score=-0.005 total time=   0.0s\n",
            "[CV 8/10] END C=1, epsilon=0.001, gamma=0.1, kernel=rbf;, score=-0.003 total time=   0.0s\n",
            "[CV 9/10] END C=1, epsilon=0.001, gamma=0.1, kernel=rbf;, score=-0.005 total time=   0.0s\n",
            "[CV 10/10] END C=1, epsilon=0.001, gamma=0.1, kernel=rbf;, score=-0.004 total time=   0.0s\n",
            "[CV 1/10] END C=1, epsilon=0.001, gamma=0.1, kernel=poly;, score=-0.013 total time=   0.0s\n",
            "[CV 2/10] END C=1, epsilon=0.001, gamma=0.1, kernel=poly;, score=-0.014 total time=   0.0s\n",
            "[CV 3/10] END C=1, epsilon=0.001, gamma=0.1, kernel=poly;, score=-0.015 total time=   0.0s\n",
            "[CV 4/10] END C=1, epsilon=0.001, gamma=0.1, kernel=poly;, score=-0.013 total time=   0.0s\n",
            "[CV 5/10] END C=1, epsilon=0.001, gamma=0.1, kernel=poly;, score=-0.025 total time=   0.0s\n",
            "[CV 6/10] END C=1, epsilon=0.001, gamma=0.1, kernel=poly;, score=-0.021 total time=   0.0s\n",
            "[CV 7/10] END C=1, epsilon=0.001, gamma=0.1, kernel=poly;, score=-0.014 total time=   0.0s\n",
            "[CV 8/10] END C=1, epsilon=0.001, gamma=0.1, kernel=poly;, score=-0.009 total time=   0.0s\n",
            "[CV 9/10] END C=1, epsilon=0.001, gamma=0.1, kernel=poly;, score=-0.024 total time=   0.0s\n",
            "[CV 10/10] END C=1, epsilon=0.001, gamma=0.1, kernel=poly;, score=-0.018 total time=   0.0s\n",
            "[CV 1/10] END C=1, epsilon=0.001, gamma=0.1, kernel=linear;, score=-0.007 total time=   0.0s\n",
            "[CV 2/10] END C=1, epsilon=0.001, gamma=0.1, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 3/10] END C=1, epsilon=0.001, gamma=0.1, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 4/10] END C=1, epsilon=0.001, gamma=0.1, kernel=linear;, score=-0.003 total time=   0.0s\n",
            "[CV 5/10] END C=1, epsilon=0.001, gamma=0.1, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 6/10] END C=1, epsilon=0.001, gamma=0.1, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 7/10] END C=1, epsilon=0.001, gamma=0.1, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 8/10] END C=1, epsilon=0.001, gamma=0.1, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 9/10] END C=1, epsilon=0.001, gamma=0.1, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 10/10] END C=1, epsilon=0.001, gamma=0.1, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 1/10] END C=1, epsilon=0.001, gamma=0.01, kernel=rbf;, score=-0.010 total time=   0.0s\n",
            "[CV 2/10] END C=1, epsilon=0.001, gamma=0.01, kernel=rbf;, score=-0.006 total time=   0.0s\n",
            "[CV 3/10] END C=1, epsilon=0.001, gamma=0.01, kernel=rbf;, score=-0.009 total time=   0.0s\n",
            "[CV 4/10] END C=1, epsilon=0.001, gamma=0.01, kernel=rbf;, score=-0.007 total time=   0.0s\n",
            "[CV 5/10] END C=1, epsilon=0.001, gamma=0.01, kernel=rbf;, score=-0.011 total time=   0.0s\n",
            "[CV 6/10] END C=1, epsilon=0.001, gamma=0.01, kernel=rbf;, score=-0.014 total time=   0.0s\n",
            "[CV 7/10] END C=1, epsilon=0.001, gamma=0.01, kernel=rbf;, score=-0.007 total time=   0.0s\n",
            "[CV 8/10] END C=1, epsilon=0.001, gamma=0.01, kernel=rbf;, score=-0.007 total time=   0.0s\n",
            "[CV 9/10] END C=1, epsilon=0.001, gamma=0.01, kernel=rbf;, score=-0.013 total time=   0.0s\n",
            "[CV 10/10] END C=1, epsilon=0.001, gamma=0.01, kernel=rbf;, score=-0.009 total time=   0.0s\n",
            "[CV 1/10] END C=1, epsilon=0.001, gamma=0.01, kernel=poly;, score=-0.042 total time=   0.0s\n",
            "[CV 2/10] END C=1, epsilon=0.001, gamma=0.01, kernel=poly;, score=-0.031 total time=   0.0s\n",
            "[CV 3/10] END C=1, epsilon=0.001, gamma=0.01, kernel=poly;, score=-0.048 total time=   0.0s\n",
            "[CV 4/10] END C=1, epsilon=0.001, gamma=0.01, kernel=poly;, score=-0.061 total time=   0.0s\n",
            "[CV 5/10] END C=1, epsilon=0.001, gamma=0.01, kernel=poly;, score=-0.078 total time=   0.0s\n",
            "[CV 6/10] END C=1, epsilon=0.001, gamma=0.01, kernel=poly;, score=-0.111 total time=   0.0s\n",
            "[CV 7/10] END C=1, epsilon=0.001, gamma=0.01, kernel=poly;, score=-0.047 total time=   0.0s\n",
            "[CV 8/10] END C=1, epsilon=0.001, gamma=0.01, kernel=poly;, score=-0.053 total time=   0.0s\n",
            "[CV 9/10] END C=1, epsilon=0.001, gamma=0.01, kernel=poly;, score=-0.085 total time=   0.0s\n",
            "[CV 10/10] END C=1, epsilon=0.001, gamma=0.01, kernel=poly;, score=-0.080 total time=   0.0s\n",
            "[CV 1/10] END C=1, epsilon=0.001, gamma=0.01, kernel=linear;, score=-0.007 total time=   0.0s\n",
            "[CV 2/10] END C=1, epsilon=0.001, gamma=0.01, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 3/10] END C=1, epsilon=0.001, gamma=0.01, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 4/10] END C=1, epsilon=0.001, gamma=0.01, kernel=linear;, score=-0.003 total time=   0.0s\n",
            "[CV 5/10] END C=1, epsilon=0.001, gamma=0.01, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 6/10] END C=1, epsilon=0.001, gamma=0.01, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 7/10] END C=1, epsilon=0.001, gamma=0.01, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 8/10] END C=1, epsilon=0.001, gamma=0.01, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 9/10] END C=1, epsilon=0.001, gamma=0.01, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 10/10] END C=1, epsilon=0.001, gamma=0.01, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 1/10] END C=1, epsilon=0.001, gamma=0.001, kernel=rbf;, score=-0.031 total time=   0.0s\n",
            "[CV 2/10] END C=1, epsilon=0.001, gamma=0.001, kernel=rbf;, score=-0.024 total time=   0.0s\n",
            "[CV 3/10] END C=1, epsilon=0.001, gamma=0.001, kernel=rbf;, score=-0.036 total time=   0.0s\n",
            "[CV 4/10] END C=1, epsilon=0.001, gamma=0.001, kernel=rbf;, score=-0.046 total time=   0.0s\n",
            "[CV 5/10] END C=1, epsilon=0.001, gamma=0.001, kernel=rbf;, score=-0.059 total time=   0.0s\n",
            "[CV 6/10] END C=1, epsilon=0.001, gamma=0.001, kernel=rbf;, score=-0.085 total time=   0.0s\n",
            "[CV 7/10] END C=1, epsilon=0.001, gamma=0.001, kernel=rbf;, score=-0.035 total time=   0.0s\n",
            "[CV 8/10] END C=1, epsilon=0.001, gamma=0.001, kernel=rbf;, score=-0.039 total time=   0.0s\n",
            "[CV 9/10] END C=1, epsilon=0.001, gamma=0.001, kernel=rbf;, score=-0.066 total time=   0.0s\n",
            "[CV 10/10] END C=1, epsilon=0.001, gamma=0.001, kernel=rbf;, score=-0.060 total time=   0.0s\n",
            "[CV 1/10] END C=1, epsilon=0.001, gamma=0.001, kernel=poly;, score=-0.042 total time=   0.0s\n",
            "[CV 2/10] END C=1, epsilon=0.001, gamma=0.001, kernel=poly;, score=-0.031 total time=   0.0s\n",
            "[CV 3/10] END C=1, epsilon=0.001, gamma=0.001, kernel=poly;, score=-0.048 total time=   0.0s\n",
            "[CV 4/10] END C=1, epsilon=0.001, gamma=0.001, kernel=poly;, score=-0.061 total time=   0.0s\n",
            "[CV 5/10] END C=1, epsilon=0.001, gamma=0.001, kernel=poly;, score=-0.078 total time=   0.0s\n",
            "[CV 6/10] END C=1, epsilon=0.001, gamma=0.001, kernel=poly;, score=-0.111 total time=   0.0s\n",
            "[CV 7/10] END C=1, epsilon=0.001, gamma=0.001, kernel=poly;, score=-0.047 total time=   0.0s\n",
            "[CV 8/10] END C=1, epsilon=0.001, gamma=0.001, kernel=poly;, score=-0.053 total time=   0.0s\n",
            "[CV 9/10] END C=1, epsilon=0.001, gamma=0.001, kernel=poly;, score=-0.085 total time=   0.0s\n",
            "[CV 10/10] END C=1, epsilon=0.001, gamma=0.001, kernel=poly;, score=-0.080 total time=   0.0s\n",
            "[CV 1/10] END C=1, epsilon=0.001, gamma=0.001, kernel=linear;, score=-0.007 total time=   0.0s\n",
            "[CV 2/10] END C=1, epsilon=0.001, gamma=0.001, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 3/10] END C=1, epsilon=0.001, gamma=0.001, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 4/10] END C=1, epsilon=0.001, gamma=0.001, kernel=linear;, score=-0.003 total time=   0.0s\n",
            "[CV 5/10] END C=1, epsilon=0.001, gamma=0.001, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 6/10] END C=1, epsilon=0.001, gamma=0.001, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 7/10] END C=1, epsilon=0.001, gamma=0.001, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 8/10] END C=1, epsilon=0.001, gamma=0.001, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 9/10] END C=1, epsilon=0.001, gamma=0.001, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 10/10] END C=1, epsilon=0.001, gamma=0.001, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 1/10] END C=10, epsilon=0.0001, gamma=1, kernel=rbf;, score=-0.008 total time=   0.0s\n",
            "[CV 2/10] END C=10, epsilon=0.0001, gamma=1, kernel=rbf;, score=-0.002 total time=   0.0s\n",
            "[CV 3/10] END C=10, epsilon=0.0001, gamma=1, kernel=rbf;, score=-0.003 total time=   0.0s\n",
            "[CV 4/10] END C=10, epsilon=0.0001, gamma=1, kernel=rbf;, score=-0.002 total time=   0.0s\n",
            "[CV 5/10] END C=10, epsilon=0.0001, gamma=1, kernel=rbf;, score=-0.005 total time=   0.0s\n",
            "[CV 6/10] END C=10, epsilon=0.0001, gamma=1, kernel=rbf;, score=-0.002 total time=   0.0s\n",
            "[CV 7/10] END C=10, epsilon=0.0001, gamma=1, kernel=rbf;, score=-0.002 total time=   0.0s\n",
            "[CV 8/10] END C=10, epsilon=0.0001, gamma=1, kernel=rbf;, score=-0.003 total time=   0.0s\n",
            "[CV 9/10] END C=10, epsilon=0.0001, gamma=1, kernel=rbf;, score=-0.004 total time=   0.0s\n",
            "[CV 10/10] END C=10, epsilon=0.0001, gamma=1, kernel=rbf;, score=-0.002 total time=   0.0s\n",
            "[CV 1/10] END C=10, epsilon=0.0001, gamma=1, kernel=poly;, score=-0.006 total time=   0.1s\n",
            "[CV 2/10] END C=10, epsilon=0.0001, gamma=1, kernel=poly;, score=-0.004 total time=   0.1s\n",
            "[CV 3/10] END C=10, epsilon=0.0001, gamma=1, kernel=poly;, score=-0.006 total time=   0.1s\n",
            "[CV 4/10] END C=10, epsilon=0.0001, gamma=1, kernel=poly;, score=-0.004 total time=   0.1s\n",
            "[CV 5/10] END C=10, epsilon=0.0001, gamma=1, kernel=poly;, score=-0.026 total time=   0.0s\n",
            "[CV 6/10] END C=10, epsilon=0.0001, gamma=1, kernel=poly;, score=-0.006 total time=   0.1s\n",
            "[CV 7/10] END C=10, epsilon=0.0001, gamma=1, kernel=poly;, score=-0.008 total time=   0.1s\n",
            "[CV 8/10] END C=10, epsilon=0.0001, gamma=1, kernel=poly;, score=-0.001 total time=   0.1s\n",
            "[CV 9/10] END C=10, epsilon=0.0001, gamma=1, kernel=poly;, score=-0.017 total time=   0.0s\n",
            "[CV 10/10] END C=10, epsilon=0.0001, gamma=1, kernel=poly;, score=-0.010 total time=   0.0s\n",
            "[CV 1/10] END C=10, epsilon=0.0001, gamma=1, kernel=linear;, score=-0.007 total time=   0.0s\n",
            "[CV 2/10] END C=10, epsilon=0.0001, gamma=1, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 3/10] END C=10, epsilon=0.0001, gamma=1, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 4/10] END C=10, epsilon=0.0001, gamma=1, kernel=linear;, score=-0.003 total time=   0.0s\n",
            "[CV 5/10] END C=10, epsilon=0.0001, gamma=1, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 6/10] END C=10, epsilon=0.0001, gamma=1, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 7/10] END C=10, epsilon=0.0001, gamma=1, kernel=linear;, score=-0.006 total time=   0.0s\n",
            "[CV 8/10] END C=10, epsilon=0.0001, gamma=1, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 9/10] END C=10, epsilon=0.0001, gamma=1, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 10/10] END C=10, epsilon=0.0001, gamma=1, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 1/10] END C=10, epsilon=0.0001, gamma=0.1, kernel=rbf;, score=-0.008 total time=   0.0s\n",
            "[CV 2/10] END C=10, epsilon=0.0001, gamma=0.1, kernel=rbf;, score=-0.004 total time=   0.0s\n",
            "[CV 3/10] END C=10, epsilon=0.0001, gamma=0.1, kernel=rbf;, score=-0.004 total time=   0.0s\n",
            "[CV 4/10] END C=10, epsilon=0.0001, gamma=0.1, kernel=rbf;, score=-0.003 total time=   0.0s\n",
            "[CV 5/10] END C=10, epsilon=0.0001, gamma=0.1, kernel=rbf;, score=-0.007 total time=   0.0s\n",
            "[CV 6/10] END C=10, epsilon=0.0001, gamma=0.1, kernel=rbf;, score=-0.003 total time=   0.0s\n",
            "[CV 7/10] END C=10, epsilon=0.0001, gamma=0.1, kernel=rbf;, score=-0.005 total time=   0.0s\n",
            "[CV 8/10] END C=10, epsilon=0.0001, gamma=0.1, kernel=rbf;, score=-0.004 total time=   0.0s\n",
            "[CV 9/10] END C=10, epsilon=0.0001, gamma=0.1, kernel=rbf;, score=-0.006 total time=   0.0s\n",
            "[CV 10/10] END C=10, epsilon=0.0001, gamma=0.1, kernel=rbf;, score=-0.004 total time=   0.0s\n",
            "[CV 1/10] END C=10, epsilon=0.0001, gamma=0.1, kernel=poly;, score=-0.010 total time=   0.0s\n",
            "[CV 2/10] END C=10, epsilon=0.0001, gamma=0.1, kernel=poly;, score=-0.008 total time=   0.0s\n",
            "[CV 3/10] END C=10, epsilon=0.0001, gamma=0.1, kernel=poly;, score=-0.008 total time=   0.0s\n",
            "[CV 4/10] END C=10, epsilon=0.0001, gamma=0.1, kernel=poly;, score=-0.008 total time=   0.0s\n",
            "[CV 5/10] END C=10, epsilon=0.0001, gamma=0.1, kernel=poly;, score=-0.017 total time=   0.0s\n",
            "[CV 6/10] END C=10, epsilon=0.0001, gamma=0.1, kernel=poly;, score=-0.010 total time=   0.0s\n",
            "[CV 7/10] END C=10, epsilon=0.0001, gamma=0.1, kernel=poly;, score=-0.010 total time=   0.0s\n",
            "[CV 8/10] END C=10, epsilon=0.0001, gamma=0.1, kernel=poly;, score=-0.002 total time=   0.0s\n",
            "[CV 9/10] END C=10, epsilon=0.0001, gamma=0.1, kernel=poly;, score=-0.012 total time=   0.0s\n",
            "[CV 10/10] END C=10, epsilon=0.0001, gamma=0.1, kernel=poly;, score=-0.009 total time=   0.0s\n",
            "[CV 1/10] END C=10, epsilon=0.0001, gamma=0.1, kernel=linear;, score=-0.007 total time=   0.0s\n",
            "[CV 2/10] END C=10, epsilon=0.0001, gamma=0.1, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 3/10] END C=10, epsilon=0.0001, gamma=0.1, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 4/10] END C=10, epsilon=0.0001, gamma=0.1, kernel=linear;, score=-0.003 total time=   0.0s\n",
            "[CV 5/10] END C=10, epsilon=0.0001, gamma=0.1, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 6/10] END C=10, epsilon=0.0001, gamma=0.1, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 7/10] END C=10, epsilon=0.0001, gamma=0.1, kernel=linear;, score=-0.006 total time=   0.0s\n",
            "[CV 8/10] END C=10, epsilon=0.0001, gamma=0.1, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 9/10] END C=10, epsilon=0.0001, gamma=0.1, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 10/10] END C=10, epsilon=0.0001, gamma=0.1, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 1/10] END C=10, epsilon=0.0001, gamma=0.01, kernel=rbf;, score=-0.008 total time=   0.0s\n",
            "[CV 2/10] END C=10, epsilon=0.0001, gamma=0.01, kernel=rbf;, score=-0.004 total time=   0.0s\n",
            "[CV 3/10] END C=10, epsilon=0.0001, gamma=0.01, kernel=rbf;, score=-0.004 total time=   0.0s\n",
            "[CV 4/10] END C=10, epsilon=0.0001, gamma=0.01, kernel=rbf;, score=-0.004 total time=   0.0s\n",
            "[CV 5/10] END C=10, epsilon=0.0001, gamma=0.01, kernel=rbf;, score=-0.006 total time=   0.0s\n",
            "[CV 6/10] END C=10, epsilon=0.0001, gamma=0.01, kernel=rbf;, score=-0.004 total time=   0.0s\n",
            "[CV 7/10] END C=10, epsilon=0.0001, gamma=0.01, kernel=rbf;, score=-0.005 total time=   0.0s\n",
            "[CV 8/10] END C=10, epsilon=0.0001, gamma=0.01, kernel=rbf;, score=-0.004 total time=   0.0s\n",
            "[CV 9/10] END C=10, epsilon=0.0001, gamma=0.01, kernel=rbf;, score=-0.005 total time=   0.0s\n",
            "[CV 10/10] END C=10, epsilon=0.0001, gamma=0.01, kernel=rbf;, score=-0.004 total time=   0.0s\n",
            "[CV 1/10] END C=10, epsilon=0.0001, gamma=0.01, kernel=poly;, score=-0.042 total time=   0.0s\n",
            "[CV 2/10] END C=10, epsilon=0.0001, gamma=0.01, kernel=poly;, score=-0.031 total time=   0.0s\n",
            "[CV 3/10] END C=10, epsilon=0.0001, gamma=0.01, kernel=poly;, score=-0.047 total time=   0.0s\n",
            "[CV 4/10] END C=10, epsilon=0.0001, gamma=0.01, kernel=poly;, score=-0.060 total time=   0.0s\n",
            "[CV 5/10] END C=10, epsilon=0.0001, gamma=0.01, kernel=poly;, score=-0.077 total time=   0.0s\n",
            "[CV 6/10] END C=10, epsilon=0.0001, gamma=0.01, kernel=poly;, score=-0.109 total time=   0.0s\n",
            "[CV 7/10] END C=10, epsilon=0.0001, gamma=0.01, kernel=poly;, score=-0.046 total time=   0.0s\n",
            "[CV 8/10] END C=10, epsilon=0.0001, gamma=0.01, kernel=poly;, score=-0.052 total time=   0.0s\n",
            "[CV 9/10] END C=10, epsilon=0.0001, gamma=0.01, kernel=poly;, score=-0.084 total time=   0.0s\n",
            "[CV 10/10] END C=10, epsilon=0.0001, gamma=0.01, kernel=poly;, score=-0.079 total time=   0.0s\n",
            "[CV 1/10] END C=10, epsilon=0.0001, gamma=0.01, kernel=linear;, score=-0.007 total time=   0.0s\n",
            "[CV 2/10] END C=10, epsilon=0.0001, gamma=0.01, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 3/10] END C=10, epsilon=0.0001, gamma=0.01, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 4/10] END C=10, epsilon=0.0001, gamma=0.01, kernel=linear;, score=-0.003 total time=   0.0s\n",
            "[CV 5/10] END C=10, epsilon=0.0001, gamma=0.01, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 6/10] END C=10, epsilon=0.0001, gamma=0.01, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 7/10] END C=10, epsilon=0.0001, gamma=0.01, kernel=linear;, score=-0.006 total time=   0.0s\n",
            "[CV 8/10] END C=10, epsilon=0.0001, gamma=0.01, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 9/10] END C=10, epsilon=0.0001, gamma=0.01, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 10/10] END C=10, epsilon=0.0001, gamma=0.01, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 1/10] END C=10, epsilon=0.0001, gamma=0.001, kernel=rbf;, score=-0.010 total time=   0.0s\n",
            "[CV 2/10] END C=10, epsilon=0.0001, gamma=0.001, kernel=rbf;, score=-0.006 total time=   0.0s\n",
            "[CV 3/10] END C=10, epsilon=0.0001, gamma=0.001, kernel=rbf;, score=-0.009 total time=   0.0s\n",
            "[CV 4/10] END C=10, epsilon=0.0001, gamma=0.001, kernel=rbf;, score=-0.007 total time=   0.0s\n",
            "[CV 5/10] END C=10, epsilon=0.0001, gamma=0.001, kernel=rbf;, score=-0.011 total time=   0.0s\n",
            "[CV 6/10] END C=10, epsilon=0.0001, gamma=0.001, kernel=rbf;, score=-0.014 total time=   0.0s\n",
            "[CV 7/10] END C=10, epsilon=0.0001, gamma=0.001, kernel=rbf;, score=-0.007 total time=   0.0s\n",
            "[CV 8/10] END C=10, epsilon=0.0001, gamma=0.001, kernel=rbf;, score=-0.007 total time=   0.0s\n",
            "[CV 9/10] END C=10, epsilon=0.0001, gamma=0.001, kernel=rbf;, score=-0.013 total time=   0.0s\n",
            "[CV 10/10] END C=10, epsilon=0.0001, gamma=0.001, kernel=rbf;, score=-0.008 total time=   0.0s\n",
            "[CV 1/10] END C=10, epsilon=0.0001, gamma=0.001, kernel=poly;, score=-0.042 total time=   0.0s\n",
            "[CV 2/10] END C=10, epsilon=0.0001, gamma=0.001, kernel=poly;, score=-0.031 total time=   0.0s\n",
            "[CV 3/10] END C=10, epsilon=0.0001, gamma=0.001, kernel=poly;, score=-0.048 total time=   0.0s\n",
            "[CV 4/10] END C=10, epsilon=0.0001, gamma=0.001, kernel=poly;, score=-0.061 total time=   0.0s\n",
            "[CV 5/10] END C=10, epsilon=0.0001, gamma=0.001, kernel=poly;, score=-0.078 total time=   0.0s\n",
            "[CV 6/10] END C=10, epsilon=0.0001, gamma=0.001, kernel=poly;, score=-0.111 total time=   0.0s\n",
            "[CV 7/10] END C=10, epsilon=0.0001, gamma=0.001, kernel=poly;, score=-0.047 total time=   0.0s\n",
            "[CV 8/10] END C=10, epsilon=0.0001, gamma=0.001, kernel=poly;, score=-0.053 total time=   0.0s\n",
            "[CV 9/10] END C=10, epsilon=0.0001, gamma=0.001, kernel=poly;, score=-0.085 total time=   0.0s\n",
            "[CV 10/10] END C=10, epsilon=0.0001, gamma=0.001, kernel=poly;, score=-0.080 total time=   0.0s\n",
            "[CV 1/10] END C=10, epsilon=0.0001, gamma=0.001, kernel=linear;, score=-0.007 total time=   0.0s\n",
            "[CV 2/10] END C=10, epsilon=0.0001, gamma=0.001, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 3/10] END C=10, epsilon=0.0001, gamma=0.001, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 4/10] END C=10, epsilon=0.0001, gamma=0.001, kernel=linear;, score=-0.003 total time=   0.0s\n",
            "[CV 5/10] END C=10, epsilon=0.0001, gamma=0.001, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 6/10] END C=10, epsilon=0.0001, gamma=0.001, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 7/10] END C=10, epsilon=0.0001, gamma=0.001, kernel=linear;, score=-0.006 total time=   0.0s\n",
            "[CV 8/10] END C=10, epsilon=0.0001, gamma=0.001, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 9/10] END C=10, epsilon=0.0001, gamma=0.001, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 10/10] END C=10, epsilon=0.0001, gamma=0.001, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 1/10] END C=10, epsilon=0.001, gamma=1, kernel=rbf;, score=-0.008 total time=   0.0s\n",
            "[CV 2/10] END C=10, epsilon=0.001, gamma=1, kernel=rbf;, score=-0.002 total time=   0.0s\n",
            "[CV 3/10] END C=10, epsilon=0.001, gamma=1, kernel=rbf;, score=-0.003 total time=   0.0s\n",
            "[CV 4/10] END C=10, epsilon=0.001, gamma=1, kernel=rbf;, score=-0.002 total time=   0.0s\n",
            "[CV 5/10] END C=10, epsilon=0.001, gamma=1, kernel=rbf;, score=-0.005 total time=   0.0s\n",
            "[CV 6/10] END C=10, epsilon=0.001, gamma=1, kernel=rbf;, score=-0.002 total time=   0.0s\n",
            "[CV 7/10] END C=10, epsilon=0.001, gamma=1, kernel=rbf;, score=-0.002 total time=   0.0s\n",
            "[CV 8/10] END C=10, epsilon=0.001, gamma=1, kernel=rbf;, score=-0.003 total time=   0.0s\n",
            "[CV 9/10] END C=10, epsilon=0.001, gamma=1, kernel=rbf;, score=-0.004 total time=   0.0s\n",
            "[CV 10/10] END C=10, epsilon=0.001, gamma=1, kernel=rbf;, score=-0.002 total time=   0.0s\n",
            "[CV 1/10] END C=10, epsilon=0.001, gamma=1, kernel=poly;, score=-0.005 total time=   0.0s\n",
            "[CV 2/10] END C=10, epsilon=0.001, gamma=1, kernel=poly;, score=-0.004 total time=   0.0s\n",
            "[CV 3/10] END C=10, epsilon=0.001, gamma=1, kernel=poly;, score=-0.006 total time=   0.0s\n",
            "[CV 4/10] END C=10, epsilon=0.001, gamma=1, kernel=poly;, score=-0.004 total time=   0.1s\n",
            "[CV 5/10] END C=10, epsilon=0.001, gamma=1, kernel=poly;, score=-0.026 total time=   0.1s\n",
            "[CV 6/10] END C=10, epsilon=0.001, gamma=1, kernel=poly;, score=-0.006 total time=   0.0s\n",
            "[CV 7/10] END C=10, epsilon=0.001, gamma=1, kernel=poly;, score=-0.008 total time=   0.0s\n",
            "[CV 8/10] END C=10, epsilon=0.001, gamma=1, kernel=poly;, score=-0.001 total time=   0.0s\n",
            "[CV 9/10] END C=10, epsilon=0.001, gamma=1, kernel=poly;, score=-0.016 total time=   0.0s\n",
            "[CV 10/10] END C=10, epsilon=0.001, gamma=1, kernel=poly;, score=-0.010 total time=   0.0s\n",
            "[CV 1/10] END C=10, epsilon=0.001, gamma=1, kernel=linear;, score=-0.007 total time=   0.0s\n",
            "[CV 2/10] END C=10, epsilon=0.001, gamma=1, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 3/10] END C=10, epsilon=0.001, gamma=1, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 4/10] END C=10, epsilon=0.001, gamma=1, kernel=linear;, score=-0.003 total time=   0.0s\n",
            "[CV 5/10] END C=10, epsilon=0.001, gamma=1, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 6/10] END C=10, epsilon=0.001, gamma=1, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 7/10] END C=10, epsilon=0.001, gamma=1, kernel=linear;, score=-0.006 total time=   0.0s\n",
            "[CV 8/10] END C=10, epsilon=0.001, gamma=1, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 9/10] END C=10, epsilon=0.001, gamma=1, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 10/10] END C=10, epsilon=0.001, gamma=1, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 1/10] END C=10, epsilon=0.001, gamma=0.1, kernel=rbf;, score=-0.008 total time=   0.0s\n",
            "[CV 2/10] END C=10, epsilon=0.001, gamma=0.1, kernel=rbf;, score=-0.004 total time=   0.0s\n",
            "[CV 3/10] END C=10, epsilon=0.001, gamma=0.1, kernel=rbf;, score=-0.004 total time=   0.0s\n",
            "[CV 4/10] END C=10, epsilon=0.001, gamma=0.1, kernel=rbf;, score=-0.003 total time=   0.0s\n",
            "[CV 5/10] END C=10, epsilon=0.001, gamma=0.1, kernel=rbf;, score=-0.007 total time=   0.0s\n",
            "[CV 6/10] END C=10, epsilon=0.001, gamma=0.1, kernel=rbf;, score=-0.003 total time=   0.0s\n",
            "[CV 7/10] END C=10, epsilon=0.001, gamma=0.1, kernel=rbf;, score=-0.005 total time=   0.0s\n",
            "[CV 8/10] END C=10, epsilon=0.001, gamma=0.1, kernel=rbf;, score=-0.004 total time=   0.0s\n",
            "[CV 9/10] END C=10, epsilon=0.001, gamma=0.1, kernel=rbf;, score=-0.006 total time=   0.0s\n",
            "[CV 10/10] END C=10, epsilon=0.001, gamma=0.1, kernel=rbf;, score=-0.004 total time=   0.0s\n",
            "[CV 1/10] END C=10, epsilon=0.001, gamma=0.1, kernel=poly;, score=-0.010 total time=   0.0s\n",
            "[CV 2/10] END C=10, epsilon=0.001, gamma=0.1, kernel=poly;, score=-0.008 total time=   0.0s\n",
            "[CV 3/10] END C=10, epsilon=0.001, gamma=0.1, kernel=poly;, score=-0.008 total time=   0.0s\n",
            "[CV 4/10] END C=10, epsilon=0.001, gamma=0.1, kernel=poly;, score=-0.008 total time=   0.0s\n",
            "[CV 5/10] END C=10, epsilon=0.001, gamma=0.1, kernel=poly;, score=-0.017 total time=   0.0s\n",
            "[CV 6/10] END C=10, epsilon=0.001, gamma=0.1, kernel=poly;, score=-0.010 total time=   0.0s\n",
            "[CV 7/10] END C=10, epsilon=0.001, gamma=0.1, kernel=poly;, score=-0.010 total time=   0.0s\n",
            "[CV 8/10] END C=10, epsilon=0.001, gamma=0.1, kernel=poly;, score=-0.002 total time=   0.0s\n",
            "[CV 9/10] END C=10, epsilon=0.001, gamma=0.1, kernel=poly;, score=-0.012 total time=   0.0s\n",
            "[CV 10/10] END C=10, epsilon=0.001, gamma=0.1, kernel=poly;, score=-0.009 total time=   0.0s\n",
            "[CV 1/10] END C=10, epsilon=0.001, gamma=0.1, kernel=linear;, score=-0.007 total time=   0.0s\n",
            "[CV 2/10] END C=10, epsilon=0.001, gamma=0.1, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 3/10] END C=10, epsilon=0.001, gamma=0.1, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 4/10] END C=10, epsilon=0.001, gamma=0.1, kernel=linear;, score=-0.003 total time=   0.0s\n",
            "[CV 5/10] END C=10, epsilon=0.001, gamma=0.1, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 6/10] END C=10, epsilon=0.001, gamma=0.1, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 7/10] END C=10, epsilon=0.001, gamma=0.1, kernel=linear;, score=-0.006 total time=   0.0s\n",
            "[CV 8/10] END C=10, epsilon=0.001, gamma=0.1, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 9/10] END C=10, epsilon=0.001, gamma=0.1, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 10/10] END C=10, epsilon=0.001, gamma=0.1, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 1/10] END C=10, epsilon=0.001, gamma=0.01, kernel=rbf;, score=-0.008 total time=   0.0s\n",
            "[CV 2/10] END C=10, epsilon=0.001, gamma=0.01, kernel=rbf;, score=-0.004 total time=   0.0s\n",
            "[CV 3/10] END C=10, epsilon=0.001, gamma=0.01, kernel=rbf;, score=-0.004 total time=   0.0s\n",
            "[CV 4/10] END C=10, epsilon=0.001, gamma=0.01, kernel=rbf;, score=-0.004 total time=   0.0s\n",
            "[CV 5/10] END C=10, epsilon=0.001, gamma=0.01, kernel=rbf;, score=-0.006 total time=   0.0s\n",
            "[CV 6/10] END C=10, epsilon=0.001, gamma=0.01, kernel=rbf;, score=-0.004 total time=   0.0s\n",
            "[CV 7/10] END C=10, epsilon=0.001, gamma=0.01, kernel=rbf;, score=-0.005 total time=   0.0s\n",
            "[CV 8/10] END C=10, epsilon=0.001, gamma=0.01, kernel=rbf;, score=-0.004 total time=   0.0s\n",
            "[CV 9/10] END C=10, epsilon=0.001, gamma=0.01, kernel=rbf;, score=-0.005 total time=   0.0s\n",
            "[CV 10/10] END C=10, epsilon=0.001, gamma=0.01, kernel=rbf;, score=-0.004 total time=   0.0s\n",
            "[CV 1/10] END C=10, epsilon=0.001, gamma=0.01, kernel=poly;, score=-0.042 total time=   0.0s\n",
            "[CV 2/10] END C=10, epsilon=0.001, gamma=0.01, kernel=poly;, score=-0.031 total time=   0.0s\n",
            "[CV 3/10] END C=10, epsilon=0.001, gamma=0.01, kernel=poly;, score=-0.047 total time=   0.0s\n",
            "[CV 4/10] END C=10, epsilon=0.001, gamma=0.01, kernel=poly;, score=-0.060 total time=   0.0s\n",
            "[CV 5/10] END C=10, epsilon=0.001, gamma=0.01, kernel=poly;, score=-0.077 total time=   0.0s\n",
            "[CV 6/10] END C=10, epsilon=0.001, gamma=0.01, kernel=poly;, score=-0.109 total time=   0.0s\n",
            "[CV 7/10] END C=10, epsilon=0.001, gamma=0.01, kernel=poly;, score=-0.046 total time=   0.0s\n",
            "[CV 8/10] END C=10, epsilon=0.001, gamma=0.01, kernel=poly;, score=-0.052 total time=   0.0s\n",
            "[CV 9/10] END C=10, epsilon=0.001, gamma=0.01, kernel=poly;, score=-0.084 total time=   0.0s\n",
            "[CV 10/10] END C=10, epsilon=0.001, gamma=0.01, kernel=poly;, score=-0.079 total time=   0.0s\n",
            "[CV 1/10] END C=10, epsilon=0.001, gamma=0.01, kernel=linear;, score=-0.007 total time=   0.0s\n",
            "[CV 2/10] END C=10, epsilon=0.001, gamma=0.01, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 3/10] END C=10, epsilon=0.001, gamma=0.01, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 4/10] END C=10, epsilon=0.001, gamma=0.01, kernel=linear;, score=-0.003 total time=   0.0s\n",
            "[CV 5/10] END C=10, epsilon=0.001, gamma=0.01, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 6/10] END C=10, epsilon=0.001, gamma=0.01, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 7/10] END C=10, epsilon=0.001, gamma=0.01, kernel=linear;, score=-0.006 total time=   0.0s\n",
            "[CV 8/10] END C=10, epsilon=0.001, gamma=0.01, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 9/10] END C=10, epsilon=0.001, gamma=0.01, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 10/10] END C=10, epsilon=0.001, gamma=0.01, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 1/10] END C=10, epsilon=0.001, gamma=0.001, kernel=rbf;, score=-0.010 total time=   0.0s\n",
            "[CV 2/10] END C=10, epsilon=0.001, gamma=0.001, kernel=rbf;, score=-0.006 total time=   0.0s\n",
            "[CV 3/10] END C=10, epsilon=0.001, gamma=0.001, kernel=rbf;, score=-0.009 total time=   0.0s\n",
            "[CV 4/10] END C=10, epsilon=0.001, gamma=0.001, kernel=rbf;, score=-0.007 total time=   0.0s\n",
            "[CV 5/10] END C=10, epsilon=0.001, gamma=0.001, kernel=rbf;, score=-0.011 total time=   0.0s\n",
            "[CV 6/10] END C=10, epsilon=0.001, gamma=0.001, kernel=rbf;, score=-0.014 total time=   0.0s\n",
            "[CV 7/10] END C=10, epsilon=0.001, gamma=0.001, kernel=rbf;, score=-0.007 total time=   0.0s\n",
            "[CV 8/10] END C=10, epsilon=0.001, gamma=0.001, kernel=rbf;, score=-0.007 total time=   0.0s\n",
            "[CV 9/10] END C=10, epsilon=0.001, gamma=0.001, kernel=rbf;, score=-0.013 total time=   0.0s\n",
            "[CV 10/10] END C=10, epsilon=0.001, gamma=0.001, kernel=rbf;, score=-0.009 total time=   0.0s\n",
            "[CV 1/10] END C=10, epsilon=0.001, gamma=0.001, kernel=poly;, score=-0.042 total time=   0.0s\n",
            "[CV 2/10] END C=10, epsilon=0.001, gamma=0.001, kernel=poly;, score=-0.031 total time=   0.0s\n",
            "[CV 3/10] END C=10, epsilon=0.001, gamma=0.001, kernel=poly;, score=-0.048 total time=   0.0s\n",
            "[CV 4/10] END C=10, epsilon=0.001, gamma=0.001, kernel=poly;, score=-0.061 total time=   0.0s\n",
            "[CV 5/10] END C=10, epsilon=0.001, gamma=0.001, kernel=poly;, score=-0.078 total time=   0.0s\n",
            "[CV 6/10] END C=10, epsilon=0.001, gamma=0.001, kernel=poly;, score=-0.111 total time=   0.0s\n",
            "[CV 7/10] END C=10, epsilon=0.001, gamma=0.001, kernel=poly;, score=-0.047 total time=   0.0s\n",
            "[CV 8/10] END C=10, epsilon=0.001, gamma=0.001, kernel=poly;, score=-0.053 total time=   0.0s\n",
            "[CV 9/10] END C=10, epsilon=0.001, gamma=0.001, kernel=poly;, score=-0.085 total time=   0.0s\n",
            "[CV 10/10] END C=10, epsilon=0.001, gamma=0.001, kernel=poly;, score=-0.080 total time=   0.0s\n",
            "[CV 1/10] END C=10, epsilon=0.001, gamma=0.001, kernel=linear;, score=-0.007 total time=   0.0s\n",
            "[CV 2/10] END C=10, epsilon=0.001, gamma=0.001, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 3/10] END C=10, epsilon=0.001, gamma=0.001, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 4/10] END C=10, epsilon=0.001, gamma=0.001, kernel=linear;, score=-0.003 total time=   0.0s\n",
            "[CV 5/10] END C=10, epsilon=0.001, gamma=0.001, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 6/10] END C=10, epsilon=0.001, gamma=0.001, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 7/10] END C=10, epsilon=0.001, gamma=0.001, kernel=linear;, score=-0.006 total time=   0.0s\n",
            "[CV 8/10] END C=10, epsilon=0.001, gamma=0.001, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 9/10] END C=10, epsilon=0.001, gamma=0.001, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 10/10] END C=10, epsilon=0.001, gamma=0.001, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 1/10] END C=100, epsilon=0.0001, gamma=1, kernel=rbf;, score=-0.011 total time=   0.1s\n",
            "[CV 2/10] END C=100, epsilon=0.0001, gamma=1, kernel=rbf;, score=-0.001 total time=   0.0s\n",
            "[CV 3/10] END C=100, epsilon=0.0001, gamma=1, kernel=rbf;, score=-0.003 total time=   0.0s\n",
            "[CV 4/10] END C=100, epsilon=0.0001, gamma=1, kernel=rbf;, score=-0.002 total time=   0.1s\n",
            "[CV 5/10] END C=100, epsilon=0.0001, gamma=1, kernel=rbf;, score=-0.007 total time=   0.0s\n",
            "[CV 6/10] END C=100, epsilon=0.0001, gamma=1, kernel=rbf;, score=-0.001 total time=   0.0s\n",
            "[CV 7/10] END C=100, epsilon=0.0001, gamma=1, kernel=rbf;, score=-0.001 total time=   0.1s\n",
            "[CV 8/10] END C=100, epsilon=0.0001, gamma=1, kernel=rbf;, score=-0.002 total time=   0.0s\n",
            "[CV 9/10] END C=100, epsilon=0.0001, gamma=1, kernel=rbf;, score=-0.004 total time=   0.0s\n",
            "[CV 10/10] END C=100, epsilon=0.0001, gamma=1, kernel=rbf;, score=-0.002 total time=   0.0s\n",
            "[CV 1/10] END C=100, epsilon=0.0001, gamma=1, kernel=poly;, score=-0.003 total time=   0.3s\n",
            "[CV 2/10] END C=100, epsilon=0.0001, gamma=1, kernel=poly;, score=-0.004 total time=   0.6s\n",
            "[CV 3/10] END C=100, epsilon=0.0001, gamma=1, kernel=poly;, score=-0.006 total time=   0.7s\n",
            "[CV 4/10] END C=100, epsilon=0.0001, gamma=1, kernel=poly;, score=-0.004 total time=   0.4s\n",
            "[CV 5/10] END C=100, epsilon=0.0001, gamma=1, kernel=poly;, score=-0.026 total time=   0.4s\n",
            "[CV 6/10] END C=100, epsilon=0.0001, gamma=1, kernel=poly;, score=-0.007 total time=   0.4s\n",
            "[CV 7/10] END C=100, epsilon=0.0001, gamma=1, kernel=poly;, score=-0.008 total time=   0.7s\n",
            "[CV 8/10] END C=100, epsilon=0.0001, gamma=1, kernel=poly;, score=-0.002 total time=   0.4s\n",
            "[CV 9/10] END C=100, epsilon=0.0001, gamma=1, kernel=poly;, score=-0.016 total time=   0.4s\n",
            "[CV 10/10] END C=100, epsilon=0.0001, gamma=1, kernel=poly;, score=-0.015 total time=   0.5s\n",
            "[CV 1/10] END C=100, epsilon=0.0001, gamma=1, kernel=linear;, score=-0.007 total time=   0.0s\n",
            "[CV 2/10] END C=100, epsilon=0.0001, gamma=1, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 3/10] END C=100, epsilon=0.0001, gamma=1, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 4/10] END C=100, epsilon=0.0001, gamma=1, kernel=linear;, score=-0.003 total time=   0.0s\n",
            "[CV 5/10] END C=100, epsilon=0.0001, gamma=1, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 6/10] END C=100, epsilon=0.0001, gamma=1, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 7/10] END C=100, epsilon=0.0001, gamma=1, kernel=linear;, score=-0.006 total time=   0.0s\n",
            "[CV 8/10] END C=100, epsilon=0.0001, gamma=1, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 9/10] END C=100, epsilon=0.0001, gamma=1, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 10/10] END C=100, epsilon=0.0001, gamma=1, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 1/10] END C=100, epsilon=0.0001, gamma=0.1, kernel=rbf;, score=-0.008 total time=   0.0s\n",
            "[CV 2/10] END C=100, epsilon=0.0001, gamma=0.1, kernel=rbf;, score=-0.003 total time=   0.0s\n",
            "[CV 3/10] END C=100, epsilon=0.0001, gamma=0.1, kernel=rbf;, score=-0.003 total time=   0.0s\n",
            "[CV 4/10] END C=100, epsilon=0.0001, gamma=0.1, kernel=rbf;, score=-0.003 total time=   0.0s\n",
            "[CV 5/10] END C=100, epsilon=0.0001, gamma=0.1, kernel=rbf;, score=-0.005 total time=   0.0s\n",
            "[CV 6/10] END C=100, epsilon=0.0001, gamma=0.1, kernel=rbf;, score=-0.003 total time=   0.0s\n",
            "[CV 7/10] END C=100, epsilon=0.0001, gamma=0.1, kernel=rbf;, score=-0.004 total time=   0.0s\n",
            "[CV 8/10] END C=100, epsilon=0.0001, gamma=0.1, kernel=rbf;, score=-0.003 total time=   0.0s\n",
            "[CV 9/10] END C=100, epsilon=0.0001, gamma=0.1, kernel=rbf;, score=-0.006 total time=   0.0s\n",
            "[CV 10/10] END C=100, epsilon=0.0001, gamma=0.1, kernel=rbf;, score=-0.003 total time=   0.0s\n",
            "[CV 1/10] END C=100, epsilon=0.0001, gamma=0.1, kernel=poly;, score=-0.008 total time=   0.0s\n",
            "[CV 2/10] END C=100, epsilon=0.0001, gamma=0.1, kernel=poly;, score=-0.007 total time=   0.0s\n",
            "[CV 3/10] END C=100, epsilon=0.0001, gamma=0.1, kernel=poly;, score=-0.006 total time=   0.0s\n",
            "[CV 4/10] END C=100, epsilon=0.0001, gamma=0.1, kernel=poly;, score=-0.011 total time=   0.0s\n",
            "[CV 5/10] END C=100, epsilon=0.0001, gamma=0.1, kernel=poly;, score=-0.016 total time=   0.0s\n",
            "[CV 6/10] END C=100, epsilon=0.0001, gamma=0.1, kernel=poly;, score=-0.009 total time=   0.0s\n",
            "[CV 7/10] END C=100, epsilon=0.0001, gamma=0.1, kernel=poly;, score=-0.009 total time=   0.0s\n",
            "[CV 8/10] END C=100, epsilon=0.0001, gamma=0.1, kernel=poly;, score=-0.002 total time=   0.0s\n",
            "[CV 9/10] END C=100, epsilon=0.0001, gamma=0.1, kernel=poly;, score=-0.009 total time=   0.0s\n",
            "[CV 10/10] END C=100, epsilon=0.0001, gamma=0.1, kernel=poly;, score=-0.008 total time=   0.0s\n",
            "[CV 1/10] END C=100, epsilon=0.0001, gamma=0.1, kernel=linear;, score=-0.007 total time=   0.0s\n",
            "[CV 2/10] END C=100, epsilon=0.0001, gamma=0.1, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 3/10] END C=100, epsilon=0.0001, gamma=0.1, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 4/10] END C=100, epsilon=0.0001, gamma=0.1, kernel=linear;, score=-0.003 total time=   0.0s\n",
            "[CV 5/10] END C=100, epsilon=0.0001, gamma=0.1, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 6/10] END C=100, epsilon=0.0001, gamma=0.1, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 7/10] END C=100, epsilon=0.0001, gamma=0.1, kernel=linear;, score=-0.006 total time=   0.0s\n",
            "[CV 8/10] END C=100, epsilon=0.0001, gamma=0.1, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 9/10] END C=100, epsilon=0.0001, gamma=0.1, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 10/10] END C=100, epsilon=0.0001, gamma=0.1, kernel=linear;, score=-0.005 total time=   0.1s\n",
            "[CV 1/10] END C=100, epsilon=0.0001, gamma=0.01, kernel=rbf;, score=-0.007 total time=   0.0s\n",
            "[CV 2/10] END C=100, epsilon=0.0001, gamma=0.01, kernel=rbf;, score=-0.004 total time=   0.0s\n",
            "[CV 3/10] END C=100, epsilon=0.0001, gamma=0.01, kernel=rbf;, score=-0.004 total time=   0.0s\n",
            "[CV 4/10] END C=100, epsilon=0.0001, gamma=0.01, kernel=rbf;, score=-0.003 total time=   0.0s\n",
            "[CV 5/10] END C=100, epsilon=0.0001, gamma=0.01, kernel=rbf;, score=-0.007 total time=   0.0s\n",
            "[CV 6/10] END C=100, epsilon=0.0001, gamma=0.01, kernel=rbf;, score=-0.003 total time=   0.0s\n",
            "[CV 7/10] END C=100, epsilon=0.0001, gamma=0.01, kernel=rbf;, score=-0.005 total time=   0.0s\n",
            "[CV 8/10] END C=100, epsilon=0.0001, gamma=0.01, kernel=rbf;, score=-0.003 total time=   0.0s\n",
            "[CV 9/10] END C=100, epsilon=0.0001, gamma=0.01, kernel=rbf;, score=-0.005 total time=   0.0s\n",
            "[CV 10/10] END C=100, epsilon=0.0001, gamma=0.01, kernel=rbf;, score=-0.004 total time=   0.0s\n",
            "[CV 1/10] END C=100, epsilon=0.0001, gamma=0.01, kernel=poly;, score=-0.035 total time=   0.0s\n",
            "[CV 2/10] END C=100, epsilon=0.0001, gamma=0.01, kernel=poly;, score=-0.029 total time=   0.0s\n",
            "[CV 3/10] END C=100, epsilon=0.0001, gamma=0.01, kernel=poly;, score=-0.040 total time=   0.0s\n",
            "[CV 4/10] END C=100, epsilon=0.0001, gamma=0.01, kernel=poly;, score=-0.051 total time=   0.0s\n",
            "[CV 5/10] END C=100, epsilon=0.0001, gamma=0.01, kernel=poly;, score=-0.067 total time=   0.0s\n",
            "[CV 6/10] END C=100, epsilon=0.0001, gamma=0.01, kernel=poly;, score=-0.093 total time=   0.0s\n",
            "[CV 7/10] END C=100, epsilon=0.0001, gamma=0.01, kernel=poly;, score=-0.040 total time=   0.0s\n",
            "[CV 8/10] END C=100, epsilon=0.0001, gamma=0.01, kernel=poly;, score=-0.044 total time=   0.0s\n",
            "[CV 9/10] END C=100, epsilon=0.0001, gamma=0.01, kernel=poly;, score=-0.073 total time=   0.0s\n",
            "[CV 10/10] END C=100, epsilon=0.0001, gamma=0.01, kernel=poly;, score=-0.067 total time=   0.0s\n",
            "[CV 1/10] END C=100, epsilon=0.0001, gamma=0.01, kernel=linear;, score=-0.007 total time=   0.0s\n",
            "[CV 2/10] END C=100, epsilon=0.0001, gamma=0.01, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 3/10] END C=100, epsilon=0.0001, gamma=0.01, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 4/10] END C=100, epsilon=0.0001, gamma=0.01, kernel=linear;, score=-0.003 total time=   0.0s\n",
            "[CV 5/10] END C=100, epsilon=0.0001, gamma=0.01, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 6/10] END C=100, epsilon=0.0001, gamma=0.01, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 7/10] END C=100, epsilon=0.0001, gamma=0.01, kernel=linear;, score=-0.006 total time=   0.0s\n",
            "[CV 8/10] END C=100, epsilon=0.0001, gamma=0.01, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 9/10] END C=100, epsilon=0.0001, gamma=0.01, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 10/10] END C=100, epsilon=0.0001, gamma=0.01, kernel=linear;, score=-0.005 total time=   0.1s\n",
            "[CV 1/10] END C=100, epsilon=0.0001, gamma=0.001, kernel=rbf;, score=-0.008 total time=   0.0s\n",
            "[CV 2/10] END C=100, epsilon=0.0001, gamma=0.001, kernel=rbf;, score=-0.004 total time=   0.0s\n",
            "[CV 3/10] END C=100, epsilon=0.0001, gamma=0.001, kernel=rbf;, score=-0.004 total time=   0.0s\n",
            "[CV 4/10] END C=100, epsilon=0.0001, gamma=0.001, kernel=rbf;, score=-0.004 total time=   0.0s\n",
            "[CV 5/10] END C=100, epsilon=0.0001, gamma=0.001, kernel=rbf;, score=-0.006 total time=   0.0s\n",
            "[CV 6/10] END C=100, epsilon=0.0001, gamma=0.001, kernel=rbf;, score=-0.004 total time=   0.0s\n",
            "[CV 7/10] END C=100, epsilon=0.0001, gamma=0.001, kernel=rbf;, score=-0.005 total time=   0.0s\n",
            "[CV 8/10] END C=100, epsilon=0.0001, gamma=0.001, kernel=rbf;, score=-0.004 total time=   0.0s\n",
            "[CV 9/10] END C=100, epsilon=0.0001, gamma=0.001, kernel=rbf;, score=-0.005 total time=   0.0s\n",
            "[CV 10/10] END C=100, epsilon=0.0001, gamma=0.001, kernel=rbf;, score=-0.004 total time=   0.0s\n",
            "[CV 1/10] END C=100, epsilon=0.0001, gamma=0.001, kernel=poly;, score=-0.042 total time=   0.0s\n",
            "[CV 2/10] END C=100, epsilon=0.0001, gamma=0.001, kernel=poly;, score=-0.031 total time=   0.0s\n",
            "[CV 3/10] END C=100, epsilon=0.0001, gamma=0.001, kernel=poly;, score=-0.048 total time=   0.0s\n",
            "[CV 4/10] END C=100, epsilon=0.0001, gamma=0.001, kernel=poly;, score=-0.061 total time=   0.0s\n",
            "[CV 5/10] END C=100, epsilon=0.0001, gamma=0.001, kernel=poly;, score=-0.078 total time=   0.0s\n",
            "[CV 6/10] END C=100, epsilon=0.0001, gamma=0.001, kernel=poly;, score=-0.111 total time=   0.0s\n",
            "[CV 7/10] END C=100, epsilon=0.0001, gamma=0.001, kernel=poly;, score=-0.047 total time=   0.0s\n",
            "[CV 8/10] END C=100, epsilon=0.0001, gamma=0.001, kernel=poly;, score=-0.053 total time=   0.0s\n",
            "[CV 9/10] END C=100, epsilon=0.0001, gamma=0.001, kernel=poly;, score=-0.085 total time=   0.0s\n",
            "[CV 10/10] END C=100, epsilon=0.0001, gamma=0.001, kernel=poly;, score=-0.080 total time=   0.0s\n",
            "[CV 1/10] END C=100, epsilon=0.0001, gamma=0.001, kernel=linear;, score=-0.007 total time=   0.0s\n",
            "[CV 2/10] END C=100, epsilon=0.0001, gamma=0.001, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 3/10] END C=100, epsilon=0.0001, gamma=0.001, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 4/10] END C=100, epsilon=0.0001, gamma=0.001, kernel=linear;, score=-0.003 total time=   0.0s\n",
            "[CV 5/10] END C=100, epsilon=0.0001, gamma=0.001, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 6/10] END C=100, epsilon=0.0001, gamma=0.001, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 7/10] END C=100, epsilon=0.0001, gamma=0.001, kernel=linear;, score=-0.006 total time=   0.0s\n",
            "[CV 8/10] END C=100, epsilon=0.0001, gamma=0.001, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 9/10] END C=100, epsilon=0.0001, gamma=0.001, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 10/10] END C=100, epsilon=0.0001, gamma=0.001, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 1/10] END C=100, epsilon=0.001, gamma=1, kernel=rbf;, score=-0.010 total time=   0.1s\n",
            "[CV 2/10] END C=100, epsilon=0.001, gamma=1, kernel=rbf;, score=-0.001 total time=   0.1s\n",
            "[CV 3/10] END C=100, epsilon=0.001, gamma=1, kernel=rbf;, score=-0.003 total time=   0.0s\n",
            "[CV 4/10] END C=100, epsilon=0.001, gamma=1, kernel=rbf;, score=-0.002 total time=   0.1s\n",
            "[CV 5/10] END C=100, epsilon=0.001, gamma=1, kernel=rbf;, score=-0.007 total time=   0.0s\n",
            "[CV 6/10] END C=100, epsilon=0.001, gamma=1, kernel=rbf;, score=-0.001 total time=   0.0s\n",
            "[CV 7/10] END C=100, epsilon=0.001, gamma=1, kernel=rbf;, score=-0.001 total time=   0.1s\n",
            "[CV 8/10] END C=100, epsilon=0.001, gamma=1, kernel=rbf;, score=-0.002 total time=   0.0s\n",
            "[CV 9/10] END C=100, epsilon=0.001, gamma=1, kernel=rbf;, score=-0.004 total time=   0.0s\n",
            "[CV 10/10] END C=100, epsilon=0.001, gamma=1, kernel=rbf;, score=-0.002 total time=   0.0s\n",
            "[CV 1/10] END C=100, epsilon=0.001, gamma=1, kernel=poly;, score=-0.003 total time=   0.3s\n",
            "[CV 2/10] END C=100, epsilon=0.001, gamma=1, kernel=poly;, score=-0.005 total time=   0.4s\n",
            "[CV 3/10] END C=100, epsilon=0.001, gamma=1, kernel=poly;, score=-0.006 total time=   0.6s\n",
            "[CV 4/10] END C=100, epsilon=0.001, gamma=1, kernel=poly;, score=-0.004 total time=   0.3s\n",
            "[CV 5/10] END C=100, epsilon=0.001, gamma=1, kernel=poly;, score=-0.026 total time=   0.4s\n",
            "[CV 6/10] END C=100, epsilon=0.001, gamma=1, kernel=poly;, score=-0.006 total time=   0.4s\n",
            "[CV 7/10] END C=100, epsilon=0.001, gamma=1, kernel=poly;, score=-0.008 total time=   0.4s\n",
            "[CV 8/10] END C=100, epsilon=0.001, gamma=1, kernel=poly;, score=-0.002 total time=   0.3s\n",
            "[CV 9/10] END C=100, epsilon=0.001, gamma=1, kernel=poly;, score=-0.016 total time=   0.4s\n",
            "[CV 10/10] END C=100, epsilon=0.001, gamma=1, kernel=poly;, score=-0.014 total time=   0.5s\n",
            "[CV 1/10] END C=100, epsilon=0.001, gamma=1, kernel=linear;, score=-0.007 total time=   0.0s\n",
            "[CV 2/10] END C=100, epsilon=0.001, gamma=1, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 3/10] END C=100, epsilon=0.001, gamma=1, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 4/10] END C=100, epsilon=0.001, gamma=1, kernel=linear;, score=-0.003 total time=   0.0s\n",
            "[CV 5/10] END C=100, epsilon=0.001, gamma=1, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 6/10] END C=100, epsilon=0.001, gamma=1, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 7/10] END C=100, epsilon=0.001, gamma=1, kernel=linear;, score=-0.006 total time=   0.0s\n",
            "[CV 8/10] END C=100, epsilon=0.001, gamma=1, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 9/10] END C=100, epsilon=0.001, gamma=1, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 10/10] END C=100, epsilon=0.001, gamma=1, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 1/10] END C=100, epsilon=0.001, gamma=0.1, kernel=rbf;, score=-0.008 total time=   0.0s\n",
            "[CV 2/10] END C=100, epsilon=0.001, gamma=0.1, kernel=rbf;, score=-0.003 total time=   0.0s\n",
            "[CV 3/10] END C=100, epsilon=0.001, gamma=0.1, kernel=rbf;, score=-0.003 total time=   0.0s\n",
            "[CV 4/10] END C=100, epsilon=0.001, gamma=0.1, kernel=rbf;, score=-0.003 total time=   0.0s\n",
            "[CV 5/10] END C=100, epsilon=0.001, gamma=0.1, kernel=rbf;, score=-0.005 total time=   0.0s\n",
            "[CV 6/10] END C=100, epsilon=0.001, gamma=0.1, kernel=rbf;, score=-0.003 total time=   0.0s\n",
            "[CV 7/10] END C=100, epsilon=0.001, gamma=0.1, kernel=rbf;, score=-0.004 total time=   0.0s\n",
            "[CV 8/10] END C=100, epsilon=0.001, gamma=0.1, kernel=rbf;, score=-0.003 total time=   0.0s\n",
            "[CV 9/10] END C=100, epsilon=0.001, gamma=0.1, kernel=rbf;, score=-0.006 total time=   0.0s\n",
            "[CV 10/10] END C=100, epsilon=0.001, gamma=0.1, kernel=rbf;, score=-0.003 total time=   0.0s\n",
            "[CV 1/10] END C=100, epsilon=0.001, gamma=0.1, kernel=poly;, score=-0.008 total time=   0.0s\n",
            "[CV 2/10] END C=100, epsilon=0.001, gamma=0.1, kernel=poly;, score=-0.007 total time=   0.0s\n",
            "[CV 3/10] END C=100, epsilon=0.001, gamma=0.1, kernel=poly;, score=-0.006 total time=   0.0s\n",
            "[CV 4/10] END C=100, epsilon=0.001, gamma=0.1, kernel=poly;, score=-0.012 total time=   0.0s\n",
            "[CV 5/10] END C=100, epsilon=0.001, gamma=0.1, kernel=poly;, score=-0.016 total time=   0.0s\n",
            "[CV 6/10] END C=100, epsilon=0.001, gamma=0.1, kernel=poly;, score=-0.010 total time=   0.0s\n",
            "[CV 7/10] END C=100, epsilon=0.001, gamma=0.1, kernel=poly;, score=-0.009 total time=   0.0s\n",
            "[CV 8/10] END C=100, epsilon=0.001, gamma=0.1, kernel=poly;, score=-0.002 total time=   0.0s\n",
            "[CV 9/10] END C=100, epsilon=0.001, gamma=0.1, kernel=poly;, score=-0.009 total time=   0.0s\n",
            "[CV 10/10] END C=100, epsilon=0.001, gamma=0.1, kernel=poly;, score=-0.008 total time=   0.0s\n",
            "[CV 1/10] END C=100, epsilon=0.001, gamma=0.1, kernel=linear;, score=-0.007 total time=   0.0s\n",
            "[CV 2/10] END C=100, epsilon=0.001, gamma=0.1, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 3/10] END C=100, epsilon=0.001, gamma=0.1, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 4/10] END C=100, epsilon=0.001, gamma=0.1, kernel=linear;, score=-0.003 total time=   0.0s\n",
            "[CV 5/10] END C=100, epsilon=0.001, gamma=0.1, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 6/10] END C=100, epsilon=0.001, gamma=0.1, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 7/10] END C=100, epsilon=0.001, gamma=0.1, kernel=linear;, score=-0.006 total time=   0.0s\n",
            "[CV 8/10] END C=100, epsilon=0.001, gamma=0.1, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 9/10] END C=100, epsilon=0.001, gamma=0.1, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 10/10] END C=100, epsilon=0.001, gamma=0.1, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 1/10] END C=100, epsilon=0.001, gamma=0.01, kernel=rbf;, score=-0.007 total time=   0.0s\n",
            "[CV 2/10] END C=100, epsilon=0.001, gamma=0.01, kernel=rbf;, score=-0.004 total time=   0.0s\n",
            "[CV 3/10] END C=100, epsilon=0.001, gamma=0.01, kernel=rbf;, score=-0.004 total time=   0.0s\n",
            "[CV 4/10] END C=100, epsilon=0.001, gamma=0.01, kernel=rbf;, score=-0.003 total time=   0.0s\n",
            "[CV 5/10] END C=100, epsilon=0.001, gamma=0.01, kernel=rbf;, score=-0.007 total time=   0.0s\n",
            "[CV 6/10] END C=100, epsilon=0.001, gamma=0.01, kernel=rbf;, score=-0.003 total time=   0.0s\n",
            "[CV 7/10] END C=100, epsilon=0.001, gamma=0.01, kernel=rbf;, score=-0.005 total time=   0.0s\n",
            "[CV 8/10] END C=100, epsilon=0.001, gamma=0.01, kernel=rbf;, score=-0.003 total time=   0.0s\n",
            "[CV 9/10] END C=100, epsilon=0.001, gamma=0.01, kernel=rbf;, score=-0.005 total time=   0.0s\n",
            "[CV 10/10] END C=100, epsilon=0.001, gamma=0.01, kernel=rbf;, score=-0.004 total time=   0.0s\n",
            "[CV 1/10] END C=100, epsilon=0.001, gamma=0.01, kernel=poly;, score=-0.035 total time=   0.0s\n",
            "[CV 2/10] END C=100, epsilon=0.001, gamma=0.01, kernel=poly;, score=-0.029 total time=   0.0s\n",
            "[CV 3/10] END C=100, epsilon=0.001, gamma=0.01, kernel=poly;, score=-0.040 total time=   0.0s\n",
            "[CV 4/10] END C=100, epsilon=0.001, gamma=0.01, kernel=poly;, score=-0.051 total time=   0.0s\n",
            "[CV 5/10] END C=100, epsilon=0.001, gamma=0.01, kernel=poly;, score=-0.067 total time=   0.0s\n",
            "[CV 6/10] END C=100, epsilon=0.001, gamma=0.01, kernel=poly;, score=-0.093 total time=   0.0s\n",
            "[CV 7/10] END C=100, epsilon=0.001, gamma=0.01, kernel=poly;, score=-0.040 total time=   0.0s\n",
            "[CV 8/10] END C=100, epsilon=0.001, gamma=0.01, kernel=poly;, score=-0.044 total time=   0.0s\n",
            "[CV 9/10] END C=100, epsilon=0.001, gamma=0.01, kernel=poly;, score=-0.073 total time=   0.0s\n",
            "[CV 10/10] END C=100, epsilon=0.001, gamma=0.01, kernel=poly;, score=-0.067 total time=   0.0s\n",
            "[CV 1/10] END C=100, epsilon=0.001, gamma=0.01, kernel=linear;, score=-0.007 total time=   0.0s\n",
            "[CV 2/10] END C=100, epsilon=0.001, gamma=0.01, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 3/10] END C=100, epsilon=0.001, gamma=0.01, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 4/10] END C=100, epsilon=0.001, gamma=0.01, kernel=linear;, score=-0.003 total time=   0.0s\n",
            "[CV 5/10] END C=100, epsilon=0.001, gamma=0.01, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 6/10] END C=100, epsilon=0.001, gamma=0.01, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 7/10] END C=100, epsilon=0.001, gamma=0.01, kernel=linear;, score=-0.006 total time=   0.0s\n",
            "[CV 8/10] END C=100, epsilon=0.001, gamma=0.01, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 9/10] END C=100, epsilon=0.001, gamma=0.01, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 10/10] END C=100, epsilon=0.001, gamma=0.01, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 1/10] END C=100, epsilon=0.001, gamma=0.001, kernel=rbf;, score=-0.008 total time=   0.0s\n",
            "[CV 2/10] END C=100, epsilon=0.001, gamma=0.001, kernel=rbf;, score=-0.005 total time=   0.0s\n",
            "[CV 3/10] END C=100, epsilon=0.001, gamma=0.001, kernel=rbf;, score=-0.004 total time=   0.0s\n",
            "[CV 4/10] END C=100, epsilon=0.001, gamma=0.001, kernel=rbf;, score=-0.004 total time=   0.0s\n",
            "[CV 5/10] END C=100, epsilon=0.001, gamma=0.001, kernel=rbf;, score=-0.006 total time=   0.0s\n",
            "[CV 6/10] END C=100, epsilon=0.001, gamma=0.001, kernel=rbf;, score=-0.004 total time=   0.0s\n",
            "[CV 7/10] END C=100, epsilon=0.001, gamma=0.001, kernel=rbf;, score=-0.005 total time=   0.0s\n",
            "[CV 8/10] END C=100, epsilon=0.001, gamma=0.001, kernel=rbf;, score=-0.004 total time=   0.0s\n",
            "[CV 9/10] END C=100, epsilon=0.001, gamma=0.001, kernel=rbf;, score=-0.005 total time=   0.0s\n",
            "[CV 10/10] END C=100, epsilon=0.001, gamma=0.001, kernel=rbf;, score=-0.004 total time=   0.0s\n",
            "[CV 1/10] END C=100, epsilon=0.001, gamma=0.001, kernel=poly;, score=-0.042 total time=   0.0s\n",
            "[CV 2/10] END C=100, epsilon=0.001, gamma=0.001, kernel=poly;, score=-0.031 total time=   0.0s\n",
            "[CV 3/10] END C=100, epsilon=0.001, gamma=0.001, kernel=poly;, score=-0.048 total time=   0.0s\n",
            "[CV 4/10] END C=100, epsilon=0.001, gamma=0.001, kernel=poly;, score=-0.061 total time=   0.0s\n",
            "[CV 5/10] END C=100, epsilon=0.001, gamma=0.001, kernel=poly;, score=-0.078 total time=   0.0s\n",
            "[CV 6/10] END C=100, epsilon=0.001, gamma=0.001, kernel=poly;, score=-0.111 total time=   0.0s\n",
            "[CV 7/10] END C=100, epsilon=0.001, gamma=0.001, kernel=poly;, score=-0.047 total time=   0.0s\n",
            "[CV 8/10] END C=100, epsilon=0.001, gamma=0.001, kernel=poly;, score=-0.053 total time=   0.0s\n",
            "[CV 9/10] END C=100, epsilon=0.001, gamma=0.001, kernel=poly;, score=-0.085 total time=   0.0s\n",
            "[CV 10/10] END C=100, epsilon=0.001, gamma=0.001, kernel=poly;, score=-0.080 total time=   0.0s\n",
            "[CV 1/10] END C=100, epsilon=0.001, gamma=0.001, kernel=linear;, score=-0.007 total time=   0.0s\n",
            "[CV 2/10] END C=100, epsilon=0.001, gamma=0.001, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 3/10] END C=100, epsilon=0.001, gamma=0.001, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 4/10] END C=100, epsilon=0.001, gamma=0.001, kernel=linear;, score=-0.003 total time=   0.0s\n",
            "[CV 5/10] END C=100, epsilon=0.001, gamma=0.001, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 6/10] END C=100, epsilon=0.001, gamma=0.001, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 7/10] END C=100, epsilon=0.001, gamma=0.001, kernel=linear;, score=-0.006 total time=   0.0s\n",
            "[CV 8/10] END C=100, epsilon=0.001, gamma=0.001, kernel=linear;, score=-0.004 total time=   0.0s\n",
            "[CV 9/10] END C=100, epsilon=0.001, gamma=0.001, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "[CV 10/10] END C=100, epsilon=0.001, gamma=0.001, kernel=linear;, score=-0.005 total time=   0.0s\n",
            "{'C': 10, 'epsilon': 0.001, 'gamma': 1, 'kernel': 'rbf'}\n"
          ]
        }
      ],
      "source": [
        "param_grid = {'C': [0.1, 1, 10, 100],\n",
        "             'gamma' :[1, 0.1, 0.01, 0.001,],\n",
        "             'kernel' :['rbf', 'poly', 'linear','sigmoid'],\n",
        "              'epsilon': [1e-4, 1e-3]}\n",
        "scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
        "model = SVR()\n",
        "grid = GridSearchCV(SVR(),param_grid,cv = 10, scoring=scorer, refit = True, verbose =3)\n",
        "grid.fit(X_train,np.ravel(y_train))\n",
        "svr_gpred = grid.predict(X_test)\n",
        "print(grid.best_params_)\n",
        "#print(grid.best_estimator_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65JH9xPZQ72M"
      },
      "source": [
        "SVR Best Parameters are:\n",
        "* C: 10\n",
        "* epsilon: 0.001\n",
        "* gamma: 1\n",
        "* kernel: rbf "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "Nt_tEHu1NfJ_",
        "outputId": "2c105371-1535-4f8d-8933-db32c58cac4d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-4db94e70-1288-44a5-8297-fd562429e12e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predictions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>443.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1012.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>323.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>661.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>466.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4db94e70-1288-44a5-8297-fd562429e12e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4db94e70-1288-44a5-8297-fd562429e12e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4db94e70-1288-44a5-8297-fd562429e12e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Predictions\n",
              "0       443.00\n",
              "1      1012.25\n",
              "2       323.00\n",
              "3       661.00\n",
              "4       466.00"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "testY = scaler_y.inverse_transform(y_test)\n",
        "testY2 = pd.DataFrame(testY, columns = ['Predictions'])\n",
        "testY2.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pQd_ZC3cTOJF",
        "outputId": "3c69268f-758b-4b2f-9827-2b58f4f07b09"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-479b1159-4cc6-4c16-8924-6500f4f3a9c4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predictions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>440.559860</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1009.202464</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>301.601396</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>696.175818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>444.920879</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>406.358818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>764.548713</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>595.182321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>780.530763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>480.154403</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>503.102322</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>259.214433</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>566.580872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>406.256374</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>399.471885</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>438.996981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>355.388474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>365.260117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>540.322659</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>462.403898</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>517.627192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>287.077321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>637.047117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>797.958172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>285.008876</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>519.130406</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>468.542006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>591.888894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>409.937314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>420.801301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>521.900838</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>475.290623</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>843.191164</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>569.710872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>453.821267</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>417.412620</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>393.133516</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>536.795566</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>395.297061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>369.132265</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>566.484373</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>566.551579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>514.133841</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>481.767291</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>551.843228</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>1016.428844</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-479b1159-4cc6-4c16-8924-6500f4f3a9c4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-479b1159-4cc6-4c16-8924-6500f4f3a9c4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-479b1159-4cc6-4c16-8924-6500f4f3a9c4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "    Predictions\n",
              "0    440.559860\n",
              "1   1009.202464\n",
              "2    301.601396\n",
              "3    696.175818\n",
              "4    444.920879\n",
              "5    406.358818\n",
              "6    764.548713\n",
              "7    595.182321\n",
              "8    780.530763\n",
              "9    480.154403\n",
              "10   503.102322\n",
              "11   259.214433\n",
              "12   566.580872\n",
              "13   406.256374\n",
              "14   399.471885\n",
              "15   438.996981\n",
              "16   355.388474\n",
              "17   365.260117\n",
              "18   540.322659\n",
              "19   462.403898\n",
              "20   517.627192\n",
              "21   287.077321\n",
              "22   637.047117\n",
              "23   797.958172\n",
              "24   285.008876\n",
              "25   519.130406\n",
              "26   468.542006\n",
              "27   591.888894\n",
              "28   409.937314\n",
              "29   420.801301\n",
              "30   521.900838\n",
              "31   475.290623\n",
              "32   843.191164\n",
              "33   569.710872\n",
              "34   453.821267\n",
              "35   417.412620\n",
              "36   393.133516\n",
              "37   536.795566\n",
              "38   395.297061\n",
              "39   369.132265\n",
              "40   566.484373\n",
              "41   566.551579\n",
              "42   514.133841\n",
              "43   481.767291\n",
              "44   551.843228\n",
              "45  1016.428844"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "svr_gprediction = np.reshape(svr_gpred, (-1,1))\n",
        "svr_gprediction = scaler_y.inverse_transform(svr_gprediction)\n",
        "svr_prediction = pd.DataFrame(svr_gprediction, columns = ['Predictions'])\n",
        "svr_prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfPeC4YtM3Ha"
      },
      "source": [
        "####Plot train, test and forecast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "R5UpKjcgTuKt",
        "outputId": "bf22094c-7f78-4da2-9e08-2099656029e6"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x576 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(16,8))\n",
        "plt.grid()\n",
        "plt.plot(df_training.index, df_training.cpo_pri, label = 'Train')\n",
        "plt.plot(df_test.index, testY2,  label = 'Test')\n",
        "plt.plot(df_test.index, svr_prediction,label = 'SVR Prediction')\n",
        "plt.legend(['True Values', 'Train Prediction by SVR', 'Test Prediction by SVR'],loc='best')\n",
        "plt.title('Mlp Method: Actual vs. Prediction')\n",
        "plt.ylabel('Monthly Crude Palm Oil Price')\n",
        "plt.xlabel('Date')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UiX-AHJCT9n4"
      },
      "source": [
        "####SVR Prediction Plot Zoomed-In\n",
        "Zoom in to a closer timeframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "1a-eSA4uT43w",
        "outputId": "bdc9500c-6ed4-4a0d-f209-22fc7a7df791"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x576 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(16,8))\n",
        "plt.grid()\n",
        "plt.plot(df_test.index, testY2, color = 'red',  label = 'Test')\n",
        "plt.plot(df_test.index,  svr_prediction, color = 'blue',label = 'SVR Prediction')\n",
        "plt.legend(['True Values', 'Predictions by SVR', 'SVR Prediction'],loc='best')\n",
        "plt.title('SVR Method: Actual vs. Prediction')\n",
        "plt.ylabel('Monthly Crude Palm Oil Price')\n",
        "plt.xlabel('Date')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InNq3pQBUTxm"
      },
      "source": [
        "####Accuracy and Precision the Suppor Vector Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "veMp0mShUH4P",
        "outputId": "993897bd-8aee-446a-dcf6-1f2d648225d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MAE value of the SVR Model is: 22.615709233845653\n",
            "MDA value of the SVR Model is: 0.9565217391304348\n",
            "MAPE value of the SVR Model is: 4.2424465551087875\n",
            "RMSE value of the SVR Model is: 30.656818356487694\n",
            "MSE value of the SVR Model is: 939.8405117426809\n"
          ]
        }
      ],
      "source": [
        "MAE_svr = mean_absolute_error(testY2, svr_prediction)\n",
        "print('MAE value of the SVR Model is:', MAE_svr)\n",
        "\n",
        "MDA_svr = mda(testY2, svr_prediction)\n",
        "print('MDA value of the SVR Model is:', *MDA_svr)\n",
        "\n",
        "MAPE_svr = mean_absolute_percentage_error(testY2, svr_prediction)\n",
        "print('MAPE value of the SVR Model is:', MAPE_svr)\n",
        "\n",
        "RMSE_svr = mean_squared_error(testY2,svr_prediction, squared=False)\n",
        "print('RMSE value of the SVR Model is:', RMSE_svr)\n",
        "\n",
        "MSE_svr = mean_squared_error(testY2,svr_prediction)\n",
        "print('MSE value of the SVR Model is:', MSE_svr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHj0IFEQskJe"
      },
      "source": [
        "###Define MLPRegression pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1blgfZN2sM5w"
      },
      "outputs": [],
      "source": [
        "pipe_MLPRegressor = Pipeline([('scaler',  MinMaxScaler()),\n",
        "            ('MLPRegressor', MLPRegressor(random_state = 42))])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbVEDP12tPpd"
      },
      "source": [
        "###Apply Grid Search to MLP Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjlx8CEbsM9L",
        "outputId": "3525b8ed-4747-4de2-e291-a0834c22eed4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.26855124 0.24206006]\n",
            " [1.         0.90593157]\n",
            " [0.11435914 0.10433442]\n",
            " [0.54866688 0.59790512]\n",
            " [0.29810472 0.26312596]\n",
            " [0.19787986 0.29682895]\n",
            " [0.63090267 0.68987568]\n",
            " [0.42659814 0.44497244]\n",
            " [0.76582075 0.75638406]\n",
            " [0.29938966 0.32679554]\n",
            " [0.3610665  0.32406574]\n",
            " [0.03983296 0.04254538]\n",
            " [0.42788307 0.43882256]\n",
            " [0.20044973 0.23139749]\n",
            " [0.24670736 0.2214183 ]\n",
            " [0.28268551 0.24197102]\n",
            " [0.12592355 0.19009682]\n",
            " [0.19017025 0.24016516]\n",
            " [0.48442017 0.37689951]\n",
            " [0.27240604 0.36024887]\n",
            " [0.34050755 0.40347935]\n",
            " [0.06938644 0.02807012]\n",
            " [0.54609701 0.59372758]\n",
            " [0.82107292 0.76264894]\n",
            " [0.02698362 0.03600115]\n",
            " [0.42017347 0.42960394]\n",
            " [0.30452939 0.40259244]\n",
            " [0.49084484 0.4154426 ]\n",
            " [0.20173466 0.13107019]\n",
            " [0.2634115  0.20391347]\n",
            " [0.35592676 0.38788109]\n",
            " [0.32380341 0.31022683]\n",
            " [0.79794411 0.80966504]\n",
            " [0.4214584  0.47728078]\n",
            " [0.30966913 0.41264775]\n",
            " [0.22357854 0.0954725 ]\n",
            " [0.214584   0.11797549]\n",
            " [0.35978156 0.41021765]\n",
            " [0.21586894 0.2240394 ]\n",
            " [0.18888532 0.27678374]\n",
            " [0.44587215 0.58612204]\n",
            " [0.42017347 0.36407366]\n",
            " [0.40346932 0.35782322]\n",
            " [0.29681979 0.3242769 ]\n",
            " [0.54738195 0.48668621]\n",
            " [0.93800193 0.90730308]]\n",
            "Best Parameters :  {'MLPRegressor__activation': 'tanh', 'MLPRegressor__alpha': 0.05, 'MLPRegressor__hidden_layer_sizes': (50, 50, 50), 'MLPRegressor__learning_rate': 'constant', 'MLPRegressor__max_iter': 100, 'MLPRegressor__solver': 'adam'}\n"
          ]
        }
      ],
      "source": [
        "grid_params_MLPRegressor = [{\n",
        "    'MLPRegressor__solver': ['sgd', 'adam'],\n",
        "    'MLPRegressor__alpha': [0.0001, 0.05],\n",
        "    'MLPRegressor__max_iter': [100,200,300, 500, 1000],\n",
        "    'MLPRegressor__activation' : ['relu','logistic','tanh'],\n",
        "    'MLPRegressor__learning_rate' : ['constant', 'adaptive'],\n",
        "    'MLPRegressor__hidden_layer_sizes':[(50,50,50), (50,100,50), (100,)],}]\n",
        "\n",
        "\n",
        "CV_mlpregressor_grid = GridSearchCV (estimator = pipe_MLPRegressor,\n",
        "                               param_grid = grid_params_MLPRegressor, n_jobs=-1,\n",
        "                               cv = 5,return_train_score=True, verbose=0)\n",
        "\n",
        "\n",
        "#CV_mlpregressor_grid.fit(X_train, y_train)\n",
        "\n",
        "CV_mlpregressor_grid.fit(X_train, np.ravel(y_train))\n",
        "\n",
        "ypred=CV_mlpregressor_grid.predict(X_test)\n",
        "\n",
        "print (np.c_[y_test, ypred])\n",
        "print('Best Parameters : ',CV_mlpregressor_grid.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "QHTADqJiKk7x",
        "outputId": "ec7d4186-ab46-4521-bf67-f97b87805642"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nGridSearchCV(cv=5, estimator=MLPRegressor(random_state=42), n_jobs=-1,\\n             param_grid={'activation': ['relu', 'identity', 'tanh', 'logistic'],\\n                         'hidden_layer_sizes': [50, 100, 150, (50, 100),\\n                                                (50, 150), (100, 50),\\n                                                (100, 150), (150, 50),\\n                                                (150, 100), (50, 100, 150),\\n                                                (50, 150, 100), (100, 50, 150),\\n                                                (100, 150, 50), (150, 50, 100),\\n                                                (150, 100, 50)],\\n                         'learning_rate': ['constant', 'adaptive',\\n                                           'invscaling'],\\n                         'solver': ['lbfgs', 'adam']},\\n             verbose=10)\\n\""
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "GridSearchCV(cv=5, estimator=MLPRegressor(random_state=42), n_jobs=-1,\n",
        "             param_grid={'activation': ['relu', 'identity', 'tanh', 'logistic'],\n",
        "                         'hidden_layer_sizes': [50, 100, 150, (50, 100),\n",
        "                                                (50, 150), (100, 50),\n",
        "                                                (100, 150), (150, 50),\n",
        "                                                (150, 100), (50, 100, 150),\n",
        "                                                (50, 150, 100), (100, 50, 150),\n",
        "                                                (100, 150, 50), (150, 50, 100),\n",
        "                                                (150, 100, 50)],\n",
        "                         'learning_rate': ['constant', 'adaptive',\n",
        "                                           'invscaling'],\n",
        "                         'solver': ['lbfgs', 'adam']},\n",
        "             verbose=10)\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0CqWkGD1TzF"
      },
      "source": [
        "MLP Output/Best Parameters\n",
        "\n",
        "* MLPRegressor__activation: 'tanh'\n",
        "* MLPRegressor__alpha: 0.05\n",
        "* MLPRegressor__hidden_layer_sizes: (50, 50, 50)\n",
        "* MLPRegressor__learning_rate: 'constant'\n",
        "* MLPRegressor__max_iter: 100\n",
        "* MLPRegressor__solver: 'adam'\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HZJCLUssNB7",
        "outputId": "eff93f6b-d84b-4487-fe4f-fd56c89b99b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 12)                72        \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 8)                 104       \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 185\n",
            "Trainable params: 185\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(5, input_dim=5, kernel_initializer='normal', activation='tanh')) #old:12/5\n",
        "model.add(Dense(5, activation='tanh')) # old:8\n",
        "model.add(Dense(1, activation='tanh'))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rY4VwoePzXn2"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='mse', optimizer='adam', metrics=['mse','mae'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNgECst-zXrn",
        "outputId": "b2a1b42f-7564-4c8c-e944-0508177e03b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/250\n",
            "3/3 [==============================] - 1s 83ms/step - loss: 0.1098 - mse: 0.1098 - mae: 0.2687 - val_loss: 0.1282 - val_mse: 0.1282 - val_mae: 0.3021\n",
            "Epoch 2/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0799 - mse: 0.0799 - mae: 0.2186 - val_loss: 0.0948 - val_mse: 0.0948 - val_mae: 0.2513\n",
            "Epoch 3/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0579 - mse: 0.0579 - mae: 0.1786 - val_loss: 0.0699 - val_mse: 0.0699 - val_mae: 0.2090\n",
            "Epoch 4/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0441 - mse: 0.0441 - mae: 0.1510 - val_loss: 0.0527 - val_mse: 0.0527 - val_mae: 0.1779\n",
            "Epoch 5/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0349 - mse: 0.0349 - mae: 0.1388 - val_loss: 0.0424 - val_mse: 0.0424 - val_mae: 0.1675\n",
            "Epoch 6/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0316 - mse: 0.0316 - mae: 0.1368 - val_loss: 0.0366 - val_mse: 0.0366 - val_mae: 0.1625\n",
            "Epoch 7/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0306 - mse: 0.0306 - mae: 0.1410 - val_loss: 0.0338 - val_mse: 0.0338 - val_mae: 0.1593\n",
            "Epoch 8/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0312 - mse: 0.0312 - mae: 0.1466 - val_loss: 0.0324 - val_mse: 0.0324 - val_mae: 0.1571\n",
            "Epoch 9/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0314 - mse: 0.0314 - mae: 0.1494 - val_loss: 0.0315 - val_mse: 0.0315 - val_mae: 0.1554\n",
            "Epoch 10/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0310 - mse: 0.0310 - mae: 0.1493 - val_loss: 0.0307 - val_mse: 0.0307 - val_mae: 0.1538\n",
            "Epoch 11/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0301 - mse: 0.0301 - mae: 0.1469 - val_loss: 0.0301 - val_mse: 0.0301 - val_mae: 0.1524\n",
            "Epoch 12/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0287 - mse: 0.0287 - mae: 0.1425 - val_loss: 0.0296 - val_mse: 0.0296 - val_mae: 0.1511\n",
            "Epoch 13/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0271 - mse: 0.0271 - mae: 0.1371 - val_loss: 0.0293 - val_mse: 0.0293 - val_mae: 0.1498\n",
            "Epoch 14/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0260 - mse: 0.0260 - mae: 0.1323 - val_loss: 0.0293 - val_mse: 0.0293 - val_mae: 0.1489\n",
            "Epoch 15/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0249 - mse: 0.0249 - mae: 0.1274 - val_loss: 0.0294 - val_mse: 0.0294 - val_mae: 0.1479\n",
            "Epoch 16/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0243 - mse: 0.0243 - mae: 0.1239 - val_loss: 0.0295 - val_mse: 0.0295 - val_mae: 0.1468\n",
            "Epoch 17/250\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0235 - mse: 0.0235 - mae: 0.1206 - val_loss: 0.0291 - val_mse: 0.0291 - val_mae: 0.1453\n",
            "Epoch 18/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0230 - mse: 0.0230 - mae: 0.1186 - val_loss: 0.0285 - val_mse: 0.0285 - val_mae: 0.1435\n",
            "Epoch 19/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0224 - mse: 0.0224 - mae: 0.1168 - val_loss: 0.0275 - val_mse: 0.0275 - val_mae: 0.1414\n",
            "Epoch 20/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0216 - mse: 0.0216 - mae: 0.1149 - val_loss: 0.0266 - val_mse: 0.0266 - val_mae: 0.1393\n",
            "Epoch 21/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0210 - mse: 0.0210 - mae: 0.1136 - val_loss: 0.0254 - val_mse: 0.0254 - val_mae: 0.1370\n",
            "Epoch 22/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0202 - mse: 0.0202 - mae: 0.1123 - val_loss: 0.0242 - val_mse: 0.0242 - val_mae: 0.1347\n",
            "Epoch 23/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0196 - mse: 0.0196 - mae: 0.1110 - val_loss: 0.0231 - val_mse: 0.0231 - val_mae: 0.1324\n",
            "Epoch 24/250\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0190 - mse: 0.0190 - mae: 0.1100 - val_loss: 0.0221 - val_mse: 0.0221 - val_mae: 0.1302\n",
            "Epoch 25/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0185 - mse: 0.0185 - mae: 0.1084 - val_loss: 0.0213 - val_mse: 0.0213 - val_mae: 0.1280\n",
            "Epoch 26/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0180 - mse: 0.0180 - mae: 0.1071 - val_loss: 0.0205 - val_mse: 0.0205 - val_mae: 0.1259\n",
            "Epoch 27/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0174 - mse: 0.0174 - mae: 0.1056 - val_loss: 0.0198 - val_mse: 0.0198 - val_mae: 0.1238\n",
            "Epoch 28/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0170 - mse: 0.0170 - mae: 0.1039 - val_loss: 0.0192 - val_mse: 0.0192 - val_mae: 0.1218\n",
            "Epoch 29/250\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.0165 - mse: 0.0165 - mae: 0.1023 - val_loss: 0.0187 - val_mse: 0.0187 - val_mae: 0.1199\n",
            "Epoch 30/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0160 - mse: 0.0160 - mae: 0.1007 - val_loss: 0.0183 - val_mse: 0.0183 - val_mae: 0.1181\n",
            "Epoch 31/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0157 - mse: 0.0157 - mae: 0.0994 - val_loss: 0.0178 - val_mse: 0.0178 - val_mae: 0.1162\n",
            "Epoch 32/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0153 - mse: 0.0153 - mae: 0.0985 - val_loss: 0.0174 - val_mse: 0.0174 - val_mae: 0.1143\n",
            "Epoch 33/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0150 - mse: 0.0150 - mae: 0.0976 - val_loss: 0.0168 - val_mse: 0.0168 - val_mae: 0.1124\n",
            "Epoch 34/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0147 - mse: 0.0147 - mae: 0.0969 - val_loss: 0.0162 - val_mse: 0.0162 - val_mae: 0.1104\n",
            "Epoch 35/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0144 - mse: 0.0144 - mae: 0.0962 - val_loss: 0.0156 - val_mse: 0.0156 - val_mae: 0.1085\n",
            "Epoch 36/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0141 - mse: 0.0141 - mae: 0.0956 - val_loss: 0.0152 - val_mse: 0.0152 - val_mae: 0.1067\n",
            "Epoch 37/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0139 - mse: 0.0139 - mae: 0.0949 - val_loss: 0.0147 - val_mse: 0.0147 - val_mae: 0.1050\n",
            "Epoch 38/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0136 - mse: 0.0136 - mae: 0.0942 - val_loss: 0.0144 - val_mse: 0.0144 - val_mae: 0.1035\n",
            "Epoch 39/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0134 - mse: 0.0134 - mae: 0.0936 - val_loss: 0.0141 - val_mse: 0.0141 - val_mae: 0.1019\n",
            "Epoch 40/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0133 - mse: 0.0133 - mae: 0.0930 - val_loss: 0.0138 - val_mse: 0.0138 - val_mae: 0.1005\n",
            "Epoch 41/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0131 - mse: 0.0131 - mae: 0.0924 - val_loss: 0.0135 - val_mse: 0.0135 - val_mae: 0.0991\n",
            "Epoch 42/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0129 - mse: 0.0129 - mae: 0.0920 - val_loss: 0.0132 - val_mse: 0.0132 - val_mae: 0.0977\n",
            "Epoch 43/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0128 - mse: 0.0128 - mae: 0.0916 - val_loss: 0.0129 - val_mse: 0.0129 - val_mae: 0.0964\n",
            "Epoch 44/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0126 - mse: 0.0126 - mae: 0.0910 - val_loss: 0.0126 - val_mse: 0.0126 - val_mae: 0.0952\n",
            "Epoch 45/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0125 - mse: 0.0125 - mae: 0.0906 - val_loss: 0.0124 - val_mse: 0.0124 - val_mae: 0.0940\n",
            "Epoch 46/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0124 - mse: 0.0124 - mae: 0.0901 - val_loss: 0.0122 - val_mse: 0.0122 - val_mae: 0.0930\n",
            "Epoch 47/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0123 - mse: 0.0123 - mae: 0.0896 - val_loss: 0.0121 - val_mse: 0.0121 - val_mae: 0.0920\n",
            "Epoch 48/250\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.0122 - mse: 0.0122 - mae: 0.0891 - val_loss: 0.0119 - val_mse: 0.0119 - val_mae: 0.0910\n",
            "Epoch 49/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0121 - mse: 0.0121 - mae: 0.0887 - val_loss: 0.0116 - val_mse: 0.0116 - val_mae: 0.0900\n",
            "Epoch 50/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0120 - mse: 0.0120 - mae: 0.0884 - val_loss: 0.0114 - val_mse: 0.0114 - val_mae: 0.0891\n",
            "Epoch 51/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0119 - mse: 0.0119 - mae: 0.0881 - val_loss: 0.0113 - val_mse: 0.0113 - val_mae: 0.0882\n",
            "Epoch 52/250\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0118 - mse: 0.0118 - mae: 0.0877 - val_loss: 0.0111 - val_mse: 0.0111 - val_mae: 0.0875\n",
            "Epoch 53/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0117 - mse: 0.0117 - mae: 0.0876 - val_loss: 0.0109 - val_mse: 0.0109 - val_mae: 0.0868\n",
            "Epoch 54/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0116 - mse: 0.0116 - mae: 0.0870 - val_loss: 0.0109 - val_mse: 0.0109 - val_mae: 0.0863\n",
            "Epoch 55/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0115 - mse: 0.0115 - mae: 0.0866 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0857\n",
            "Epoch 56/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0114 - mse: 0.0114 - mae: 0.0862 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0851\n",
            "Epoch 57/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0113 - mse: 0.0113 - mae: 0.0859 - val_loss: 0.0105 - val_mse: 0.0105 - val_mae: 0.0845\n",
            "Epoch 58/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0112 - mse: 0.0112 - mae: 0.0856 - val_loss: 0.0104 - val_mse: 0.0104 - val_mae: 0.0839\n",
            "Epoch 59/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0112 - mse: 0.0112 - mae: 0.0852 - val_loss: 0.0103 - val_mse: 0.0103 - val_mae: 0.0833\n",
            "Epoch 60/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0111 - mse: 0.0111 - mae: 0.0849 - val_loss: 0.0101 - val_mse: 0.0101 - val_mae: 0.0827\n",
            "Epoch 61/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0110 - mse: 0.0110 - mae: 0.0847 - val_loss: 0.0100 - val_mse: 0.0100 - val_mae: 0.0821\n",
            "Epoch 62/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0109 - mse: 0.0109 - mae: 0.0844 - val_loss: 0.0098 - val_mse: 0.0098 - val_mae: 0.0815\n",
            "Epoch 63/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0108 - mse: 0.0108 - mae: 0.0841 - val_loss: 0.0098 - val_mse: 0.0098 - val_mae: 0.0810\n",
            "Epoch 64/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0108 - mse: 0.0108 - mae: 0.0838 - val_loss: 0.0096 - val_mse: 0.0096 - val_mae: 0.0804\n",
            "Epoch 65/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0107 - mse: 0.0107 - mae: 0.0834 - val_loss: 0.0096 - val_mse: 0.0096 - val_mae: 0.0800\n",
            "Epoch 66/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0106 - mse: 0.0106 - mae: 0.0830 - val_loss: 0.0095 - val_mse: 0.0095 - val_mae: 0.0796\n",
            "Epoch 67/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0105 - mse: 0.0105 - mae: 0.0827 - val_loss: 0.0095 - val_mse: 0.0095 - val_mae: 0.0794\n",
            "Epoch 68/250\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0105 - mse: 0.0105 - mae: 0.0823 - val_loss: 0.0095 - val_mse: 0.0095 - val_mae: 0.0790\n",
            "Epoch 69/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0104 - mse: 0.0104 - mae: 0.0820 - val_loss: 0.0093 - val_mse: 0.0093 - val_mae: 0.0782\n",
            "Epoch 70/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0103 - mse: 0.0103 - mae: 0.0817 - val_loss: 0.0091 - val_mse: 0.0091 - val_mae: 0.0775\n",
            "Epoch 71/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0103 - mse: 0.0103 - mae: 0.0816 - val_loss: 0.0090 - val_mse: 0.0090 - val_mae: 0.0769\n",
            "Epoch 72/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0102 - mse: 0.0102 - mae: 0.0812 - val_loss: 0.0089 - val_mse: 0.0089 - val_mae: 0.0765\n",
            "Epoch 73/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0101 - mse: 0.0101 - mae: 0.0809 - val_loss: 0.0089 - val_mse: 0.0089 - val_mae: 0.0761\n",
            "Epoch 74/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0100 - mse: 0.0100 - mae: 0.0805 - val_loss: 0.0089 - val_mse: 0.0089 - val_mae: 0.0760\n",
            "Epoch 75/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0100 - mse: 0.0100 - mae: 0.0801 - val_loss: 0.0089 - val_mse: 0.0089 - val_mae: 0.0758\n",
            "Epoch 76/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0099 - mse: 0.0099 - mae: 0.0797 - val_loss: 0.0088 - val_mse: 0.0088 - val_mae: 0.0753\n",
            "Epoch 77/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0098 - mse: 0.0098 - mae: 0.0795 - val_loss: 0.0086 - val_mse: 0.0086 - val_mae: 0.0747\n",
            "Epoch 78/250\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0098 - mse: 0.0098 - mae: 0.0792 - val_loss: 0.0086 - val_mse: 0.0086 - val_mae: 0.0744\n",
            "Epoch 79/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0097 - mse: 0.0097 - mae: 0.0789 - val_loss: 0.0085 - val_mse: 0.0085 - val_mae: 0.0739\n",
            "Epoch 80/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0096 - mse: 0.0096 - mae: 0.0786 - val_loss: 0.0084 - val_mse: 0.0084 - val_mae: 0.0734\n",
            "Epoch 81/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0096 - mse: 0.0096 - mae: 0.0784 - val_loss: 0.0083 - val_mse: 0.0083 - val_mae: 0.0731\n",
            "Epoch 82/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0095 - mse: 0.0095 - mae: 0.0780 - val_loss: 0.0083 - val_mse: 0.0083 - val_mae: 0.0727\n",
            "Epoch 83/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0095 - mse: 0.0095 - mae: 0.0777 - val_loss: 0.0082 - val_mse: 0.0082 - val_mae: 0.0723\n",
            "Epoch 84/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0094 - mse: 0.0094 - mae: 0.0774 - val_loss: 0.0082 - val_mse: 0.0082 - val_mae: 0.0723\n",
            "Epoch 85/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0094 - mse: 0.0094 - mae: 0.0771 - val_loss: 0.0080 - val_mse: 0.0080 - val_mae: 0.0715\n",
            "Epoch 86/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0093 - mse: 0.0093 - mae: 0.0772 - val_loss: 0.0079 - val_mse: 0.0079 - val_mae: 0.0710\n",
            "Epoch 87/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0092 - mse: 0.0092 - mae: 0.0767 - val_loss: 0.0080 - val_mse: 0.0080 - val_mae: 0.0712\n",
            "Epoch 88/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0092 - mse: 0.0092 - mae: 0.0761 - val_loss: 0.0079 - val_mse: 0.0079 - val_mae: 0.0709\n",
            "Epoch 89/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0091 - mse: 0.0091 - mae: 0.0758 - val_loss: 0.0079 - val_mse: 0.0079 - val_mae: 0.0706\n",
            "Epoch 90/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0091 - mse: 0.0091 - mae: 0.0755 - val_loss: 0.0078 - val_mse: 0.0078 - val_mae: 0.0705\n",
            "Epoch 91/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0090 - mse: 0.0090 - mae: 0.0752 - val_loss: 0.0078 - val_mse: 0.0078 - val_mae: 0.0703\n",
            "Epoch 92/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0089 - mse: 0.0089 - mae: 0.0750 - val_loss: 0.0076 - val_mse: 0.0076 - val_mae: 0.0694\n",
            "Epoch 93/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0089 - mse: 0.0089 - mae: 0.0750 - val_loss: 0.0075 - val_mse: 0.0075 - val_mae: 0.0690\n",
            "Epoch 94/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0088 - mse: 0.0088 - mae: 0.0747 - val_loss: 0.0075 - val_mse: 0.0075 - val_mae: 0.0688\n",
            "Epoch 95/250\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0088 - mse: 0.0088 - mae: 0.0743 - val_loss: 0.0075 - val_mse: 0.0075 - val_mae: 0.0687\n",
            "Epoch 96/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0087 - mse: 0.0087 - mae: 0.0739 - val_loss: 0.0075 - val_mse: 0.0075 - val_mae: 0.0687\n",
            "Epoch 97/250\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0086 - mse: 0.0086 - mae: 0.0735 - val_loss: 0.0075 - val_mse: 0.0075 - val_mae: 0.0685\n",
            "Epoch 98/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0086 - mse: 0.0086 - mae: 0.0733 - val_loss: 0.0074 - val_mse: 0.0074 - val_mae: 0.0681\n",
            "Epoch 99/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0086 - mse: 0.0086 - mae: 0.0729 - val_loss: 0.0074 - val_mse: 0.0074 - val_mae: 0.0682\n",
            "Epoch 100/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0085 - mse: 0.0085 - mae: 0.0726 - val_loss: 0.0074 - val_mse: 0.0074 - val_mae: 0.0682\n",
            "Epoch 101/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0084 - mse: 0.0084 - mae: 0.0723 - val_loss: 0.0072 - val_mse: 0.0072 - val_mae: 0.0673\n",
            "Epoch 102/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0084 - mse: 0.0084 - mae: 0.0724 - val_loss: 0.0071 - val_mse: 0.0071 - val_mae: 0.0668\n",
            "Epoch 103/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0083 - mse: 0.0083 - mae: 0.0723 - val_loss: 0.0071 - val_mse: 0.0071 - val_mae: 0.0667\n",
            "Epoch 104/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0083 - mse: 0.0083 - mae: 0.0718 - val_loss: 0.0071 - val_mse: 0.0071 - val_mae: 0.0666\n",
            "Epoch 105/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0082 - mse: 0.0082 - mae: 0.0714 - val_loss: 0.0071 - val_mse: 0.0071 - val_mae: 0.0665\n",
            "Epoch 106/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0082 - mse: 0.0082 - mae: 0.0710 - val_loss: 0.0071 - val_mse: 0.0071 - val_mae: 0.0668\n",
            "Epoch 107/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0081 - mse: 0.0081 - mae: 0.0707 - val_loss: 0.0070 - val_mse: 0.0070 - val_mae: 0.0663\n",
            "Epoch 108/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0081 - mse: 0.0081 - mae: 0.0706 - val_loss: 0.0069 - val_mse: 0.0069 - val_mae: 0.0657\n",
            "Epoch 109/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0080 - mse: 0.0080 - mae: 0.0705 - val_loss: 0.0068 - val_mse: 0.0068 - val_mae: 0.0653\n",
            "Epoch 110/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0080 - mse: 0.0080 - mae: 0.0705 - val_loss: 0.0067 - val_mse: 0.0067 - val_mae: 0.0649\n",
            "Epoch 111/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0080 - mse: 0.0080 - mae: 0.0702 - val_loss: 0.0068 - val_mse: 0.0068 - val_mae: 0.0654\n",
            "Epoch 112/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0079 - mse: 0.0079 - mae: 0.0695 - val_loss: 0.0069 - val_mse: 0.0069 - val_mae: 0.0655\n",
            "Epoch 113/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0078 - mse: 0.0078 - mae: 0.0692 - val_loss: 0.0068 - val_mse: 0.0068 - val_mae: 0.0653\n",
            "Epoch 114/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0078 - mse: 0.0078 - mae: 0.0689 - val_loss: 0.0068 - val_mse: 0.0068 - val_mae: 0.0650\n",
            "Epoch 115/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0078 - mse: 0.0078 - mae: 0.0689 - val_loss: 0.0066 - val_mse: 0.0066 - val_mae: 0.0640\n",
            "Epoch 116/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0077 - mse: 0.0077 - mae: 0.0688 - val_loss: 0.0066 - val_mse: 0.0066 - val_mae: 0.0640\n",
            "Epoch 117/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0077 - mse: 0.0077 - mae: 0.0685 - val_loss: 0.0066 - val_mse: 0.0066 - val_mae: 0.0639\n",
            "Epoch 118/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0076 - mse: 0.0076 - mae: 0.0682 - val_loss: 0.0065 - val_mse: 0.0065 - val_mae: 0.0638\n",
            "Epoch 119/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0076 - mse: 0.0076 - mae: 0.0680 - val_loss: 0.0065 - val_mse: 0.0065 - val_mae: 0.0636\n",
            "Epoch 120/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0075 - mse: 0.0075 - mae: 0.0678 - val_loss: 0.0065 - val_mse: 0.0065 - val_mae: 0.0636\n",
            "Epoch 121/250\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0075 - mse: 0.0075 - mae: 0.0675 - val_loss: 0.0064 - val_mse: 0.0064 - val_mae: 0.0633\n",
            "Epoch 122/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0074 - mse: 0.0074 - mae: 0.0673 - val_loss: 0.0064 - val_mse: 0.0064 - val_mae: 0.0632\n",
            "Epoch 123/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0074 - mse: 0.0074 - mae: 0.0671 - val_loss: 0.0064 - val_mse: 0.0064 - val_mae: 0.0629\n",
            "Epoch 124/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0074 - mse: 0.0074 - mae: 0.0670 - val_loss: 0.0063 - val_mse: 0.0063 - val_mae: 0.0625\n",
            "Epoch 125/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0073 - mse: 0.0073 - mae: 0.0668 - val_loss: 0.0063 - val_mse: 0.0063 - val_mae: 0.0624\n",
            "Epoch 126/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0073 - mse: 0.0073 - mae: 0.0666 - val_loss: 0.0064 - val_mse: 0.0064 - val_mae: 0.0627\n",
            "Epoch 127/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0072 - mse: 0.0072 - mae: 0.0663 - val_loss: 0.0063 - val_mse: 0.0063 - val_mae: 0.0624\n",
            "Epoch 128/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0072 - mse: 0.0072 - mae: 0.0661 - val_loss: 0.0062 - val_mse: 0.0062 - val_mae: 0.0617\n",
            "Epoch 129/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0072 - mse: 0.0072 - mae: 0.0662 - val_loss: 0.0062 - val_mse: 0.0062 - val_mae: 0.0613\n",
            "Epoch 130/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0072 - mse: 0.0072 - mae: 0.0661 - val_loss: 0.0063 - val_mse: 0.0063 - val_mae: 0.0618\n",
            "Epoch 131/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0071 - mse: 0.0071 - mae: 0.0655 - val_loss: 0.0063 - val_mse: 0.0063 - val_mae: 0.0618\n",
            "Epoch 132/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0071 - mse: 0.0071 - mae: 0.0653 - val_loss: 0.0062 - val_mse: 0.0062 - val_mae: 0.0613\n",
            "Epoch 133/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0070 - mse: 0.0070 - mae: 0.0653 - val_loss: 0.0061 - val_mse: 0.0061 - val_mae: 0.0609\n",
            "Epoch 134/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0070 - mse: 0.0070 - mae: 0.0653 - val_loss: 0.0061 - val_mse: 0.0061 - val_mae: 0.0607\n",
            "Epoch 135/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0070 - mse: 0.0070 - mae: 0.0651 - val_loss: 0.0061 - val_mse: 0.0061 - val_mae: 0.0609\n",
            "Epoch 136/250\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0069 - mse: 0.0069 - mae: 0.0648 - val_loss: 0.0061 - val_mse: 0.0061 - val_mae: 0.0610\n",
            "Epoch 137/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0069 - mse: 0.0069 - mae: 0.0646 - val_loss: 0.0060 - val_mse: 0.0060 - val_mae: 0.0605\n",
            "Epoch 138/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0069 - mse: 0.0069 - mae: 0.0646 - val_loss: 0.0060 - val_mse: 0.0060 - val_mae: 0.0602\n",
            "Epoch 139/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0068 - mse: 0.0068 - mae: 0.0647 - val_loss: 0.0059 - val_mse: 0.0059 - val_mae: 0.0600\n",
            "Epoch 140/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0068 - mse: 0.0068 - mae: 0.0643 - val_loss: 0.0060 - val_mse: 0.0060 - val_mae: 0.0604\n",
            "Epoch 141/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0068 - mse: 0.0068 - mae: 0.0640 - val_loss: 0.0060 - val_mse: 0.0060 - val_mae: 0.0601\n",
            "Epoch 142/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0068 - mse: 0.0068 - mae: 0.0638 - val_loss: 0.0060 - val_mse: 0.0060 - val_mae: 0.0603\n",
            "Epoch 143/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0067 - mse: 0.0067 - mae: 0.0637 - val_loss: 0.0060 - val_mse: 0.0060 - val_mae: 0.0600\n",
            "Epoch 144/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0067 - mse: 0.0067 - mae: 0.0637 - val_loss: 0.0059 - val_mse: 0.0059 - val_mae: 0.0595\n",
            "Epoch 145/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0067 - mse: 0.0067 - mae: 0.0637 - val_loss: 0.0058 - val_mse: 0.0058 - val_mae: 0.0593\n",
            "Epoch 146/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0067 - mse: 0.0067 - mae: 0.0635 - val_loss: 0.0059 - val_mse: 0.0059 - val_mae: 0.0595\n",
            "Epoch 147/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0066 - mse: 0.0066 - mae: 0.0632 - val_loss: 0.0059 - val_mse: 0.0059 - val_mae: 0.0596\n",
            "Epoch 148/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0066 - mse: 0.0066 - mae: 0.0630 - val_loss: 0.0059 - val_mse: 0.0059 - val_mae: 0.0593\n",
            "Epoch 149/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0066 - mse: 0.0066 - mae: 0.0631 - val_loss: 0.0058 - val_mse: 0.0058 - val_mae: 0.0589\n",
            "Epoch 150/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0065 - mse: 0.0065 - mae: 0.0629 - val_loss: 0.0058 - val_mse: 0.0058 - val_mae: 0.0589\n",
            "Epoch 151/250\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0065 - mse: 0.0065 - mae: 0.0627 - val_loss: 0.0058 - val_mse: 0.0058 - val_mae: 0.0590\n",
            "Epoch 152/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0065 - mse: 0.0065 - mae: 0.0625 - val_loss: 0.0058 - val_mse: 0.0058 - val_mae: 0.0590\n",
            "Epoch 153/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0065 - mse: 0.0065 - mae: 0.0624 - val_loss: 0.0058 - val_mse: 0.0058 - val_mae: 0.0589\n",
            "Epoch 154/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0065 - mse: 0.0065 - mae: 0.0623 - val_loss: 0.0058 - val_mse: 0.0058 - val_mae: 0.0589\n",
            "Epoch 155/250\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0064 - mse: 0.0064 - mae: 0.0623 - val_loss: 0.0057 - val_mse: 0.0057 - val_mae: 0.0585\n",
            "Epoch 156/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0064 - mse: 0.0064 - mae: 0.0621 - val_loss: 0.0057 - val_mse: 0.0057 - val_mae: 0.0584\n",
            "Epoch 157/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0064 - mse: 0.0064 - mae: 0.0622 - val_loss: 0.0057 - val_mse: 0.0057 - val_mae: 0.0584\n",
            "Epoch 158/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0064 - mse: 0.0064 - mae: 0.0617 - val_loss: 0.0058 - val_mse: 0.0058 - val_mae: 0.0585\n",
            "Epoch 159/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0064 - mse: 0.0064 - mae: 0.0616 - val_loss: 0.0058 - val_mse: 0.0058 - val_mae: 0.0585\n",
            "Epoch 160/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0064 - mse: 0.0064 - mae: 0.0615 - val_loss: 0.0058 - val_mse: 0.0058 - val_mae: 0.0584\n",
            "Epoch 161/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0064 - mse: 0.0064 - mae: 0.0616 - val_loss: 0.0056 - val_mse: 0.0056 - val_mae: 0.0580\n",
            "Epoch 162/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0063 - mse: 0.0063 - mae: 0.0614 - val_loss: 0.0057 - val_mse: 0.0057 - val_mae: 0.0580\n",
            "Epoch 163/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0063 - mse: 0.0063 - mae: 0.0614 - val_loss: 0.0057 - val_mse: 0.0057 - val_mae: 0.0579\n",
            "Epoch 164/250\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0063 - mse: 0.0063 - mae: 0.0611 - val_loss: 0.0058 - val_mse: 0.0058 - val_mae: 0.0581\n",
            "Epoch 165/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0063 - mse: 0.0063 - mae: 0.0610 - val_loss: 0.0058 - val_mse: 0.0058 - val_mae: 0.0581\n",
            "Epoch 166/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0063 - mse: 0.0063 - mae: 0.0610 - val_loss: 0.0056 - val_mse: 0.0056 - val_mae: 0.0576\n",
            "Epoch 167/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0062 - mse: 0.0062 - mae: 0.0608 - val_loss: 0.0056 - val_mse: 0.0056 - val_mae: 0.0575\n",
            "Epoch 168/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0062 - mse: 0.0062 - mae: 0.0608 - val_loss: 0.0057 - val_mse: 0.0057 - val_mae: 0.0576\n",
            "Epoch 169/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0062 - mse: 0.0062 - mae: 0.0606 - val_loss: 0.0057 - val_mse: 0.0057 - val_mae: 0.0575\n",
            "Epoch 170/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0062 - mse: 0.0062 - mae: 0.0605 - val_loss: 0.0056 - val_mse: 0.0056 - val_mae: 0.0574\n",
            "Epoch 171/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0062 - mse: 0.0062 - mae: 0.0605 - val_loss: 0.0056 - val_mse: 0.0056 - val_mae: 0.0574\n",
            "Epoch 172/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0062 - mse: 0.0062 - mae: 0.0606 - val_loss: 0.0057 - val_mse: 0.0057 - val_mae: 0.0573\n",
            "Epoch 173/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0061 - mse: 0.0061 - mae: 0.0602 - val_loss: 0.0056 - val_mse: 0.0056 - val_mae: 0.0572\n",
            "Epoch 174/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0062 - mse: 0.0062 - mae: 0.0605 - val_loss: 0.0056 - val_mse: 0.0056 - val_mae: 0.0569\n",
            "Epoch 175/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0062 - mse: 0.0062 - mae: 0.0603 - val_loss: 0.0056 - val_mse: 0.0056 - val_mae: 0.0570\n",
            "Epoch 176/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0061 - mse: 0.0061 - mae: 0.0602 - val_loss: 0.0058 - val_mse: 0.0058 - val_mae: 0.0579\n",
            "Epoch 177/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0061 - mse: 0.0061 - mae: 0.0603 - val_loss: 0.0057 - val_mse: 0.0057 - val_mae: 0.0577\n",
            "Epoch 178/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0061 - mse: 0.0061 - mae: 0.0600 - val_loss: 0.0056 - val_mse: 0.0056 - val_mae: 0.0569\n",
            "Epoch 179/250\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0061 - mse: 0.0061 - mae: 0.0598 - val_loss: 0.0055 - val_mse: 0.0055 - val_mae: 0.0566\n",
            "Epoch 180/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0061 - mse: 0.0061 - mae: 0.0598 - val_loss: 0.0056 - val_mse: 0.0056 - val_mae: 0.0567\n",
            "Epoch 181/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0061 - mse: 0.0061 - mae: 0.0597 - val_loss: 0.0056 - val_mse: 0.0056 - val_mae: 0.0568\n",
            "Epoch 182/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0061 - mse: 0.0061 - mae: 0.0599 - val_loss: 0.0057 - val_mse: 0.0057 - val_mae: 0.0573\n",
            "Epoch 183/250\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0061 - mse: 0.0061 - mae: 0.0598 - val_loss: 0.0057 - val_mse: 0.0057 - val_mae: 0.0572\n",
            "Epoch 184/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0060 - mse: 0.0060 - mae: 0.0594 - val_loss: 0.0056 - val_mse: 0.0056 - val_mae: 0.0564\n",
            "Epoch 185/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0061 - mse: 0.0061 - mae: 0.0595 - val_loss: 0.0055 - val_mse: 0.0055 - val_mae: 0.0563\n",
            "Epoch 186/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0061 - mse: 0.0061 - mae: 0.0594 - val_loss: 0.0056 - val_mse: 0.0056 - val_mae: 0.0566\n",
            "Epoch 187/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0060 - mse: 0.0060 - mae: 0.0592 - val_loss: 0.0057 - val_mse: 0.0057 - val_mae: 0.0568\n",
            "Epoch 188/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0060 - mse: 0.0060 - mae: 0.0593 - val_loss: 0.0056 - val_mse: 0.0056 - val_mae: 0.0568\n",
            "Epoch 189/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0061 - mse: 0.0061 - mae: 0.0598 - val_loss: 0.0057 - val_mse: 0.0057 - val_mae: 0.0570\n",
            "Epoch 190/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0060 - mse: 0.0060 - mae: 0.0594 - val_loss: 0.0056 - val_mse: 0.0056 - val_mae: 0.0561\n",
            "Epoch 191/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0060 - mse: 0.0060 - mae: 0.0592 - val_loss: 0.0056 - val_mse: 0.0056 - val_mae: 0.0562\n",
            "Epoch 192/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0060 - mse: 0.0060 - mae: 0.0591 - val_loss: 0.0056 - val_mse: 0.0056 - val_mae: 0.0563\n",
            "Epoch 193/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0060 - mse: 0.0060 - mae: 0.0590 - val_loss: 0.0056 - val_mse: 0.0056 - val_mae: 0.0561\n",
            "Epoch 194/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0060 - mse: 0.0060 - mae: 0.0591 - val_loss: 0.0057 - val_mse: 0.0057 - val_mae: 0.0566\n",
            "Epoch 195/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0060 - mse: 0.0060 - mae: 0.0591 - val_loss: 0.0057 - val_mse: 0.0057 - val_mae: 0.0566\n",
            "Epoch 196/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0060 - mse: 0.0060 - mae: 0.0589 - val_loss: 0.0056 - val_mse: 0.0056 - val_mae: 0.0562\n",
            "Epoch 197/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0060 - mse: 0.0060 - mae: 0.0589 - val_loss: 0.0056 - val_mse: 0.0056 - val_mae: 0.0559\n",
            "Epoch 198/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0060 - mse: 0.0060 - mae: 0.0587 - val_loss: 0.0056 - val_mse: 0.0056 - val_mae: 0.0562\n",
            "Epoch 199/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0060 - mse: 0.0060 - mae: 0.0588 - val_loss: 0.0056 - val_mse: 0.0056 - val_mae: 0.0560\n",
            "Epoch 200/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0060 - mse: 0.0060 - mae: 0.0586 - val_loss: 0.0057 - val_mse: 0.0057 - val_mae: 0.0564\n",
            "Epoch 201/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0060 - mse: 0.0060 - mae: 0.0587 - val_loss: 0.0057 - val_mse: 0.0057 - val_mae: 0.0563\n",
            "Epoch 202/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0587 - val_loss: 0.0056 - val_mse: 0.0056 - val_mae: 0.0558\n",
            "Epoch 203/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0060 - mse: 0.0060 - mae: 0.0587 - val_loss: 0.0055 - val_mse: 0.0055 - val_mae: 0.0556\n",
            "Epoch 204/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0060 - mse: 0.0060 - mae: 0.0592 - val_loss: 0.0056 - val_mse: 0.0056 - val_mae: 0.0562\n",
            "Epoch 205/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0060 - mse: 0.0060 - mae: 0.0588 - val_loss: 0.0056 - val_mse: 0.0056 - val_mae: 0.0559\n",
            "Epoch 206/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0587 - val_loss: 0.0056 - val_mse: 0.0056 - val_mae: 0.0562\n",
            "Epoch 207/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0060 - mse: 0.0060 - mae: 0.0589 - val_loss: 0.0057 - val_mse: 0.0057 - val_mae: 0.0563\n",
            "Epoch 208/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0060 - mse: 0.0060 - mae: 0.0587 - val_loss: 0.0055 - val_mse: 0.0055 - val_mae: 0.0555\n",
            "Epoch 209/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0060 - mse: 0.0060 - mae: 0.0586 - val_loss: 0.0055 - val_mse: 0.0055 - val_mae: 0.0556\n",
            "Epoch 210/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0584 - val_loss: 0.0056 - val_mse: 0.0056 - val_mae: 0.0559\n",
            "Epoch 211/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0586 - val_loss: 0.0057 - val_mse: 0.0057 - val_mae: 0.0561\n",
            "Epoch 212/250\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0586 - val_loss: 0.0056 - val_mse: 0.0056 - val_mae: 0.0557\n",
            "Epoch 213/250\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0586 - val_loss: 0.0056 - val_mse: 0.0056 - val_mae: 0.0556\n",
            "Epoch 214/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0060 - mse: 0.0060 - mae: 0.0586 - val_loss: 0.0057 - val_mse: 0.0057 - val_mae: 0.0559\n",
            "Epoch 215/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0583 - val_loss: 0.0056 - val_mse: 0.0056 - val_mae: 0.0557\n",
            "Epoch 216/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0583 - val_loss: 0.0056 - val_mse: 0.0056 - val_mae: 0.0556\n",
            "Epoch 217/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0582 - val_loss: 0.0056 - val_mse: 0.0056 - val_mae: 0.0557\n",
            "Epoch 218/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0581 - val_loss: 0.0056 - val_mse: 0.0056 - val_mae: 0.0557\n",
            "Epoch 219/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0582 - val_loss: 0.0056 - val_mse: 0.0056 - val_mae: 0.0557\n",
            "Epoch 220/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0582 - val_loss: 0.0056 - val_mse: 0.0056 - val_mae: 0.0556\n",
            "Epoch 221/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0582 - val_loss: 0.0056 - val_mse: 0.0056 - val_mae: 0.0556\n",
            "Epoch 222/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0583 - val_loss: 0.0056 - val_mse: 0.0056 - val_mae: 0.0557\n",
            "Epoch 223/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0583 - val_loss: 0.0056 - val_mse: 0.0056 - val_mae: 0.0556\n",
            "Epoch 224/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0060 - mse: 0.0060 - mae: 0.0587 - val_loss: 0.0056 - val_mse: 0.0056 - val_mae: 0.0554\n",
            "Epoch 225/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0584 - val_loss: 0.0057 - val_mse: 0.0057 - val_mae: 0.0559\n",
            "Epoch 226/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0583 - val_loss: 0.0057 - val_mse: 0.0057 - val_mae: 0.0560\n",
            "Epoch 227/250\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0582 - val_loss: 0.0056 - val_mse: 0.0056 - val_mae: 0.0555\n",
            "Epoch 228/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0583 - val_loss: 0.0055 - val_mse: 0.0055 - val_mae: 0.0552\n",
            "Epoch 229/250\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0585 - val_loss: 0.0056 - val_mse: 0.0056 - val_mae: 0.0555\n",
            "Epoch 230/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0581 - val_loss: 0.0056 - val_mse: 0.0056 - val_mae: 0.0556\n",
            "Epoch 231/250\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0581 - val_loss: 0.0057 - val_mse: 0.0057 - val_mae: 0.0560\n",
            "Epoch 232/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0581 - val_loss: 0.0056 - val_mse: 0.0056 - val_mae: 0.0555\n",
            "Epoch 233/250\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0580 - val_loss: 0.0056 - val_mse: 0.0056 - val_mae: 0.0554\n",
            "Epoch 234/250\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0580 - val_loss: 0.0056 - val_mse: 0.0056 - val_mae: 0.0554\n",
            "Epoch 235/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0579 - val_loss: 0.0056 - val_mse: 0.0056 - val_mae: 0.0555\n",
            "Epoch 236/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0578 - val_loss: 0.0057 - val_mse: 0.0057 - val_mae: 0.0556\n",
            "Epoch 237/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0582 - val_loss: 0.0056 - val_mse: 0.0056 - val_mae: 0.0554\n",
            "Epoch 238/250\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0579 - val_loss: 0.0056 - val_mse: 0.0056 - val_mae: 0.0555\n",
            "Epoch 239/250\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0580 - val_loss: 0.0056 - val_mse: 0.0056 - val_mae: 0.0554\n",
            "Epoch 240/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0580 - val_loss: 0.0056 - val_mse: 0.0056 - val_mae: 0.0554\n",
            "Epoch 241/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0580 - val_loss: 0.0056 - val_mse: 0.0056 - val_mae: 0.0554\n",
            "Epoch 242/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0579 - val_loss: 0.0057 - val_mse: 0.0057 - val_mae: 0.0555\n",
            "Epoch 243/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0581 - val_loss: 0.0057 - val_mse: 0.0057 - val_mae: 0.0557\n",
            "Epoch 244/250\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0584 - val_loss: 0.0056 - val_mse: 0.0056 - val_mae: 0.0551\n",
            "Epoch 245/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0581 - val_loss: 0.0056 - val_mse: 0.0056 - val_mae: 0.0552\n",
            "Epoch 246/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0579 - val_loss: 0.0057 - val_mse: 0.0057 - val_mae: 0.0555\n",
            "Epoch 247/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0578 - val_loss: 0.0057 - val_mse: 0.0057 - val_mae: 0.0555\n",
            "Epoch 248/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0578 - val_loss: 0.0057 - val_mse: 0.0057 - val_mae: 0.0554\n",
            "Epoch 249/250\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0579 - val_loss: 0.0056 - val_mse: 0.0056 - val_mae: 0.0553\n",
            "Epoch 250/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0580 - val_loss: 0.0056 - val_mse: 0.0056 - val_mae: 0.0553\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(X_train, y_train, epochs=250, batch_size=50,  verbose=1, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "WHOt50xUzXva",
        "outputId": "49f8e83f-4a54-44ce-8878-51a7616c6d20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['loss', 'mse', 'mae', 'val_loss', 'val_mse', 'val_mae'])\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(history.history.keys())\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGOC50R14OCV"
      },
      "source": [
        "###Invert Transformed Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "QddlrHsq3Y-P",
        "outputId": "aa167627-38b1-44c5-9b38-d0454e06eb8c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-bda3d542-9f0f-47cb-9da4-95ffc4130bf0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predictions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>443.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1012.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>323.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>661.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>466.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bda3d542-9f0f-47cb-9da4-95ffc4130bf0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bda3d542-9f0f-47cb-9da4-95ffc4130bf0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bda3d542-9f0f-47cb-9da4-95ffc4130bf0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Predictions\n",
              "0       443.00\n",
              "1      1012.25\n",
              "2       323.00\n",
              "3       661.00\n",
              "4       466.00"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ypred = model.predict(X_test)\n",
        "mlp_pred = scaler_y.inverse_transform(ypred)\n",
        "MLP_predictions = pd.DataFrame(mlp_pred, columns = ['Predictions'])\n",
        "testY = scaler_y.inverse_transform(y_test)\n",
        "testY2 = pd.DataFrame(testY, columns = ['Predictions'])\n",
        "testY2.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yoGAtKxe3ZCs"
      },
      "outputs": [],
      "source": [
        "ActPred = pd.DataFrame(np.concatenate([testY, mlp_pred], axis=1), columns= ['Actual','MLP Predicted'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "--D2FYII5vw4",
        "outputId": "d7d5acd6-6ded-42dc-ef05-f2b8d492e82b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-0555f074-4059-421a-897b-7cde41ce8c62\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Actual</th>\n",
              "      <th>MLP Predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>443.00</td>\n",
              "      <td>431.906799</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1012.25</td>\n",
              "      <td>844.826660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>323.00</td>\n",
              "      <td>321.206451</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>661.00</td>\n",
              "      <td>709.909424</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>466.00</td>\n",
              "      <td>426.018677</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>388.00</td>\n",
              "      <td>418.724731</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>725.00</td>\n",
              "      <td>797.027588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>566.00</td>\n",
              "      <td>629.755432</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>830.00</td>\n",
              "      <td>814.885010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>467.00</td>\n",
              "      <td>489.931213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>515.00</td>\n",
              "      <td>484.564362</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>265.00</td>\n",
              "      <td>231.645523</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>567.00</td>\n",
              "      <td>567.845337</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>390.00</td>\n",
              "      <td>401.607605</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>426.00</td>\n",
              "      <td>452.593781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>454.00</td>\n",
              "      <td>424.540802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>332.00</td>\n",
              "      <td>343.926025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>382.00</td>\n",
              "      <td>395.463257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>611.00</td>\n",
              "      <td>543.209351</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>446.00</td>\n",
              "      <td>468.468414</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>499.00</td>\n",
              "      <td>590.942993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>288.00</td>\n",
              "      <td>230.138885</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>659.00</td>\n",
              "      <td>679.111755</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>873.00</td>\n",
              "      <td>803.892639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>255.00</td>\n",
              "      <td>237.042801</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>561.00</td>\n",
              "      <td>548.844238</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>471.00</td>\n",
              "      <td>512.932434</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>616.00</td>\n",
              "      <td>575.645508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>391.00</td>\n",
              "      <td>347.704895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>439.00</td>\n",
              "      <td>350.190491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>511.00</td>\n",
              "      <td>549.234070</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>486.00</td>\n",
              "      <td>502.103394</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>855.00</td>\n",
              "      <td>816.482239</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>562.00</td>\n",
              "      <td>600.373047</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>475.00</td>\n",
              "      <td>508.507812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>408.00</td>\n",
              "      <td>324.473175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>401.00</td>\n",
              "      <td>340.620392</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>514.00</td>\n",
              "      <td>561.412964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>402.00</td>\n",
              "      <td>392.859558</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>381.00</td>\n",
              "      <td>389.645569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>581.00</td>\n",
              "      <td>669.711975</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>561.00</td>\n",
              "      <td>496.717163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>548.00</td>\n",
              "      <td>514.315613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>465.00</td>\n",
              "      <td>548.423340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>660.00</td>\n",
              "      <td>610.892700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>964.00</td>\n",
              "      <td>845.964172</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0555f074-4059-421a-897b-7cde41ce8c62')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0555f074-4059-421a-897b-7cde41ce8c62 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0555f074-4059-421a-897b-7cde41ce8c62');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     Actual  MLP Predicted\n",
              "0    443.00     431.906799\n",
              "1   1012.25     844.826660\n",
              "2    323.00     321.206451\n",
              "3    661.00     709.909424\n",
              "4    466.00     426.018677\n",
              "5    388.00     418.724731\n",
              "6    725.00     797.027588\n",
              "7    566.00     629.755432\n",
              "8    830.00     814.885010\n",
              "9    467.00     489.931213\n",
              "10   515.00     484.564362\n",
              "11   265.00     231.645523\n",
              "12   567.00     567.845337\n",
              "13   390.00     401.607605\n",
              "14   426.00     452.593781\n",
              "15   454.00     424.540802\n",
              "16   332.00     343.926025\n",
              "17   382.00     395.463257\n",
              "18   611.00     543.209351\n",
              "19   446.00     468.468414\n",
              "20   499.00     590.942993\n",
              "21   288.00     230.138885\n",
              "22   659.00     679.111755\n",
              "23   873.00     803.892639\n",
              "24   255.00     237.042801\n",
              "25   561.00     548.844238\n",
              "26   471.00     512.932434\n",
              "27   616.00     575.645508\n",
              "28   391.00     347.704895\n",
              "29   439.00     350.190491\n",
              "30   511.00     549.234070\n",
              "31   486.00     502.103394\n",
              "32   855.00     816.482239\n",
              "33   562.00     600.373047\n",
              "34   475.00     508.507812\n",
              "35   408.00     324.473175\n",
              "36   401.00     340.620392\n",
              "37   514.00     561.412964\n",
              "38   402.00     392.859558\n",
              "39   381.00     389.645569\n",
              "40   581.00     669.711975\n",
              "41   561.00     496.717163\n",
              "42   548.00     514.315613\n",
              "43   465.00     548.423340\n",
              "44   660.00     610.892700\n",
              "45   964.00     845.964172"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ActPred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EU6xu5z06ULv"
      },
      "source": [
        "###Plot train, test and forecast MLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "xddVroVt5v0n",
        "outputId": "1f2d07cb-6280-47bd-f856-36362fa22727"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x576 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(16,8))\n",
        "plt.grid()\n",
        "plt.plot(df_training.index, df_training.cpo_pri, label = 'Train')\n",
        "plt.plot(df_test.index, testY2,  label = 'Test')\n",
        "plt.plot(df_test.index, ActPred,label = 'MLP Prediction')\n",
        "plt.legend(['True Values', 'Train Prediction by Mlp', 'Test Prediction by Mlp'],loc='best')\n",
        "plt.title('Mlp Method: Actual vs. Prediction')\n",
        "plt.ylabel('Monthly Crude Palm Oil Price')\n",
        "plt.xlabel('Date')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61xRPaT16vsP"
      },
      "source": [
        "###MLP Prediction Plot Zoomed-In"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "6-jqL6uw6bEh",
        "outputId": "cb8660bd-d9d6-40ad-c8e5-5980b1c71283"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x576 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(16,8))\n",
        "plt.grid()\n",
        "plt.plot(df_test.index, testY2, color = 'red',  label = 'Test')\n",
        "plt.plot(df_test.index,  MLP_predictions, color = 'blue',label = 'MLP Prediction')\n",
        "plt.legend(['True Values', 'Predictions by Mlp', 'MLP Prediction'],loc='best')\n",
        "plt.title('Mlp Method: Actual vs. Prediction')\n",
        "plt.ylabel('Monthly Crude Palm Oil Price')\n",
        "plt.xlabel('Date')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2C_EtSoQ69yf"
      },
      "source": [
        "###Accuracy and Precision the Multilayer Perceptron"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkVXAr036bLW",
        "outputId": "79ae92e9-6c9d-4e03-b602-70b205dc9b3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MAE value of the MLP Model is: 43.83291426948879\n",
            "MDA value of the MLP Model is: 0.9565217391304348\n",
            "MAPE value of the MLP Model is: 8.336063677079041\n",
            "RMSE value of the MLP Model is: 54.800247630836736\n",
            "MSE value of the MLP Model is: 3003.0671404010272\n"
          ]
        }
      ],
      "source": [
        "MAE_mlp = mean_absolute_error(testY2, MLP_predictions)\n",
        "print('MAE value of the MLP Model is:', MAE_mlp)\n",
        "\n",
        "MDA_mlp = mda(testY2, MLP_predictions)\n",
        "print(\"MDA value of the MLP Model is:\", *MDA_mlp)\n",
        "\n",
        "MAPE_mlp = mean_absolute_percentage_error(testY2, MLP_predictions)\n",
        "print('MAPE value of the MLP Model is:', MAPE_mlp)\n",
        "\n",
        "RMSE_mlp = mean_squared_error(testY2, MLP_predictions, squared=False)\n",
        "print('RMSE value of the MLP Model is:', RMSE_mlp)\n",
        "\n",
        "MSE_mlp = mean_squared_error(testY2, MLP_predictions)\n",
        "print('MSE value of the MLP Model is:', MSE_mlp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NRkNmbDGsz3"
      },
      "source": [
        "**OLD**\n",
        "MAE value of the MLP Model is: 43.83291426948879\n",
        "MDA value of the MLP Model is: 0.9565217391304348\n",
        "MAPE value of the MLP Model is: 8.336063677079041\n",
        "RMSE value of the MLP Model is: 54.800247630836736\n",
        "MSE value of the MLP Model is: 3003.0671404010272"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "98Zuv0-03ZGb"
      },
      "outputs": [],
      "source": [
        "#####################################################################################################\n",
        "# RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NTmvu0iZZG0U"
      },
      "outputs": [],
      "source": [
        "from sklearn import datasets, linear_model\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.constraints import maxnorm\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "from keras.models import Sequential\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "seed = 1 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQKp_EXM-jDm"
      },
      "outputs": [],
      "source": [
        "X = df[['cno_pri', 'rps_pri', 'pno_pri', 'sbo_pri', 'wti_spri']]\n",
        "y = np.array(df[['cpo_pri']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wm-RWyixk-UT",
        "outputId": "aab75860-21c0-4928-cdbb-cb3dfce4f317"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5\n"
          ]
        }
      ],
      "source": [
        "input_dim = 5\n",
        "print(input_dim) # 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dbuKt-RiYqI",
        "outputId": "434662a0-85f8-427d-9176-47f50ffeef1f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n"
          ]
        }
      ],
      "source": [
        "def create_model():\n",
        "    # default values\n",
        "    activation='relu' # or linear\n",
        "    dropout_rate=0.0 # or 0.2\n",
        "    init_mode='uniform'\n",
        "    weight_constraint=0 # or  4\n",
        "    optimizer='adam' # or SGD\n",
        "    lr = 0.01\n",
        "    momemntum=0\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    model.add(Dense(5, \n",
        "                    input_dim=input_dim, kernel_initializer=init_mode, \n",
        "                    activation=activation,\n",
        "                    kernel_constraint=maxnorm(weight_constraint)))\n",
        "    model.add(Dropout(dropout_rate)) \n",
        "    model.add(Dense(1, kernel_initializer=init_mode, activation='sigmoid'))\n",
        "    # Compile model\n",
        "    model.compile(loss='mae', \n",
        "                  optimizer=optimizer, \n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# create model\n",
        "model = KerasRegressor(build_fn=create_model, batch_size=1000, epochs=10) \n",
        "# use verbose=0 if you do not want to see progress"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VxVhmlykkAcA"
      },
      "outputs": [],
      "source": [
        "########################################################\n",
        "# Use scikit-learn to grid search \n",
        "activation =  ['relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear'] # softmax, softplus, softsign \n",
        "momentum = [0.0, 0.2, 0.4, 0.6, 0.8, 0.9]\n",
        "learn_rate = [0.001, 0.01, 0.1, 0.2, 0.3]\n",
        "dropout_rate = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
        "weight_constraint=[1, 2, 3, 4, 5]\n",
        "neurons = [1, 5, 10, 15, 20, 25, 30]\n",
        "init = ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']\n",
        "optimizer = [ 'SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ac-qo8lkH8-"
      },
      "outputs": [],
      "source": [
        "##############################################################\n",
        "# grid search epochs, batch size\n",
        "epochs = [1, 10, 50, 100] # add 50, 100, 150 etc\n",
        "batch_size = [5, 10, 20, 40, 60, 80, 100] # add 5, 10, 20, 40, 60, 80, 100 etc\n",
        "param_grid = dict(epochs=epochs, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90h4fhemkQPT",
        "outputId": "79802367-c765-4e2a-8f07-0fdaa5c9bf91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 539.7878 - accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 539.7650 - accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 539.7517 - accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 539.7358 - accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 539.7166 - accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 539.6942 - accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 539.6691 - accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 539.6421 - accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 539.6140 - accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 539.5854 - accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 539.5572 - accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 539.5298 - accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 539.5040 - accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 539.4801 - accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 539.4583 - accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 539.4387 - accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 539.4211 - accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 539.4056 - accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 539.3920 - accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 539.3801 - accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 539.3698 - accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 539.3607 - accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 539.3527 - accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 539.3458 - accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 539.3396 - accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 539.3344 - accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 539.3295 - accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 539.3254 - accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 539.3217 - accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 539.3184 - accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 539.3155 - accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 539.3129 - accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 539.3105 - accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 539.3083 - accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 539.3066 - accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 539.3049 - accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 539.3033 - accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 539.3018 - accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 539.3004 - accuracy: 0.0000e+00\n",
            "Epoch 40/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 539.2996 - accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 539.2983 - accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 539.2972 - accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 539.2967 - accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 539.2955 - accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 539.2951 - accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 539.2940 - accuracy: 0.0000e+00\n",
            "Epoch 47/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 539.2936 - accuracy: 0.0000e+00\n",
            "Epoch 48/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 539.2928 - accuracy: 0.0000e+00\n",
            "Epoch 49/50\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 539.2922 - accuracy: 0.0000e+00\n",
            "Epoch 50/50\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 539.2920 - accuracy: 0.0000e+00\n"
          ]
        }
      ],
      "source": [
        "##############################################################\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1)\n",
        "grid_result = grid.fit(X,y) \n",
        "##############################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCXI9Glbmtuk",
        "outputId": "ea6d4688-6b98-462a-df4d-3a592248732a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best: -539.292639 using {'batch_size': 5, 'epochs': 50}\n",
            "-539.772949 (163.002788) with: {'batch_size': 5, 'epochs': 1}\n",
            "-539.661249 (162.978963) with: {'batch_size': 5, 'epochs': 10}\n",
            "-539.292639 (163.002061) with: {'batch_size': 5, 'epochs': 50}\n",
            "-539.295752 (162.997122) with: {'batch_size': 5, 'epochs': 100}\n",
            "-539.777460 (163.002611) with: {'batch_size': 10, 'epochs': 1}\n",
            "-539.726404 (163.001302) with: {'batch_size': 10, 'epochs': 10}\n",
            "-539.388458 (163.021046) with: {'batch_size': 10, 'epochs': 50}\n",
            "-539.349939 (163.040197) with: {'batch_size': 10, 'epochs': 100}\n",
            "-539.780103 (163.002658) with: {'batch_size': 20, 'epochs': 1}\n",
            "-539.755823 (163.003135) with: {'batch_size': 20, 'epochs': 10}\n",
            "-539.557782 (163.044771) with: {'batch_size': 20, 'epochs': 50}\n",
            "-539.356732 (162.976593) with: {'batch_size': 20, 'epochs': 100}\n",
            "-539.781305 (163.002637) with: {'batch_size': 40, 'epochs': 1}\n",
            "-539.769611 (163.002940) with: {'batch_size': 40, 'epochs': 10}\n",
            "-539.693182 (162.975244) with: {'batch_size': 40, 'epochs': 50}\n",
            "-539.631012 (162.999884) with: {'batch_size': 40, 'epochs': 100}\n",
            "-539.781604 (163.002574) with: {'batch_size': 60, 'epochs': 1}\n",
            "-539.772144 (163.002909) with: {'batch_size': 60, 'epochs': 10}\n",
            "-539.730585 (163.001799) with: {'batch_size': 60, 'epochs': 50}\n",
            "-539.662616 (163.012605) with: {'batch_size': 60, 'epochs': 100}\n",
            "-539.781873 (163.002639) with: {'batch_size': 80, 'epochs': 1}\n",
            "-539.774823 (163.002573) with: {'batch_size': 80, 'epochs': 10}\n",
            "-539.739093 (163.000591) with: {'batch_size': 80, 'epochs': 50}\n",
            "-539.685864 (163.013589) with: {'batch_size': 80, 'epochs': 100}\n",
            "-539.782092 (163.002646) with: {'batch_size': 100, 'epochs': 1}\n",
            "-539.777234 (163.002827) with: {'batch_size': 100, 'epochs': 10}\n",
            "-539.756061 (163.000249) with: {'batch_size': 100, 'epochs': 50}\n",
            "-539.716779 (163.003757) with: {'batch_size': 100, 'epochs': 100}\n"
          ]
        }
      ],
      "source": [
        "##############################################################\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sbi5mm03hDmd",
        "outputId": "d9310570-a72d-4314-ff50-7e30a3a0ae3d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, estimator=<function baseline_model at 0x7f62015fea70>,\n",
              "             n_jobs=-1,\n",
              "             param_grid={'activation': ['relu', 'identity', 'tanh', 'logistic'],\n",
              "                         'hidden_layer_sizes': [50, 100, 150, (50, 100),\n",
              "                                                (50, 150), (100, 50),\n",
              "                                                (100, 150), (150, 50),\n",
              "                                                (150, 100), (50, 100, 150),\n",
              "                                                (50, 150, 100), (100, 50, 150),\n",
              "                                                (100, 150, 50), (150, 50, 100),\n",
              "                                                (150, 100, 50)],\n",
              "                         'learning_rate': ['constant', 'adaptive',\n",
              "                                           'invscaling'],\n",
              "                         'solver': ['lbfgs', 'adam']},\n",
              "             verbose=10)"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "GridSearchCV(cv=5, estimator=baseline_model, n_jobs=-1,\n",
        "             param_grid={'activation': ['relu', 'identity', 'tanh', 'logistic'],\n",
        "                         'hidden_layer_sizes': [50, 100, 150, (50, 100),\n",
        "                                                (50, 150), (100, 50),\n",
        "                                                (100, 150), (150, 50),\n",
        "                                                (150, 100), (50, 100, 150),\n",
        "                                                (50, 150, 100), (100, 50, 150),\n",
        "                                                (100, 150, 50), (150, 50, 100),\n",
        "                                                (150, 100, 50)],\n",
        "                         'learning_rate': ['constant', 'adaptive',\n",
        "                                           'invscaling'],\n",
        "                         'solver': ['lbfgs', 'adam']},\n",
        "             verbose=10)\n",
        "\n",
        "#GridSearchCV(estimator=baseline_model, param_grid=param_grid, n_jobs=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q0uZhLhNY1aW"
      },
      "outputs": [],
      "source": [
        "def baseline_model():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(5, input_dim=5, activation='relu'))\n",
        "    model.add(Dense(1))\n",
        "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MYfrkaaogbVD"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MV6VzxBccm5M"
      },
      "outputs": [],
      "source": [
        "# Use scikit-learn to grid search \n",
        "activation =  ['relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear'] # softmax, softplus, softsign \n",
        "momentum = [0.0, 0.2, 0.4, 0.6, 0.8, 0.9]\n",
        "learn_rate = [0.001, 0.01, 0.1, 0.2, 0.3]\n",
        "dropout_rate = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
        "weight_constraint=[1, 2, 3, 4, 5]\n",
        "neurons = [1, 5, 10, 15, 20, 25, 30]\n",
        "init = ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']\n",
        "optimizer = [ 'SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tA2gCcp8cqAs"
      },
      "outputs": [],
      "source": [
        "# grid search epochs, batch size\n",
        "epochs = [1, 10] # add 50, 100, 150 etc\n",
        "batch_size = [1000, 5000] # add 5, 10, 20, 40, 60, 80, 100 etc\n",
        "param_grid = dict(epochs=epochs, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "id": "e7Hck_epcw9C",
        "outputId": "789a9c39-bdc2-45a7-c7ba-aa5c0bb0d25f"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-355bf4571f0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbaseline_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgrid_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0mscorers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscoring\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 793\u001b[0;31m             \u001b[0mscorers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    794\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m             \u001b[0mscorers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_multimetric_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36mcheck_scoring\u001b[0;34m(estimator, scoring, allow_none)\u001b[0m\n\u001b[1;32m    448\u001b[0m         raise TypeError(\n\u001b[1;32m    449\u001b[0m             \u001b[0;34m\"estimator should be an estimator implementing 'fit' method, %r was passed\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m             \u001b[0;34m%\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    451\u001b[0m         )\n\u001b[1;32m    452\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: estimator should be an estimator implementing 'fit' method, <function baseline_model at 0x7f620148f0e0> was passed"
          ]
        }
      ],
      "source": [
        "grid = GridSearchCV(estimator=baseline_model, param_grid=param_grid, n_jobs=-1)\n",
        "grid_result = grid.fit(X,y) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BeeKA-0Y9xA",
        "outputId": "29f9e7db-65df-4e3f-927a-74b20ec0878b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results: -2173467.39 (3313375.22) MSE\n"
          ]
        }
      ],
      "source": [
        "estimator = KerasRegressor(build_fn=baseline_model, nb_epoch=100, batch_size=100, verbose=False)\n",
        "kfold = KFold(n_splits=10, random_state=None)\n",
        "results = cross_val_score(estimator, X, y, cv=kfold)\n",
        "print(\"Results: %.2f (%.2f) MSE\" % (results.mean(), results.std()))\n",
        "estimator.fit(X, y)\n",
        "prediction = estimator.predict(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TdDKlz7HcRJZ"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0a-BxdcuYoEy",
        "outputId": "d700c85c-2470-402a-b7cd-cef2da798924"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([137.92558, 137.55106, 134.18709, 130.80394, 143.0881 , 144.45842,\n",
              "       146.78502, 149.81392, 153.1086 , 156.90895, 155.90654, 153.02109,\n",
              "       145.6549 , 140.56737, 140.51799, 149.29158, 149.2753 , 145.28734,\n",
              "       139.0138 , 138.4713 , 150.24242, 154.05862, 162.39111, 172.73988,\n",
              "       172.67267, 167.60388, 163.36395, 186.44734, 189.74716, 183.84283,\n",
              "       184.65747, 186.08026, 189.9438 , 192.27734, 195.09525, 192.5296 ,\n",
              "       186.97821, 192.52957, 193.65845, 192.67558, 188.06073, 188.13281,\n",
              "       188.39415, 192.92392, 198.50452, 202.00177, 201.93726, 206.27   ,\n",
              "       204.31429, 209.23866, 216.08383, 222.75615, 222.6442 , 220.11082,\n",
              "       217.20488, 214.87146, 215.57053, 224.70596, 227.67236, 219.11378,\n",
              "       210.59439, 207.97441, 215.09283, 221.53654, 222.19507, 232.35036,\n",
              "       235.229  , 248.74742, 262.07642, 280.74405, 294.8521 , 296.54315,\n",
              "       299.88336, 299.6989 , 298.6809 , 295.81403, 293.91708, 292.37662,\n",
              "       286.35272, 272.56003, 252.70747, 241.91032, 223.04567, 219.88411,\n",
              "       211.70178, 206.04115, 213.6535 , 227.15202, 230.53145, 217.76923,\n",
              "       213.14313, 211.49266, 228.9563 , 237.16891, 229.83827, 228.26917,\n",
              "       226.9134 , 231.58401, 235.56898, 218.24136, 212.31638, 219.54245,\n",
              "       230.41609, 237.77467, 249.25969, 259.73163, 272.98233, 270.2096 ,\n",
              "       268.17285, 268.6345 , 272.03094, 274.05325, 274.40494, 271.57428,\n",
              "       269.0119 , 262.1599 , 254.93185, 255.80322, 250.08998, 249.73909,\n",
              "       254.81682, 255.55998, 260.97177, 253.81714, 243.38684, 244.615  ,\n",
              "       246.11057, 252.4936 , 243.84587, 240.0755 , 245.32353, 252.96773,\n",
              "       253.33885, 246.56128, 245.45729, 250.11792, 259.2544 , 243.06378,\n",
              "       240.45451, 238.57373, 249.68431, 258.34097, 259.79996, 253.76093,\n",
              "       258.14145, 265.3132 , 267.27283, 265.04346, 265.1018 , 261.5    ,\n",
              "       252.82909, 252.53539, 255.94302, 248.48991, 243.11858, 233.41934,\n",
              "       231.84908, 228.05002, 228.40407, 227.89612, 236.00208, 233.688  ,\n",
              "       228.21124, 229.9539 , 233.46162, 230.0301 , 227.25323, 215.2621 ,\n",
              "       216.65714, 212.93683, 212.20705, 208.94284, 206.19734, 201.1455 ,\n",
              "       206.67908, 210.21764, 219.42093, 221.1429 , 223.6575 , 222.98543,\n",
              "       224.59816, 224.73596, 222.47739, 229.1561 , 227.7851 , 233.622  ,\n",
              "       231.14055, 235.30078, 246.64398, 264.97864, 261.30795, 256.34   ,\n",
              "       257.007  , 266.4746 , 285.6232 , 289.79694, 294.47394, 295.32358,\n",
              "       296.1823 , 292.79367, 298.43304, 296.5977 , 295.66702, 299.58173,\n",
              "       295.90472, 278.69034, 249.61836, 260.17014, 260.17825, 254.29036,\n",
              "       256.69193, 259.89142, 261.36633, 248.98691, 248.3738 , 251.1604 ,\n",
              "       239.89682, 218.24196, 213.97926, 224.53345, 238.95209, 244.61624,\n",
              "       252.31789, 255.3069 , 258.71423, 281.41162, 289.3893 , 298.09866,\n",
              "       318.6272 , 328.48633], dtype=float32)"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prediction = estimator.predict(X)\n",
        "prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mrkrNQ_YbR1L"
      },
      "outputs": [],
      "source": [
        "##########################################################################################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mS_Vf-IH9cOr"
      },
      "outputs": [],
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(x1, y1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5daxBX209cSU",
        "outputId": "4ee80cc5-9edf-4515-f1e9-31878342b89b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MinMaxScaler()\n",
            "MinMaxScaler()\n",
            "MinMaxScaler()\n",
            "MinMaxScaler()\n"
          ]
        }
      ],
      "source": [
        "y_train=np.reshape(y_train, (-1,1))\n",
        "y_val=np.reshape(y_val, (-1,1))\n",
        "scaler_x = MinMaxScaler()\n",
        "scaler_y = MinMaxScaler()\n",
        "print(scaler_x.fit(X_train))\n",
        "xtrain_scale=scaler_x.transform(X_train)\n",
        "print(scaler_x.fit(X_val))\n",
        "xval_scale=scaler_x.transform(X_val)\n",
        "print(scaler_y.fit(y_train))\n",
        "ytrain_scale=scaler_y.transform(y_train)\n",
        "print(scaler_y.fit(y_val))\n",
        "yval_scale=scaler_y.transform(y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ePBIiqMrUPho"
      },
      "outputs": [],
      "source": [
        "#Grid search\n",
        "grid_params_MLPRegressor = [{\n",
        "    'MLPRegressor__solver': ['sgd', 'adam'],\n",
        "    'MLPRegressor__alpha': [0.0001, 0.05],\n",
        "    'MLPRegressor__max_iter': [100,200,300, 500, 1000],\n",
        "    'MLPRegressor__activation' : ['relu','logistic','tanh'],\n",
        "    'MLPRegressor__learning_rate' : ['constant', 'adaptive'],\n",
        "    'MLPRegressor__hidden_layer_sizes':[(50,50,50), (50,100,50), (100,)],}]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onqD9KIr9cWP",
        "outputId": "975d5bbb-3e48-4d90-f514-90e198c5269c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_9 (Dense)             (None, 5)                 30        \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 1150)              6900      \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 1)                 1151      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,081\n",
            "Trainable params: 8,081\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(5, input_dim=5, kernel_initializer='normal', activation='relu'))\n",
        "model.add(Dense(1150, activation='relu'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-GsBbsi_7Yl",
        "outputId": "f03ae2d2-da2e-4315-88da-84590842b566"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 0.2119 - mse: 0.2119 - mae: 0.3939 - val_loss: 0.1757 - val_mse: 0.1757 - val_mae: 0.3614\n",
            "Epoch 2/30\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.1927 - mse: 0.1927 - mae: 0.3693 - val_loss: 0.1591 - val_mse: 0.1591 - val_mae: 0.3418\n",
            "Epoch 3/30\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.1757 - mse: 0.1757 - mae: 0.3474 - val_loss: 0.1437 - val_mse: 0.1437 - val_mae: 0.3225\n",
            "Epoch 4/30\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.1598 - mse: 0.1598 - mae: 0.3257 - val_loss: 0.1287 - val_mse: 0.1287 - val_mae: 0.3022\n",
            "Epoch 5/30\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.1444 - mse: 0.1444 - mae: 0.3035 - val_loss: 0.1143 - val_mse: 0.1143 - val_mae: 0.2807\n",
            "Epoch 6/30\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.1295 - mse: 0.1295 - mae: 0.2817 - val_loss: 0.1006 - val_mse: 0.1006 - val_mae: 0.2581\n",
            "Epoch 7/30\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.1153 - mse: 0.1153 - mae: 0.2594 - val_loss: 0.0878 - val_mse: 0.0878 - val_mae: 0.2361\n",
            "Epoch 8/30\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.1019 - mse: 0.1019 - mae: 0.2387 - val_loss: 0.0762 - val_mse: 0.0762 - val_mae: 0.2145\n",
            "Epoch 9/30\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0896 - mse: 0.0896 - mae: 0.2208 - val_loss: 0.0659 - val_mse: 0.0659 - val_mae: 0.1932\n",
            "Epoch 10/30\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0788 - mse: 0.0788 - mae: 0.2062 - val_loss: 0.0574 - val_mse: 0.0574 - val_mae: 0.1756\n",
            "Epoch 11/30\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0695 - mse: 0.0695 - mae: 0.1942 - val_loss: 0.0508 - val_mse: 0.0508 - val_mae: 0.1642\n",
            "Epoch 12/30\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0622 - mse: 0.0622 - mae: 0.1870 - val_loss: 0.0464 - val_mse: 0.0464 - val_mae: 0.1602\n",
            "Epoch 13/30\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0571 - mse: 0.0571 - mae: 0.1837 - val_loss: 0.0442 - val_mse: 0.0442 - val_mae: 0.1576\n",
            "Epoch 14/30\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0541 - mse: 0.0541 - mae: 0.1839 - val_loss: 0.0441 - val_mse: 0.0441 - val_mae: 0.1603\n",
            "Epoch 15/30\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0533 - mse: 0.0533 - mae: 0.1879 - val_loss: 0.0458 - val_mse: 0.0458 - val_mae: 0.1688\n",
            "Epoch 16/30\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0544 - mse: 0.0544 - mae: 0.1936 - val_loss: 0.0487 - val_mse: 0.0487 - val_mae: 0.1793\n",
            "Epoch 17/30\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0567 - mse: 0.0567 - mae: 0.2003 - val_loss: 0.0520 - val_mse: 0.0520 - val_mae: 0.1876\n",
            "Epoch 18/30\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0594 - mse: 0.0594 - mae: 0.2065 - val_loss: 0.0546 - val_mse: 0.0546 - val_mae: 0.1943\n",
            "Epoch 19/30\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0617 - mse: 0.0617 - mae: 0.2107 - val_loss: 0.0562 - val_mse: 0.0562 - val_mae: 0.1987\n",
            "Epoch 20/30\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0630 - mse: 0.0630 - mae: 0.2133 - val_loss: 0.0565 - val_mse: 0.0565 - val_mae: 0.1998\n",
            "Epoch 21/30\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0631 - mse: 0.0631 - mae: 0.2136 - val_loss: 0.0555 - val_mse: 0.0555 - val_mae: 0.1980\n",
            "Epoch 22/30\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0620 - mse: 0.0620 - mae: 0.2119 - val_loss: 0.0536 - val_mse: 0.0536 - val_mae: 0.1936\n",
            "Epoch 23/30\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0601 - mse: 0.0601 - mae: 0.2085 - val_loss: 0.0510 - val_mse: 0.0510 - val_mae: 0.1876\n",
            "Epoch 24/30\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0577 - mse: 0.0577 - mae: 0.2040 - val_loss: 0.0482 - val_mse: 0.0482 - val_mae: 0.1812\n",
            "Epoch 25/30\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0550 - mse: 0.0550 - mae: 0.1991 - val_loss: 0.0455 - val_mse: 0.0455 - val_mae: 0.1746\n",
            "Epoch 26/30\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0524 - mse: 0.0524 - mae: 0.1939 - val_loss: 0.0430 - val_mse: 0.0430 - val_mae: 0.1678\n",
            "Epoch 27/30\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0501 - mse: 0.0501 - mae: 0.1885 - val_loss: 0.0410 - val_mse: 0.0410 - val_mae: 0.1611\n",
            "Epoch 28/30\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0482 - mse: 0.0482 - mae: 0.1837 - val_loss: 0.0393 - val_mse: 0.0393 - val_mae: 0.1548\n",
            "Epoch 29/30\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0467 - mse: 0.0467 - mae: 0.1794 - val_loss: 0.0382 - val_mse: 0.0382 - val_mae: 0.1505\n",
            "Epoch 30/30\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0456 - mse: 0.0456 - mae: 0.1757 - val_loss: 0.0373 - val_mse: 0.0373 - val_mae: 0.1476\n"
          ]
        }
      ],
      "source": [
        "model.compile(loss='mse', optimizer='adam', metrics=['mse','mae'])\n",
        "history=model.fit(xtrain_scale, ytrain_scale, epochs=30, batch_size=150, verbose=1, validation_split=0.2)\n",
        "predictions = model.predict(xval_scale)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "xdzzeOuP_7gs",
        "outputId": "e233613d-7661-4d92-ac1e-2ab23567cfc1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['loss', 'mse', 'mae', 'val_loss', 'val_mse', 'val_mae'])\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(history.history.keys())\n",
        "# \"Loss\"\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ovg1FuvKREGo"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVgPrIcz9cZ8",
        "outputId": "1ac75e2f-e8a3-4b1f-ecb1-56d3f1c43802"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[536.4475 ],\n",
              "       [547.6313 ],\n",
              "       [604.8438 ],\n",
              "       [548.039  ],\n",
              "       [525.06305],\n",
              "       [516.21484],\n",
              "       [549.2116 ],\n",
              "       [586.03   ],\n",
              "       [603.2041 ],\n",
              "       [611.8776 ],\n",
              "       [534.4038 ],\n",
              "       [545.34106],\n",
              "       [611.8022 ],\n",
              "       [537.63354],\n",
              "       [527.63086],\n",
              "       [544.4875 ],\n",
              "       [556.25867],\n",
              "       [551.87244],\n",
              "       [575.29156],\n",
              "       [526.301  ],\n",
              "       [545.851  ],\n",
              "       [530.06036],\n",
              "       [542.44836],\n",
              "       [524.2276 ],\n",
              "       [546.48254],\n",
              "       [548.0777 ],\n",
              "       [535.6315 ],\n",
              "       [548.2    ],\n",
              "       [577.3203 ],\n",
              "       [544.0516 ],\n",
              "       [543.8167 ],\n",
              "       [555.0335 ],\n",
              "       [544.7712 ],\n",
              "       [579.9567 ],\n",
              "       [541.31024],\n",
              "       [521.9905 ],\n",
              "       [514.2243 ],\n",
              "       [542.9846 ],\n",
              "       [552.3525 ],\n",
              "       [524.53357],\n",
              "       [536.57294],\n",
              "       [537.79004],\n",
              "       [552.6294 ],\n",
              "       [532.4163 ],\n",
              "       [548.77747],\n",
              "       [514.15424],\n",
              "       [524.2036 ],\n",
              "       [612.01263],\n",
              "       [540.11206],\n",
              "       [602.84546],\n",
              "       [598.93317],\n",
              "       [562.04407],\n",
              "       [538.18036],\n",
              "       [545.9161 ],\n",
              "       [569.9577 ],\n",
              "       [549.7648 ],\n",
              "       [537.12897],\n",
              "       [588.0502 ]], dtype=float32)"
            ]
          },
          "execution_count": 115,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictions = scaler_y.inverse_transform(predictions)\n",
        "predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEHOtDvFNQ3Y",
        "outputId": "dafdebb5-da35-4fc5-cf44-2f1887bb820b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "46"
            ]
          },
          "execution_count": 123,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(df_test.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8qyr3bVBEIIW"
      },
      "outputs": [],
      "source": [
        "ActPred2 = pd.DataFrame(np.concatenate([y_val, predictions], axis=1), columns= ['Actual','NN_Predicted'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "IEcHsXGPEIMK",
        "outputId": "1b33569c-0355-472d-9a96-15f5d01f168d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-278a43f1-edeb-4d1d-b77a-aac35393d142\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Actual</th>\n",
              "      <th>NN_Predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>288.00</td>\n",
              "      <td>536.447510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>452.00</td>\n",
              "      <td>547.631287</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>949.00</td>\n",
              "      <td>604.843811</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>504.00</td>\n",
              "      <td>548.039001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>390.00</td>\n",
              "      <td>525.063049</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>410.00</td>\n",
              "      <td>516.214844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>515.00</td>\n",
              "      <td>549.211609</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>855.00</td>\n",
              "      <td>586.030029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>944.00</td>\n",
              "      <td>603.204102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1012.25</td>\n",
              "      <td>611.877625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>330.00</td>\n",
              "      <td>534.403809</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>562.00</td>\n",
              "      <td>545.341064</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1012.25</td>\n",
              "      <td>611.802185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>476.00</td>\n",
              "      <td>537.633545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>349.00</td>\n",
              "      <td>527.630859</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>468.00</td>\n",
              "      <td>544.487488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>540.00</td>\n",
              "      <td>556.258667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>615.00</td>\n",
              "      <td>551.872437</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>816.00</td>\n",
              "      <td>575.291565</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>345.00</td>\n",
              "      <td>526.301025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>419.00</td>\n",
              "      <td>545.851013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>372.00</td>\n",
              "      <td>530.060364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>441.00</td>\n",
              "      <td>542.448364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>348.00</td>\n",
              "      <td>524.227600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>694.00</td>\n",
              "      <td>546.482544</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>562.00</td>\n",
              "      <td>548.077698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>427.00</td>\n",
              "      <td>535.631470</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>446.00</td>\n",
              "      <td>548.200012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>587.00</td>\n",
              "      <td>577.320312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>423.00</td>\n",
              "      <td>544.051575</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>561.00</td>\n",
              "      <td>543.816711</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>719.00</td>\n",
              "      <td>555.033508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>674.00</td>\n",
              "      <td>544.771179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>822.00</td>\n",
              "      <td>579.956726</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>411.00</td>\n",
              "      <td>541.310242</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>323.00</td>\n",
              "      <td>521.990479</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>408.00</td>\n",
              "      <td>514.224304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>550.00</td>\n",
              "      <td>542.984619</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>471.00</td>\n",
              "      <td>552.352478</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>404.00</td>\n",
              "      <td>524.533569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>509.00</td>\n",
              "      <td>536.572937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>473.00</td>\n",
              "      <td>537.790039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>548.00</td>\n",
              "      <td>552.629395</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>353.00</td>\n",
              "      <td>532.416321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>458.00</td>\n",
              "      <td>548.777466</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>392.00</td>\n",
              "      <td>514.154236</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>332.00</td>\n",
              "      <td>524.203613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>1012.25</td>\n",
              "      <td>612.012634</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>387.00</td>\n",
              "      <td>540.112061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>926.00</td>\n",
              "      <td>602.845459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>636.00</td>\n",
              "      <td>598.933167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>661.00</td>\n",
              "      <td>562.044067</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>240.00</td>\n",
              "      <td>538.180359</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>499.00</td>\n",
              "      <td>545.916077</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>656.00</td>\n",
              "      <td>569.957703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>451.00</td>\n",
              "      <td>549.764771</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>323.00</td>\n",
              "      <td>537.128967</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>863.00</td>\n",
              "      <td>588.050171</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-278a43f1-edeb-4d1d-b77a-aac35393d142')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-278a43f1-edeb-4d1d-b77a-aac35393d142 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-278a43f1-edeb-4d1d-b77a-aac35393d142');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     Actual  NN_Predicted\n",
              "0    288.00    536.447510\n",
              "1    452.00    547.631287\n",
              "2    949.00    604.843811\n",
              "3    504.00    548.039001\n",
              "4    390.00    525.063049\n",
              "5    410.00    516.214844\n",
              "6    515.00    549.211609\n",
              "7    855.00    586.030029\n",
              "8    944.00    603.204102\n",
              "9   1012.25    611.877625\n",
              "10   330.00    534.403809\n",
              "11   562.00    545.341064\n",
              "12  1012.25    611.802185\n",
              "13   476.00    537.633545\n",
              "14   349.00    527.630859\n",
              "15   468.00    544.487488\n",
              "16   540.00    556.258667\n",
              "17   615.00    551.872437\n",
              "18   816.00    575.291565\n",
              "19   345.00    526.301025\n",
              "20   419.00    545.851013\n",
              "21   372.00    530.060364\n",
              "22   441.00    542.448364\n",
              "23   348.00    524.227600\n",
              "24   694.00    546.482544\n",
              "25   562.00    548.077698\n",
              "26   427.00    535.631470\n",
              "27   446.00    548.200012\n",
              "28   587.00    577.320312\n",
              "29   423.00    544.051575\n",
              "30   561.00    543.816711\n",
              "31   719.00    555.033508\n",
              "32   674.00    544.771179\n",
              "33   822.00    579.956726\n",
              "34   411.00    541.310242\n",
              "35   323.00    521.990479\n",
              "36   408.00    514.224304\n",
              "37   550.00    542.984619\n",
              "38   471.00    552.352478\n",
              "39   404.00    524.533569\n",
              "40   509.00    536.572937\n",
              "41   473.00    537.790039\n",
              "42   548.00    552.629395\n",
              "43   353.00    532.416321\n",
              "44   458.00    548.777466\n",
              "45   392.00    514.154236\n",
              "46   332.00    524.203613\n",
              "47  1012.25    612.012634\n",
              "48   387.00    540.112061\n",
              "49   926.00    602.845459\n",
              "50   636.00    598.933167\n",
              "51   661.00    562.044067\n",
              "52   240.00    538.180359\n",
              "53   499.00    545.916077\n",
              "54   656.00    569.957703\n",
              "55   451.00    549.764771\n",
              "56   323.00    537.128967\n",
              "57   863.00    588.050171"
            ]
          },
          "execution_count": 125,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ActPred2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 845
        },
        "id": "ZG_ZA2RnEIQQ",
        "outputId": "4722e67a-d845-40e5-d5b2-f8ef596f0bdd"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-129-0e1ca7e15c2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'red'\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mActPred2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'blue'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'MLP Prediction'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'True Values'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Predictions by Mlp'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'MLP Prediction'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'best'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2761\u001b[0m     return gca().plot(\n\u001b[1;32m   2762\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[0;32m-> 2763\u001b[0;31m         is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1645\u001b[0m         \"\"\"\n\u001b[1;32m   1646\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1647\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1648\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    343\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (230,) and (58, 1)"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x576 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(16,8))\n",
        "plt.grid()\n",
        "plt.plot(df.index, y_val, color = 'red',  label = 'Test')\n",
        "plt.plot(df.index,  ActPred2, color = 'blue',label = 'MLP Prediction')\n",
        "plt.legend(['True Values', 'Predictions by Mlp', 'MLP Prediction'],loc='best')\n",
        "plt.title('Mlp Method: Actual vs. Prediction')\n",
        "plt.ylabel('Monthly Crude Palm Oil Price')\n",
        "plt.xlabel('Date')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c-gxcBLSEIUK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bad5d9b-f92b-4673-f077-015861886d45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 1s 2ms/step - loss: 0.0716 - accuracy: 0.0068\n",
            "Epoch 2/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0711 - accuracy: 0.0068\n",
            "Epoch 3/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0706 - accuracy: 0.0068\n",
            "Epoch 4/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0701 - accuracy: 0.0068\n",
            "Epoch 5/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0696 - accuracy: 0.0068\n",
            "Epoch 6/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0690 - accuracy: 0.0068\n",
            "Epoch 7/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0683 - accuracy: 0.0068\n",
            "Epoch 8/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0676 - accuracy: 0.0068\n",
            "Epoch 9/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0667 - accuracy: 0.0068\n",
            "Epoch 10/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0658 - accuracy: 0.0068\n",
            "Epoch 11/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0648 - accuracy: 0.0068\n",
            "Epoch 12/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0640 - accuracy: 0.0068\n",
            "Epoch 13/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0628 - accuracy: 0.0068\n",
            "Epoch 14/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0618 - accuracy: 0.0068\n",
            "Epoch 15/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0607 - accuracy: 0.0068\n",
            "Epoch 16/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0598 - accuracy: 0.0068\n",
            "Epoch 17/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0585 - accuracy: 0.0068\n",
            "Epoch 18/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0576 - accuracy: 0.0068\n",
            "Epoch 19/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0566 - accuracy: 0.0068\n",
            "Epoch 20/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0556 - accuracy: 0.0068\n",
            "Epoch 21/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0547 - accuracy: 0.0068\n",
            "Epoch 22/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0538 - accuracy: 0.0068\n",
            "Epoch 23/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0527 - accuracy: 0.0068\n",
            "Epoch 24/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0516 - accuracy: 0.0068\n",
            "Epoch 25/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0504 - accuracy: 0.0068\n",
            "Epoch 26/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0493 - accuracy: 0.0068\n",
            "Epoch 27/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0482 - accuracy: 0.0068\n",
            "Epoch 28/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0470 - accuracy: 0.0068\n",
            "Epoch 29/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0458 - accuracy: 0.0068\n",
            "Epoch 30/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0446 - accuracy: 0.0068\n",
            "Epoch 31/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0436 - accuracy: 0.0068\n",
            "Epoch 32/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0424 - accuracy: 0.0136\n",
            "Epoch 33/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0412 - accuracy: 0.0476\n",
            "Epoch 34/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0400 - accuracy: 0.0476\n",
            "Epoch 35/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0389 - accuracy: 0.0476\n",
            "Epoch 36/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0378 - accuracy: 0.0476\n",
            "Epoch 37/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0366 - accuracy: 0.0476\n",
            "Epoch 38/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0356 - accuracy: 0.0476\n",
            "Epoch 39/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0345 - accuracy: 0.0476\n",
            "Epoch 40/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0335 - accuracy: 0.0476\n",
            "Epoch 41/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0325 - accuracy: 0.0476\n",
            "Epoch 42/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0317 - accuracy: 0.0476\n",
            "Epoch 43/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0307 - accuracy: 0.0476\n",
            "Epoch 44/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0298 - accuracy: 0.0476\n",
            "Epoch 45/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0289 - accuracy: 0.0476\n",
            "Epoch 46/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0282 - accuracy: 0.0476\n",
            "Epoch 47/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0274 - accuracy: 0.0476\n",
            "Epoch 48/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0267 - accuracy: 0.0476\n",
            "Epoch 49/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0260 - accuracy: 0.0476\n",
            "Epoch 50/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0254 - accuracy: 0.0476\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 1s 2ms/step - loss: 0.0719 - accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0713 - accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0707 - accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0701 - accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0695 - accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0688 - accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0683 - accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0674 - accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0667 - accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0658 - accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0648 - accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0638 - accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0627 - accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0613 - accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0598 - accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0579 - accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0558 - accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0537 - accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0514 - accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0488 - accuracy: 0.0272\n",
            "Epoch 21/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0462 - accuracy: 0.0340\n",
            "Epoch 22/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0437 - accuracy: 0.0340\n",
            "Epoch 23/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0409 - accuracy: 0.0340\n",
            "Epoch 24/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0381 - accuracy: 0.0340\n",
            "Epoch 25/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0357 - accuracy: 0.0340\n",
            "Epoch 26/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0331 - accuracy: 0.0340\n",
            "Epoch 27/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0306 - accuracy: 0.0340\n",
            "Epoch 28/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0285 - accuracy: 0.0340\n",
            "Epoch 29/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0264 - accuracy: 0.0340\n",
            "Epoch 30/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0246 - accuracy: 0.0340\n",
            "Epoch 31/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0229 - accuracy: 0.0340\n",
            "Epoch 32/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0217 - accuracy: 0.0340\n",
            "Epoch 33/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0201 - accuracy: 0.0340\n",
            "Epoch 34/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0190 - accuracy: 0.0340\n",
            "Epoch 35/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0181 - accuracy: 0.0340\n",
            "Epoch 36/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0170 - accuracy: 0.0340\n",
            "Epoch 37/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0162 - accuracy: 0.0340\n",
            "Epoch 38/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0155 - accuracy: 0.0340\n",
            "Epoch 39/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0148 - accuracy: 0.0340\n",
            "Epoch 40/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0143 - accuracy: 0.0340\n",
            "Epoch 41/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0138 - accuracy: 0.0340\n",
            "Epoch 42/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0133 - accuracy: 0.0340\n",
            "Epoch 43/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0130 - accuracy: 0.0340\n",
            "Epoch 44/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0126 - accuracy: 0.0340\n",
            "Epoch 45/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0122 - accuracy: 0.0340\n",
            "Epoch 46/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0118 - accuracy: 0.0340\n",
            "Epoch 47/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0116 - accuracy: 0.0340\n",
            "Epoch 48/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0113 - accuracy: 0.0340\n",
            "Epoch 49/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0110 - accuracy: 0.0340\n",
            "Epoch 50/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0107 - accuracy: 0.0340\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 1s 2ms/step - loss: 0.0653 - accuracy: 0.0068\n",
            "Epoch 2/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0646 - accuracy: 0.0068\n",
            "Epoch 3/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0639 - accuracy: 0.0068\n",
            "Epoch 4/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0632 - accuracy: 0.0068\n",
            "Epoch 5/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0624 - accuracy: 0.0068\n",
            "Epoch 6/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0617 - accuracy: 0.0068\n",
            "Epoch 7/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0609 - accuracy: 0.0068\n",
            "Epoch 8/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0601 - accuracy: 0.0068\n",
            "Epoch 9/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0594 - accuracy: 0.0068\n",
            "Epoch 10/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0586 - accuracy: 0.0068\n",
            "Epoch 11/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0579 - accuracy: 0.0068\n",
            "Epoch 12/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0571 - accuracy: 0.0068\n",
            "Epoch 13/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0564 - accuracy: 0.0068\n",
            "Epoch 14/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0558 - accuracy: 0.0068\n",
            "Epoch 15/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0552 - accuracy: 0.0068\n",
            "Epoch 16/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0546 - accuracy: 0.0068\n",
            "Epoch 17/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0541 - accuracy: 0.0068\n",
            "Epoch 18/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0535 - accuracy: 0.0068\n",
            "Epoch 19/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0530 - accuracy: 0.0068\n",
            "Epoch 20/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0525 - accuracy: 0.0068\n",
            "Epoch 21/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0520 - accuracy: 0.0068\n",
            "Epoch 22/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0514 - accuracy: 0.0068\n",
            "Epoch 23/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0507 - accuracy: 0.0068\n",
            "Epoch 24/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0500 - accuracy: 0.0068\n",
            "Epoch 25/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0492 - accuracy: 0.0068\n",
            "Epoch 26/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0483 - accuracy: 0.0068\n",
            "Epoch 27/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0473 - accuracy: 0.0068\n",
            "Epoch 28/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0464 - accuracy: 0.0068\n",
            "Epoch 29/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0452 - accuracy: 0.0068\n",
            "Epoch 30/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0442 - accuracy: 0.0068\n",
            "Epoch 31/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0428 - accuracy: 0.0068\n",
            "Epoch 32/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0417 - accuracy: 0.0068\n",
            "Epoch 33/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0403 - accuracy: 0.0068\n",
            "Epoch 34/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0389 - accuracy: 0.0340\n",
            "Epoch 35/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0375 - accuracy: 0.0408\n",
            "Epoch 36/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0359 - accuracy: 0.0476\n",
            "Epoch 37/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0345 - accuracy: 0.0476\n",
            "Epoch 38/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0331 - accuracy: 0.0476\n",
            "Epoch 39/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0315 - accuracy: 0.0476\n",
            "Epoch 40/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0300 - accuracy: 0.0476\n",
            "Epoch 41/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0287 - accuracy: 0.0476\n",
            "Epoch 42/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0272 - accuracy: 0.0476\n",
            "Epoch 43/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0259 - accuracy: 0.0476\n",
            "Epoch 44/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0246 - accuracy: 0.0476\n",
            "Epoch 45/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0234 - accuracy: 0.0476\n",
            "Epoch 46/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0222 - accuracy: 0.0476\n",
            "Epoch 47/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0211 - accuracy: 0.0476\n",
            "Epoch 48/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0202 - accuracy: 0.0476\n",
            "Epoch 49/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0192 - accuracy: 0.0476\n",
            "Epoch 50/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0183 - accuracy: 0.0476\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 1s 2ms/step - loss: 0.0696 - accuracy: 0.0068\n",
            "Epoch 2/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0690 - accuracy: 0.0068\n",
            "Epoch 3/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0685 - accuracy: 0.0068\n",
            "Epoch 4/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0678 - accuracy: 0.0068\n",
            "Epoch 5/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0671 - accuracy: 0.0068\n",
            "Epoch 6/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0662 - accuracy: 0.0068\n",
            "Epoch 7/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0651 - accuracy: 0.0068\n",
            "Epoch 8/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0639 - accuracy: 0.0068\n",
            "Epoch 9/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0625 - accuracy: 0.0068\n",
            "Epoch 10/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0611 - accuracy: 0.0068\n",
            "Epoch 11/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0594 - accuracy: 0.0068\n",
            "Epoch 12/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0577 - accuracy: 0.0068\n",
            "Epoch 13/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0556 - accuracy: 0.0068\n",
            "Epoch 14/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0535 - accuracy: 0.0068\n",
            "Epoch 15/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0512 - accuracy: 0.0068\n",
            "Epoch 16/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0491 - accuracy: 0.0068\n",
            "Epoch 17/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0469 - accuracy: 0.0068\n",
            "Epoch 18/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0450 - accuracy: 0.0068\n",
            "Epoch 19/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0431 - accuracy: 0.0136\n",
            "Epoch 20/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0413 - accuracy: 0.0408\n",
            "Epoch 21/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0396 - accuracy: 0.0408\n",
            "Epoch 22/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0378 - accuracy: 0.0408\n",
            "Epoch 23/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0362 - accuracy: 0.0408\n",
            "Epoch 24/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0344 - accuracy: 0.0408\n",
            "Epoch 25/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0326 - accuracy: 0.0408\n",
            "Epoch 26/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0308 - accuracy: 0.0408\n",
            "Epoch 27/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0292 - accuracy: 0.0408\n",
            "Epoch 28/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0276 - accuracy: 0.0408\n",
            "Epoch 29/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0259 - accuracy: 0.0408\n",
            "Epoch 30/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0246 - accuracy: 0.0408\n",
            "Epoch 31/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0230 - accuracy: 0.0408\n",
            "Epoch 32/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0219 - accuracy: 0.0408\n",
            "Epoch 33/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0207 - accuracy: 0.0408\n",
            "Epoch 34/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0194 - accuracy: 0.0408\n",
            "Epoch 35/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0186 - accuracy: 0.0408\n",
            "Epoch 36/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0178 - accuracy: 0.0408\n",
            "Epoch 37/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0166 - accuracy: 0.0408\n",
            "Epoch 38/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0159 - accuracy: 0.0408\n",
            "Epoch 39/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0151 - accuracy: 0.0408\n",
            "Epoch 40/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0145 - accuracy: 0.0408\n",
            "Epoch 41/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0139 - accuracy: 0.0408\n",
            "Epoch 42/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0134 - accuracy: 0.0408\n",
            "Epoch 43/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0129 - accuracy: 0.0408\n",
            "Epoch 44/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0123 - accuracy: 0.0408\n",
            "Epoch 45/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0119 - accuracy: 0.0408\n",
            "Epoch 46/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0116 - accuracy: 0.0408\n",
            "Epoch 47/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0111 - accuracy: 0.0408\n",
            "Epoch 48/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0108 - accuracy: 0.0408\n",
            "Epoch 49/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0105 - accuracy: 0.0408\n",
            "Epoch 50/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0102 - accuracy: 0.0408\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 1s 2ms/step - loss: 0.0707 - accuracy: 0.0068\n",
            "Epoch 2/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0699 - accuracy: 0.0068\n",
            "Epoch 3/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0691 - accuracy: 0.0068\n",
            "Epoch 4/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0682 - accuracy: 0.0068\n",
            "Epoch 5/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0673 - accuracy: 0.0068\n",
            "Epoch 6/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0664 - accuracy: 0.0068\n",
            "Epoch 7/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0656 - accuracy: 0.0068\n",
            "Epoch 8/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0645 - accuracy: 0.0068\n",
            "Epoch 9/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0634 - accuracy: 0.0068\n",
            "Epoch 10/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0624 - accuracy: 0.0068\n",
            "Epoch 11/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0614 - accuracy: 0.0068\n",
            "Epoch 12/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0601 - accuracy: 0.0068\n",
            "Epoch 13/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0594 - accuracy: 0.0068\n",
            "Epoch 14/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0580 - accuracy: 0.0068\n",
            "Epoch 15/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0571 - accuracy: 0.0068\n",
            "Epoch 16/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0559 - accuracy: 0.0068\n",
            "Epoch 17/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0550 - accuracy: 0.0068\n",
            "Epoch 18/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0539 - accuracy: 0.0068\n",
            "Epoch 19/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0530 - accuracy: 0.0068\n",
            "Epoch 20/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0522 - accuracy: 0.0068\n",
            "Epoch 21/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0513 - accuracy: 0.0068\n",
            "Epoch 22/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0504 - accuracy: 0.0068\n",
            "Epoch 23/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0496 - accuracy: 0.0068\n",
            "Epoch 24/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0487 - accuracy: 0.0068\n",
            "Epoch 25/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0479 - accuracy: 0.0068\n",
            "Epoch 26/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0470 - accuracy: 0.0068\n",
            "Epoch 27/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0462 - accuracy: 0.0068\n",
            "Epoch 28/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0454 - accuracy: 0.0068\n",
            "Epoch 29/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0446 - accuracy: 0.0068\n",
            "Epoch 30/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0438 - accuracy: 0.0068\n",
            "Epoch 31/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0431 - accuracy: 0.0068\n",
            "Epoch 32/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0424 - accuracy: 0.0068\n",
            "Epoch 33/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0416 - accuracy: 0.0068\n",
            "Epoch 34/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0410 - accuracy: 0.0068\n",
            "Epoch 35/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0403 - accuracy: 0.0068\n",
            "Epoch 36/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0395 - accuracy: 0.0068\n",
            "Epoch 37/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0388 - accuracy: 0.0068\n",
            "Epoch 38/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0381 - accuracy: 0.0068\n",
            "Epoch 39/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0373 - accuracy: 0.0068\n",
            "Epoch 40/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0366 - accuracy: 0.0068\n",
            "Epoch 41/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0360 - accuracy: 0.0068\n",
            "Epoch 42/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0353 - accuracy: 0.0068\n",
            "Epoch 43/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0346 - accuracy: 0.0270\n",
            "Epoch 44/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0339 - accuracy: 0.0473\n",
            "Epoch 45/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0331 - accuracy: 0.0473\n",
            "Epoch 46/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0325 - accuracy: 0.0473\n",
            "Epoch 47/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0319 - accuracy: 0.0473\n",
            "Epoch 48/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0311 - accuracy: 0.0473\n",
            "Epoch 49/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0305 - accuracy: 0.0473\n",
            "Epoch 50/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0300 - accuracy: 0.0473\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0717 - accuracy: 0.0136\n",
            "Epoch 2/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0714 - accuracy: 0.0068\n",
            "Epoch 3/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0711 - accuracy: 0.0068\n",
            "Epoch 4/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0709 - accuracy: 0.0068\n",
            "Epoch 5/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0707 - accuracy: 0.0068\n",
            "Epoch 6/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0704 - accuracy: 0.0068\n",
            "Epoch 7/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0702 - accuracy: 0.0068\n",
            "Epoch 8/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0700 - accuracy: 0.0068\n",
            "Epoch 9/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0698 - accuracy: 0.0068\n",
            "Epoch 10/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0696 - accuracy: 0.0068\n",
            "Epoch 11/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0694 - accuracy: 0.0068\n",
            "Epoch 12/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0692 - accuracy: 0.0068\n",
            "Epoch 13/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0691 - accuracy: 0.0068\n",
            "Epoch 14/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0689 - accuracy: 0.0068\n",
            "Epoch 15/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0687 - accuracy: 0.0068\n",
            "Epoch 16/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0686 - accuracy: 0.0068\n",
            "Epoch 17/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0684 - accuracy: 0.0068\n",
            "Epoch 18/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0683 - accuracy: 0.0068\n",
            "Epoch 19/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0681 - accuracy: 0.0068\n",
            "Epoch 20/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0680 - accuracy: 0.0068\n",
            "Epoch 21/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0679 - accuracy: 0.0068\n",
            "Epoch 22/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0677 - accuracy: 0.0068\n",
            "Epoch 23/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0676 - accuracy: 0.0068\n",
            "Epoch 24/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0675 - accuracy: 0.0068\n",
            "Epoch 25/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0674 - accuracy: 0.0068\n",
            "Epoch 26/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0673 - accuracy: 0.0068\n",
            "Epoch 27/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0672 - accuracy: 0.0068\n",
            "Epoch 28/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0671 - accuracy: 0.0068\n",
            "Epoch 29/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0670 - accuracy: 0.0068\n",
            "Epoch 30/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0669 - accuracy: 0.0068\n",
            "Epoch 31/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0668 - accuracy: 0.0068\n",
            "Epoch 32/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0667 - accuracy: 0.0068\n",
            "Epoch 33/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0666 - accuracy: 0.0068\n",
            "Epoch 34/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0666 - accuracy: 0.0068\n",
            "Epoch 35/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0665 - accuracy: 0.0068\n",
            "Epoch 36/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0664 - accuracy: 0.0068\n",
            "Epoch 37/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0663 - accuracy: 0.0068\n",
            "Epoch 38/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0663 - accuracy: 0.0068\n",
            "Epoch 39/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0662 - accuracy: 0.0068\n",
            "Epoch 40/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0661 - accuracy: 0.0068\n",
            "Epoch 41/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0661 - accuracy: 0.0068\n",
            "Epoch 42/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0660 - accuracy: 0.0068\n",
            "Epoch 43/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0660 - accuracy: 0.0068\n",
            "Epoch 44/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0659 - accuracy: 0.0068\n",
            "Epoch 45/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0659 - accuracy: 0.0068\n",
            "Epoch 46/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0658 - accuracy: 0.0068\n",
            "Epoch 47/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0658 - accuracy: 0.0068\n",
            "Epoch 48/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0657 - accuracy: 0.0068\n",
            "Epoch 49/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0657 - accuracy: 0.0068\n",
            "Epoch 50/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0656 - accuracy: 0.0068\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0720 - accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0717 - accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0713 - accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0710 - accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0707 - accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0704 - accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0701 - accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0699 - accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0696 - accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0693 - accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0691 - accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0688 - accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0686 - accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0684 - accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0682 - accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0680 - accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0678 - accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0676 - accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0674 - accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0672 - accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0670 - accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0669 - accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0667 - accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0666 - accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0664 - accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0663 - accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0661 - accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0660 - accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0659 - accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0658 - accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0656 - accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0655 - accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0654 - accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0653 - accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0652 - accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0651 - accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0650 - accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0650 - accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0649 - accuracy: 0.0000e+00\n",
            "Epoch 40/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0648 - accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0647 - accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0646 - accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0645 - accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0645 - accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0644 - accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0643 - accuracy: 0.0000e+00\n",
            "Epoch 47/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0643 - accuracy: 0.0000e+00\n",
            "Epoch 48/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0642 - accuracy: 0.0000e+00\n",
            "Epoch 49/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0642 - accuracy: 0.0000e+00\n",
            "Epoch 50/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0641 - accuracy: 0.0000e+00\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0654 - accuracy: 0.0068\n",
            "Epoch 2/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 3/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0645 - accuracy: 0.0068\n",
            "Epoch 4/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0641 - accuracy: 0.0068\n",
            "Epoch 5/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0636 - accuracy: 0.0068\n",
            "Epoch 6/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0632 - accuracy: 0.0068\n",
            "Epoch 7/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0628 - accuracy: 0.0068\n",
            "Epoch 8/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0625 - accuracy: 0.0068\n",
            "Epoch 9/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0621 - accuracy: 0.0068\n",
            "Epoch 10/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0618 - accuracy: 0.0068\n",
            "Epoch 11/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0615 - accuracy: 0.0068\n",
            "Epoch 12/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0611 - accuracy: 0.0068\n",
            "Epoch 13/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0608 - accuracy: 0.0068\n",
            "Epoch 14/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0605 - accuracy: 0.0068\n",
            "Epoch 15/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0603 - accuracy: 0.0068\n",
            "Epoch 16/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0600 - accuracy: 0.0068\n",
            "Epoch 17/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0597 - accuracy: 0.0068\n",
            "Epoch 18/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0595 - accuracy: 0.0068\n",
            "Epoch 19/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0592 - accuracy: 0.0068\n",
            "Epoch 20/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0590 - accuracy: 0.0068\n",
            "Epoch 21/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0588 - accuracy: 0.0068\n",
            "Epoch 22/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0585 - accuracy: 0.0068\n",
            "Epoch 23/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0583 - accuracy: 0.0068\n",
            "Epoch 24/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0581 - accuracy: 0.0068\n",
            "Epoch 25/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0579 - accuracy: 0.0068\n",
            "Epoch 26/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0577 - accuracy: 0.0068\n",
            "Epoch 27/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0576 - accuracy: 0.0068\n",
            "Epoch 28/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0574 - accuracy: 0.0068\n",
            "Epoch 29/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0572 - accuracy: 0.0068\n",
            "Epoch 30/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0571 - accuracy: 0.0068\n",
            "Epoch 31/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0569 - accuracy: 0.0068\n",
            "Epoch 32/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0567 - accuracy: 0.0068\n",
            "Epoch 33/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0566 - accuracy: 0.0068\n",
            "Epoch 34/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0565 - accuracy: 0.0068\n",
            "Epoch 35/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0563 - accuracy: 0.0068\n",
            "Epoch 36/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0562 - accuracy: 0.0068\n",
            "Epoch 37/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0561 - accuracy: 0.0068\n",
            "Epoch 38/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0559 - accuracy: 0.0068\n",
            "Epoch 39/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0558 - accuracy: 0.0068\n",
            "Epoch 40/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0557 - accuracy: 0.0068\n",
            "Epoch 41/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0556 - accuracy: 0.0068\n",
            "Epoch 42/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0555 - accuracy: 0.0068\n",
            "Epoch 43/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0554 - accuracy: 0.0068\n",
            "Epoch 44/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0553 - accuracy: 0.0068\n",
            "Epoch 45/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0552 - accuracy: 0.0068\n",
            "Epoch 46/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0551 - accuracy: 0.0068\n",
            "Epoch 47/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0551 - accuracy: 0.0068\n",
            "Epoch 48/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0550 - accuracy: 0.0068\n",
            "Epoch 49/50\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0549 - accuracy: 0.0068\n",
            "Epoch 50/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0548 - accuracy: 0.0068\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0697 - accuracy: 0.0068\n",
            "Epoch 2/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0695 - accuracy: 0.0068\n",
            "Epoch 3/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0692 - accuracy: 0.0068\n",
            "Epoch 4/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0689 - accuracy: 0.0068\n",
            "Epoch 5/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0686 - accuracy: 0.0068\n",
            "Epoch 6/50\n",
            "15/15 [==============================] - 83s 2ms/step - loss: 0.0684 - accuracy: 0.0068  \n",
            "Epoch 7/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0681 - accuracy: 0.0068\n",
            "Epoch 8/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0679 - accuracy: 0.0068\n",
            "Epoch 9/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0677 - accuracy: 0.0068\n",
            "Epoch 10/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0675 - accuracy: 0.0068\n",
            "Epoch 11/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0673 - accuracy: 0.0068\n",
            "Epoch 12/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0671 - accuracy: 0.0068\n",
            "Epoch 13/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0669 - accuracy: 0.0068\n",
            "Epoch 14/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0667 - accuracy: 0.0068\n",
            "Epoch 15/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0665 - accuracy: 0.0068\n",
            "Epoch 16/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0664 - accuracy: 0.0068\n",
            "Epoch 17/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0662 - accuracy: 0.0068\n",
            "Epoch 18/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0660 - accuracy: 0.0068\n",
            "Epoch 19/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0659 - accuracy: 0.0068\n",
            "Epoch 20/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0657 - accuracy: 0.0068\n",
            "Epoch 21/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0656 - accuracy: 0.0068\n",
            "Epoch 22/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0654 - accuracy: 0.0068\n",
            "Epoch 23/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0653 - accuracy: 0.0068\n",
            "Epoch 24/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0652 - accuracy: 0.0068\n",
            "Epoch 25/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0651 - accuracy: 0.0068\n",
            "Epoch 26/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 27/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0648 - accuracy: 0.0068\n",
            "Epoch 28/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 29/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0646 - accuracy: 0.0068\n",
            "Epoch 30/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0645 - accuracy: 0.0068\n",
            "Epoch 31/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0644 - accuracy: 0.0068\n",
            "Epoch 32/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0643 - accuracy: 0.0068\n",
            "Epoch 33/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0642 - accuracy: 0.0068\n",
            "Epoch 34/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0642 - accuracy: 0.0068\n",
            "Epoch 35/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0641 - accuracy: 0.0068\n",
            "Epoch 36/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0640 - accuracy: 0.0068\n",
            "Epoch 37/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0639 - accuracy: 0.0068\n",
            "Epoch 38/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0638 - accuracy: 0.0068\n",
            "Epoch 39/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0638 - accuracy: 0.0068\n",
            "Epoch 40/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0637 - accuracy: 0.0068\n",
            "Epoch 41/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0636 - accuracy: 0.0068\n",
            "Epoch 42/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0636 - accuracy: 0.0068\n",
            "Epoch 43/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0635 - accuracy: 0.0068\n",
            "Epoch 44/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0634 - accuracy: 0.0068\n",
            "Epoch 45/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0634 - accuracy: 0.0068\n",
            "Epoch 46/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0633 - accuracy: 0.0068\n",
            "Epoch 47/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0633 - accuracy: 0.0068\n",
            "Epoch 48/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0632 - accuracy: 0.0068\n",
            "Epoch 49/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0632 - accuracy: 0.0068\n",
            "Epoch 50/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0631 - accuracy: 0.0068\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0709 - accuracy: 0.0068\n",
            "Epoch 2/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0704 - accuracy: 0.0068\n",
            "Epoch 3/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0699 - accuracy: 0.0068\n",
            "Epoch 4/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0694 - accuracy: 0.0068\n",
            "Epoch 5/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0690 - accuracy: 0.0068\n",
            "Epoch 6/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0685 - accuracy: 0.0068\n",
            "Epoch 7/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0681 - accuracy: 0.0068\n",
            "Epoch 8/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0677 - accuracy: 0.0068\n",
            "Epoch 9/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0673 - accuracy: 0.0068\n",
            "Epoch 10/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0669 - accuracy: 0.0068\n",
            "Epoch 11/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0666 - accuracy: 0.0068\n",
            "Epoch 12/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0662 - accuracy: 0.0068\n",
            "Epoch 13/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0659 - accuracy: 0.0068\n",
            "Epoch 14/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0656 - accuracy: 0.0068\n",
            "Epoch 15/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0652 - accuracy: 0.0068\n",
            "Epoch 16/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 17/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 18/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0644 - accuracy: 0.0068\n",
            "Epoch 19/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0641 - accuracy: 0.0068\n",
            "Epoch 20/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0638 - accuracy: 0.0068\n",
            "Epoch 21/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0636 - accuracy: 0.0068\n",
            "Epoch 22/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0633 - accuracy: 0.0068\n",
            "Epoch 23/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0631 - accuracy: 0.0068\n",
            "Epoch 24/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0629 - accuracy: 0.0068\n",
            "Epoch 25/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0627 - accuracy: 0.0068\n",
            "Epoch 26/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0625 - accuracy: 0.0068\n",
            "Epoch 27/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0623 - accuracy: 0.0068\n",
            "Epoch 28/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0621 - accuracy: 0.0068\n",
            "Epoch 29/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0619 - accuracy: 0.0068\n",
            "Epoch 30/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0617 - accuracy: 0.0068\n",
            "Epoch 31/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0616 - accuracy: 0.0068\n",
            "Epoch 32/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0614 - accuracy: 0.0068\n",
            "Epoch 33/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0612 - accuracy: 0.0068\n",
            "Epoch 34/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0611 - accuracy: 0.0068\n",
            "Epoch 35/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0609 - accuracy: 0.0068\n",
            "Epoch 36/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0608 - accuracy: 0.0068\n",
            "Epoch 37/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0607 - accuracy: 0.0068\n",
            "Epoch 38/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0605 - accuracy: 0.0068\n",
            "Epoch 39/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0604 - accuracy: 0.0068\n",
            "Epoch 40/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0603 - accuracy: 0.0068\n",
            "Epoch 41/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0602 - accuracy: 0.0068\n",
            "Epoch 42/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0601 - accuracy: 0.0068\n",
            "Epoch 43/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0600 - accuracy: 0.0068\n",
            "Epoch 44/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0599 - accuracy: 0.0068\n",
            "Epoch 45/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0598 - accuracy: 0.0068\n",
            "Epoch 46/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0597 - accuracy: 0.0068\n",
            "Epoch 47/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0596 - accuracy: 0.0068\n",
            "Epoch 48/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0595 - accuracy: 0.0068\n",
            "Epoch 49/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0594 - accuracy: 0.0068\n",
            "Epoch 50/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0593 - accuracy: 0.0068\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 1s 2ms/step - loss: 0.0715 - accuracy: 0.0136\n",
            "Epoch 2/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0711 - accuracy: 0.0068\n",
            "Epoch 3/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0706 - accuracy: 0.0068\n",
            "Epoch 4/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0702 - accuracy: 0.0068\n",
            "Epoch 5/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0698 - accuracy: 0.0068\n",
            "Epoch 6/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0694 - accuracy: 0.0068\n",
            "Epoch 7/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0690 - accuracy: 0.0068\n",
            "Epoch 8/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0685 - accuracy: 0.0068\n",
            "Epoch 9/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0679 - accuracy: 0.0068\n",
            "Epoch 10/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0673 - accuracy: 0.0068\n",
            "Epoch 11/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0665 - accuracy: 0.0068\n",
            "Epoch 12/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0656 - accuracy: 0.0068\n",
            "Epoch 13/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0645 - accuracy: 0.0068\n",
            "Epoch 14/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0633 - accuracy: 0.0476\n",
            "Epoch 15/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0620 - accuracy: 0.0476\n",
            "Epoch 16/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0607 - accuracy: 0.0476\n",
            "Epoch 17/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0591 - accuracy: 0.0476\n",
            "Epoch 18/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0575 - accuracy: 0.0476\n",
            "Epoch 19/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0558 - accuracy: 0.0476\n",
            "Epoch 20/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0541 - accuracy: 0.0476\n",
            "Epoch 21/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0522 - accuracy: 0.0476\n",
            "Epoch 22/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0503 - accuracy: 0.0476\n",
            "Epoch 23/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0485 - accuracy: 0.0476\n",
            "Epoch 24/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0468 - accuracy: 0.0476\n",
            "Epoch 25/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0450 - accuracy: 0.0476\n",
            "Epoch 26/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0433 - accuracy: 0.0476\n",
            "Epoch 27/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0416 - accuracy: 0.0476\n",
            "Epoch 28/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0402 - accuracy: 0.0476\n",
            "Epoch 29/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0386 - accuracy: 0.0476\n",
            "Epoch 30/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0373 - accuracy: 0.0476\n",
            "Epoch 31/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0358 - accuracy: 0.0476\n",
            "Epoch 32/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0346 - accuracy: 0.0476\n",
            "Epoch 33/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0333 - accuracy: 0.0476\n",
            "Epoch 34/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0323 - accuracy: 0.0476\n",
            "Epoch 35/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0313 - accuracy: 0.0476\n",
            "Epoch 36/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0303 - accuracy: 0.0476\n",
            "Epoch 37/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0294 - accuracy: 0.0476\n",
            "Epoch 38/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0286 - accuracy: 0.0476\n",
            "Epoch 39/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0278 - accuracy: 0.0476\n",
            "Epoch 40/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0271 - accuracy: 0.0476\n",
            "Epoch 41/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0264 - accuracy: 0.0476\n",
            "Epoch 42/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0258 - accuracy: 0.0476\n",
            "Epoch 43/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0252 - accuracy: 0.0476\n",
            "Epoch 44/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0246 - accuracy: 0.0476\n",
            "Epoch 45/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0241 - accuracy: 0.0476\n",
            "Epoch 46/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0236 - accuracy: 0.0476\n",
            "Epoch 47/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0231 - accuracy: 0.0476\n",
            "Epoch 48/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0226 - accuracy: 0.0476\n",
            "Epoch 49/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0221 - accuracy: 0.0476\n",
            "Epoch 50/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0217 - accuracy: 0.0476\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0719 - accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0712 - accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0706 - accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0700 - accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0693 - accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0686 - accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0678 - accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0670 - accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0661 - accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0652 - accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0641 - accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0631 - accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0618 - accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0606 - accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0594 - accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0581 - accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0570 - accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0559 - accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0549 - accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0538 - accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0530 - accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0521 - accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0513 - accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0505 - accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0497 - accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0490 - accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0483 - accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0476 - accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0469 - accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0463 - accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0456 - accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0449 - accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0443 - accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0436 - accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0429 - accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0423 - accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0417 - accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0411 - accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0405 - accuracy: 0.0000e+00\n",
            "Epoch 40/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0399 - accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0393 - accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0387 - accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0381 - accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0375 - accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0370 - accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0365 - accuracy: 0.0068\n",
            "Epoch 47/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0361 - accuracy: 0.0340\n",
            "Epoch 48/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0357 - accuracy: 0.0340\n",
            "Epoch 49/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0353 - accuracy: 0.0340\n",
            "Epoch 50/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0349 - accuracy: 0.0340\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 1s 2ms/step - loss: 0.0653 - accuracy: 0.0068\n",
            "Epoch 2/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0645 - accuracy: 0.0068\n",
            "Epoch 3/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0637 - accuracy: 0.0068\n",
            "Epoch 4/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0630 - accuracy: 0.0068\n",
            "Epoch 5/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0622 - accuracy: 0.0068\n",
            "Epoch 6/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0613 - accuracy: 0.0068\n",
            "Epoch 7/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0604 - accuracy: 0.0068\n",
            "Epoch 8/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0595 - accuracy: 0.0068\n",
            "Epoch 9/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0585 - accuracy: 0.0068\n",
            "Epoch 10/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0573 - accuracy: 0.0068\n",
            "Epoch 11/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0564 - accuracy: 0.0068\n",
            "Epoch 12/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0554 - accuracy: 0.0068\n",
            "Epoch 13/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0543 - accuracy: 0.0068\n",
            "Epoch 14/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0534 - accuracy: 0.0068\n",
            "Epoch 15/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0524 - accuracy: 0.0068\n",
            "Epoch 16/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0515 - accuracy: 0.0068\n",
            "Epoch 17/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0508 - accuracy: 0.0068\n",
            "Epoch 18/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0498 - accuracy: 0.0068\n",
            "Epoch 19/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0489 - accuracy: 0.0068\n",
            "Epoch 20/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0480 - accuracy: 0.0068\n",
            "Epoch 21/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0471 - accuracy: 0.0068\n",
            "Epoch 22/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0462 - accuracy: 0.0068\n",
            "Epoch 23/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0455 - accuracy: 0.0068\n",
            "Epoch 24/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0448 - accuracy: 0.0068\n",
            "Epoch 25/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0442 - accuracy: 0.0068\n",
            "Epoch 26/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0436 - accuracy: 0.0068\n",
            "Epoch 27/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0430 - accuracy: 0.0068\n",
            "Epoch 28/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0423 - accuracy: 0.0068\n",
            "Epoch 29/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0416 - accuracy: 0.0068\n",
            "Epoch 30/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0409 - accuracy: 0.0068\n",
            "Epoch 31/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0401 - accuracy: 0.0068\n",
            "Epoch 32/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0393 - accuracy: 0.0068\n",
            "Epoch 33/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0385 - accuracy: 0.0068\n",
            "Epoch 34/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0378 - accuracy: 0.0068\n",
            "Epoch 35/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0370 - accuracy: 0.0068\n",
            "Epoch 36/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0362 - accuracy: 0.0068\n",
            "Epoch 37/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0354 - accuracy: 0.0068\n",
            "Epoch 38/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0346 - accuracy: 0.0068\n",
            "Epoch 39/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0337 - accuracy: 0.0068\n",
            "Epoch 40/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0331 - accuracy: 0.0068\n",
            "Epoch 41/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0322 - accuracy: 0.0068\n",
            "Epoch 42/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0314 - accuracy: 0.0476\n",
            "Epoch 43/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0306 - accuracy: 0.0476\n",
            "Epoch 44/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0299 - accuracy: 0.0476\n",
            "Epoch 45/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0291 - accuracy: 0.0476\n",
            "Epoch 46/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0285 - accuracy: 0.0476\n",
            "Epoch 47/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0277 - accuracy: 0.0476\n",
            "Epoch 48/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0270 - accuracy: 0.0476\n",
            "Epoch 49/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0264 - accuracy: 0.0476\n",
            "Epoch 50/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0257 - accuracy: 0.0476\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0695 - accuracy: 0.0068\n",
            "Epoch 2/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0688 - accuracy: 0.0068\n",
            "Epoch 3/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0683 - accuracy: 0.0068\n",
            "Epoch 4/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0676 - accuracy: 0.0068\n",
            "Epoch 5/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0669 - accuracy: 0.0068\n",
            "Epoch 6/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0662 - accuracy: 0.0068\n",
            "Epoch 7/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0653 - accuracy: 0.0068\n",
            "Epoch 8/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0643 - accuracy: 0.0068\n",
            "Epoch 9/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0632 - accuracy: 0.0068\n",
            "Epoch 10/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0619 - accuracy: 0.0068\n",
            "Epoch 11/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0606 - accuracy: 0.0068\n",
            "Epoch 12/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0590 - accuracy: 0.0068\n",
            "Epoch 13/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0573 - accuracy: 0.0068\n",
            "Epoch 14/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0554 - accuracy: 0.0068\n",
            "Epoch 15/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0534 - accuracy: 0.0068\n",
            "Epoch 16/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0515 - accuracy: 0.0068\n",
            "Epoch 17/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0495 - accuracy: 0.0068\n",
            "Epoch 18/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0475 - accuracy: 0.0068\n",
            "Epoch 19/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0455 - accuracy: 0.0340\n",
            "Epoch 20/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0435 - accuracy: 0.0408\n",
            "Epoch 21/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0418 - accuracy: 0.0408\n",
            "Epoch 22/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0396 - accuracy: 0.0408\n",
            "Epoch 23/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0378 - accuracy: 0.0408\n",
            "Epoch 24/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0360 - accuracy: 0.0408\n",
            "Epoch 25/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0342 - accuracy: 0.0408\n",
            "Epoch 26/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0322 - accuracy: 0.0408\n",
            "Epoch 27/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0306 - accuracy: 0.0408\n",
            "Epoch 28/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0287 - accuracy: 0.0408\n",
            "Epoch 29/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0271 - accuracy: 0.0408\n",
            "Epoch 30/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0254 - accuracy: 0.0408\n",
            "Epoch 31/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0240 - accuracy: 0.0408\n",
            "Epoch 32/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0226 - accuracy: 0.0408\n",
            "Epoch 33/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0214 - accuracy: 0.0408\n",
            "Epoch 34/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0201 - accuracy: 0.0408\n",
            "Epoch 35/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0190 - accuracy: 0.0408\n",
            "Epoch 36/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0180 - accuracy: 0.0408\n",
            "Epoch 37/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0171 - accuracy: 0.0408\n",
            "Epoch 38/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0163 - accuracy: 0.0408\n",
            "Epoch 39/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0156 - accuracy: 0.0408\n",
            "Epoch 40/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0149 - accuracy: 0.0408\n",
            "Epoch 41/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0143 - accuracy: 0.0408\n",
            "Epoch 42/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0137 - accuracy: 0.0408\n",
            "Epoch 43/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0132 - accuracy: 0.0408\n",
            "Epoch 44/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0127 - accuracy: 0.0408\n",
            "Epoch 45/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0123 - accuracy: 0.0408\n",
            "Epoch 46/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0119 - accuracy: 0.0408\n",
            "Epoch 47/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0115 - accuracy: 0.0408\n",
            "Epoch 48/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0112 - accuracy: 0.0408\n",
            "Epoch 49/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0108 - accuracy: 0.0408\n",
            "Epoch 50/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0105 - accuracy: 0.0408\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 1s 2ms/step - loss: 0.0709 - accuracy: 0.0068\n",
            "Epoch 2/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0702 - accuracy: 0.0068\n",
            "Epoch 3/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0694 - accuracy: 0.0068\n",
            "Epoch 4/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0687 - accuracy: 0.0068\n",
            "Epoch 5/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0678 - accuracy: 0.0068\n",
            "Epoch 6/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0667 - accuracy: 0.0068\n",
            "Epoch 7/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0653 - accuracy: 0.0068\n",
            "Epoch 8/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0637 - accuracy: 0.0068\n",
            "Epoch 9/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0618 - accuracy: 0.0068\n",
            "Epoch 10/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0597 - accuracy: 0.0068\n",
            "Epoch 11/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0574 - accuracy: 0.0068\n",
            "Epoch 12/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0552 - accuracy: 0.0068\n",
            "Epoch 13/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0527 - accuracy: 0.0068\n",
            "Epoch 14/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0500 - accuracy: 0.0068\n",
            "Epoch 15/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0472 - accuracy: 0.0068\n",
            "Epoch 16/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0443 - accuracy: 0.0068\n",
            "Epoch 17/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0417 - accuracy: 0.0068\n",
            "Epoch 18/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0393 - accuracy: 0.0270\n",
            "Epoch 19/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0372 - accuracy: 0.0473\n",
            "Epoch 20/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0350 - accuracy: 0.0473\n",
            "Epoch 21/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0330 - accuracy: 0.0473\n",
            "Epoch 22/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0312 - accuracy: 0.0473\n",
            "Epoch 23/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0294 - accuracy: 0.0473\n",
            "Epoch 24/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0277 - accuracy: 0.0473\n",
            "Epoch 25/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0260 - accuracy: 0.0473\n",
            "Epoch 26/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0242 - accuracy: 0.0473\n",
            "Epoch 27/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0228 - accuracy: 0.0473\n",
            "Epoch 28/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0213 - accuracy: 0.0473\n",
            "Epoch 29/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0201 - accuracy: 0.0473\n",
            "Epoch 30/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0187 - accuracy: 0.0473\n",
            "Epoch 31/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0178 - accuracy: 0.0473\n",
            "Epoch 32/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0167 - accuracy: 0.0473\n",
            "Epoch 33/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0158 - accuracy: 0.0473\n",
            "Epoch 34/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0151 - accuracy: 0.0473\n",
            "Epoch 35/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0143 - accuracy: 0.0473\n",
            "Epoch 36/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0137 - accuracy: 0.0473\n",
            "Epoch 37/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0131 - accuracy: 0.0473\n",
            "Epoch 38/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0127 - accuracy: 0.0473\n",
            "Epoch 39/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0121 - accuracy: 0.0473\n",
            "Epoch 40/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0117 - accuracy: 0.0473\n",
            "Epoch 41/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0114 - accuracy: 0.0473\n",
            "Epoch 42/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0110 - accuracy: 0.0473\n",
            "Epoch 43/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0107 - accuracy: 0.0473\n",
            "Epoch 44/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0104 - accuracy: 0.0473\n",
            "Epoch 45/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0102 - accuracy: 0.0473\n",
            "Epoch 46/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0098 - accuracy: 0.0473\n",
            "Epoch 47/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0097 - accuracy: 0.0473\n",
            "Epoch 48/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0095 - accuracy: 0.0473\n",
            "Epoch 49/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0092 - accuracy: 0.0473\n",
            "Epoch 50/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0091 - accuracy: 0.0473\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0717 - accuracy: 0.0340\n",
            "Epoch 2/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0714 - accuracy: 0.0068\n",
            "Epoch 3/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0711 - accuracy: 0.0068\n",
            "Epoch 4/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0709 - accuracy: 0.0068\n",
            "Epoch 5/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0707 - accuracy: 0.0068\n",
            "Epoch 6/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0704 - accuracy: 0.0068\n",
            "Epoch 7/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0702 - accuracy: 0.0068\n",
            "Epoch 8/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0700 - accuracy: 0.0068\n",
            "Epoch 9/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0698 - accuracy: 0.0068\n",
            "Epoch 10/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0696 - accuracy: 0.0068\n",
            "Epoch 11/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0694 - accuracy: 0.0068\n",
            "Epoch 12/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0692 - accuracy: 0.0068\n",
            "Epoch 13/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0691 - accuracy: 0.0068\n",
            "Epoch 14/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0689 - accuracy: 0.0068\n",
            "Epoch 15/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0687 - accuracy: 0.0068\n",
            "Epoch 16/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0686 - accuracy: 0.0068\n",
            "Epoch 17/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0684 - accuracy: 0.0068\n",
            "Epoch 18/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0683 - accuracy: 0.0068\n",
            "Epoch 19/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0681 - accuracy: 0.0068\n",
            "Epoch 20/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0680 - accuracy: 0.0068\n",
            "Epoch 21/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0679 - accuracy: 0.0068\n",
            "Epoch 22/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0677 - accuracy: 0.0068\n",
            "Epoch 23/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0676 - accuracy: 0.0068\n",
            "Epoch 24/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0675 - accuracy: 0.0068\n",
            "Epoch 25/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0674 - accuracy: 0.0068\n",
            "Epoch 26/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0673 - accuracy: 0.0068\n",
            "Epoch 27/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0672 - accuracy: 0.0068\n",
            "Epoch 28/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0671 - accuracy: 0.0068\n",
            "Epoch 29/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0670 - accuracy: 0.0068\n",
            "Epoch 30/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0669 - accuracy: 0.0068\n",
            "Epoch 31/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0668 - accuracy: 0.0068\n",
            "Epoch 32/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0667 - accuracy: 0.0068\n",
            "Epoch 33/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0666 - accuracy: 0.0068\n",
            "Epoch 34/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0666 - accuracy: 0.0068\n",
            "Epoch 35/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0665 - accuracy: 0.0068\n",
            "Epoch 36/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0664 - accuracy: 0.0068\n",
            "Epoch 37/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0663 - accuracy: 0.0068\n",
            "Epoch 38/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0663 - accuracy: 0.0068\n",
            "Epoch 39/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0662 - accuracy: 0.0068\n",
            "Epoch 40/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0662 - accuracy: 0.0068\n",
            "Epoch 41/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0661 - accuracy: 0.0068\n",
            "Epoch 42/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0660 - accuracy: 0.0068\n",
            "Epoch 43/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0660 - accuracy: 0.0068\n",
            "Epoch 44/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0659 - accuracy: 0.0068\n",
            "Epoch 45/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0659 - accuracy: 0.0068\n",
            "Epoch 46/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0658 - accuracy: 0.0068\n",
            "Epoch 47/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0658 - accuracy: 0.0068\n",
            "Epoch 48/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0657 - accuracy: 0.0068\n",
            "Epoch 49/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0657 - accuracy: 0.0068\n",
            "Epoch 50/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0656 - accuracy: 0.0068\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0720 - accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0717 - accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0713 - accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0710 - accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0707 - accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0704 - accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0701 - accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0698 - accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0696 - accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0693 - accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0691 - accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0688 - accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0686 - accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0684 - accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0681 - accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0679 - accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0677 - accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0675 - accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0673 - accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0672 - accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0670 - accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0668 - accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0667 - accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0665 - accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0664 - accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0662 - accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0661 - accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0660 - accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0658 - accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0657 - accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0656 - accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0655 - accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0654 - accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0653 - accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0652 - accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0651 - accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0650 - accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0649 - accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0648 - accuracy: 0.0000e+00\n",
            "Epoch 40/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0647 - accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0646 - accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0646 - accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0645 - accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0644 - accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0643 - accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0643 - accuracy: 0.0000e+00\n",
            "Epoch 47/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0642 - accuracy: 0.0000e+00\n",
            "Epoch 48/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0642 - accuracy: 0.0000e+00\n",
            "Epoch 49/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0641 - accuracy: 0.0000e+00\n",
            "Epoch 50/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0640 - accuracy: 0.0000e+00\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0654 - accuracy: 0.0136\n",
            "Epoch 2/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 3/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0645 - accuracy: 0.0068\n",
            "Epoch 4/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0640 - accuracy: 0.0068\n",
            "Epoch 5/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0636 - accuracy: 0.0068\n",
            "Epoch 6/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0632 - accuracy: 0.0068\n",
            "Epoch 7/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0628 - accuracy: 0.0068\n",
            "Epoch 8/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0625 - accuracy: 0.0068\n",
            "Epoch 9/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0621 - accuracy: 0.0068\n",
            "Epoch 10/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0618 - accuracy: 0.0068\n",
            "Epoch 11/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0614 - accuracy: 0.0068\n",
            "Epoch 12/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0611 - accuracy: 0.0068\n",
            "Epoch 13/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0608 - accuracy: 0.0068\n",
            "Epoch 14/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0605 - accuracy: 0.0068\n",
            "Epoch 15/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0602 - accuracy: 0.0068\n",
            "Epoch 16/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0599 - accuracy: 0.0068\n",
            "Epoch 17/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0597 - accuracy: 0.0068\n",
            "Epoch 18/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0594 - accuracy: 0.0068\n",
            "Epoch 19/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0592 - accuracy: 0.0068\n",
            "Epoch 20/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0589 - accuracy: 0.0068\n",
            "Epoch 21/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0587 - accuracy: 0.0068\n",
            "Epoch 22/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0585 - accuracy: 0.0068\n",
            "Epoch 23/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0583 - accuracy: 0.0068\n",
            "Epoch 24/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0581 - accuracy: 0.0068\n",
            "Epoch 25/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0579 - accuracy: 0.0068\n",
            "Epoch 26/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0577 - accuracy: 0.0068\n",
            "Epoch 27/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0575 - accuracy: 0.0068\n",
            "Epoch 28/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0574 - accuracy: 0.0068\n",
            "Epoch 29/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0572 - accuracy: 0.0068\n",
            "Epoch 30/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0570 - accuracy: 0.0068\n",
            "Epoch 31/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0569 - accuracy: 0.0068\n",
            "Epoch 32/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0567 - accuracy: 0.0068\n",
            "Epoch 33/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0566 - accuracy: 0.0068\n",
            "Epoch 34/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0564 - accuracy: 0.0068\n",
            "Epoch 35/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0563 - accuracy: 0.0068\n",
            "Epoch 36/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0562 - accuracy: 0.0068\n",
            "Epoch 37/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0561 - accuracy: 0.0068\n",
            "Epoch 38/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0559 - accuracy: 0.0068\n",
            "Epoch 39/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0558 - accuracy: 0.0068\n",
            "Epoch 40/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0557 - accuracy: 0.0068\n",
            "Epoch 41/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0556 - accuracy: 0.0068\n",
            "Epoch 42/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0555 - accuracy: 0.0068\n",
            "Epoch 43/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0554 - accuracy: 0.0068\n",
            "Epoch 44/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0553 - accuracy: 0.0068\n",
            "Epoch 45/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0552 - accuracy: 0.0068\n",
            "Epoch 46/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0551 - accuracy: 0.0068\n",
            "Epoch 47/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0550 - accuracy: 0.0068\n",
            "Epoch 48/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0550 - accuracy: 0.0068\n",
            "Epoch 49/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0549 - accuracy: 0.0068\n",
            "Epoch 50/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0548 - accuracy: 0.0068\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0697 - accuracy: 0.0068\n",
            "Epoch 2/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0694 - accuracy: 0.0068\n",
            "Epoch 3/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0692 - accuracy: 0.0068\n",
            "Epoch 4/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0689 - accuracy: 0.0068\n",
            "Epoch 5/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0687 - accuracy: 0.0068\n",
            "Epoch 6/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0684 - accuracy: 0.0068\n",
            "Epoch 7/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0681 - accuracy: 0.0068\n",
            "Epoch 8/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0679 - accuracy: 0.0068\n",
            "Epoch 9/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0677 - accuracy: 0.0068\n",
            "Epoch 10/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0675 - accuracy: 0.0068\n",
            "Epoch 11/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0673 - accuracy: 0.0068\n",
            "Epoch 12/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0671 - accuracy: 0.0068\n",
            "Epoch 13/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0669 - accuracy: 0.0068\n",
            "Epoch 14/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0667 - accuracy: 0.0068\n",
            "Epoch 15/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0665 - accuracy: 0.0068\n",
            "Epoch 16/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0663 - accuracy: 0.0068\n",
            "Epoch 17/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0662 - accuracy: 0.0068\n",
            "Epoch 18/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0660 - accuracy: 0.0068\n",
            "Epoch 19/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0659 - accuracy: 0.0068\n",
            "Epoch 20/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0657 - accuracy: 0.0068\n",
            "Epoch 21/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0656 - accuracy: 0.0068\n",
            "Epoch 22/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0654 - accuracy: 0.0068\n",
            "Epoch 23/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0653 - accuracy: 0.0068\n",
            "Epoch 24/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0652 - accuracy: 0.0068\n",
            "Epoch 25/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0651 - accuracy: 0.0068\n",
            "Epoch 26/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 27/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0648 - accuracy: 0.0068\n",
            "Epoch 28/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 29/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0646 - accuracy: 0.0068\n",
            "Epoch 30/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0645 - accuracy: 0.0068\n",
            "Epoch 31/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0644 - accuracy: 0.0068\n",
            "Epoch 32/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0643 - accuracy: 0.0068\n",
            "Epoch 33/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0642 - accuracy: 0.0068\n",
            "Epoch 34/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0641 - accuracy: 0.0068\n",
            "Epoch 35/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0641 - accuracy: 0.0068\n",
            "Epoch 36/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0640 - accuracy: 0.0068\n",
            "Epoch 37/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0639 - accuracy: 0.0068\n",
            "Epoch 38/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0638 - accuracy: 0.0068\n",
            "Epoch 39/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0638 - accuracy: 0.0068\n",
            "Epoch 40/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0637 - accuracy: 0.0068\n",
            "Epoch 41/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0636 - accuracy: 0.0068\n",
            "Epoch 42/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0636 - accuracy: 0.0068\n",
            "Epoch 43/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0635 - accuracy: 0.0068\n",
            "Epoch 44/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0634 - accuracy: 0.0068\n",
            "Epoch 45/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0634 - accuracy: 0.0068\n",
            "Epoch 46/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0633 - accuracy: 0.0068\n",
            "Epoch 47/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0633 - accuracy: 0.0068\n",
            "Epoch 48/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0632 - accuracy: 0.0068\n",
            "Epoch 49/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0632 - accuracy: 0.0068\n",
            "Epoch 50/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0631 - accuracy: 0.0068\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0709 - accuracy: 0.0068\n",
            "Epoch 2/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0704 - accuracy: 0.0068\n",
            "Epoch 3/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0699 - accuracy: 0.0068\n",
            "Epoch 4/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0694 - accuracy: 0.0068\n",
            "Epoch 5/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0690 - accuracy: 0.0068\n",
            "Epoch 6/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0685 - accuracy: 0.0068\n",
            "Epoch 7/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0681 - accuracy: 0.0068\n",
            "Epoch 8/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0677 - accuracy: 0.0068\n",
            "Epoch 9/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0673 - accuracy: 0.0068\n",
            "Epoch 10/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0669 - accuracy: 0.0068\n",
            "Epoch 11/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0666 - accuracy: 0.0068\n",
            "Epoch 12/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0662 - accuracy: 0.0068\n",
            "Epoch 13/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0659 - accuracy: 0.0068\n",
            "Epoch 14/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0655 - accuracy: 0.0068\n",
            "Epoch 15/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0652 - accuracy: 0.0068\n",
            "Epoch 16/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 17/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0646 - accuracy: 0.0068\n",
            "Epoch 18/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0644 - accuracy: 0.0068\n",
            "Epoch 19/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0641 - accuracy: 0.0068\n",
            "Epoch 20/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0638 - accuracy: 0.0068\n",
            "Epoch 21/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0636 - accuracy: 0.0068\n",
            "Epoch 22/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0633 - accuracy: 0.0068\n",
            "Epoch 23/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0631 - accuracy: 0.0068\n",
            "Epoch 24/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0629 - accuracy: 0.0068\n",
            "Epoch 25/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0627 - accuracy: 0.0068\n",
            "Epoch 26/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0625 - accuracy: 0.0068\n",
            "Epoch 27/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0623 - accuracy: 0.0068\n",
            "Epoch 28/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0621 - accuracy: 0.0068\n",
            "Epoch 29/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0619 - accuracy: 0.0068\n",
            "Epoch 30/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0617 - accuracy: 0.0068\n",
            "Epoch 31/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0616 - accuracy: 0.0068\n",
            "Epoch 32/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0614 - accuracy: 0.0068\n",
            "Epoch 33/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0612 - accuracy: 0.0068\n",
            "Epoch 34/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0611 - accuracy: 0.0068\n",
            "Epoch 35/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0609 - accuracy: 0.0068\n",
            "Epoch 36/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0608 - accuracy: 0.0068\n",
            "Epoch 37/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0607 - accuracy: 0.0068\n",
            "Epoch 38/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0605 - accuracy: 0.0068\n",
            "Epoch 39/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0604 - accuracy: 0.0068\n",
            "Epoch 40/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0603 - accuracy: 0.0068\n",
            "Epoch 41/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0602 - accuracy: 0.0068\n",
            "Epoch 42/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0601 - accuracy: 0.0068\n",
            "Epoch 43/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0600 - accuracy: 0.0068\n",
            "Epoch 44/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0599 - accuracy: 0.0068\n",
            "Epoch 45/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0598 - accuracy: 0.0068\n",
            "Epoch 46/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0597 - accuracy: 0.0068\n",
            "Epoch 47/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0596 - accuracy: 0.0068\n",
            "Epoch 48/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0595 - accuracy: 0.0068\n",
            "Epoch 49/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0594 - accuracy: 0.0068\n",
            "Epoch 50/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0593 - accuracy: 0.0068\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 1s 2ms/step - loss: 0.0716 - accuracy: 0.0068\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0710 - accuracy: 0.0068\n",
            "Epoch 3/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0704 - accuracy: 0.0068\n",
            "Epoch 4/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0697 - accuracy: 0.0068\n",
            "Epoch 5/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0689 - accuracy: 0.0068\n",
            "Epoch 6/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0680 - accuracy: 0.0068\n",
            "Epoch 7/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0669 - accuracy: 0.0068\n",
            "Epoch 8/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0656 - accuracy: 0.0068\n",
            "Epoch 9/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0641 - accuracy: 0.0068\n",
            "Epoch 10/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0623 - accuracy: 0.0068\n",
            "Epoch 11/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0603 - accuracy: 0.0068\n",
            "Epoch 12/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0581 - accuracy: 0.0068\n",
            "Epoch 13/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0560 - accuracy: 0.0068\n",
            "Epoch 14/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0537 - accuracy: 0.0068\n",
            "Epoch 15/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0518 - accuracy: 0.0068\n",
            "Epoch 16/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0499 - accuracy: 0.0068\n",
            "Epoch 17/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0483 - accuracy: 0.0068\n",
            "Epoch 18/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0468 - accuracy: 0.0068\n",
            "Epoch 19/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0456 - accuracy: 0.0068\n",
            "Epoch 20/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0444 - accuracy: 0.0068\n",
            "Epoch 21/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0433 - accuracy: 0.0068\n",
            "Epoch 22/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0424 - accuracy: 0.0068\n",
            "Epoch 23/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0413 - accuracy: 0.0068\n",
            "Epoch 24/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0404 - accuracy: 0.0068\n",
            "Epoch 25/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0396 - accuracy: 0.0068\n",
            "Epoch 26/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0388 - accuracy: 0.0068\n",
            "Epoch 27/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0381 - accuracy: 0.0068\n",
            "Epoch 28/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0374 - accuracy: 0.0068\n",
            "Epoch 29/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0367 - accuracy: 0.0068\n",
            "Epoch 30/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0361 - accuracy: 0.0068\n",
            "Epoch 31/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0356 - accuracy: 0.0204\n",
            "Epoch 32/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0348 - accuracy: 0.0476\n",
            "Epoch 33/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0342 - accuracy: 0.0476\n",
            "Epoch 34/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0336 - accuracy: 0.0476\n",
            "Epoch 35/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0330 - accuracy: 0.0476\n",
            "Epoch 36/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0325 - accuracy: 0.0476\n",
            "Epoch 37/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0320 - accuracy: 0.0476\n",
            "Epoch 38/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0314 - accuracy: 0.0476\n",
            "Epoch 39/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0309 - accuracy: 0.0476\n",
            "Epoch 40/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0303 - accuracy: 0.0476\n",
            "Epoch 41/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0298 - accuracy: 0.0476\n",
            "Epoch 42/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0293 - accuracy: 0.0476\n",
            "Epoch 43/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0288 - accuracy: 0.0476\n",
            "Epoch 44/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0283 - accuracy: 0.0476\n",
            "Epoch 45/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0278 - accuracy: 0.0476\n",
            "Epoch 46/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0274 - accuracy: 0.0476\n",
            "Epoch 47/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0270 - accuracy: 0.0476\n",
            "Epoch 48/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0265 - accuracy: 0.0476\n",
            "Epoch 49/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0260 - accuracy: 0.0476\n",
            "Epoch 50/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0256 - accuracy: 0.0476\n",
            "Epoch 51/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0251 - accuracy: 0.0476\n",
            "Epoch 52/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0247 - accuracy: 0.0476\n",
            "Epoch 53/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0243 - accuracy: 0.0476\n",
            "Epoch 54/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0239 - accuracy: 0.0476\n",
            "Epoch 55/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0234 - accuracy: 0.0476\n",
            "Epoch 56/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0230 - accuracy: 0.0476\n",
            "Epoch 57/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0228 - accuracy: 0.0476\n",
            "Epoch 58/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0222 - accuracy: 0.0476\n",
            "Epoch 59/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0220 - accuracy: 0.0476\n",
            "Epoch 60/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0215 - accuracy: 0.0476\n",
            "Epoch 61/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0212 - accuracy: 0.0476\n",
            "Epoch 62/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0210 - accuracy: 0.0476\n",
            "Epoch 63/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0205 - accuracy: 0.0476\n",
            "Epoch 64/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0202 - accuracy: 0.0476\n",
            "Epoch 65/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0198 - accuracy: 0.0476\n",
            "Epoch 66/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0195 - accuracy: 0.0476\n",
            "Epoch 67/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0192 - accuracy: 0.0476\n",
            "Epoch 68/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0189 - accuracy: 0.0476\n",
            "Epoch 69/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0187 - accuracy: 0.0476\n",
            "Epoch 70/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0184 - accuracy: 0.0476\n",
            "Epoch 71/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0181 - accuracy: 0.0476\n",
            "Epoch 72/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0178 - accuracy: 0.0476\n",
            "Epoch 73/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0175 - accuracy: 0.0476\n",
            "Epoch 74/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0173 - accuracy: 0.0476\n",
            "Epoch 75/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0170 - accuracy: 0.0476\n",
            "Epoch 76/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0168 - accuracy: 0.0476\n",
            "Epoch 77/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0165 - accuracy: 0.0476\n",
            "Epoch 78/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0163 - accuracy: 0.0476\n",
            "Epoch 79/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0161 - accuracy: 0.0476\n",
            "Epoch 80/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0159 - accuracy: 0.0476\n",
            "Epoch 81/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0156 - accuracy: 0.0476\n",
            "Epoch 82/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0153 - accuracy: 0.0476\n",
            "Epoch 83/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0152 - accuracy: 0.0476\n",
            "Epoch 84/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0149 - accuracy: 0.0476\n",
            "Epoch 85/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0147 - accuracy: 0.0476\n",
            "Epoch 86/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0146 - accuracy: 0.0476\n",
            "Epoch 87/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0143 - accuracy: 0.0476\n",
            "Epoch 88/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0141 - accuracy: 0.0476\n",
            "Epoch 89/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0140 - accuracy: 0.0476\n",
            "Epoch 90/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0137 - accuracy: 0.0476\n",
            "Epoch 91/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0136 - accuracy: 0.0476\n",
            "Epoch 92/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0134 - accuracy: 0.0476\n",
            "Epoch 93/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0132 - accuracy: 0.0476\n",
            "Epoch 94/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0131 - accuracy: 0.0476\n",
            "Epoch 95/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0129 - accuracy: 0.0476\n",
            "Epoch 96/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0127 - accuracy: 0.0476\n",
            "Epoch 97/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0126 - accuracy: 0.0476\n",
            "Epoch 98/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0125 - accuracy: 0.0476\n",
            "Epoch 99/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0123 - accuracy: 0.0476\n",
            "Epoch 100/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0121 - accuracy: 0.0476\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 1s 2ms/step - loss: 0.0718 - accuracy: 0.0068\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0712 - accuracy: 0.0000e+00\n",
            "Epoch 3/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0703 - accuracy: 0.0000e+00\n",
            "Epoch 4/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0694 - accuracy: 0.0000e+00\n",
            "Epoch 5/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0683 - accuracy: 0.0000e+00\n",
            "Epoch 6/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0670 - accuracy: 0.0000e+00\n",
            "Epoch 7/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0655 - accuracy: 0.0000e+00\n",
            "Epoch 8/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0637 - accuracy: 0.0000e+00\n",
            "Epoch 9/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0617 - accuracy: 0.0000e+00\n",
            "Epoch 10/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0593 - accuracy: 0.0000e+00\n",
            "Epoch 11/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0567 - accuracy: 0.0000e+00\n",
            "Epoch 12/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0534 - accuracy: 0.0000e+00\n",
            "Epoch 13/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0504 - accuracy: 0.0000e+00\n",
            "Epoch 14/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0475 - accuracy: 0.0000e+00\n",
            "Epoch 15/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0444 - accuracy: 0.0272\n",
            "Epoch 16/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0417 - accuracy: 0.0340\n",
            "Epoch 17/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0389 - accuracy: 0.0340\n",
            "Epoch 18/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0364 - accuracy: 0.0340\n",
            "Epoch 19/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0340 - accuracy: 0.0340\n",
            "Epoch 20/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0317 - accuracy: 0.0340\n",
            "Epoch 21/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0296 - accuracy: 0.0340\n",
            "Epoch 22/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0275 - accuracy: 0.0340\n",
            "Epoch 23/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0255 - accuracy: 0.0340\n",
            "Epoch 24/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0237 - accuracy: 0.0340\n",
            "Epoch 25/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0220 - accuracy: 0.0340\n",
            "Epoch 26/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0206 - accuracy: 0.0340\n",
            "Epoch 27/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0191 - accuracy: 0.0340\n",
            "Epoch 28/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0179 - accuracy: 0.0340\n",
            "Epoch 29/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0168 - accuracy: 0.0340\n",
            "Epoch 30/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0158 - accuracy: 0.0340\n",
            "Epoch 31/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0149 - accuracy: 0.0340\n",
            "Epoch 32/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0141 - accuracy: 0.0340\n",
            "Epoch 33/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0134 - accuracy: 0.0340\n",
            "Epoch 34/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0128 - accuracy: 0.0340\n",
            "Epoch 35/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0122 - accuracy: 0.0340\n",
            "Epoch 36/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0118 - accuracy: 0.0340\n",
            "Epoch 37/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0114 - accuracy: 0.0340\n",
            "Epoch 38/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0109 - accuracy: 0.0340\n",
            "Epoch 39/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0105 - accuracy: 0.0340\n",
            "Epoch 40/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0102 - accuracy: 0.0340\n",
            "Epoch 41/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0100 - accuracy: 0.0340\n",
            "Epoch 42/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0098 - accuracy: 0.0340\n",
            "Epoch 43/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0094 - accuracy: 0.0340\n",
            "Epoch 44/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0093 - accuracy: 0.0340\n",
            "Epoch 45/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0089 - accuracy: 0.0340\n",
            "Epoch 46/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0089 - accuracy: 0.0340\n",
            "Epoch 47/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0085 - accuracy: 0.0340\n",
            "Epoch 48/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0084 - accuracy: 0.0340\n",
            "Epoch 49/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0082 - accuracy: 0.0340\n",
            "Epoch 50/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0081 - accuracy: 0.0340\n",
            "Epoch 51/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0081 - accuracy: 0.0340\n",
            "Epoch 52/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0079 - accuracy: 0.0340\n",
            "Epoch 53/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0077 - accuracy: 0.0340\n",
            "Epoch 54/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0078 - accuracy: 0.0340\n",
            "Epoch 55/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0077 - accuracy: 0.0340\n",
            "Epoch 56/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0074 - accuracy: 0.0340\n",
            "Epoch 57/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0073 - accuracy: 0.0340\n",
            "Epoch 58/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0072 - accuracy: 0.0340\n",
            "Epoch 59/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0071 - accuracy: 0.0340\n",
            "Epoch 60/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0070 - accuracy: 0.0340\n",
            "Epoch 61/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0069 - accuracy: 0.0340\n",
            "Epoch 62/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0069 - accuracy: 0.0340\n",
            "Epoch 63/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0068 - accuracy: 0.0340\n",
            "Epoch 64/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0069 - accuracy: 0.0340\n",
            "Epoch 65/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0068 - accuracy: 0.0340\n",
            "Epoch 66/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0066 - accuracy: 0.0340\n",
            "Epoch 67/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0065 - accuracy: 0.0340\n",
            "Epoch 68/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0065 - accuracy: 0.0340\n",
            "Epoch 69/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0067 - accuracy: 0.0340\n",
            "Epoch 70/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0064 - accuracy: 0.0340\n",
            "Epoch 71/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0064 - accuracy: 0.0340\n",
            "Epoch 72/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0064 - accuracy: 0.0340\n",
            "Epoch 73/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0062 - accuracy: 0.0340\n",
            "Epoch 74/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0063 - accuracy: 0.0340\n",
            "Epoch 75/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0061 - accuracy: 0.0340\n",
            "Epoch 76/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0061 - accuracy: 0.0340\n",
            "Epoch 77/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0060 - accuracy: 0.0340\n",
            "Epoch 78/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0060 - accuracy: 0.0340\n",
            "Epoch 79/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0060 - accuracy: 0.0340\n",
            "Epoch 80/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0059 - accuracy: 0.0340\n",
            "Epoch 81/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0059 - accuracy: 0.0340\n",
            "Epoch 82/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0058 - accuracy: 0.0340\n",
            "Epoch 83/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0058 - accuracy: 0.0340\n",
            "Epoch 84/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0057 - accuracy: 0.0340\n",
            "Epoch 85/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0056 - accuracy: 0.0340\n",
            "Epoch 86/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0056 - accuracy: 0.0340\n",
            "Epoch 87/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0057 - accuracy: 0.0340\n",
            "Epoch 88/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0056 - accuracy: 0.0340\n",
            "Epoch 89/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0055 - accuracy: 0.0340\n",
            "Epoch 90/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0057 - accuracy: 0.0340\n",
            "Epoch 91/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 0.0340\n",
            "Epoch 92/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0055 - accuracy: 0.0340\n",
            "Epoch 93/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0054 - accuracy: 0.0340\n",
            "Epoch 94/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0054 - accuracy: 0.0340\n",
            "Epoch 95/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0053 - accuracy: 0.0340\n",
            "Epoch 96/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0053 - accuracy: 0.0340\n",
            "Epoch 97/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0052 - accuracy: 0.0340\n",
            "Epoch 98/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0052 - accuracy: 0.0340\n",
            "Epoch 99/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0052 - accuracy: 0.0340\n",
            "Epoch 100/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0052 - accuracy: 0.0340\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 1s 2ms/step - loss: 0.0652 - accuracy: 0.0068\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0645 - accuracy: 0.0068\n",
            "Epoch 3/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0636 - accuracy: 0.0068\n",
            "Epoch 4/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0627 - accuracy: 0.0068\n",
            "Epoch 5/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0616 - accuracy: 0.0068\n",
            "Epoch 6/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0605 - accuracy: 0.0068\n",
            "Epoch 7/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0593 - accuracy: 0.0068\n",
            "Epoch 8/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0579 - accuracy: 0.0068\n",
            "Epoch 9/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0567 - accuracy: 0.0068\n",
            "Epoch 10/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0553 - accuracy: 0.0068\n",
            "Epoch 11/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0539 - accuracy: 0.0068\n",
            "Epoch 12/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0527 - accuracy: 0.0068\n",
            "Epoch 13/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0514 - accuracy: 0.0068\n",
            "Epoch 14/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0502 - accuracy: 0.0068\n",
            "Epoch 15/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0490 - accuracy: 0.0068\n",
            "Epoch 16/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0478 - accuracy: 0.0068\n",
            "Epoch 17/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0467 - accuracy: 0.0068\n",
            "Epoch 18/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0458 - accuracy: 0.0068\n",
            "Epoch 19/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0449 - accuracy: 0.0068\n",
            "Epoch 20/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0442 - accuracy: 0.0068\n",
            "Epoch 21/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0435 - accuracy: 0.0068\n",
            "Epoch 22/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0428 - accuracy: 0.0068\n",
            "Epoch 23/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0422 - accuracy: 0.0068\n",
            "Epoch 24/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0416 - accuracy: 0.0068\n",
            "Epoch 25/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0410 - accuracy: 0.0068\n",
            "Epoch 26/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0404 - accuracy: 0.0068\n",
            "Epoch 27/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0399 - accuracy: 0.0068\n",
            "Epoch 28/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0393 - accuracy: 0.0068\n",
            "Epoch 29/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0387 - accuracy: 0.0068\n",
            "Epoch 30/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0381 - accuracy: 0.0068\n",
            "Epoch 31/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0376 - accuracy: 0.0068\n",
            "Epoch 32/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0370 - accuracy: 0.0068\n",
            "Epoch 33/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0364 - accuracy: 0.0068\n",
            "Epoch 34/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0358 - accuracy: 0.0068\n",
            "Epoch 35/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0353 - accuracy: 0.0068\n",
            "Epoch 36/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0347 - accuracy: 0.0068\n",
            "Epoch 37/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0341 - accuracy: 0.0068\n",
            "Epoch 38/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0336 - accuracy: 0.0068\n",
            "Epoch 39/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0330 - accuracy: 0.0068\n",
            "Epoch 40/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0325 - accuracy: 0.0068\n",
            "Epoch 41/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0320 - accuracy: 0.0068\n",
            "Epoch 42/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0315 - accuracy: 0.0068\n",
            "Epoch 43/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0309 - accuracy: 0.0068\n",
            "Epoch 44/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0304 - accuracy: 0.0068\n",
            "Epoch 45/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0299 - accuracy: 0.0068\n",
            "Epoch 46/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0295 - accuracy: 0.0068\n",
            "Epoch 47/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0292 - accuracy: 0.0068\n",
            "Epoch 48/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0289 - accuracy: 0.0408\n",
            "Epoch 49/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0285 - accuracy: 0.0476\n",
            "Epoch 50/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0282 - accuracy: 0.0476\n",
            "Epoch 51/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0279 - accuracy: 0.0476\n",
            "Epoch 52/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0276 - accuracy: 0.0476\n",
            "Epoch 53/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0273 - accuracy: 0.0476\n",
            "Epoch 54/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0270 - accuracy: 0.0476\n",
            "Epoch 55/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0266 - accuracy: 0.0476\n",
            "Epoch 56/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0263 - accuracy: 0.0476\n",
            "Epoch 57/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0260 - accuracy: 0.0476\n",
            "Epoch 58/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0257 - accuracy: 0.0476\n",
            "Epoch 59/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0254 - accuracy: 0.0476\n",
            "Epoch 60/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0251 - accuracy: 0.0476\n",
            "Epoch 61/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0248 - accuracy: 0.0476\n",
            "Epoch 62/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0246 - accuracy: 0.0476\n",
            "Epoch 63/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0242 - accuracy: 0.0476\n",
            "Epoch 64/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0240 - accuracy: 0.0476\n",
            "Epoch 65/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0237 - accuracy: 0.0476\n",
            "Epoch 66/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0234 - accuracy: 0.0476\n",
            "Epoch 67/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0231 - accuracy: 0.0476\n",
            "Epoch 68/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0228 - accuracy: 0.0476\n",
            "Epoch 69/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0225 - accuracy: 0.0476\n",
            "Epoch 70/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0223 - accuracy: 0.0476\n",
            "Epoch 71/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0219 - accuracy: 0.0476\n",
            "Epoch 72/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0217 - accuracy: 0.0476\n",
            "Epoch 73/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0215 - accuracy: 0.0476\n",
            "Epoch 74/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0212 - accuracy: 0.0476\n",
            "Epoch 75/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0209 - accuracy: 0.0476\n",
            "Epoch 76/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0207 - accuracy: 0.0476\n",
            "Epoch 77/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0204 - accuracy: 0.0476\n",
            "Epoch 78/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0201 - accuracy: 0.0476\n",
            "Epoch 79/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0198 - accuracy: 0.0476\n",
            "Epoch 80/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0196 - accuracy: 0.0476\n",
            "Epoch 81/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0194 - accuracy: 0.0476\n",
            "Epoch 82/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0191 - accuracy: 0.0476\n",
            "Epoch 83/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0188 - accuracy: 0.0476\n",
            "Epoch 84/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0186 - accuracy: 0.0476\n",
            "Epoch 85/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0184 - accuracy: 0.0476\n",
            "Epoch 86/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0182 - accuracy: 0.0476\n",
            "Epoch 87/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0179 - accuracy: 0.0476\n",
            "Epoch 88/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0178 - accuracy: 0.0476\n",
            "Epoch 89/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0175 - accuracy: 0.0476\n",
            "Epoch 90/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0173 - accuracy: 0.0476\n",
            "Epoch 91/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0171 - accuracy: 0.0476\n",
            "Epoch 92/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0169 - accuracy: 0.0476\n",
            "Epoch 93/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0166 - accuracy: 0.0476\n",
            "Epoch 94/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0164 - accuracy: 0.0476\n",
            "Epoch 95/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0162 - accuracy: 0.0476\n",
            "Epoch 96/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0160 - accuracy: 0.0476\n",
            "Epoch 97/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0159 - accuracy: 0.0476\n",
            "Epoch 98/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0156 - accuracy: 0.0476\n",
            "Epoch 99/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0155 - accuracy: 0.0476\n",
            "Epoch 100/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0152 - accuracy: 0.0476\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 1s 2ms/step - loss: 0.0697 - accuracy: 0.0068\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0692 - accuracy: 0.0068\n",
            "Epoch 3/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0688 - accuracy: 0.0068\n",
            "Epoch 4/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0683 - accuracy: 0.0068\n",
            "Epoch 5/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0679 - accuracy: 0.0068\n",
            "Epoch 6/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0675 - accuracy: 0.0068\n",
            "Epoch 7/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0671 - accuracy: 0.0068\n",
            "Epoch 8/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0668 - accuracy: 0.0068\n",
            "Epoch 9/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0665 - accuracy: 0.0068\n",
            "Epoch 10/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0661 - accuracy: 0.0068\n",
            "Epoch 11/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0658 - accuracy: 0.0068\n",
            "Epoch 12/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0656 - accuracy: 0.0068\n",
            "Epoch 13/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0653 - accuracy: 0.0068\n",
            "Epoch 14/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0651 - accuracy: 0.0068\n",
            "Epoch 15/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0648 - accuracy: 0.0068\n",
            "Epoch 16/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0646 - accuracy: 0.0068\n",
            "Epoch 17/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0644 - accuracy: 0.0068\n",
            "Epoch 18/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0642 - accuracy: 0.0068\n",
            "Epoch 19/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0641 - accuracy: 0.0068\n",
            "Epoch 20/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0639 - accuracy: 0.0068\n",
            "Epoch 21/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0637 - accuracy: 0.0068\n",
            "Epoch 22/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0636 - accuracy: 0.0068\n",
            "Epoch 23/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0635 - accuracy: 0.0068\n",
            "Epoch 24/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0634 - accuracy: 0.0068\n",
            "Epoch 25/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0632 - accuracy: 0.0068\n",
            "Epoch 26/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0632 - accuracy: 0.0068\n",
            "Epoch 27/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0631 - accuracy: 0.0068\n",
            "Epoch 28/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0630 - accuracy: 0.0068\n",
            "Epoch 29/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0629 - accuracy: 0.0068\n",
            "Epoch 30/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0628 - accuracy: 0.0068\n",
            "Epoch 31/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0627 - accuracy: 0.0068\n",
            "Epoch 32/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0627 - accuracy: 0.0068\n",
            "Epoch 33/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0626 - accuracy: 0.0068\n",
            "Epoch 34/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0625 - accuracy: 0.0068\n",
            "Epoch 35/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0625 - accuracy: 0.0068\n",
            "Epoch 36/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0624 - accuracy: 0.0068\n",
            "Epoch 37/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0624 - accuracy: 0.0068\n",
            "Epoch 38/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0623 - accuracy: 0.0068\n",
            "Epoch 39/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0623 - accuracy: 0.0068\n",
            "Epoch 40/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0623 - accuracy: 0.0068\n",
            "Epoch 41/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0622 - accuracy: 0.0068\n",
            "Epoch 42/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0622 - accuracy: 0.0068\n",
            "Epoch 43/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0622 - accuracy: 0.0068\n",
            "Epoch 44/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0621 - accuracy: 0.0068\n",
            "Epoch 45/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0621 - accuracy: 0.0068\n",
            "Epoch 46/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0621 - accuracy: 0.0068\n",
            "Epoch 47/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0621 - accuracy: 0.0068\n",
            "Epoch 48/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0621 - accuracy: 0.0068\n",
            "Epoch 49/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0620 - accuracy: 0.0068\n",
            "Epoch 50/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0620 - accuracy: 0.0068\n",
            "Epoch 51/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0620 - accuracy: 0.0068\n",
            "Epoch 52/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0620 - accuracy: 0.0068\n",
            "Epoch 53/100\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.0620 - accuracy: 0.0068\n",
            "Epoch 54/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0620 - accuracy: 0.0068\n",
            "Epoch 55/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0620 - accuracy: 0.0068\n",
            "Epoch 56/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0619 - accuracy: 0.0068\n",
            "Epoch 57/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0619 - accuracy: 0.0068\n",
            "Epoch 58/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0619 - accuracy: 0.0068\n",
            "Epoch 59/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0619 - accuracy: 0.0068\n",
            "Epoch 60/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0619 - accuracy: 0.0068\n",
            "Epoch 61/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0619 - accuracy: 0.0068\n",
            "Epoch 62/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0619 - accuracy: 0.0068\n",
            "Epoch 63/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0619 - accuracy: 0.0068\n",
            "Epoch 64/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0619 - accuracy: 0.0068\n",
            "Epoch 65/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0619 - accuracy: 0.0068\n",
            "Epoch 66/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0619 - accuracy: 0.0068\n",
            "Epoch 67/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0619 - accuracy: 0.0068\n",
            "Epoch 68/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0619 - accuracy: 0.0068\n",
            "Epoch 69/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0619 - accuracy: 0.0068\n",
            "Epoch 70/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0619 - accuracy: 0.0068\n",
            "Epoch 71/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0619 - accuracy: 0.0068\n",
            "Epoch 72/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0619 - accuracy: 0.0068\n",
            "Epoch 73/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0619 - accuracy: 0.0068\n",
            "Epoch 74/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0619 - accuracy: 0.0068\n",
            "Epoch 75/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0619 - accuracy: 0.0068\n",
            "Epoch 76/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0619 - accuracy: 0.0068\n",
            "Epoch 77/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0619 - accuracy: 0.0068\n",
            "Epoch 78/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0618 - accuracy: 0.0068\n",
            "Epoch 79/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0618 - accuracy: 0.0068\n",
            "Epoch 80/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0618 - accuracy: 0.0068\n",
            "Epoch 81/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0619 - accuracy: 0.0068\n",
            "Epoch 82/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0619 - accuracy: 0.0068\n",
            "Epoch 83/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0618 - accuracy: 0.0068\n",
            "Epoch 84/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0618 - accuracy: 0.0068\n",
            "Epoch 85/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0618 - accuracy: 0.0068\n",
            "Epoch 86/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0618 - accuracy: 0.0068\n",
            "Epoch 87/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0618 - accuracy: 0.0068\n",
            "Epoch 88/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0618 - accuracy: 0.0068\n",
            "Epoch 89/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0619 - accuracy: 0.0068\n",
            "Epoch 90/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0619 - accuracy: 0.0068\n",
            "Epoch 91/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0618 - accuracy: 0.0068\n",
            "Epoch 92/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0619 - accuracy: 0.0068\n",
            "Epoch 93/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0618 - accuracy: 0.0068\n",
            "Epoch 94/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0618 - accuracy: 0.0068\n",
            "Epoch 95/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0618 - accuracy: 0.0068\n",
            "Epoch 96/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0618 - accuracy: 0.0068\n",
            "Epoch 97/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0618 - accuracy: 0.0068\n",
            "Epoch 98/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0618 - accuracy: 0.0068\n",
            "Epoch 99/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0618 - accuracy: 0.0068\n",
            "Epoch 100/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0618 - accuracy: 0.0068\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0708 - accuracy: 0.0000e+00\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0700 - accuracy: 0.0068\n",
            "Epoch 3/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0692 - accuracy: 0.0068\n",
            "Epoch 4/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0682 - accuracy: 0.0068\n",
            "Epoch 5/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0672 - accuracy: 0.0068\n",
            "Epoch 6/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0660 - accuracy: 0.0068\n",
            "Epoch 7/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0646 - accuracy: 0.0068\n",
            "Epoch 8/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0628 - accuracy: 0.0068\n",
            "Epoch 9/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0610 - accuracy: 0.0068\n",
            "Epoch 10/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0590 - accuracy: 0.0068\n",
            "Epoch 11/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0568 - accuracy: 0.0068\n",
            "Epoch 12/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0547 - accuracy: 0.0068\n",
            "Epoch 13/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0525 - accuracy: 0.0068\n",
            "Epoch 14/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0503 - accuracy: 0.0068\n",
            "Epoch 15/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0478 - accuracy: 0.0068\n",
            "Epoch 16/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0458 - accuracy: 0.0068\n",
            "Epoch 17/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0438 - accuracy: 0.0068\n",
            "Epoch 18/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0423 - accuracy: 0.0068\n",
            "Epoch 19/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0408 - accuracy: 0.0068\n",
            "Epoch 20/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0397 - accuracy: 0.0068\n",
            "Epoch 21/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0388 - accuracy: 0.0068\n",
            "Epoch 22/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0378 - accuracy: 0.0068\n",
            "Epoch 23/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0370 - accuracy: 0.0068\n",
            "Epoch 24/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0363 - accuracy: 0.0068\n",
            "Epoch 25/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0355 - accuracy: 0.0068\n",
            "Epoch 26/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0348 - accuracy: 0.0068\n",
            "Epoch 27/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0343 - accuracy: 0.0068\n",
            "Epoch 28/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0336 - accuracy: 0.0068\n",
            "Epoch 29/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0331 - accuracy: 0.0068\n",
            "Epoch 30/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0327 - accuracy: 0.0068\n",
            "Epoch 31/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0322 - accuracy: 0.0068\n",
            "Epoch 32/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0317 - accuracy: 0.0068\n",
            "Epoch 33/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0312 - accuracy: 0.0068\n",
            "Epoch 34/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0308 - accuracy: 0.0068\n",
            "Epoch 35/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0303 - accuracy: 0.0068\n",
            "Epoch 36/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0299 - accuracy: 0.0068\n",
            "Epoch 37/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0296 - accuracy: 0.0068\n",
            "Epoch 38/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0292 - accuracy: 0.0068\n",
            "Epoch 39/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0287 - accuracy: 0.0068\n",
            "Epoch 40/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0284 - accuracy: 0.0068\n",
            "Epoch 41/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0279 - accuracy: 0.0068\n",
            "Epoch 42/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0275 - accuracy: 0.0473\n",
            "Epoch 43/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0273 - accuracy: 0.0473\n",
            "Epoch 44/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0268 - accuracy: 0.0473\n",
            "Epoch 45/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0265 - accuracy: 0.0473\n",
            "Epoch 46/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0262 - accuracy: 0.0473\n",
            "Epoch 47/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0260 - accuracy: 0.0473\n",
            "Epoch 48/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0259 - accuracy: 0.0473\n",
            "Epoch 49/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0251 - accuracy: 0.0473\n",
            "Epoch 50/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0248 - accuracy: 0.0473\n",
            "Epoch 51/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0245 - accuracy: 0.0473\n",
            "Epoch 52/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0242 - accuracy: 0.0473\n",
            "Epoch 53/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0239 - accuracy: 0.0473\n",
            "Epoch 54/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0236 - accuracy: 0.0473\n",
            "Epoch 55/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0233 - accuracy: 0.0473\n",
            "Epoch 56/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0231 - accuracy: 0.0473\n",
            "Epoch 57/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0227 - accuracy: 0.0473\n",
            "Epoch 58/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0224 - accuracy: 0.0473\n",
            "Epoch 59/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0221 - accuracy: 0.0473\n",
            "Epoch 60/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0218 - accuracy: 0.0473\n",
            "Epoch 61/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0216 - accuracy: 0.0473\n",
            "Epoch 62/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0212 - accuracy: 0.0473\n",
            "Epoch 63/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0209 - accuracy: 0.0473\n",
            "Epoch 64/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0207 - accuracy: 0.0473\n",
            "Epoch 65/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0205 - accuracy: 0.0473\n",
            "Epoch 66/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0202 - accuracy: 0.0473\n",
            "Epoch 67/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0199 - accuracy: 0.0473\n",
            "Epoch 68/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0196 - accuracy: 0.0473\n",
            "Epoch 69/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0194 - accuracy: 0.0473\n",
            "Epoch 70/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0192 - accuracy: 0.0473\n",
            "Epoch 71/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0189 - accuracy: 0.0473\n",
            "Epoch 72/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0187 - accuracy: 0.0473\n",
            "Epoch 73/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0184 - accuracy: 0.0473\n",
            "Epoch 74/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0182 - accuracy: 0.0473\n",
            "Epoch 75/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0180 - accuracy: 0.0473\n",
            "Epoch 76/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0178 - accuracy: 0.0473\n",
            "Epoch 77/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0176 - accuracy: 0.0473\n",
            "Epoch 78/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0174 - accuracy: 0.0473\n",
            "Epoch 79/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0171 - accuracy: 0.0473\n",
            "Epoch 80/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0169 - accuracy: 0.0473\n",
            "Epoch 81/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0167 - accuracy: 0.0473\n",
            "Epoch 82/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0165 - accuracy: 0.0473\n",
            "Epoch 83/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0164 - accuracy: 0.0473\n",
            "Epoch 84/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0161 - accuracy: 0.0473\n",
            "Epoch 85/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0160 - accuracy: 0.0473\n",
            "Epoch 86/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0157 - accuracy: 0.0473\n",
            "Epoch 87/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0155 - accuracy: 0.0473\n",
            "Epoch 88/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0154 - accuracy: 0.0473\n",
            "Epoch 89/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0152 - accuracy: 0.0473\n",
            "Epoch 90/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0150 - accuracy: 0.0473\n",
            "Epoch 91/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0148 - accuracy: 0.0473\n",
            "Epoch 92/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0146 - accuracy: 0.0473\n",
            "Epoch 93/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0145 - accuracy: 0.0473\n",
            "Epoch 94/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0143 - accuracy: 0.0473\n",
            "Epoch 95/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0141 - accuracy: 0.0473\n",
            "Epoch 96/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0141 - accuracy: 0.0473\n",
            "Epoch 97/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0138 - accuracy: 0.0473\n",
            "Epoch 98/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0137 - accuracy: 0.0473\n",
            "Epoch 99/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0135 - accuracy: 0.0473\n",
            "Epoch 100/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0134 - accuracy: 0.0473\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0717 - accuracy: 0.0068\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0714 - accuracy: 0.0068\n",
            "Epoch 3/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0712 - accuracy: 0.0068\n",
            "Epoch 4/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0709 - accuracy: 0.0068\n",
            "Epoch 5/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0707 - accuracy: 0.0068\n",
            "Epoch 6/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0704 - accuracy: 0.0068\n",
            "Epoch 7/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0702 - accuracy: 0.0068\n",
            "Epoch 8/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0700 - accuracy: 0.0068\n",
            "Epoch 9/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0698 - accuracy: 0.0068\n",
            "Epoch 10/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0696 - accuracy: 0.0068\n",
            "Epoch 11/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0694 - accuracy: 0.0068\n",
            "Epoch 12/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0692 - accuracy: 0.0068\n",
            "Epoch 13/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0691 - accuracy: 0.0068\n",
            "Epoch 14/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0689 - accuracy: 0.0068\n",
            "Epoch 15/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0687 - accuracy: 0.0068\n",
            "Epoch 16/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0686 - accuracy: 0.0068\n",
            "Epoch 17/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0684 - accuracy: 0.0068\n",
            "Epoch 18/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0682 - accuracy: 0.0068\n",
            "Epoch 19/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0681 - accuracy: 0.0068\n",
            "Epoch 20/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0680 - accuracy: 0.0068\n",
            "Epoch 21/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0678 - accuracy: 0.0068\n",
            "Epoch 22/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0677 - accuracy: 0.0068\n",
            "Epoch 23/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0676 - accuracy: 0.0068\n",
            "Epoch 24/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0675 - accuracy: 0.0068\n",
            "Epoch 25/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0674 - accuracy: 0.0068\n",
            "Epoch 26/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0673 - accuracy: 0.0068\n",
            "Epoch 27/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0672 - accuracy: 0.0068\n",
            "Epoch 28/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0671 - accuracy: 0.0068\n",
            "Epoch 29/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0670 - accuracy: 0.0068\n",
            "Epoch 30/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0669 - accuracy: 0.0068\n",
            "Epoch 31/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0668 - accuracy: 0.0068\n",
            "Epoch 32/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0667 - accuracy: 0.0068\n",
            "Epoch 33/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0666 - accuracy: 0.0068\n",
            "Epoch 34/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0665 - accuracy: 0.0068\n",
            "Epoch 35/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0665 - accuracy: 0.0068\n",
            "Epoch 36/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0664 - accuracy: 0.0068\n",
            "Epoch 37/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0663 - accuracy: 0.0068\n",
            "Epoch 38/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0663 - accuracy: 0.0068\n",
            "Epoch 39/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0662 - accuracy: 0.0068\n",
            "Epoch 40/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0661 - accuracy: 0.0068\n",
            "Epoch 41/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0661 - accuracy: 0.0068\n",
            "Epoch 42/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0660 - accuracy: 0.0068\n",
            "Epoch 43/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0660 - accuracy: 0.0068\n",
            "Epoch 44/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0659 - accuracy: 0.0068\n",
            "Epoch 45/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0659 - accuracy: 0.0068\n",
            "Epoch 46/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0658 - accuracy: 0.0068\n",
            "Epoch 47/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0658 - accuracy: 0.0068\n",
            "Epoch 48/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0657 - accuracy: 0.0068\n",
            "Epoch 49/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0657 - accuracy: 0.0068\n",
            "Epoch 50/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0656 - accuracy: 0.0068\n",
            "Epoch 51/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0656 - accuracy: 0.0068\n",
            "Epoch 52/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0655 - accuracy: 0.0068\n",
            "Epoch 53/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0655 - accuracy: 0.0068\n",
            "Epoch 54/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0655 - accuracy: 0.0068\n",
            "Epoch 55/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0654 - accuracy: 0.0068\n",
            "Epoch 56/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0654 - accuracy: 0.0068\n",
            "Epoch 57/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0654 - accuracy: 0.0068\n",
            "Epoch 58/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0653 - accuracy: 0.0068\n",
            "Epoch 59/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0653 - accuracy: 0.0068\n",
            "Epoch 60/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0653 - accuracy: 0.0068\n",
            "Epoch 61/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0652 - accuracy: 0.0068\n",
            "Epoch 62/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0652 - accuracy: 0.0068\n",
            "Epoch 63/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0652 - accuracy: 0.0068\n",
            "Epoch 64/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0651 - accuracy: 0.0068\n",
            "Epoch 65/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0651 - accuracy: 0.0068\n",
            "Epoch 66/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0651 - accuracy: 0.0068\n",
            "Epoch 67/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0651 - accuracy: 0.0068\n",
            "Epoch 68/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0651 - accuracy: 0.0068\n",
            "Epoch 69/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0650 - accuracy: 0.0068\n",
            "Epoch 70/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0650 - accuracy: 0.0068\n",
            "Epoch 71/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0650 - accuracy: 0.0068\n",
            "Epoch 72/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0650 - accuracy: 0.0068\n",
            "Epoch 73/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 74/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 75/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 76/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 77/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 78/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 79/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0648 - accuracy: 0.0068\n",
            "Epoch 80/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0648 - accuracy: 0.0068\n",
            "Epoch 81/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0648 - accuracy: 0.0068\n",
            "Epoch 82/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0648 - accuracy: 0.0068\n",
            "Epoch 83/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0648 - accuracy: 0.0068\n",
            "Epoch 84/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0648 - accuracy: 0.0068\n",
            "Epoch 85/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0648 - accuracy: 0.0068\n",
            "Epoch 86/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0648 - accuracy: 0.0068\n",
            "Epoch 87/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0648 - accuracy: 0.0068\n",
            "Epoch 88/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 89/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 90/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 91/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 92/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 93/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 94/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 95/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 96/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 97/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 98/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 99/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0646 - accuracy: 0.0068\n",
            "Epoch 100/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0646 - accuracy: 0.0068\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0720 - accuracy: 0.0000e+00\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0717 - accuracy: 0.0000e+00\n",
            "Epoch 3/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0713 - accuracy: 0.0000e+00\n",
            "Epoch 4/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0710 - accuracy: 0.0000e+00\n",
            "Epoch 5/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0707 - accuracy: 0.0000e+00\n",
            "Epoch 6/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0704 - accuracy: 0.0000e+00\n",
            "Epoch 7/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0701 - accuracy: 0.0000e+00\n",
            "Epoch 8/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0698 - accuracy: 0.0000e+00\n",
            "Epoch 9/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0696 - accuracy: 0.0000e+00\n",
            "Epoch 10/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0693 - accuracy: 0.0000e+00\n",
            "Epoch 11/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0690 - accuracy: 0.0000e+00\n",
            "Epoch 12/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0688 - accuracy: 0.0000e+00\n",
            "Epoch 13/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0686 - accuracy: 0.0000e+00\n",
            "Epoch 14/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0683 - accuracy: 0.0000e+00\n",
            "Epoch 15/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0681 - accuracy: 0.0000e+00\n",
            "Epoch 16/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0679 - accuracy: 0.0000e+00\n",
            "Epoch 17/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0677 - accuracy: 0.0000e+00\n",
            "Epoch 18/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0675 - accuracy: 0.0000e+00\n",
            "Epoch 19/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0674 - accuracy: 0.0000e+00\n",
            "Epoch 20/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0672 - accuracy: 0.0000e+00\n",
            "Epoch 21/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0670 - accuracy: 0.0000e+00\n",
            "Epoch 22/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0668 - accuracy: 0.0000e+00\n",
            "Epoch 23/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0667 - accuracy: 0.0000e+00\n",
            "Epoch 24/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0665 - accuracy: 0.0000e+00\n",
            "Epoch 25/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0664 - accuracy: 0.0000e+00\n",
            "Epoch 26/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0663 - accuracy: 0.0000e+00\n",
            "Epoch 27/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0661 - accuracy: 0.0000e+00\n",
            "Epoch 28/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0660 - accuracy: 0.0000e+00\n",
            "Epoch 29/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0659 - accuracy: 0.0000e+00\n",
            "Epoch 30/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0658 - accuracy: 0.0000e+00\n",
            "Epoch 31/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0656 - accuracy: 0.0000e+00\n",
            "Epoch 32/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0655 - accuracy: 0.0000e+00\n",
            "Epoch 33/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0654 - accuracy: 0.0000e+00\n",
            "Epoch 34/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0653 - accuracy: 0.0000e+00\n",
            "Epoch 35/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0652 - accuracy: 0.0000e+00\n",
            "Epoch 36/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0651 - accuracy: 0.0000e+00\n",
            "Epoch 37/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0650 - accuracy: 0.0000e+00\n",
            "Epoch 38/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0649 - accuracy: 0.0000e+00\n",
            "Epoch 39/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0648 - accuracy: 0.0000e+00\n",
            "Epoch 40/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0648 - accuracy: 0.0000e+00\n",
            "Epoch 41/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0647 - accuracy: 0.0000e+00\n",
            "Epoch 42/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0646 - accuracy: 0.0000e+00\n",
            "Epoch 43/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0645 - accuracy: 0.0000e+00\n",
            "Epoch 44/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0645 - accuracy: 0.0000e+00\n",
            "Epoch 45/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0644 - accuracy: 0.0000e+00\n",
            "Epoch 46/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0643 - accuracy: 0.0000e+00\n",
            "Epoch 47/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0643 - accuracy: 0.0000e+00\n",
            "Epoch 48/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0642 - accuracy: 0.0000e+00\n",
            "Epoch 49/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0641 - accuracy: 0.0000e+00\n",
            "Epoch 50/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0641 - accuracy: 0.0000e+00\n",
            "Epoch 51/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0640 - accuracy: 0.0000e+00\n",
            "Epoch 52/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0640 - accuracy: 0.0000e+00\n",
            "Epoch 53/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0639 - accuracy: 0.0000e+00\n",
            "Epoch 54/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0639 - accuracy: 0.0000e+00\n",
            "Epoch 55/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0638 - accuracy: 0.0000e+00\n",
            "Epoch 56/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0638 - accuracy: 0.0000e+00\n",
            "Epoch 57/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0637 - accuracy: 0.0000e+00\n",
            "Epoch 58/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0637 - accuracy: 0.0000e+00\n",
            "Epoch 59/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0636 - accuracy: 0.0000e+00\n",
            "Epoch 60/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0636 - accuracy: 0.0000e+00\n",
            "Epoch 61/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0636 - accuracy: 0.0000e+00\n",
            "Epoch 62/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0635 - accuracy: 0.0000e+00\n",
            "Epoch 63/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0635 - accuracy: 0.0000e+00\n",
            "Epoch 64/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0634 - accuracy: 0.0000e+00\n",
            "Epoch 65/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0634 - accuracy: 0.0000e+00\n",
            "Epoch 66/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0634 - accuracy: 0.0000e+00\n",
            "Epoch 67/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0634 - accuracy: 0.0000e+00\n",
            "Epoch 68/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0633 - accuracy: 0.0000e+00\n",
            "Epoch 69/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0633 - accuracy: 0.0000e+00\n",
            "Epoch 70/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0633 - accuracy: 0.0000e+00\n",
            "Epoch 71/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0632 - accuracy: 0.0000e+00\n",
            "Epoch 72/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0632 - accuracy: 0.0000e+00\n",
            "Epoch 73/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0632 - accuracy: 0.0000e+00\n",
            "Epoch 74/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0632 - accuracy: 0.0000e+00\n",
            "Epoch 75/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0631 - accuracy: 0.0000e+00\n",
            "Epoch 76/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0631 - accuracy: 0.0000e+00\n",
            "Epoch 77/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0631 - accuracy: 0.0000e+00\n",
            "Epoch 78/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0631 - accuracy: 0.0000e+00\n",
            "Epoch 79/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0631 - accuracy: 0.0000e+00\n",
            "Epoch 80/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0630 - accuracy: 0.0000e+00\n",
            "Epoch 81/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0630 - accuracy: 0.0000e+00\n",
            "Epoch 82/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0630 - accuracy: 0.0000e+00\n",
            "Epoch 83/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0630 - accuracy: 0.0000e+00\n",
            "Epoch 84/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0630 - accuracy: 0.0000e+00\n",
            "Epoch 85/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0630 - accuracy: 0.0000e+00\n",
            "Epoch 86/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0629 - accuracy: 0.0000e+00\n",
            "Epoch 87/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0629 - accuracy: 0.0000e+00\n",
            "Epoch 88/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0629 - accuracy: 0.0000e+00\n",
            "Epoch 89/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0629 - accuracy: 0.0000e+00\n",
            "Epoch 90/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0629 - accuracy: 0.0000e+00\n",
            "Epoch 91/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0629 - accuracy: 0.0000e+00\n",
            "Epoch 92/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0629 - accuracy: 0.0000e+00\n",
            "Epoch 93/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0629 - accuracy: 0.0000e+00\n",
            "Epoch 94/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0628 - accuracy: 0.0000e+00\n",
            "Epoch 95/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0628 - accuracy: 0.0000e+00\n",
            "Epoch 96/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0628 - accuracy: 0.0000e+00\n",
            "Epoch 97/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0628 - accuracy: 0.0000e+00\n",
            "Epoch 98/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0628 - accuracy: 0.0000e+00\n",
            "Epoch 99/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0628 - accuracy: 0.0000e+00\n",
            "Epoch 100/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0628 - accuracy: 0.0000e+00\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0654 - accuracy: 0.0068\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 3/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0645 - accuracy: 0.0068\n",
            "Epoch 4/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0640 - accuracy: 0.0068\n",
            "Epoch 5/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0636 - accuracy: 0.0068\n",
            "Epoch 6/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0632 - accuracy: 0.0068\n",
            "Epoch 7/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0628 - accuracy: 0.0068\n",
            "Epoch 8/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0625 - accuracy: 0.0068\n",
            "Epoch 9/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0621 - accuracy: 0.0068\n",
            "Epoch 10/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0618 - accuracy: 0.0068\n",
            "Epoch 11/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0614 - accuracy: 0.0068\n",
            "Epoch 12/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0611 - accuracy: 0.0068\n",
            "Epoch 13/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0608 - accuracy: 0.0068\n",
            "Epoch 14/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0605 - accuracy: 0.0068\n",
            "Epoch 15/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0602 - accuracy: 0.0068\n",
            "Epoch 16/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0599 - accuracy: 0.0068\n",
            "Epoch 17/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0597 - accuracy: 0.0068\n",
            "Epoch 18/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0594 - accuracy: 0.0068\n",
            "Epoch 19/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0592 - accuracy: 0.0068\n",
            "Epoch 20/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0589 - accuracy: 0.0068\n",
            "Epoch 21/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0587 - accuracy: 0.0068\n",
            "Epoch 22/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0585 - accuracy: 0.0068\n",
            "Epoch 23/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0583 - accuracy: 0.0068\n",
            "Epoch 24/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0581 - accuracy: 0.0068\n",
            "Epoch 25/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0579 - accuracy: 0.0068\n",
            "Epoch 26/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0577 - accuracy: 0.0068\n",
            "Epoch 27/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0575 - accuracy: 0.0068\n",
            "Epoch 28/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0574 - accuracy: 0.0068\n",
            "Epoch 29/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0572 - accuracy: 0.0068\n",
            "Epoch 30/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0570 - accuracy: 0.0068\n",
            "Epoch 31/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0569 - accuracy: 0.0068\n",
            "Epoch 32/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0567 - accuracy: 0.0068\n",
            "Epoch 33/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0566 - accuracy: 0.0068\n",
            "Epoch 34/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0564 - accuracy: 0.0068\n",
            "Epoch 35/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0563 - accuracy: 0.0068\n",
            "Epoch 36/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0562 - accuracy: 0.0068\n",
            "Epoch 37/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0560 - accuracy: 0.0068\n",
            "Epoch 38/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0559 - accuracy: 0.0068\n",
            "Epoch 39/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0558 - accuracy: 0.0068\n",
            "Epoch 40/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0557 - accuracy: 0.0068\n",
            "Epoch 41/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0556 - accuracy: 0.0068\n",
            "Epoch 42/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0555 - accuracy: 0.0068\n",
            "Epoch 43/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0554 - accuracy: 0.0068\n",
            "Epoch 44/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0553 - accuracy: 0.0068\n",
            "Epoch 45/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0552 - accuracy: 0.0068\n",
            "Epoch 46/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0551 - accuracy: 0.0068\n",
            "Epoch 47/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0551 - accuracy: 0.0068\n",
            "Epoch 48/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0550 - accuracy: 0.0068\n",
            "Epoch 49/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0549 - accuracy: 0.0068\n",
            "Epoch 50/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0548 - accuracy: 0.0068\n",
            "Epoch 51/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0547 - accuracy: 0.0068\n",
            "Epoch 52/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0547 - accuracy: 0.0068\n",
            "Epoch 53/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0546 - accuracy: 0.0068\n",
            "Epoch 54/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0545 - accuracy: 0.0068\n",
            "Epoch 55/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0545 - accuracy: 0.0068\n",
            "Epoch 56/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0544 - accuracy: 0.0068\n",
            "Epoch 57/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0544 - accuracy: 0.0068\n",
            "Epoch 58/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0543 - accuracy: 0.0068\n",
            "Epoch 59/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0542 - accuracy: 0.0068\n",
            "Epoch 60/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0542 - accuracy: 0.0068\n",
            "Epoch 61/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0541 - accuracy: 0.0068\n",
            "Epoch 62/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0541 - accuracy: 0.0068\n",
            "Epoch 63/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0541 - accuracy: 0.0068\n",
            "Epoch 64/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0540 - accuracy: 0.0068\n",
            "Epoch 65/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0540 - accuracy: 0.0068\n",
            "Epoch 66/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0539 - accuracy: 0.0068\n",
            "Epoch 67/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0539 - accuracy: 0.0068\n",
            "Epoch 68/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0539 - accuracy: 0.0068\n",
            "Epoch 69/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0538 - accuracy: 0.0068\n",
            "Epoch 70/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0538 - accuracy: 0.0068\n",
            "Epoch 71/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0537 - accuracy: 0.0068\n",
            "Epoch 72/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0537 - accuracy: 0.0068\n",
            "Epoch 73/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0537 - accuracy: 0.0068\n",
            "Epoch 74/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0536 - accuracy: 0.0068\n",
            "Epoch 75/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0536 - accuracy: 0.0068\n",
            "Epoch 76/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0536 - accuracy: 0.0068\n",
            "Epoch 77/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0535 - accuracy: 0.0068\n",
            "Epoch 78/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0535 - accuracy: 0.0068\n",
            "Epoch 79/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0535 - accuracy: 0.0068\n",
            "Epoch 80/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0535 - accuracy: 0.0068\n",
            "Epoch 81/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0534 - accuracy: 0.0068\n",
            "Epoch 82/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0534 - accuracy: 0.0068\n",
            "Epoch 83/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0534 - accuracy: 0.0068\n",
            "Epoch 84/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0534 - accuracy: 0.0068\n",
            "Epoch 85/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0533 - accuracy: 0.0068\n",
            "Epoch 86/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0533 - accuracy: 0.0068\n",
            "Epoch 87/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0533 - accuracy: 0.0068\n",
            "Epoch 88/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0533 - accuracy: 0.0068\n",
            "Epoch 89/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0533 - accuracy: 0.0068\n",
            "Epoch 90/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0533 - accuracy: 0.0068\n",
            "Epoch 91/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0532 - accuracy: 0.0068\n",
            "Epoch 92/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0532 - accuracy: 0.0068\n",
            "Epoch 93/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0532 - accuracy: 0.0068\n",
            "Epoch 94/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0532 - accuracy: 0.0068\n",
            "Epoch 95/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0532 - accuracy: 0.0068\n",
            "Epoch 96/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0532 - accuracy: 0.0068\n",
            "Epoch 97/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0531 - accuracy: 0.0068\n",
            "Epoch 98/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0531 - accuracy: 0.0068\n",
            "Epoch 99/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0531 - accuracy: 0.0068\n",
            "Epoch 100/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0531 - accuracy: 0.0068\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0697 - accuracy: 0.0068\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0694 - accuracy: 0.0068\n",
            "Epoch 3/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0692 - accuracy: 0.0068\n",
            "Epoch 4/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0689 - accuracy: 0.0068\n",
            "Epoch 5/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0686 - accuracy: 0.0068\n",
            "Epoch 6/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0684 - accuracy: 0.0068\n",
            "Epoch 7/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0681 - accuracy: 0.0068\n",
            "Epoch 8/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0679 - accuracy: 0.0068\n",
            "Epoch 9/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0677 - accuracy: 0.0068\n",
            "Epoch 10/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0675 - accuracy: 0.0068\n",
            "Epoch 11/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0673 - accuracy: 0.0068\n",
            "Epoch 12/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0671 - accuracy: 0.0068\n",
            "Epoch 13/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0669 - accuracy: 0.0068\n",
            "Epoch 14/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0667 - accuracy: 0.0068\n",
            "Epoch 15/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0665 - accuracy: 0.0068\n",
            "Epoch 16/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0664 - accuracy: 0.0068\n",
            "Epoch 17/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0662 - accuracy: 0.0068\n",
            "Epoch 18/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0660 - accuracy: 0.0068\n",
            "Epoch 19/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0659 - accuracy: 0.0068\n",
            "Epoch 20/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0657 - accuracy: 0.0068\n",
            "Epoch 21/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0656 - accuracy: 0.0068\n",
            "Epoch 22/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0654 - accuracy: 0.0068\n",
            "Epoch 23/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0653 - accuracy: 0.0068\n",
            "Epoch 24/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0652 - accuracy: 0.0068\n",
            "Epoch 25/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0650 - accuracy: 0.0068\n",
            "Epoch 26/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 27/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0648 - accuracy: 0.0068\n",
            "Epoch 28/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 29/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0646 - accuracy: 0.0068\n",
            "Epoch 30/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0645 - accuracy: 0.0068\n",
            "Epoch 31/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0644 - accuracy: 0.0068\n",
            "Epoch 32/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0643 - accuracy: 0.0068\n",
            "Epoch 33/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0642 - accuracy: 0.0068\n",
            "Epoch 34/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0641 - accuracy: 0.0068\n",
            "Epoch 35/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0641 - accuracy: 0.0068\n",
            "Epoch 36/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0640 - accuracy: 0.0068\n",
            "Epoch 37/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0639 - accuracy: 0.0068\n",
            "Epoch 38/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0638 - accuracy: 0.0068\n",
            "Epoch 39/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0637 - accuracy: 0.0068\n",
            "Epoch 40/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0637 - accuracy: 0.0068\n",
            "Epoch 41/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0636 - accuracy: 0.0068\n",
            "Epoch 42/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0635 - accuracy: 0.0068\n",
            "Epoch 43/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0635 - accuracy: 0.0068\n",
            "Epoch 44/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0634 - accuracy: 0.0068\n",
            "Epoch 45/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0634 - accuracy: 0.0068\n",
            "Epoch 46/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0633 - accuracy: 0.0068\n",
            "Epoch 47/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0632 - accuracy: 0.0068\n",
            "Epoch 48/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0632 - accuracy: 0.0068\n",
            "Epoch 49/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0632 - accuracy: 0.0068\n",
            "Epoch 50/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0631 - accuracy: 0.0068\n",
            "Epoch 51/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0631 - accuracy: 0.0068\n",
            "Epoch 52/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0630 - accuracy: 0.0068\n",
            "Epoch 53/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0630 - accuracy: 0.0068\n",
            "Epoch 54/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0629 - accuracy: 0.0068\n",
            "Epoch 55/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0629 - accuracy: 0.0068\n",
            "Epoch 56/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0628 - accuracy: 0.0068\n",
            "Epoch 57/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0628 - accuracy: 0.0068\n",
            "Epoch 58/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0628 - accuracy: 0.0068\n",
            "Epoch 59/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0627 - accuracy: 0.0068\n",
            "Epoch 60/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0627 - accuracy: 0.0068\n",
            "Epoch 61/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0627 - accuracy: 0.0068\n",
            "Epoch 62/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0627 - accuracy: 0.0068\n",
            "Epoch 63/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0626 - accuracy: 0.0068\n",
            "Epoch 64/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0626 - accuracy: 0.0068\n",
            "Epoch 65/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0626 - accuracy: 0.0068\n",
            "Epoch 66/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0625 - accuracy: 0.0068\n",
            "Epoch 67/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0625 - accuracy: 0.0068\n",
            "Epoch 68/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0625 - accuracy: 0.0068\n",
            "Epoch 69/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0625 - accuracy: 0.0068\n",
            "Epoch 70/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0625 - accuracy: 0.0068\n",
            "Epoch 71/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0624 - accuracy: 0.0068\n",
            "Epoch 72/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0624 - accuracy: 0.0068\n",
            "Epoch 73/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0624 - accuracy: 0.0068\n",
            "Epoch 74/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0624 - accuracy: 0.0068\n",
            "Epoch 75/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0623 - accuracy: 0.0068\n",
            "Epoch 76/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0623 - accuracy: 0.0068\n",
            "Epoch 77/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0623 - accuracy: 0.0068\n",
            "Epoch 78/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0623 - accuracy: 0.0068\n",
            "Epoch 79/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0623 - accuracy: 0.0068\n",
            "Epoch 80/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0623 - accuracy: 0.0068\n",
            "Epoch 81/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0622 - accuracy: 0.0068\n",
            "Epoch 82/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0622 - accuracy: 0.0068\n",
            "Epoch 83/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0622 - accuracy: 0.0068\n",
            "Epoch 84/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0622 - accuracy: 0.0068\n",
            "Epoch 85/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0622 - accuracy: 0.0068\n",
            "Epoch 86/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0622 - accuracy: 0.0068\n",
            "Epoch 87/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0622 - accuracy: 0.0068\n",
            "Epoch 88/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0622 - accuracy: 0.0068\n",
            "Epoch 89/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0621 - accuracy: 0.0068\n",
            "Epoch 90/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0621 - accuracy: 0.0068\n",
            "Epoch 91/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0621 - accuracy: 0.0068\n",
            "Epoch 92/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0621 - accuracy: 0.0068\n",
            "Epoch 93/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0621 - accuracy: 0.0068\n",
            "Epoch 94/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0621 - accuracy: 0.0068\n",
            "Epoch 95/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0621 - accuracy: 0.0068\n",
            "Epoch 96/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0621 - accuracy: 0.0068\n",
            "Epoch 97/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0621 - accuracy: 0.0068\n",
            "Epoch 98/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0621 - accuracy: 0.0068\n",
            "Epoch 99/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0621 - accuracy: 0.0068\n",
            "Epoch 100/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0620 - accuracy: 0.0068\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0709 - accuracy: 0.0068\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0704 - accuracy: 0.0068\n",
            "Epoch 3/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0699 - accuracy: 0.0068\n",
            "Epoch 4/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0694 - accuracy: 0.0068\n",
            "Epoch 5/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0690 - accuracy: 0.0068\n",
            "Epoch 6/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0685 - accuracy: 0.0068\n",
            "Epoch 7/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0681 - accuracy: 0.0068\n",
            "Epoch 8/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0677 - accuracy: 0.0068\n",
            "Epoch 9/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0673 - accuracy: 0.0068\n",
            "Epoch 10/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0669 - accuracy: 0.0068\n",
            "Epoch 11/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0666 - accuracy: 0.0068\n",
            "Epoch 12/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0662 - accuracy: 0.0068\n",
            "Epoch 13/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0659 - accuracy: 0.0068\n",
            "Epoch 14/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0656 - accuracy: 0.0068\n",
            "Epoch 15/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0652 - accuracy: 0.0068\n",
            "Epoch 16/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 17/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0646 - accuracy: 0.0068\n",
            "Epoch 18/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0644 - accuracy: 0.0068\n",
            "Epoch 19/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0641 - accuracy: 0.0068\n",
            "Epoch 20/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0638 - accuracy: 0.0068\n",
            "Epoch 21/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0636 - accuracy: 0.0068\n",
            "Epoch 22/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0634 - accuracy: 0.0068\n",
            "Epoch 23/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0631 - accuracy: 0.0068\n",
            "Epoch 24/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0629 - accuracy: 0.0068\n",
            "Epoch 25/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0627 - accuracy: 0.0068\n",
            "Epoch 26/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0625 - accuracy: 0.0068\n",
            "Epoch 27/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0623 - accuracy: 0.0068\n",
            "Epoch 28/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0621 - accuracy: 0.0068\n",
            "Epoch 29/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0619 - accuracy: 0.0068\n",
            "Epoch 30/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0617 - accuracy: 0.0068\n",
            "Epoch 31/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0616 - accuracy: 0.0068\n",
            "Epoch 32/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0614 - accuracy: 0.0068\n",
            "Epoch 33/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0612 - accuracy: 0.0068\n",
            "Epoch 34/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0611 - accuracy: 0.0068\n",
            "Epoch 35/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0609 - accuracy: 0.0068\n",
            "Epoch 36/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0608 - accuracy: 0.0068\n",
            "Epoch 37/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0607 - accuracy: 0.0068\n",
            "Epoch 38/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0605 - accuracy: 0.0068\n",
            "Epoch 39/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0604 - accuracy: 0.0068\n",
            "Epoch 40/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0603 - accuracy: 0.0068\n",
            "Epoch 41/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0602 - accuracy: 0.0068\n",
            "Epoch 42/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0601 - accuracy: 0.0068\n",
            "Epoch 43/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0600 - accuracy: 0.0068\n",
            "Epoch 44/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0599 - accuracy: 0.0068\n",
            "Epoch 45/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0598 - accuracy: 0.0068\n",
            "Epoch 46/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0597 - accuracy: 0.0068\n",
            "Epoch 47/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0596 - accuracy: 0.0068\n",
            "Epoch 48/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0595 - accuracy: 0.0068\n",
            "Epoch 49/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0594 - accuracy: 0.0068\n",
            "Epoch 50/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0593 - accuracy: 0.0068\n",
            "Epoch 51/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0592 - accuracy: 0.0068\n",
            "Epoch 52/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0592 - accuracy: 0.0068\n",
            "Epoch 53/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0591 - accuracy: 0.0068\n",
            "Epoch 54/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0590 - accuracy: 0.0068\n",
            "Epoch 55/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0589 - accuracy: 0.0068\n",
            "Epoch 56/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0589 - accuracy: 0.0068\n",
            "Epoch 57/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0588 - accuracy: 0.0068\n",
            "Epoch 58/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0587 - accuracy: 0.0068\n",
            "Epoch 59/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0587 - accuracy: 0.0068\n",
            "Epoch 60/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0586 - accuracy: 0.0068\n",
            "Epoch 61/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0586 - accuracy: 0.0068\n",
            "Epoch 62/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0585 - accuracy: 0.0068\n",
            "Epoch 63/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0585 - accuracy: 0.0068\n",
            "Epoch 64/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0584 - accuracy: 0.0068\n",
            "Epoch 65/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0584 - accuracy: 0.0068\n",
            "Epoch 66/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0583 - accuracy: 0.0068\n",
            "Epoch 67/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0583 - accuracy: 0.0068\n",
            "Epoch 68/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0582 - accuracy: 0.0068\n",
            "Epoch 69/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0582 - accuracy: 0.0068\n",
            "Epoch 70/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0582 - accuracy: 0.0068\n",
            "Epoch 71/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0581 - accuracy: 0.0068\n",
            "Epoch 72/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0581 - accuracy: 0.0068\n",
            "Epoch 73/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0580 - accuracy: 0.0068\n",
            "Epoch 74/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0580 - accuracy: 0.0068\n",
            "Epoch 75/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0580 - accuracy: 0.0068\n",
            "Epoch 76/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0579 - accuracy: 0.0068\n",
            "Epoch 77/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0579 - accuracy: 0.0068\n",
            "Epoch 78/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0579 - accuracy: 0.0068\n",
            "Epoch 79/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0578 - accuracy: 0.0068\n",
            "Epoch 80/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0578 - accuracy: 0.0068\n",
            "Epoch 81/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0578 - accuracy: 0.0068\n",
            "Epoch 82/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0578 - accuracy: 0.0068\n",
            "Epoch 83/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0577 - accuracy: 0.0068\n",
            "Epoch 84/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0577 - accuracy: 0.0068\n",
            "Epoch 85/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0577 - accuracy: 0.0068\n",
            "Epoch 86/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0577 - accuracy: 0.0068\n",
            "Epoch 87/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0576 - accuracy: 0.0068\n",
            "Epoch 88/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0576 - accuracy: 0.0068\n",
            "Epoch 89/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0576 - accuracy: 0.0068\n",
            "Epoch 90/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0576 - accuracy: 0.0068\n",
            "Epoch 91/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0576 - accuracy: 0.0068\n",
            "Epoch 92/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0575 - accuracy: 0.0068\n",
            "Epoch 93/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0575 - accuracy: 0.0068\n",
            "Epoch 94/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0575 - accuracy: 0.0068\n",
            "Epoch 95/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0575 - accuracy: 0.0068\n",
            "Epoch 96/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0575 - accuracy: 0.0068\n",
            "Epoch 97/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0575 - accuracy: 0.0068\n",
            "Epoch 98/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0575 - accuracy: 0.0068\n",
            "Epoch 99/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0574 - accuracy: 0.0068\n",
            "Epoch 100/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0574 - accuracy: 0.0068\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0715 - accuracy: 0.0068\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0710 - accuracy: 0.0068\n",
            "Epoch 3/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0706 - accuracy: 0.0068\n",
            "Epoch 4/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0699 - accuracy: 0.0068\n",
            "Epoch 5/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0693 - accuracy: 0.0068\n",
            "Epoch 6/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0686 - accuracy: 0.0068\n",
            "Epoch 7/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0679 - accuracy: 0.0068\n",
            "Epoch 8/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0669 - accuracy: 0.0068\n",
            "Epoch 9/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0660 - accuracy: 0.0068\n",
            "Epoch 10/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 11/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0637 - accuracy: 0.0068\n",
            "Epoch 12/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0626 - accuracy: 0.0068\n",
            "Epoch 13/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0611 - accuracy: 0.0068\n",
            "Epoch 14/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0600 - accuracy: 0.0068\n",
            "Epoch 15/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0586 - accuracy: 0.0068\n",
            "Epoch 16/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0574 - accuracy: 0.0068\n",
            "Epoch 17/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0563 - accuracy: 0.0068\n",
            "Epoch 18/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0553 - accuracy: 0.0068\n",
            "Epoch 19/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0541 - accuracy: 0.0068\n",
            "Epoch 20/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0531 - accuracy: 0.0068\n",
            "Epoch 21/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0521 - accuracy: 0.0068\n",
            "Epoch 22/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0511 - accuracy: 0.0068\n",
            "Epoch 23/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0501 - accuracy: 0.0068\n",
            "Epoch 24/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0492 - accuracy: 0.0068\n",
            "Epoch 25/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0483 - accuracy: 0.0068\n",
            "Epoch 26/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0474 - accuracy: 0.0068\n",
            "Epoch 27/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0466 - accuracy: 0.0068\n",
            "Epoch 28/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0457 - accuracy: 0.0068\n",
            "Epoch 29/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0448 - accuracy: 0.0068\n",
            "Epoch 30/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0438 - accuracy: 0.0068\n",
            "Epoch 31/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0430 - accuracy: 0.0068\n",
            "Epoch 32/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0421 - accuracy: 0.0068\n",
            "Epoch 33/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0412 - accuracy: 0.0068\n",
            "Epoch 34/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0405 - accuracy: 0.0068\n",
            "Epoch 35/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0398 - accuracy: 0.0068\n",
            "Epoch 36/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0392 - accuracy: 0.0068\n",
            "Epoch 37/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0387 - accuracy: 0.0204\n",
            "Epoch 38/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0382 - accuracy: 0.0476\n",
            "Epoch 39/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0377 - accuracy: 0.0476\n",
            "Epoch 40/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0372 - accuracy: 0.0476\n",
            "Epoch 41/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0367 - accuracy: 0.0476\n",
            "Epoch 42/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0363 - accuracy: 0.0476\n",
            "Epoch 43/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0358 - accuracy: 0.0476\n",
            "Epoch 44/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0353 - accuracy: 0.0476\n",
            "Epoch 45/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0349 - accuracy: 0.0476\n",
            "Epoch 46/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0345 - accuracy: 0.0476\n",
            "Epoch 47/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0340 - accuracy: 0.0476\n",
            "Epoch 48/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0335 - accuracy: 0.0476\n",
            "Epoch 49/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0330 - accuracy: 0.0476\n",
            "Epoch 50/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0326 - accuracy: 0.0476\n",
            "Epoch 51/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0321 - accuracy: 0.0476\n",
            "Epoch 52/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0318 - accuracy: 0.0476\n",
            "Epoch 53/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0314 - accuracy: 0.0476\n",
            "Epoch 54/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0309 - accuracy: 0.0476\n",
            "Epoch 55/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0305 - accuracy: 0.0476\n",
            "Epoch 56/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0301 - accuracy: 0.0476\n",
            "Epoch 57/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0296 - accuracy: 0.0476\n",
            "Epoch 58/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0292 - accuracy: 0.0476\n",
            "Epoch 59/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0288 - accuracy: 0.0476\n",
            "Epoch 60/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0285 - accuracy: 0.0476\n",
            "Epoch 61/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0280 - accuracy: 0.0476\n",
            "Epoch 62/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0276 - accuracy: 0.0476\n",
            "Epoch 63/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0272 - accuracy: 0.0476\n",
            "Epoch 64/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0268 - accuracy: 0.0476\n",
            "Epoch 65/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0264 - accuracy: 0.0476\n",
            "Epoch 66/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0262 - accuracy: 0.0476\n",
            "Epoch 67/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0258 - accuracy: 0.0476\n",
            "Epoch 68/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0252 - accuracy: 0.0476\n",
            "Epoch 69/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0249 - accuracy: 0.0476\n",
            "Epoch 70/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0245 - accuracy: 0.0476\n",
            "Epoch 71/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0241 - accuracy: 0.0476\n",
            "Epoch 72/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0237 - accuracy: 0.0476\n",
            "Epoch 73/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0234 - accuracy: 0.0476\n",
            "Epoch 74/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0230 - accuracy: 0.0476\n",
            "Epoch 75/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0227 - accuracy: 0.0476\n",
            "Epoch 76/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0223 - accuracy: 0.0476\n",
            "Epoch 77/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0220 - accuracy: 0.0476\n",
            "Epoch 78/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0216 - accuracy: 0.0476\n",
            "Epoch 79/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0213 - accuracy: 0.0476\n",
            "Epoch 80/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0210 - accuracy: 0.0476\n",
            "Epoch 81/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0207 - accuracy: 0.0476\n",
            "Epoch 82/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0203 - accuracy: 0.0476\n",
            "Epoch 83/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0201 - accuracy: 0.0476\n",
            "Epoch 84/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0198 - accuracy: 0.0476\n",
            "Epoch 85/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0194 - accuracy: 0.0476\n",
            "Epoch 86/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0192 - accuracy: 0.0476\n",
            "Epoch 87/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0189 - accuracy: 0.0476\n",
            "Epoch 88/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0186 - accuracy: 0.0476\n",
            "Epoch 89/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0183 - accuracy: 0.0476\n",
            "Epoch 90/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0180 - accuracy: 0.0476\n",
            "Epoch 91/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0178 - accuracy: 0.0476\n",
            "Epoch 92/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0175 - accuracy: 0.0476\n",
            "Epoch 93/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0172 - accuracy: 0.0476\n",
            "Epoch 94/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0170 - accuracy: 0.0476\n",
            "Epoch 95/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0168 - accuracy: 0.0476\n",
            "Epoch 96/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0165 - accuracy: 0.0476\n",
            "Epoch 97/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0163 - accuracy: 0.0476\n",
            "Epoch 98/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0161 - accuracy: 0.0476\n",
            "Epoch 99/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0158 - accuracy: 0.0476\n",
            "Epoch 100/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0156 - accuracy: 0.0476\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 1s 2ms/step - loss: 0.0718 - accuracy: 0.0068\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0712 - accuracy: 0.0000e+00\n",
            "Epoch 3/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0707 - accuracy: 0.0000e+00\n",
            "Epoch 4/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0701 - accuracy: 0.0000e+00\n",
            "Epoch 5/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0696 - accuracy: 0.0000e+00\n",
            "Epoch 6/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0689 - accuracy: 0.0000e+00\n",
            "Epoch 7/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0683 - accuracy: 0.0000e+00\n",
            "Epoch 8/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0676 - accuracy: 0.0000e+00\n",
            "Epoch 9/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0668 - accuracy: 0.0000e+00\n",
            "Epoch 10/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0659 - accuracy: 0.0000e+00\n",
            "Epoch 11/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0648 - accuracy: 0.0000e+00\n",
            "Epoch 12/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0635 - accuracy: 0.0000e+00\n",
            "Epoch 13/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0621 - accuracy: 0.0000e+00\n",
            "Epoch 14/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0604 - accuracy: 0.0000e+00\n",
            "Epoch 15/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0585 - accuracy: 0.0340\n",
            "Epoch 16/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0564 - accuracy: 0.0340\n",
            "Epoch 17/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0541 - accuracy: 0.0340\n",
            "Epoch 18/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0516 - accuracy: 0.0340\n",
            "Epoch 19/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0489 - accuracy: 0.0340\n",
            "Epoch 20/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0461 - accuracy: 0.0340\n",
            "Epoch 21/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0434 - accuracy: 0.0340\n",
            "Epoch 22/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0405 - accuracy: 0.0340\n",
            "Epoch 23/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0377 - accuracy: 0.0340\n",
            "Epoch 24/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0351 - accuracy: 0.0340\n",
            "Epoch 25/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0326 - accuracy: 0.0340\n",
            "Epoch 26/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0302 - accuracy: 0.0340\n",
            "Epoch 27/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0280 - accuracy: 0.0340\n",
            "Epoch 28/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0258 - accuracy: 0.0340\n",
            "Epoch 29/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0240 - accuracy: 0.0340\n",
            "Epoch 30/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0224 - accuracy: 0.0340\n",
            "Epoch 31/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0210 - accuracy: 0.0340\n",
            "Epoch 32/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0196 - accuracy: 0.0340\n",
            "Epoch 33/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0184 - accuracy: 0.0340\n",
            "Epoch 34/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0173 - accuracy: 0.0340\n",
            "Epoch 35/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0164 - accuracy: 0.0340\n",
            "Epoch 36/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0156 - accuracy: 0.0340\n",
            "Epoch 37/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0148 - accuracy: 0.0340\n",
            "Epoch 38/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0142 - accuracy: 0.0340\n",
            "Epoch 39/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0137 - accuracy: 0.0340\n",
            "Epoch 40/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0131 - accuracy: 0.0340\n",
            "Epoch 41/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0127 - accuracy: 0.0340\n",
            "Epoch 42/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0122 - accuracy: 0.0340\n",
            "Epoch 43/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0118 - accuracy: 0.0340\n",
            "Epoch 44/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0115 - accuracy: 0.0340\n",
            "Epoch 45/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0112 - accuracy: 0.0340\n",
            "Epoch 46/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0110 - accuracy: 0.0340\n",
            "Epoch 47/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0106 - accuracy: 0.0340\n",
            "Epoch 48/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0105 - accuracy: 0.0340\n",
            "Epoch 49/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0102 - accuracy: 0.0340\n",
            "Epoch 50/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0099 - accuracy: 0.0340\n",
            "Epoch 51/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0097 - accuracy: 0.0340\n",
            "Epoch 52/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0097 - accuracy: 0.0340\n",
            "Epoch 53/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0094 - accuracy: 0.0340\n",
            "Epoch 54/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0093 - accuracy: 0.0340\n",
            "Epoch 55/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0092 - accuracy: 0.0340\n",
            "Epoch 56/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0090 - accuracy: 0.0340\n",
            "Epoch 57/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0088 - accuracy: 0.0340\n",
            "Epoch 58/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0087 - accuracy: 0.0340\n",
            "Epoch 59/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0085 - accuracy: 0.0340\n",
            "Epoch 60/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0085 - accuracy: 0.0340\n",
            "Epoch 61/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0083 - accuracy: 0.0340\n",
            "Epoch 62/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0082 - accuracy: 0.0340\n",
            "Epoch 63/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0081 - accuracy: 0.0340\n",
            "Epoch 64/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0080 - accuracy: 0.0340\n",
            "Epoch 65/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0079 - accuracy: 0.0340\n",
            "Epoch 66/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0078 - accuracy: 0.0340\n",
            "Epoch 67/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0077 - accuracy: 0.0340\n",
            "Epoch 68/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0077 - accuracy: 0.0340\n",
            "Epoch 69/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0076 - accuracy: 0.0340\n",
            "Epoch 70/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0075 - accuracy: 0.0340\n",
            "Epoch 71/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0074 - accuracy: 0.0340\n",
            "Epoch 72/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0073 - accuracy: 0.0340\n",
            "Epoch 73/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0073 - accuracy: 0.0340\n",
            "Epoch 74/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0072 - accuracy: 0.0340\n",
            "Epoch 75/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0072 - accuracy: 0.0340\n",
            "Epoch 76/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0072 - accuracy: 0.0340\n",
            "Epoch 77/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0070 - accuracy: 0.0340\n",
            "Epoch 78/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0069 - accuracy: 0.0340\n",
            "Epoch 79/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0069 - accuracy: 0.0340\n",
            "Epoch 80/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0068 - accuracy: 0.0340\n",
            "Epoch 81/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0068 - accuracy: 0.0340\n",
            "Epoch 82/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0067 - accuracy: 0.0340\n",
            "Epoch 83/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0067 - accuracy: 0.0340\n",
            "Epoch 84/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0066 - accuracy: 0.0340\n",
            "Epoch 85/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0066 - accuracy: 0.0340\n",
            "Epoch 86/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0066 - accuracy: 0.0340\n",
            "Epoch 87/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0065 - accuracy: 0.0340\n",
            "Epoch 88/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0064 - accuracy: 0.0340\n",
            "Epoch 89/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0064 - accuracy: 0.0340\n",
            "Epoch 90/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0064 - accuracy: 0.0340\n",
            "Epoch 91/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0063 - accuracy: 0.0340\n",
            "Epoch 92/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0063 - accuracy: 0.0340\n",
            "Epoch 93/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0063 - accuracy: 0.0340\n",
            "Epoch 94/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0062 - accuracy: 0.0340\n",
            "Epoch 95/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0061 - accuracy: 0.0340\n",
            "Epoch 96/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0062 - accuracy: 0.0340\n",
            "Epoch 97/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0061 - accuracy: 0.0340\n",
            "Epoch 98/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0061 - accuracy: 0.0340\n",
            "Epoch 99/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0060 - accuracy: 0.0340\n",
            "Epoch 100/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0061 - accuracy: 0.0340\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 1s 2ms/step - loss: 0.0653 - accuracy: 0.0068\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0645 - accuracy: 0.0068\n",
            "Epoch 3/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0637 - accuracy: 0.0068\n",
            "Epoch 4/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0628 - accuracy: 0.0068\n",
            "Epoch 5/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0619 - accuracy: 0.0068\n",
            "Epoch 6/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0608 - accuracy: 0.0068\n",
            "Epoch 7/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0594 - accuracy: 0.0068\n",
            "Epoch 8/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0580 - accuracy: 0.0068\n",
            "Epoch 9/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0565 - accuracy: 0.0068\n",
            "Epoch 10/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0551 - accuracy: 0.0068\n",
            "Epoch 11/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0537 - accuracy: 0.0068\n",
            "Epoch 12/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0525 - accuracy: 0.0068\n",
            "Epoch 13/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0511 - accuracy: 0.0068\n",
            "Epoch 14/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0499 - accuracy: 0.0068\n",
            "Epoch 15/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0488 - accuracy: 0.0068\n",
            "Epoch 16/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0476 - accuracy: 0.0068\n",
            "Epoch 17/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0465 - accuracy: 0.0068\n",
            "Epoch 18/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0453 - accuracy: 0.0068\n",
            "Epoch 19/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0443 - accuracy: 0.0068\n",
            "Epoch 20/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0436 - accuracy: 0.0068\n",
            "Epoch 21/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0429 - accuracy: 0.0068\n",
            "Epoch 22/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0421 - accuracy: 0.0068\n",
            "Epoch 23/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0414 - accuracy: 0.0068\n",
            "Epoch 24/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0407 - accuracy: 0.0068\n",
            "Epoch 25/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0400 - accuracy: 0.0068\n",
            "Epoch 26/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0391 - accuracy: 0.0068\n",
            "Epoch 27/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0384 - accuracy: 0.0068\n",
            "Epoch 28/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0376 - accuracy: 0.0068\n",
            "Epoch 29/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0370 - accuracy: 0.0068\n",
            "Epoch 30/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0361 - accuracy: 0.0068\n",
            "Epoch 31/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0354 - accuracy: 0.0068\n",
            "Epoch 32/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0347 - accuracy: 0.0068\n",
            "Epoch 33/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0339 - accuracy: 0.0068\n",
            "Epoch 34/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0332 - accuracy: 0.0068\n",
            "Epoch 35/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0325 - accuracy: 0.0068\n",
            "Epoch 36/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0318 - accuracy: 0.0068\n",
            "Epoch 37/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0311 - accuracy: 0.0476\n",
            "Epoch 38/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0304 - accuracy: 0.0476\n",
            "Epoch 39/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0297 - accuracy: 0.0476\n",
            "Epoch 40/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0291 - accuracy: 0.0476\n",
            "Epoch 41/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0284 - accuracy: 0.0476\n",
            "Epoch 42/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0278 - accuracy: 0.0476\n",
            "Epoch 43/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0271 - accuracy: 0.0476\n",
            "Epoch 44/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0265 - accuracy: 0.0476\n",
            "Epoch 45/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0259 - accuracy: 0.0476\n",
            "Epoch 46/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0253 - accuracy: 0.0476\n",
            "Epoch 47/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0247 - accuracy: 0.0476\n",
            "Epoch 48/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0240 - accuracy: 0.0476\n",
            "Epoch 49/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0235 - accuracy: 0.0476\n",
            "Epoch 50/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0228 - accuracy: 0.0476\n",
            "Epoch 51/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0223 - accuracy: 0.0476\n",
            "Epoch 52/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0218 - accuracy: 0.0476\n",
            "Epoch 53/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0213 - accuracy: 0.0476\n",
            "Epoch 54/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0207 - accuracy: 0.0476\n",
            "Epoch 55/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0203 - accuracy: 0.0476\n",
            "Epoch 56/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0198 - accuracy: 0.0476\n",
            "Epoch 57/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0193 - accuracy: 0.0476\n",
            "Epoch 58/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0188 - accuracy: 0.0476\n",
            "Epoch 59/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0183 - accuracy: 0.0476\n",
            "Epoch 60/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0179 - accuracy: 0.0476\n",
            "Epoch 61/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0174 - accuracy: 0.0476\n",
            "Epoch 62/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0170 - accuracy: 0.0476\n",
            "Epoch 63/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0165 - accuracy: 0.0476\n",
            "Epoch 64/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0161 - accuracy: 0.0476\n",
            "Epoch 65/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0157 - accuracy: 0.0476\n",
            "Epoch 66/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0155 - accuracy: 0.0476\n",
            "Epoch 67/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0149 - accuracy: 0.0476\n",
            "Epoch 68/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0147 - accuracy: 0.0476\n",
            "Epoch 69/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0142 - accuracy: 0.0476\n",
            "Epoch 70/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0138 - accuracy: 0.0476\n",
            "Epoch 71/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0135 - accuracy: 0.0476\n",
            "Epoch 72/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0131 - accuracy: 0.0476\n",
            "Epoch 73/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0128 - accuracy: 0.0476\n",
            "Epoch 74/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0125 - accuracy: 0.0476\n",
            "Epoch 75/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0121 - accuracy: 0.0476\n",
            "Epoch 76/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0118 - accuracy: 0.0476\n",
            "Epoch 77/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0115 - accuracy: 0.0476\n",
            "Epoch 78/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0112 - accuracy: 0.0476\n",
            "Epoch 79/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0109 - accuracy: 0.0476\n",
            "Epoch 80/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0107 - accuracy: 0.0476\n",
            "Epoch 81/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0105 - accuracy: 0.0476\n",
            "Epoch 82/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0102 - accuracy: 0.0476\n",
            "Epoch 83/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0101 - accuracy: 0.0476\n",
            "Epoch 84/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0097 - accuracy: 0.0476\n",
            "Epoch 85/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0095 - accuracy: 0.0476\n",
            "Epoch 86/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0093 - accuracy: 0.0476\n",
            "Epoch 87/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0092 - accuracy: 0.0476\n",
            "Epoch 88/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0090 - accuracy: 0.0476\n",
            "Epoch 89/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0087 - accuracy: 0.0476\n",
            "Epoch 90/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0086 - accuracy: 0.0476\n",
            "Epoch 91/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0084 - accuracy: 0.0476\n",
            "Epoch 92/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0083 - accuracy: 0.0476\n",
            "Epoch 93/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0081 - accuracy: 0.0476\n",
            "Epoch 94/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0080 - accuracy: 0.0476\n",
            "Epoch 95/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0078 - accuracy: 0.0476\n",
            "Epoch 96/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0076 - accuracy: 0.0476\n",
            "Epoch 97/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0075 - accuracy: 0.0476\n",
            "Epoch 98/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0074 - accuracy: 0.0476\n",
            "Epoch 99/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0072 - accuracy: 0.0476\n",
            "Epoch 100/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0072 - accuracy: 0.0476\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 1s 3ms/step - loss: 0.0696 - accuracy: 0.0068\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0690 - accuracy: 0.0068\n",
            "Epoch 3/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0685 - accuracy: 0.0068\n",
            "Epoch 4/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0679 - accuracy: 0.0068\n",
            "Epoch 5/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0673 - accuracy: 0.0068\n",
            "Epoch 6/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0666 - accuracy: 0.0068\n",
            "Epoch 7/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0659 - accuracy: 0.0068\n",
            "Epoch 8/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 9/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0639 - accuracy: 0.0068\n",
            "Epoch 10/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0627 - accuracy: 0.0068\n",
            "Epoch 11/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0615 - accuracy: 0.0068\n",
            "Epoch 12/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0601 - accuracy: 0.0068\n",
            "Epoch 13/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0586 - accuracy: 0.0068\n",
            "Epoch 14/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0570 - accuracy: 0.0068\n",
            "Epoch 15/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0552 - accuracy: 0.0068\n",
            "Epoch 16/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0535 - accuracy: 0.0068\n",
            "Epoch 17/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0518 - accuracy: 0.0068\n",
            "Epoch 18/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0499 - accuracy: 0.0068\n",
            "Epoch 19/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0481 - accuracy: 0.0068\n",
            "Epoch 20/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0463 - accuracy: 0.0068\n",
            "Epoch 21/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0443 - accuracy: 0.0068\n",
            "Epoch 22/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0423 - accuracy: 0.0068\n",
            "Epoch 23/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0403 - accuracy: 0.0136\n",
            "Epoch 24/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0383 - accuracy: 0.0408\n",
            "Epoch 25/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0363 - accuracy: 0.0408\n",
            "Epoch 26/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0343 - accuracy: 0.0408\n",
            "Epoch 27/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0325 - accuracy: 0.0408\n",
            "Epoch 28/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0305 - accuracy: 0.0408\n",
            "Epoch 29/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0288 - accuracy: 0.0408\n",
            "Epoch 30/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0270 - accuracy: 0.0408\n",
            "Epoch 31/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0254 - accuracy: 0.0408\n",
            "Epoch 32/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0239 - accuracy: 0.0408\n",
            "Epoch 33/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0225 - accuracy: 0.0408\n",
            "Epoch 34/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0212 - accuracy: 0.0408\n",
            "Epoch 35/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0200 - accuracy: 0.0408\n",
            "Epoch 36/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0189 - accuracy: 0.0408\n",
            "Epoch 37/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0179 - accuracy: 0.0408\n",
            "Epoch 38/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0170 - accuracy: 0.0408\n",
            "Epoch 39/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0161 - accuracy: 0.0408\n",
            "Epoch 40/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0154 - accuracy: 0.0408\n",
            "Epoch 41/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0148 - accuracy: 0.0408\n",
            "Epoch 42/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0141 - accuracy: 0.0408\n",
            "Epoch 43/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0136 - accuracy: 0.0408\n",
            "Epoch 44/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0131 - accuracy: 0.0408\n",
            "Epoch 45/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0126 - accuracy: 0.0408\n",
            "Epoch 46/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0122 - accuracy: 0.0408\n",
            "Epoch 47/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0118 - accuracy: 0.0408\n",
            "Epoch 48/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0115 - accuracy: 0.0408\n",
            "Epoch 49/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0112 - accuracy: 0.0408\n",
            "Epoch 50/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0108 - accuracy: 0.0408\n",
            "Epoch 51/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0106 - accuracy: 0.0408\n",
            "Epoch 52/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0104 - accuracy: 0.0408\n",
            "Epoch 53/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0101 - accuracy: 0.0408\n",
            "Epoch 54/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0099 - accuracy: 0.0408\n",
            "Epoch 55/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0097 - accuracy: 0.0408\n",
            "Epoch 56/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0095 - accuracy: 0.0408\n",
            "Epoch 57/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0094 - accuracy: 0.0408\n",
            "Epoch 58/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0092 - accuracy: 0.0408\n",
            "Epoch 59/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0090 - accuracy: 0.0408\n",
            "Epoch 60/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0089 - accuracy: 0.0408\n",
            "Epoch 61/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0086 - accuracy: 0.0408\n",
            "Epoch 62/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0086 - accuracy: 0.0408\n",
            "Epoch 63/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0084 - accuracy: 0.0408\n",
            "Epoch 64/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0083 - accuracy: 0.0408\n",
            "Epoch 65/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0082 - accuracy: 0.0408\n",
            "Epoch 66/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0080 - accuracy: 0.0408\n",
            "Epoch 67/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0080 - accuracy: 0.0408\n",
            "Epoch 68/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0078 - accuracy: 0.0408\n",
            "Epoch 69/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0077 - accuracy: 0.0408\n",
            "Epoch 70/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0076 - accuracy: 0.0408\n",
            "Epoch 71/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0075 - accuracy: 0.0408\n",
            "Epoch 72/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0074 - accuracy: 0.0408\n",
            "Epoch 73/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0073 - accuracy: 0.0408\n",
            "Epoch 74/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0073 - accuracy: 0.0408\n",
            "Epoch 75/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0072 - accuracy: 0.0408\n",
            "Epoch 76/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0071 - accuracy: 0.0408\n",
            "Epoch 77/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0070 - accuracy: 0.0408\n",
            "Epoch 78/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0069 - accuracy: 0.0408\n",
            "Epoch 79/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0068 - accuracy: 0.0408\n",
            "Epoch 80/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0068 - accuracy: 0.0408\n",
            "Epoch 81/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0068 - accuracy: 0.0408\n",
            "Epoch 82/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0067 - accuracy: 0.0408\n",
            "Epoch 83/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0066 - accuracy: 0.0408\n",
            "Epoch 84/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0065 - accuracy: 0.0408\n",
            "Epoch 85/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0065 - accuracy: 0.0408\n",
            "Epoch 86/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0065 - accuracy: 0.0408\n",
            "Epoch 87/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0064 - accuracy: 0.0408\n",
            "Epoch 88/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0063 - accuracy: 0.0408\n",
            "Epoch 89/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0063 - accuracy: 0.0408\n",
            "Epoch 90/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0063 - accuracy: 0.0408\n",
            "Epoch 91/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0062 - accuracy: 0.0408\n",
            "Epoch 92/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0061 - accuracy: 0.0408\n",
            "Epoch 93/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0060 - accuracy: 0.0408\n",
            "Epoch 94/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0061 - accuracy: 0.0408\n",
            "Epoch 95/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0059 - accuracy: 0.0408\n",
            "Epoch 96/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0059 - accuracy: 0.0408\n",
            "Epoch 97/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0058 - accuracy: 0.0408\n",
            "Epoch 98/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0058 - accuracy: 0.0408\n",
            "Epoch 99/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0058 - accuracy: 0.0408\n",
            "Epoch 100/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0058 - accuracy: 0.0408\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0707 - accuracy: 0.0068\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0698 - accuracy: 0.0068\n",
            "Epoch 3/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0687 - accuracy: 0.0068\n",
            "Epoch 4/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0673 - accuracy: 0.0068\n",
            "Epoch 5/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0661 - accuracy: 0.0068\n",
            "Epoch 6/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0643 - accuracy: 0.0068\n",
            "Epoch 7/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0624 - accuracy: 0.0068\n",
            "Epoch 8/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0602 - accuracy: 0.0068\n",
            "Epoch 9/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0581 - accuracy: 0.0068\n",
            "Epoch 10/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0562 - accuracy: 0.0068\n",
            "Epoch 11/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0541 - accuracy: 0.0068\n",
            "Epoch 12/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0517 - accuracy: 0.0068\n",
            "Epoch 13/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0495 - accuracy: 0.0068\n",
            "Epoch 14/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0468 - accuracy: 0.0068\n",
            "Epoch 15/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0444 - accuracy: 0.0068\n",
            "Epoch 16/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0423 - accuracy: 0.0068\n",
            "Epoch 17/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0407 - accuracy: 0.0068\n",
            "Epoch 18/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0392 - accuracy: 0.0068\n",
            "Epoch 19/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0382 - accuracy: 0.0068\n",
            "Epoch 20/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0373 - accuracy: 0.0068\n",
            "Epoch 21/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0365 - accuracy: 0.0068\n",
            "Epoch 22/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0358 - accuracy: 0.0068\n",
            "Epoch 23/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0350 - accuracy: 0.0068\n",
            "Epoch 24/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0343 - accuracy: 0.0068\n",
            "Epoch 25/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0338 - accuracy: 0.0068\n",
            "Epoch 26/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0333 - accuracy: 0.0068\n",
            "Epoch 27/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0327 - accuracy: 0.0068\n",
            "Epoch 28/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0323 - accuracy: 0.0068\n",
            "Epoch 29/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0318 - accuracy: 0.0068\n",
            "Epoch 30/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0313 - accuracy: 0.0068\n",
            "Epoch 31/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0309 - accuracy: 0.0068\n",
            "Epoch 32/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0304 - accuracy: 0.0068\n",
            "Epoch 33/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0300 - accuracy: 0.0068\n",
            "Epoch 34/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0297 - accuracy: 0.0068\n",
            "Epoch 35/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0292 - accuracy: 0.0068\n",
            "Epoch 36/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0288 - accuracy: 0.0068\n",
            "Epoch 37/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0285 - accuracy: 0.0473\n",
            "Epoch 38/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0280 - accuracy: 0.0473\n",
            "Epoch 39/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0276 - accuracy: 0.0473\n",
            "Epoch 40/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0272 - accuracy: 0.0473\n",
            "Epoch 41/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0269 - accuracy: 0.0473\n",
            "Epoch 42/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0265 - accuracy: 0.0473\n",
            "Epoch 43/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0261 - accuracy: 0.0473\n",
            "Epoch 44/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0258 - accuracy: 0.0473\n",
            "Epoch 45/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0255 - accuracy: 0.0473\n",
            "Epoch 46/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0251 - accuracy: 0.0473\n",
            "Epoch 47/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0247 - accuracy: 0.0473\n",
            "Epoch 48/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0244 - accuracy: 0.0473\n",
            "Epoch 49/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0241 - accuracy: 0.0473\n",
            "Epoch 50/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0237 - accuracy: 0.0473\n",
            "Epoch 51/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0234 - accuracy: 0.0473\n",
            "Epoch 52/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0231 - accuracy: 0.0473\n",
            "Epoch 53/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0227 - accuracy: 0.0473\n",
            "Epoch 54/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0226 - accuracy: 0.0473\n",
            "Epoch 55/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0222 - accuracy: 0.0473\n",
            "Epoch 56/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0219 - accuracy: 0.0473\n",
            "Epoch 57/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0216 - accuracy: 0.0473\n",
            "Epoch 58/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0212 - accuracy: 0.0473\n",
            "Epoch 59/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0211 - accuracy: 0.0473\n",
            "Epoch 60/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0206 - accuracy: 0.0473\n",
            "Epoch 61/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0204 - accuracy: 0.0473\n",
            "Epoch 62/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0201 - accuracy: 0.0473\n",
            "Epoch 63/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0198 - accuracy: 0.0473\n",
            "Epoch 64/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0196 - accuracy: 0.0473\n",
            "Epoch 65/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0193 - accuracy: 0.0473\n",
            "Epoch 66/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0191 - accuracy: 0.0473\n",
            "Epoch 67/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0188 - accuracy: 0.0473\n",
            "Epoch 68/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0186 - accuracy: 0.0473\n",
            "Epoch 69/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0183 - accuracy: 0.0473\n",
            "Epoch 70/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0181 - accuracy: 0.0473\n",
            "Epoch 71/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0178 - accuracy: 0.0473\n",
            "Epoch 72/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0176 - accuracy: 0.0473\n",
            "Epoch 73/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0174 - accuracy: 0.0473\n",
            "Epoch 74/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0172 - accuracy: 0.0473\n",
            "Epoch 75/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0170 - accuracy: 0.0473\n",
            "Epoch 76/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0168 - accuracy: 0.0473\n",
            "Epoch 77/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0166 - accuracy: 0.0473\n",
            "Epoch 78/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0163 - accuracy: 0.0473\n",
            "Epoch 79/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0161 - accuracy: 0.0473\n",
            "Epoch 80/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0159 - accuracy: 0.0473\n",
            "Epoch 81/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0157 - accuracy: 0.0473\n",
            "Epoch 82/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0155 - accuracy: 0.0473\n",
            "Epoch 83/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0153 - accuracy: 0.0473\n",
            "Epoch 84/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0151 - accuracy: 0.0473\n",
            "Epoch 85/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0149 - accuracy: 0.0473\n",
            "Epoch 86/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0148 - accuracy: 0.0473\n",
            "Epoch 87/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0146 - accuracy: 0.0473\n",
            "Epoch 88/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0144 - accuracy: 0.0473\n",
            "Epoch 89/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0142 - accuracy: 0.0473\n",
            "Epoch 90/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0141 - accuracy: 0.0473\n",
            "Epoch 91/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0138 - accuracy: 0.0473\n",
            "Epoch 92/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0137 - accuracy: 0.0473\n",
            "Epoch 93/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0136 - accuracy: 0.0473\n",
            "Epoch 94/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0134 - accuracy: 0.0473\n",
            "Epoch 95/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0133 - accuracy: 0.0473\n",
            "Epoch 96/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0131 - accuracy: 0.0473\n",
            "Epoch 97/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0130 - accuracy: 0.0473\n",
            "Epoch 98/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0129 - accuracy: 0.0473\n",
            "Epoch 99/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0127 - accuracy: 0.0473\n",
            "Epoch 100/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0126 - accuracy: 0.0473\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0717 - accuracy: 0.0068\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0714 - accuracy: 0.0068\n",
            "Epoch 3/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0711 - accuracy: 0.0068\n",
            "Epoch 4/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0709 - accuracy: 0.0068\n",
            "Epoch 5/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0707 - accuracy: 0.0068\n",
            "Epoch 6/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0704 - accuracy: 0.0068\n",
            "Epoch 7/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0702 - accuracy: 0.0068\n",
            "Epoch 8/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0700 - accuracy: 0.0068\n",
            "Epoch 9/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0698 - accuracy: 0.0068\n",
            "Epoch 10/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0696 - accuracy: 0.0068\n",
            "Epoch 11/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0694 - accuracy: 0.0068\n",
            "Epoch 12/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0692 - accuracy: 0.0068\n",
            "Epoch 13/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0690 - accuracy: 0.0068\n",
            "Epoch 14/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0689 - accuracy: 0.0068\n",
            "Epoch 15/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0687 - accuracy: 0.0068\n",
            "Epoch 16/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0686 - accuracy: 0.0068\n",
            "Epoch 17/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0684 - accuracy: 0.0068\n",
            "Epoch 18/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0683 - accuracy: 0.0068\n",
            "Epoch 19/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0681 - accuracy: 0.0068\n",
            "Epoch 20/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0680 - accuracy: 0.0068\n",
            "Epoch 21/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0678 - accuracy: 0.0068\n",
            "Epoch 22/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0677 - accuracy: 0.0068\n",
            "Epoch 23/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0676 - accuracy: 0.0068\n",
            "Epoch 24/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0675 - accuracy: 0.0068\n",
            "Epoch 25/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0674 - accuracy: 0.0068\n",
            "Epoch 26/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0673 - accuracy: 0.0068\n",
            "Epoch 27/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0672 - accuracy: 0.0068\n",
            "Epoch 28/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0671 - accuracy: 0.0068\n",
            "Epoch 29/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0670 - accuracy: 0.0068\n",
            "Epoch 30/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0669 - accuracy: 0.0068\n",
            "Epoch 31/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0668 - accuracy: 0.0068\n",
            "Epoch 32/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0667 - accuracy: 0.0068\n",
            "Epoch 33/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0666 - accuracy: 0.0068\n",
            "Epoch 34/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0665 - accuracy: 0.0068\n",
            "Epoch 35/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0665 - accuracy: 0.0068\n",
            "Epoch 36/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0664 - accuracy: 0.0068\n",
            "Epoch 37/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0663 - accuracy: 0.0068\n",
            "Epoch 38/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0662 - accuracy: 0.0068\n",
            "Epoch 39/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0662 - accuracy: 0.0068\n",
            "Epoch 40/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0661 - accuracy: 0.0068\n",
            "Epoch 41/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0661 - accuracy: 0.0068\n",
            "Epoch 42/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0660 - accuracy: 0.0068\n",
            "Epoch 43/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0659 - accuracy: 0.0068\n",
            "Epoch 44/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0659 - accuracy: 0.0068\n",
            "Epoch 45/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0658 - accuracy: 0.0068\n",
            "Epoch 46/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0658 - accuracy: 0.0068\n",
            "Epoch 47/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0657 - accuracy: 0.0068\n",
            "Epoch 48/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0657 - accuracy: 0.0068\n",
            "Epoch 49/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0657 - accuracy: 0.0068\n",
            "Epoch 50/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0656 - accuracy: 0.0068\n",
            "Epoch 51/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0656 - accuracy: 0.0068\n",
            "Epoch 52/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0655 - accuracy: 0.0068\n",
            "Epoch 53/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0655 - accuracy: 0.0068\n",
            "Epoch 54/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0655 - accuracy: 0.0068\n",
            "Epoch 55/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0654 - accuracy: 0.0068\n",
            "Epoch 56/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0654 - accuracy: 0.0068\n",
            "Epoch 57/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0654 - accuracy: 0.0068\n",
            "Epoch 58/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0653 - accuracy: 0.0068\n",
            "Epoch 59/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0653 - accuracy: 0.0068\n",
            "Epoch 60/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0653 - accuracy: 0.0068\n",
            "Epoch 61/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0652 - accuracy: 0.0068\n",
            "Epoch 62/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0652 - accuracy: 0.0068\n",
            "Epoch 63/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0652 - accuracy: 0.0068\n",
            "Epoch 64/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0652 - accuracy: 0.0068\n",
            "Epoch 65/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0651 - accuracy: 0.0068\n",
            "Epoch 66/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0651 - accuracy: 0.0068\n",
            "Epoch 67/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0651 - accuracy: 0.0068\n",
            "Epoch 68/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0651 - accuracy: 0.0068\n",
            "Epoch 69/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0650 - accuracy: 0.0068\n",
            "Epoch 70/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0650 - accuracy: 0.0068\n",
            "Epoch 71/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0650 - accuracy: 0.0068\n",
            "Epoch 72/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0650 - accuracy: 0.0068\n",
            "Epoch 73/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0650 - accuracy: 0.0068\n",
            "Epoch 74/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 75/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 76/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 77/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 78/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 79/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 80/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0648 - accuracy: 0.0068\n",
            "Epoch 81/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0648 - accuracy: 0.0068\n",
            "Epoch 82/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0648 - accuracy: 0.0068\n",
            "Epoch 83/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0648 - accuracy: 0.0068\n",
            "Epoch 84/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0648 - accuracy: 0.0068\n",
            "Epoch 85/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0648 - accuracy: 0.0068\n",
            "Epoch 86/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0648 - accuracy: 0.0068\n",
            "Epoch 87/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0648 - accuracy: 0.0068\n",
            "Epoch 88/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 89/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 90/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 91/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 92/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 93/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 94/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 95/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 96/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 97/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 98/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 99/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 100/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0720 - accuracy: 0.0000e+00\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0717 - accuracy: 0.0000e+00\n",
            "Epoch 3/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0713 - accuracy: 0.0000e+00\n",
            "Epoch 4/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0710 - accuracy: 0.0000e+00\n",
            "Epoch 5/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0707 - accuracy: 0.0000e+00\n",
            "Epoch 6/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0704 - accuracy: 0.0000e+00\n",
            "Epoch 7/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0701 - accuracy: 0.0000e+00\n",
            "Epoch 8/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0698 - accuracy: 0.0000e+00\n",
            "Epoch 9/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0695 - accuracy: 0.0000e+00\n",
            "Epoch 10/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0693 - accuracy: 0.0000e+00\n",
            "Epoch 11/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0690 - accuracy: 0.0000e+00\n",
            "Epoch 12/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0688 - accuracy: 0.0000e+00\n",
            "Epoch 13/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0686 - accuracy: 0.0000e+00\n",
            "Epoch 14/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0684 - accuracy: 0.0000e+00\n",
            "Epoch 15/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0681 - accuracy: 0.0000e+00\n",
            "Epoch 16/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0679 - accuracy: 0.0000e+00\n",
            "Epoch 17/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0677 - accuracy: 0.0000e+00\n",
            "Epoch 18/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0676 - accuracy: 0.0000e+00\n",
            "Epoch 19/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0674 - accuracy: 0.0000e+00\n",
            "Epoch 20/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0672 - accuracy: 0.0000e+00\n",
            "Epoch 21/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0670 - accuracy: 0.0000e+00\n",
            "Epoch 22/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0669 - accuracy: 0.0000e+00\n",
            "Epoch 23/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0667 - accuracy: 0.0000e+00\n",
            "Epoch 24/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0666 - accuracy: 0.0000e+00\n",
            "Epoch 25/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0664 - accuracy: 0.0000e+00\n",
            "Epoch 26/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0663 - accuracy: 0.0000e+00\n",
            "Epoch 27/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0661 - accuracy: 0.0000e+00\n",
            "Epoch 28/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0660 - accuracy: 0.0000e+00\n",
            "Epoch 29/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0659 - accuracy: 0.0000e+00\n",
            "Epoch 30/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0658 - accuracy: 0.0000e+00\n",
            "Epoch 31/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0656 - accuracy: 0.0000e+00\n",
            "Epoch 32/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0655 - accuracy: 0.0000e+00\n",
            "Epoch 33/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0654 - accuracy: 0.0000e+00\n",
            "Epoch 34/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0653 - accuracy: 0.0000e+00\n",
            "Epoch 35/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0652 - accuracy: 0.0000e+00\n",
            "Epoch 36/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0651 - accuracy: 0.0000e+00\n",
            "Epoch 37/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0650 - accuracy: 0.0000e+00\n",
            "Epoch 38/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0649 - accuracy: 0.0000e+00\n",
            "Epoch 39/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0648 - accuracy: 0.0000e+00\n",
            "Epoch 40/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0648 - accuracy: 0.0000e+00\n",
            "Epoch 41/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0647 - accuracy: 0.0000e+00\n",
            "Epoch 42/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0646 - accuracy: 0.0000e+00\n",
            "Epoch 43/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0645 - accuracy: 0.0000e+00\n",
            "Epoch 44/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0645 - accuracy: 0.0000e+00\n",
            "Epoch 45/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0644 - accuracy: 0.0000e+00\n",
            "Epoch 46/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0643 - accuracy: 0.0000e+00\n",
            "Epoch 47/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0643 - accuracy: 0.0000e+00\n",
            "Epoch 48/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0642 - accuracy: 0.0000e+00\n",
            "Epoch 49/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0641 - accuracy: 0.0000e+00\n",
            "Epoch 50/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0641 - accuracy: 0.0000e+00\n",
            "Epoch 51/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0640 - accuracy: 0.0000e+00\n",
            "Epoch 52/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0640 - accuracy: 0.0000e+00\n",
            "Epoch 53/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0639 - accuracy: 0.0000e+00\n",
            "Epoch 54/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0639 - accuracy: 0.0000e+00\n",
            "Epoch 55/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0638 - accuracy: 0.0000e+00\n",
            "Epoch 56/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0638 - accuracy: 0.0000e+00\n",
            "Epoch 57/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0637 - accuracy: 0.0000e+00\n",
            "Epoch 58/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0637 - accuracy: 0.0000e+00\n",
            "Epoch 59/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0636 - accuracy: 0.0000e+00\n",
            "Epoch 60/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0636 - accuracy: 0.0000e+00\n",
            "Epoch 61/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0636 - accuracy: 0.0000e+00\n",
            "Epoch 62/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0635 - accuracy: 0.0000e+00\n",
            "Epoch 63/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0635 - accuracy: 0.0000e+00\n",
            "Epoch 64/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0634 - accuracy: 0.0000e+00\n",
            "Epoch 65/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0634 - accuracy: 0.0000e+00\n",
            "Epoch 66/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0634 - accuracy: 0.0000e+00\n",
            "Epoch 67/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0634 - accuracy: 0.0000e+00\n",
            "Epoch 68/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0633 - accuracy: 0.0000e+00\n",
            "Epoch 69/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0633 - accuracy: 0.0000e+00\n",
            "Epoch 70/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0633 - accuracy: 0.0000e+00\n",
            "Epoch 71/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0632 - accuracy: 0.0000e+00\n",
            "Epoch 72/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0632 - accuracy: 0.0000e+00\n",
            "Epoch 73/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0632 - accuracy: 0.0000e+00\n",
            "Epoch 74/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0632 - accuracy: 0.0000e+00\n",
            "Epoch 75/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0632 - accuracy: 0.0000e+00\n",
            "Epoch 76/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0631 - accuracy: 0.0000e+00\n",
            "Epoch 77/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0631 - accuracy: 0.0000e+00\n",
            "Epoch 78/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0631 - accuracy: 0.0000e+00\n",
            "Epoch 79/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0631 - accuracy: 0.0000e+00\n",
            "Epoch 80/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0631 - accuracy: 0.0000e+00\n",
            "Epoch 81/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0630 - accuracy: 0.0000e+00\n",
            "Epoch 82/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0630 - accuracy: 0.0000e+00\n",
            "Epoch 83/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0630 - accuracy: 0.0000e+00\n",
            "Epoch 84/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0630 - accuracy: 0.0000e+00\n",
            "Epoch 85/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0630 - accuracy: 0.0000e+00\n",
            "Epoch 86/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0629 - accuracy: 0.0000e+00\n",
            "Epoch 87/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0629 - accuracy: 0.0000e+00\n",
            "Epoch 88/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0629 - accuracy: 0.0000e+00\n",
            "Epoch 89/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0629 - accuracy: 0.0000e+00\n",
            "Epoch 90/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0629 - accuracy: 0.0000e+00\n",
            "Epoch 91/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0629 - accuracy: 0.0000e+00\n",
            "Epoch 92/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0629 - accuracy: 0.0000e+00\n",
            "Epoch 93/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0628 - accuracy: 0.0000e+00\n",
            "Epoch 94/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0628 - accuracy: 0.0000e+00\n",
            "Epoch 95/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0628 - accuracy: 0.0000e+00\n",
            "Epoch 96/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0628 - accuracy: 0.0000e+00\n",
            "Epoch 97/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0628 - accuracy: 0.0000e+00\n",
            "Epoch 98/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0628 - accuracy: 0.0000e+00\n",
            "Epoch 99/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0628 - accuracy: 0.0000e+00\n",
            "Epoch 100/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0628 - accuracy: 0.0000e+00\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0654 - accuracy: 0.0068\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 3/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0645 - accuracy: 0.0068\n",
            "Epoch 4/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0640 - accuracy: 0.0068\n",
            "Epoch 5/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0636 - accuracy: 0.0068\n",
            "Epoch 6/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0632 - accuracy: 0.0068\n",
            "Epoch 7/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0629 - accuracy: 0.0068\n",
            "Epoch 8/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0625 - accuracy: 0.0068\n",
            "Epoch 9/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0621 - accuracy: 0.0068\n",
            "Epoch 10/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0618 - accuracy: 0.0068\n",
            "Epoch 11/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0614 - accuracy: 0.0068\n",
            "Epoch 12/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0611 - accuracy: 0.0068\n",
            "Epoch 13/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0608 - accuracy: 0.0068\n",
            "Epoch 14/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0605 - accuracy: 0.0068\n",
            "Epoch 15/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0602 - accuracy: 0.0068\n",
            "Epoch 16/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0600 - accuracy: 0.0068\n",
            "Epoch 17/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0597 - accuracy: 0.0068\n",
            "Epoch 18/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0594 - accuracy: 0.0068\n",
            "Epoch 19/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0592 - accuracy: 0.0068\n",
            "Epoch 20/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0590 - accuracy: 0.0068\n",
            "Epoch 21/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0588 - accuracy: 0.0068\n",
            "Epoch 22/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0585 - accuracy: 0.0068\n",
            "Epoch 23/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0583 - accuracy: 0.0068\n",
            "Epoch 24/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0581 - accuracy: 0.0068\n",
            "Epoch 25/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0579 - accuracy: 0.0068\n",
            "Epoch 26/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0577 - accuracy: 0.0068\n",
            "Epoch 27/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0575 - accuracy: 0.0068\n",
            "Epoch 28/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0574 - accuracy: 0.0068\n",
            "Epoch 29/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0572 - accuracy: 0.0068\n",
            "Epoch 30/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0570 - accuracy: 0.0068\n",
            "Epoch 31/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0569 - accuracy: 0.0068\n",
            "Epoch 32/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0567 - accuracy: 0.0068\n",
            "Epoch 33/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0566 - accuracy: 0.0068\n",
            "Epoch 34/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0565 - accuracy: 0.0068\n",
            "Epoch 35/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0563 - accuracy: 0.0068\n",
            "Epoch 36/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0562 - accuracy: 0.0068\n",
            "Epoch 37/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0561 - accuracy: 0.0068\n",
            "Epoch 38/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0560 - accuracy: 0.0068\n",
            "Epoch 39/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0558 - accuracy: 0.0068\n",
            "Epoch 40/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0557 - accuracy: 0.0068\n",
            "Epoch 41/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0556 - accuracy: 0.0068\n",
            "Epoch 42/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0555 - accuracy: 0.0068\n",
            "Epoch 43/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0554 - accuracy: 0.0068\n",
            "Epoch 44/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0553 - accuracy: 0.0068\n",
            "Epoch 45/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0552 - accuracy: 0.0068\n",
            "Epoch 46/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0551 - accuracy: 0.0068\n",
            "Epoch 47/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0551 - accuracy: 0.0068\n",
            "Epoch 48/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0550 - accuracy: 0.0068\n",
            "Epoch 49/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0549 - accuracy: 0.0068\n",
            "Epoch 50/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0548 - accuracy: 0.0068\n",
            "Epoch 51/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0548 - accuracy: 0.0068\n",
            "Epoch 52/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0547 - accuracy: 0.0068\n",
            "Epoch 53/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0546 - accuracy: 0.0068\n",
            "Epoch 54/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0545 - accuracy: 0.0068\n",
            "Epoch 55/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0545 - accuracy: 0.0068\n",
            "Epoch 56/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0544 - accuracy: 0.0068\n",
            "Epoch 57/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0544 - accuracy: 0.0068\n",
            "Epoch 58/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0543 - accuracy: 0.0068\n",
            "Epoch 59/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0542 - accuracy: 0.0068\n",
            "Epoch 60/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0542 - accuracy: 0.0068\n",
            "Epoch 61/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0541 - accuracy: 0.0068\n",
            "Epoch 62/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0541 - accuracy: 0.0068\n",
            "Epoch 63/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0541 - accuracy: 0.0068\n",
            "Epoch 64/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0540 - accuracy: 0.0068\n",
            "Epoch 65/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0540 - accuracy: 0.0068\n",
            "Epoch 66/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0539 - accuracy: 0.0068\n",
            "Epoch 67/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0539 - accuracy: 0.0068\n",
            "Epoch 68/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0538 - accuracy: 0.0068\n",
            "Epoch 69/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0538 - accuracy: 0.0068\n",
            "Epoch 70/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0538 - accuracy: 0.0068\n",
            "Epoch 71/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0537 - accuracy: 0.0068\n",
            "Epoch 72/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0537 - accuracy: 0.0068\n",
            "Epoch 73/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0537 - accuracy: 0.0068\n",
            "Epoch 74/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0536 - accuracy: 0.0068\n",
            "Epoch 75/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0536 - accuracy: 0.0068\n",
            "Epoch 76/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0536 - accuracy: 0.0068\n",
            "Epoch 77/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0535 - accuracy: 0.0068\n",
            "Epoch 78/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0535 - accuracy: 0.0068\n",
            "Epoch 79/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0535 - accuracy: 0.0068\n",
            "Epoch 80/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0535 - accuracy: 0.0068\n",
            "Epoch 81/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0534 - accuracy: 0.0068\n",
            "Epoch 82/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0534 - accuracy: 0.0068\n",
            "Epoch 83/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0534 - accuracy: 0.0068\n",
            "Epoch 84/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0534 - accuracy: 0.0068\n",
            "Epoch 85/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0534 - accuracy: 0.0068\n",
            "Epoch 86/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0533 - accuracy: 0.0068\n",
            "Epoch 87/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0533 - accuracy: 0.0068\n",
            "Epoch 88/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0533 - accuracy: 0.0068\n",
            "Epoch 89/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0533 - accuracy: 0.0068\n",
            "Epoch 90/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0533 - accuracy: 0.0068\n",
            "Epoch 91/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0532 - accuracy: 0.0068\n",
            "Epoch 92/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0532 - accuracy: 0.0068\n",
            "Epoch 93/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0532 - accuracy: 0.0068\n",
            "Epoch 94/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0532 - accuracy: 0.0068\n",
            "Epoch 95/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0532 - accuracy: 0.0068\n",
            "Epoch 96/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0532 - accuracy: 0.0068\n",
            "Epoch 97/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0532 - accuracy: 0.0068\n",
            "Epoch 98/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0531 - accuracy: 0.0068\n",
            "Epoch 99/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0531 - accuracy: 0.0068\n",
            "Epoch 100/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0531 - accuracy: 0.0068\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0697 - accuracy: 0.0068\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0694 - accuracy: 0.0068\n",
            "Epoch 3/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0692 - accuracy: 0.0068\n",
            "Epoch 4/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0689 - accuracy: 0.0068\n",
            "Epoch 5/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0686 - accuracy: 0.0068\n",
            "Epoch 6/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0684 - accuracy: 0.0068\n",
            "Epoch 7/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0681 - accuracy: 0.0068\n",
            "Epoch 8/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0679 - accuracy: 0.0068\n",
            "Epoch 9/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0677 - accuracy: 0.0068\n",
            "Epoch 10/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0675 - accuracy: 0.0068\n",
            "Epoch 11/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0673 - accuracy: 0.0068\n",
            "Epoch 12/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0671 - accuracy: 0.0068\n",
            "Epoch 13/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0669 - accuracy: 0.0068\n",
            "Epoch 14/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0667 - accuracy: 0.0068\n",
            "Epoch 15/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0665 - accuracy: 0.0068\n",
            "Epoch 16/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0664 - accuracy: 0.0068\n",
            "Epoch 17/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0662 - accuracy: 0.0068\n",
            "Epoch 18/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0660 - accuracy: 0.0068\n",
            "Epoch 19/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0659 - accuracy: 0.0068\n",
            "Epoch 20/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0657 - accuracy: 0.0068\n",
            "Epoch 21/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0656 - accuracy: 0.0068\n",
            "Epoch 22/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0654 - accuracy: 0.0068\n",
            "Epoch 23/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0653 - accuracy: 0.0068\n",
            "Epoch 24/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0652 - accuracy: 0.0068\n",
            "Epoch 25/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0651 - accuracy: 0.0068\n",
            "Epoch 26/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 27/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0648 - accuracy: 0.0068\n",
            "Epoch 28/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 29/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0646 - accuracy: 0.0068\n",
            "Epoch 30/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0645 - accuracy: 0.0068\n",
            "Epoch 31/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0644 - accuracy: 0.0068\n",
            "Epoch 32/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0643 - accuracy: 0.0068\n",
            "Epoch 33/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0642 - accuracy: 0.0068\n",
            "Epoch 34/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0641 - accuracy: 0.0068\n",
            "Epoch 35/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0641 - accuracy: 0.0068\n",
            "Epoch 36/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0640 - accuracy: 0.0068\n",
            "Epoch 37/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0639 - accuracy: 0.0068\n",
            "Epoch 38/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0638 - accuracy: 0.0068\n",
            "Epoch 39/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0637 - accuracy: 0.0068\n",
            "Epoch 40/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0637 - accuracy: 0.0068\n",
            "Epoch 41/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0636 - accuracy: 0.0068\n",
            "Epoch 42/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0635 - accuracy: 0.0068\n",
            "Epoch 43/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0635 - accuracy: 0.0068\n",
            "Epoch 44/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0634 - accuracy: 0.0068\n",
            "Epoch 45/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0634 - accuracy: 0.0068\n",
            "Epoch 46/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0633 - accuracy: 0.0068\n",
            "Epoch 47/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0632 - accuracy: 0.0068\n",
            "Epoch 48/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0632 - accuracy: 0.0068\n",
            "Epoch 49/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0632 - accuracy: 0.0068\n",
            "Epoch 50/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0631 - accuracy: 0.0068\n",
            "Epoch 51/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0631 - accuracy: 0.0068\n",
            "Epoch 52/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0630 - accuracy: 0.0068\n",
            "Epoch 53/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0630 - accuracy: 0.0068\n",
            "Epoch 54/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0629 - accuracy: 0.0068\n",
            "Epoch 55/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0629 - accuracy: 0.0068\n",
            "Epoch 56/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0629 - accuracy: 0.0068\n",
            "Epoch 57/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0628 - accuracy: 0.0068\n",
            "Epoch 58/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0628 - accuracy: 0.0068\n",
            "Epoch 59/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0627 - accuracy: 0.0068\n",
            "Epoch 60/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0627 - accuracy: 0.0068\n",
            "Epoch 61/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0627 - accuracy: 0.0068\n",
            "Epoch 62/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0627 - accuracy: 0.0068\n",
            "Epoch 63/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0626 - accuracy: 0.0068\n",
            "Epoch 64/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0626 - accuracy: 0.0068\n",
            "Epoch 65/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0626 - accuracy: 0.0068\n",
            "Epoch 66/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0625 - accuracy: 0.0068\n",
            "Epoch 67/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0625 - accuracy: 0.0068\n",
            "Epoch 68/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0625 - accuracy: 0.0068\n",
            "Epoch 69/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0625 - accuracy: 0.0068\n",
            "Epoch 70/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0625 - accuracy: 0.0068\n",
            "Epoch 71/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0624 - accuracy: 0.0068\n",
            "Epoch 72/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0624 - accuracy: 0.0068\n",
            "Epoch 73/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0624 - accuracy: 0.0068\n",
            "Epoch 74/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0624 - accuracy: 0.0068\n",
            "Epoch 75/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0623 - accuracy: 0.0068\n",
            "Epoch 76/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0623 - accuracy: 0.0068\n",
            "Epoch 77/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0623 - accuracy: 0.0068\n",
            "Epoch 78/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0623 - accuracy: 0.0068\n",
            "Epoch 79/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0623 - accuracy: 0.0068\n",
            "Epoch 80/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0623 - accuracy: 0.0068\n",
            "Epoch 81/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0622 - accuracy: 0.0068\n",
            "Epoch 82/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0622 - accuracy: 0.0068\n",
            "Epoch 83/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0622 - accuracy: 0.0068\n",
            "Epoch 84/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0622 - accuracy: 0.0068\n",
            "Epoch 85/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0622 - accuracy: 0.0068\n",
            "Epoch 86/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0622 - accuracy: 0.0068\n",
            "Epoch 87/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0622 - accuracy: 0.0068\n",
            "Epoch 88/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0621 - accuracy: 0.0068\n",
            "Epoch 89/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0621 - accuracy: 0.0068\n",
            "Epoch 90/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0621 - accuracy: 0.0068\n",
            "Epoch 91/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0621 - accuracy: 0.0068\n",
            "Epoch 92/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0621 - accuracy: 0.0068\n",
            "Epoch 93/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0621 - accuracy: 0.0068\n",
            "Epoch 94/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0621 - accuracy: 0.0068\n",
            "Epoch 95/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0621 - accuracy: 0.0068\n",
            "Epoch 96/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0621 - accuracy: 0.0068\n",
            "Epoch 97/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0621 - accuracy: 0.0068\n",
            "Epoch 98/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0621 - accuracy: 0.0068\n",
            "Epoch 99/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0620 - accuracy: 0.0068\n",
            "Epoch 100/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0620 - accuracy: 0.0068\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0709 - accuracy: 0.0338\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0704 - accuracy: 0.0068\n",
            "Epoch 3/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0699 - accuracy: 0.0068\n",
            "Epoch 4/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0694 - accuracy: 0.0068\n",
            "Epoch 5/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0690 - accuracy: 0.0068\n",
            "Epoch 6/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0685 - accuracy: 0.0068\n",
            "Epoch 7/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0681 - accuracy: 0.0068\n",
            "Epoch 8/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0677 - accuracy: 0.0068\n",
            "Epoch 9/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0673 - accuracy: 0.0068\n",
            "Epoch 10/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0669 - accuracy: 0.0068\n",
            "Epoch 11/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0665 - accuracy: 0.0068\n",
            "Epoch 12/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0662 - accuracy: 0.0068\n",
            "Epoch 13/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0659 - accuracy: 0.0068\n",
            "Epoch 14/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0655 - accuracy: 0.0068\n",
            "Epoch 15/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0652 - accuracy: 0.0068\n",
            "Epoch 16/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 17/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0646 - accuracy: 0.0068\n",
            "Epoch 18/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0644 - accuracy: 0.0068\n",
            "Epoch 19/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0641 - accuracy: 0.0068\n",
            "Epoch 20/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0638 - accuracy: 0.0068\n",
            "Epoch 21/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0636 - accuracy: 0.0068\n",
            "Epoch 22/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0633 - accuracy: 0.0068\n",
            "Epoch 23/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0631 - accuracy: 0.0068\n",
            "Epoch 24/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0629 - accuracy: 0.0068\n",
            "Epoch 25/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0627 - accuracy: 0.0068\n",
            "Epoch 26/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0625 - accuracy: 0.0068\n",
            "Epoch 27/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0623 - accuracy: 0.0068\n",
            "Epoch 28/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0621 - accuracy: 0.0068\n",
            "Epoch 29/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0619 - accuracy: 0.0068\n",
            "Epoch 30/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0617 - accuracy: 0.0068\n",
            "Epoch 31/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0616 - accuracy: 0.0068\n",
            "Epoch 32/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0614 - accuracy: 0.0068\n",
            "Epoch 33/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0612 - accuracy: 0.0068\n",
            "Epoch 34/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0611 - accuracy: 0.0068\n",
            "Epoch 35/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0609 - accuracy: 0.0068\n",
            "Epoch 36/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0608 - accuracy: 0.0068\n",
            "Epoch 37/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0607 - accuracy: 0.0068\n",
            "Epoch 38/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0605 - accuracy: 0.0068\n",
            "Epoch 39/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0604 - accuracy: 0.0068\n",
            "Epoch 40/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0603 - accuracy: 0.0068\n",
            "Epoch 41/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0602 - accuracy: 0.0068\n",
            "Epoch 42/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0601 - accuracy: 0.0068\n",
            "Epoch 43/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0600 - accuracy: 0.0068\n",
            "Epoch 44/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0598 - accuracy: 0.0068\n",
            "Epoch 45/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0598 - accuracy: 0.0068\n",
            "Epoch 46/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0597 - accuracy: 0.0068\n",
            "Epoch 47/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0596 - accuracy: 0.0068\n",
            "Epoch 48/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0595 - accuracy: 0.0068\n",
            "Epoch 49/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0594 - accuracy: 0.0068\n",
            "Epoch 50/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0593 - accuracy: 0.0068\n",
            "Epoch 51/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0592 - accuracy: 0.0068\n",
            "Epoch 52/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0592 - accuracy: 0.0068\n",
            "Epoch 53/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0591 - accuracy: 0.0068\n",
            "Epoch 54/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0590 - accuracy: 0.0068\n",
            "Epoch 55/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0589 - accuracy: 0.0068\n",
            "Epoch 56/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0589 - accuracy: 0.0068\n",
            "Epoch 57/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0588 - accuracy: 0.0068\n",
            "Epoch 58/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0587 - accuracy: 0.0068\n",
            "Epoch 59/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0587 - accuracy: 0.0068\n",
            "Epoch 60/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0586 - accuracy: 0.0068\n",
            "Epoch 61/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0586 - accuracy: 0.0068\n",
            "Epoch 62/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0585 - accuracy: 0.0068\n",
            "Epoch 63/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0585 - accuracy: 0.0068\n",
            "Epoch 64/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0584 - accuracy: 0.0068\n",
            "Epoch 65/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0584 - accuracy: 0.0068\n",
            "Epoch 66/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0583 - accuracy: 0.0068\n",
            "Epoch 67/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0583 - accuracy: 0.0068\n",
            "Epoch 68/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0582 - accuracy: 0.0068\n",
            "Epoch 69/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0582 - accuracy: 0.0068\n",
            "Epoch 70/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0581 - accuracy: 0.0068\n",
            "Epoch 71/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0581 - accuracy: 0.0068\n",
            "Epoch 72/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0581 - accuracy: 0.0068\n",
            "Epoch 73/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0580 - accuracy: 0.0068\n",
            "Epoch 74/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0580 - accuracy: 0.0068\n",
            "Epoch 75/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0580 - accuracy: 0.0068\n",
            "Epoch 76/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0579 - accuracy: 0.0068\n",
            "Epoch 77/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0579 - accuracy: 0.0068\n",
            "Epoch 78/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0579 - accuracy: 0.0068\n",
            "Epoch 79/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0578 - accuracy: 0.0068\n",
            "Epoch 80/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0578 - accuracy: 0.0068\n",
            "Epoch 81/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0578 - accuracy: 0.0068\n",
            "Epoch 82/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0578 - accuracy: 0.0068\n",
            "Epoch 83/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0577 - accuracy: 0.0068\n",
            "Epoch 84/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0577 - accuracy: 0.0068\n",
            "Epoch 85/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0577 - accuracy: 0.0068\n",
            "Epoch 86/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0577 - accuracy: 0.0068\n",
            "Epoch 87/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0576 - accuracy: 0.0068\n",
            "Epoch 88/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0576 - accuracy: 0.0068\n",
            "Epoch 89/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0576 - accuracy: 0.0068\n",
            "Epoch 90/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0576 - accuracy: 0.0068\n",
            "Epoch 91/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0576 - accuracy: 0.0068\n",
            "Epoch 92/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0576 - accuracy: 0.0068\n",
            "Epoch 93/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0575 - accuracy: 0.0068\n",
            "Epoch 94/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0575 - accuracy: 0.0068\n",
            "Epoch 95/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0575 - accuracy: 0.0068\n",
            "Epoch 96/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0575 - accuracy: 0.0068\n",
            "Epoch 97/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0575 - accuracy: 0.0068\n",
            "Epoch 98/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0574 - accuracy: 0.0068\n",
            "Epoch 99/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0574 - accuracy: 0.0068\n",
            "Epoch 100/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0574 - accuracy: 0.0068\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0717 - accuracy: 0.0068\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0715 - accuracy: 0.0068\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0714 - accuracy: 0.0068\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0712 - accuracy: 0.0068\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0710 - accuracy: 0.0068\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0708 - accuracy: 0.0068\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0706 - accuracy: 0.0068\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0704 - accuracy: 0.0068\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0703 - accuracy: 0.0068\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0700 - accuracy: 0.0068\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0699 - accuracy: 0.0068\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0697 - accuracy: 0.0068\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0694 - accuracy: 0.0068\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0692 - accuracy: 0.0068\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0690 - accuracy: 0.0068\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0688 - accuracy: 0.0068\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0685 - accuracy: 0.0068\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0683 - accuracy: 0.0068\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0680 - accuracy: 0.0068\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0677 - accuracy: 0.0068\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0674 - accuracy: 0.0068\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0671 - accuracy: 0.0068\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0668 - accuracy: 0.0068\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0664 - accuracy: 0.0068\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0661 - accuracy: 0.0068\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0657 - accuracy: 0.0068\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0653 - accuracy: 0.0068\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0644 - accuracy: 0.0068\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0640 - accuracy: 0.0068\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0635 - accuracy: 0.0068\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0631 - accuracy: 0.0068\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0626 - accuracy: 0.0068\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0621 - accuracy: 0.0068\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0616 - accuracy: 0.0068\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0611 - accuracy: 0.0068\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0605 - accuracy: 0.0068\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0600 - accuracy: 0.0068\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0595 - accuracy: 0.0068\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0589 - accuracy: 0.0068\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0584 - accuracy: 0.0068\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0579 - accuracy: 0.0068\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0573 - accuracy: 0.0068\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0568 - accuracy: 0.0068\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0563 - accuracy: 0.0068\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0557 - accuracy: 0.0068\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0552 - accuracy: 0.0068\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0547 - accuracy: 0.0068\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0542 - accuracy: 0.0068\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0536 - accuracy: 0.0068\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 1s 5ms/step - loss: 0.0721 - accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0718 - accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0716 - accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0714 - accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0712 - accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0710 - accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0708 - accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0706 - accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0703 - accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0702 - accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0700 - accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0698 - accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0696 - accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0695 - accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0693 - accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0691 - accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0690 - accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0688 - accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0686 - accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0684 - accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0683 - accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0682 - accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0680 - accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0679 - accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0677 - accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0676 - accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0675 - accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0673 - accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0672 - accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0671 - accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0670 - accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0668 - accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0667 - accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0666 - accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0665 - accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0664 - accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0663 - accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0662 - accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0661 - accuracy: 0.0000e+00\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0660 - accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0658 - accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0658 - accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0657 - accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0656 - accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0655 - accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0654 - accuracy: 0.0000e+00\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0653 - accuracy: 0.0000e+00\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0652 - accuracy: 0.0000e+00\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0652 - accuracy: 0.0000e+00\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0651 - accuracy: 0.0000e+00\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0655 - accuracy: 0.0204\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0652 - accuracy: 0.0068\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0650 - accuracy: 0.0068\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0646 - accuracy: 0.0068\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0644 - accuracy: 0.0068\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0641 - accuracy: 0.0068\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0638 - accuracy: 0.0068\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0635 - accuracy: 0.0068\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0632 - accuracy: 0.0068\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0629 - accuracy: 0.0068\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0625 - accuracy: 0.0068\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0622 - accuracy: 0.0068\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0619 - accuracy: 0.0068\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0615 - accuracy: 0.0068\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0612 - accuracy: 0.0068\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0608 - accuracy: 0.0068\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0604 - accuracy: 0.0068\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0600 - accuracy: 0.0068\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0596 - accuracy: 0.0068\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0592 - accuracy: 0.0068\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0588 - accuracy: 0.0068\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0583 - accuracy: 0.0068\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0578 - accuracy: 0.0068\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0573 - accuracy: 0.0068\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0568 - accuracy: 0.0068\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0562 - accuracy: 0.0068\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0557 - accuracy: 0.0068\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0551 - accuracy: 0.0068\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0545 - accuracy: 0.0068\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0539 - accuracy: 0.0068\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0532 - accuracy: 0.0068\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0526 - accuracy: 0.0068\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0519 - accuracy: 0.0068\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0511 - accuracy: 0.0068\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0504 - accuracy: 0.0068\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0496 - accuracy: 0.0068\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0487 - accuracy: 0.0068\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0479 - accuracy: 0.0068\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0471 - accuracy: 0.0068\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0461 - accuracy: 0.0204\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0452 - accuracy: 0.0408\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0442 - accuracy: 0.0476\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0431 - accuracy: 0.0476\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0422 - accuracy: 0.0476\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0411 - accuracy: 0.0476\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0399 - accuracy: 0.0476\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0388 - accuracy: 0.0476\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0377 - accuracy: 0.0476\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0366 - accuracy: 0.0476\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0354 - accuracy: 0.0476\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 1s 7ms/step - loss: 0.0698 - accuracy: 0.0068\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0695 - accuracy: 0.0068\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0693 - accuracy: 0.0068\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0690 - accuracy: 0.0068\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0688 - accuracy: 0.0068\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0685 - accuracy: 0.0068\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0683 - accuracy: 0.0068\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0680 - accuracy: 0.0068\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0677 - accuracy: 0.0068\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0674 - accuracy: 0.0068\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0671 - accuracy: 0.0068\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0668 - accuracy: 0.0068\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0664 - accuracy: 0.0068\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0660 - accuracy: 0.0068\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0656 - accuracy: 0.0068\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0653 - accuracy: 0.0068\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0648 - accuracy: 0.0068\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0643 - accuracy: 0.0068\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0639 - accuracy: 0.0068\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0633 - accuracy: 0.0068\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0628 - accuracy: 0.0068\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0623 - accuracy: 0.0068\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0617 - accuracy: 0.0068\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0611 - accuracy: 0.0068\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0605 - accuracy: 0.0068\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0598 - accuracy: 0.0068\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0591 - accuracy: 0.0068\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0584 - accuracy: 0.0068\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0577 - accuracy: 0.0068\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0570 - accuracy: 0.0068\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0563 - accuracy: 0.0068\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0555 - accuracy: 0.0068\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0547 - accuracy: 0.0068\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0539 - accuracy: 0.0068\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0532 - accuracy: 0.0068\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0524 - accuracy: 0.0068\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0516 - accuracy: 0.0068\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0508 - accuracy: 0.0068\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0500 - accuracy: 0.0068\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0493 - accuracy: 0.0068\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0487 - accuracy: 0.0068\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0480 - accuracy: 0.0068\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0474 - accuracy: 0.0068\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0467 - accuracy: 0.0068\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0461 - accuracy: 0.0068\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0456 - accuracy: 0.0068\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0451 - accuracy: 0.0068\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0446 - accuracy: 0.0068\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0441 - accuracy: 0.0068\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0436 - accuracy: 0.0068\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0710 - accuracy: 0.0068\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0707 - accuracy: 0.0068\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0704 - accuracy: 0.0068\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0701 - accuracy: 0.0068\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0697 - accuracy: 0.0068\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0694 - accuracy: 0.0068\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0690 - accuracy: 0.0068\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0685 - accuracy: 0.0068\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0681 - accuracy: 0.0068\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0676 - accuracy: 0.0068\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0671 - accuracy: 0.0068\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0666 - accuracy: 0.0068\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0660 - accuracy: 0.0068\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0654 - accuracy: 0.0068\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0640 - accuracy: 0.0068\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0632 - accuracy: 0.0068\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0625 - accuracy: 0.0068\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0617 - accuracy: 0.0068\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0608 - accuracy: 0.0068\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0601 - accuracy: 0.0068\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0590 - accuracy: 0.0068\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0582 - accuracy: 0.0068\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0572 - accuracy: 0.0068\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0563 - accuracy: 0.0068\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0553 - accuracy: 0.0068\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0543 - accuracy: 0.0068\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0534 - accuracy: 0.0068\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0524 - accuracy: 0.0068\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0513 - accuracy: 0.0068\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0504 - accuracy: 0.0068\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0494 - accuracy: 0.0068\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0483 - accuracy: 0.0068\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0474 - accuracy: 0.0068\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0463 - accuracy: 0.0068\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0453 - accuracy: 0.0068\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0443 - accuracy: 0.0068\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0434 - accuracy: 0.0068\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0425 - accuracy: 0.0068\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0418 - accuracy: 0.0068\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0411 - accuracy: 0.0068\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0404 - accuracy: 0.0068\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0397 - accuracy: 0.0068\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0391 - accuracy: 0.0068\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0386 - accuracy: 0.0068\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0382 - accuracy: 0.0068\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0378 - accuracy: 0.0068\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0373 - accuracy: 0.0068\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0370 - accuracy: 0.0068\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0366 - accuracy: 0.0068\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0718 - accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0717 - accuracy: 0.0068\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0716 - accuracy: 0.0068\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0715 - accuracy: 0.0068\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0714 - accuracy: 0.0068\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0713 - accuracy: 0.0068\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0712 - accuracy: 0.0068\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0711 - accuracy: 0.0068\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0711 - accuracy: 0.0068\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0710 - accuracy: 0.0068\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0709 - accuracy: 0.0068\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0708 - accuracy: 0.0068\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0707 - accuracy: 0.0068\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0707 - accuracy: 0.0068\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0706 - accuracy: 0.0068\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0705 - accuracy: 0.0068\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0704 - accuracy: 0.0068\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0704 - accuracy: 0.0068\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0703 - accuracy: 0.0068\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0702 - accuracy: 0.0068\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0701 - accuracy: 0.0068\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0701 - accuracy: 0.0068\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0700 - accuracy: 0.0068\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0699 - accuracy: 0.0068\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0699 - accuracy: 0.0068\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0698 - accuracy: 0.0068\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0697 - accuracy: 0.0068\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0697 - accuracy: 0.0068\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0696 - accuracy: 0.0068\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0695 - accuracy: 0.0068\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0695 - accuracy: 0.0068\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0694 - accuracy: 0.0068\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0693 - accuracy: 0.0068\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0693 - accuracy: 0.0068\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0692 - accuracy: 0.0068\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0692 - accuracy: 0.0068\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0691 - accuracy: 0.0068\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0690 - accuracy: 0.0068\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0690 - accuracy: 0.0068\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0689 - accuracy: 0.0068\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0689 - accuracy: 0.0068\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0688 - accuracy: 0.0068\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0688 - accuracy: 0.0068\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0687 - accuracy: 0.0068\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0687 - accuracy: 0.0068\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0686 - accuracy: 0.0068\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0686 - accuracy: 0.0068\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0685 - accuracy: 0.0068\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0685 - accuracy: 0.0068\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0684 - accuracy: 0.0068\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0721 - accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0720 - accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0719 - accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0718 - accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0717 - accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0715 - accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0714 - accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0713 - accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0712 - accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0711 - accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0710 - accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0709 - accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0708 - accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0707 - accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0706 - accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0705 - accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0704 - accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0703 - accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0702 - accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0701 - accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0700 - accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0699 - accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0698 - accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0697 - accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0696 - accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0695 - accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0695 - accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0694 - accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0693 - accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0692 - accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0691 - accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0690 - accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0690 - accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0689 - accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0688 - accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0687 - accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0687 - accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0686 - accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0685 - accuracy: 0.0000e+00\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0684 - accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0684 - accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0683 - accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0682 - accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0681 - accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0681 - accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0680 - accuracy: 0.0000e+00\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0679 - accuracy: 0.0000e+00\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0679 - accuracy: 0.0000e+00\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0678 - accuracy: 0.0000e+00\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0677 - accuracy: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0655 - accuracy: 0.0068\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0654 - accuracy: 0.0068\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0652 - accuracy: 0.0068\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0651 - accuracy: 0.0068\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0648 - accuracy: 0.0068\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0646 - accuracy: 0.0068\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0645 - accuracy: 0.0068\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0643 - accuracy: 0.0068\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0642 - accuracy: 0.0068\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0640 - accuracy: 0.0068\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0639 - accuracy: 0.0068\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0638 - accuracy: 0.0068\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0636 - accuracy: 0.0068\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0635 - accuracy: 0.0068\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0634 - accuracy: 0.0068\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0632 - accuracy: 0.0068\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0631 - accuracy: 0.0068\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0630 - accuracy: 0.0068\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0628 - accuracy: 0.0068\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0627 - accuracy: 0.0068\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0626 - accuracy: 0.0068\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0625 - accuracy: 0.0068\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0624 - accuracy: 0.0068\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0622 - accuracy: 0.0068\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0621 - accuracy: 0.0068\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0620 - accuracy: 0.0068\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0619 - accuracy: 0.0068\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0618 - accuracy: 0.0068\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0617 - accuracy: 0.0068\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0615 - accuracy: 0.0068\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0614 - accuracy: 0.0068\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0613 - accuracy: 0.0068\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0612 - accuracy: 0.0068\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0611 - accuracy: 0.0068\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0610 - accuracy: 0.0068\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0609 - accuracy: 0.0068\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0608 - accuracy: 0.0068\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0607 - accuracy: 0.0068\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0606 - accuracy: 0.0068\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0605 - accuracy: 0.0068\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0604 - accuracy: 0.0068\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0603 - accuracy: 0.0068\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0602 - accuracy: 0.0068\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0601 - accuracy: 0.0068\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0600 - accuracy: 0.0068\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0600 - accuracy: 0.0068\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0599 - accuracy: 0.0068\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0598 - accuracy: 0.0068\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0597 - accuracy: 0.0068\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0698 - accuracy: 0.0136\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0697 - accuracy: 0.0068\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0696 - accuracy: 0.0068\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0695 - accuracy: 0.0068\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0694 - accuracy: 0.0068\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0693 - accuracy: 0.0068\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0692 - accuracy: 0.0068\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0692 - accuracy: 0.0068\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0691 - accuracy: 0.0068\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0690 - accuracy: 0.0068\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0689 - accuracy: 0.0068\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0688 - accuracy: 0.0068\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0687 - accuracy: 0.0068\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0686 - accuracy: 0.0068\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0685 - accuracy: 0.0068\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0684 - accuracy: 0.0068\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0684 - accuracy: 0.0068\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0683 - accuracy: 0.0068\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0682 - accuracy: 0.0068\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0681 - accuracy: 0.0068\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0680 - accuracy: 0.0068\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0680 - accuracy: 0.0068\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0679 - accuracy: 0.0068\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0678 - accuracy: 0.0068\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0677 - accuracy: 0.0068\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0677 - accuracy: 0.0068\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0676 - accuracy: 0.0068\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0675 - accuracy: 0.0068\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0675 - accuracy: 0.0068\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0674 - accuracy: 0.0068\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0673 - accuracy: 0.0068\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0672 - accuracy: 0.0068\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0672 - accuracy: 0.0068\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0671 - accuracy: 0.0068\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0670 - accuracy: 0.0068\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0670 - accuracy: 0.0068\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0669 - accuracy: 0.0068\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0669 - accuracy: 0.0068\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0668 - accuracy: 0.0068\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0667 - accuracy: 0.0068\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0667 - accuracy: 0.0068\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0666 - accuracy: 0.0068\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0666 - accuracy: 0.0068\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0665 - accuracy: 0.0068\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0664 - accuracy: 0.0068\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0664 - accuracy: 0.0068\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0663 - accuracy: 0.0068\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0663 - accuracy: 0.0068\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0662 - accuracy: 0.0068\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0662 - accuracy: 0.0068\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0711 - accuracy: 0.0068\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0709 - accuracy: 0.0068\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0707 - accuracy: 0.0068\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0705 - accuracy: 0.0068\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0704 - accuracy: 0.0068\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0702 - accuracy: 0.0068\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0700 - accuracy: 0.0068\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0699 - accuracy: 0.0068\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0697 - accuracy: 0.0068\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0696 - accuracy: 0.0068\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0694 - accuracy: 0.0068\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0693 - accuracy: 0.0068\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0691 - accuracy: 0.0068\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0689 - accuracy: 0.0068\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0688 - accuracy: 0.0068\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0687 - accuracy: 0.0068\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0685 - accuracy: 0.0068\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0684 - accuracy: 0.0068\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0682 - accuracy: 0.0068\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0681 - accuracy: 0.0068\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0679 - accuracy: 0.0068\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0678 - accuracy: 0.0068\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0677 - accuracy: 0.0068\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0675 - accuracy: 0.0068\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0674 - accuracy: 0.0068\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0673 - accuracy: 0.0068\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0672 - accuracy: 0.0068\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0670 - accuracy: 0.0068\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0669 - accuracy: 0.0068\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0668 - accuracy: 0.0068\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0667 - accuracy: 0.0068\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0665 - accuracy: 0.0068\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0664 - accuracy: 0.0068\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0663 - accuracy: 0.0068\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0662 - accuracy: 0.0068\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0661 - accuracy: 0.0068\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0660 - accuracy: 0.0068\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0659 - accuracy: 0.0068\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0658 - accuracy: 0.0068\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0656 - accuracy: 0.0068\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0655 - accuracy: 0.0068\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0654 - accuracy: 0.0068\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0653 - accuracy: 0.0068\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0652 - accuracy: 0.0068\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0651 - accuracy: 0.0068\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0650 - accuracy: 0.0068\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0648 - accuracy: 0.0068\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0646 - accuracy: 0.0068\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 1s 6ms/step - loss: 0.0717 - accuracy: 0.0068\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0715 - accuracy: 0.0068\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0713 - accuracy: 0.0068\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0711 - accuracy: 0.0068\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0709 - accuracy: 0.0068\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0706 - accuracy: 0.0068\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0704 - accuracy: 0.0068\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0702 - accuracy: 0.0068\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0699 - accuracy: 0.0068\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0696 - accuracy: 0.0068\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0693 - accuracy: 0.0068\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0690 - accuracy: 0.0068\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0687 - accuracy: 0.0068\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0683 - accuracy: 0.0068\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0679 - accuracy: 0.0068\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0674 - accuracy: 0.0068\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0669 - accuracy: 0.0068\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0664 - accuracy: 0.0068\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0658 - accuracy: 0.0068\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0652 - accuracy: 0.0068\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0645 - accuracy: 0.0068\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0637 - accuracy: 0.0068\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0629 - accuracy: 0.0068\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0620 - accuracy: 0.0068\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0611 - accuracy: 0.0068\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0601 - accuracy: 0.0068\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0591 - accuracy: 0.0068\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0580 - accuracy: 0.0068\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0570 - accuracy: 0.0068\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0559 - accuracy: 0.0068\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0547 - accuracy: 0.0068\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0536 - accuracy: 0.0068\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0525 - accuracy: 0.0068\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0513 - accuracy: 0.0340\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0501 - accuracy: 0.0408\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0489 - accuracy: 0.0476\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0476 - accuracy: 0.0476\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0465 - accuracy: 0.0476\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0452 - accuracy: 0.0476\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0441 - accuracy: 0.0476\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0428 - accuracy: 0.0476\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0417 - accuracy: 0.0476\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0405 - accuracy: 0.0476\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0394 - accuracy: 0.0476\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0382 - accuracy: 0.0476\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0372 - accuracy: 0.0476\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0360 - accuracy: 0.0476\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0349 - accuracy: 0.0476\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0338 - accuracy: 0.0476\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0327 - accuracy: 0.0476\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0721 - accuracy: 0.0068\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0718 - accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0716 - accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0714 - accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0712 - accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0710 - accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0707 - accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0705 - accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0703 - accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0700 - accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0698 - accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0695 - accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0693 - accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0690 - accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0688 - accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0684 - accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0681 - accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0678 - accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0675 - accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0671 - accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0668 - accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0664 - accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0660 - accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0655 - accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0650 - accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0645 - accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0640 - accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0635 - accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0629 - accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0622 - accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0616 - accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0609 - accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0601 - accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0593 - accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0585 - accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0576 - accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0567 - accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0556 - accuracy: 0.0340\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0546 - accuracy: 0.0340\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0536 - accuracy: 0.0340\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0525 - accuracy: 0.0340\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0513 - accuracy: 0.0340\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0501 - accuracy: 0.0340\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0489 - accuracy: 0.0340\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0477 - accuracy: 0.0340\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0464 - accuracy: 0.0340\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0450 - accuracy: 0.0340\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0437 - accuracy: 0.0340\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0425 - accuracy: 0.0340\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0411 - accuracy: 0.0340\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 1s 4ms/step - loss: 0.0655 - accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0652 - accuracy: 0.0068\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0650 - accuracy: 0.0068\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0645 - accuracy: 0.0068\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0642 - accuracy: 0.0068\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0640 - accuracy: 0.0068\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0638 - accuracy: 0.0068\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0635 - accuracy: 0.0068\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0633 - accuracy: 0.0068\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0630 - accuracy: 0.0068\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0628 - accuracy: 0.0068\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0626 - accuracy: 0.0068\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0624 - accuracy: 0.0068\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0622 - accuracy: 0.0068\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0619 - accuracy: 0.0068\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0617 - accuracy: 0.0068\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0615 - accuracy: 0.0068\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0613 - accuracy: 0.0068\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0611 - accuracy: 0.0068\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0609 - accuracy: 0.0068\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0607 - accuracy: 0.0068\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0606 - accuracy: 0.0068\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0604 - accuracy: 0.0068\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0602 - accuracy: 0.0068\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0600 - accuracy: 0.0068\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0599 - accuracy: 0.0068\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0597 - accuracy: 0.0068\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0595 - accuracy: 0.0068\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0593 - accuracy: 0.0068\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0592 - accuracy: 0.0068\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0590 - accuracy: 0.0068\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0589 - accuracy: 0.0068\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0587 - accuracy: 0.0068\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0586 - accuracy: 0.0068\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0584 - accuracy: 0.0068\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0583 - accuracy: 0.0068\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0582 - accuracy: 0.0068\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0580 - accuracy: 0.0068\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0579 - accuracy: 0.0068\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0578 - accuracy: 0.0068\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0576 - accuracy: 0.0068\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0575 - accuracy: 0.0068\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0574 - accuracy: 0.0068\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0573 - accuracy: 0.0068\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0572 - accuracy: 0.0068\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0570 - accuracy: 0.0068\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0569 - accuracy: 0.0068\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0568 - accuracy: 0.0068\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0567 - accuracy: 0.0068\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "5/5 [==============================] - 1s 6ms/step - loss: 0.0698 - accuracy: 0.0068\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0696 - accuracy: 0.0068\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0694 - accuracy: 0.0068\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0691 - accuracy: 0.0068\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0689 - accuracy: 0.0068\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0687 - accuracy: 0.0068\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0685 - accuracy: 0.0068\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0683 - accuracy: 0.0068\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0681 - accuracy: 0.0068\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0679 - accuracy: 0.0068\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0677 - accuracy: 0.0068\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0675 - accuracy: 0.0068\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0673 - accuracy: 0.0068\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0670 - accuracy: 0.0068\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0668 - accuracy: 0.0068\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0665 - accuracy: 0.0068\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0663 - accuracy: 0.0068\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0660 - accuracy: 0.0068\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0657 - accuracy: 0.0068\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0654 - accuracy: 0.0068\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0650 - accuracy: 0.0068\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0646 - accuracy: 0.0068\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0642 - accuracy: 0.0068\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0637 - accuracy: 0.0068\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0633 - accuracy: 0.0068\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0629 - accuracy: 0.0068\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0624 - accuracy: 0.0068\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0619 - accuracy: 0.0068\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0613 - accuracy: 0.0068\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0607 - accuracy: 0.0068\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0601 - accuracy: 0.0068\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0596 - accuracy: 0.0068\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0590 - accuracy: 0.0068\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0583 - accuracy: 0.0068\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0576 - accuracy: 0.0068\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0570 - accuracy: 0.0068\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0562 - accuracy: 0.0068\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0555 - accuracy: 0.0068\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0547 - accuracy: 0.0068\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0540 - accuracy: 0.0068\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0532 - accuracy: 0.0068\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0524 - accuracy: 0.0068\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0516 - accuracy: 0.0068\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0507 - accuracy: 0.0068\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0498 - accuracy: 0.0068\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0488 - accuracy: 0.0068\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0479 - accuracy: 0.0068\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0469 - accuracy: 0.0068\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0459 - accuracy: 0.0068\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0450 - accuracy: 0.0068\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0710 - accuracy: 0.0270\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0707 - accuracy: 0.0068\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0704 - accuracy: 0.0068\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0701 - accuracy: 0.0068\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0698 - accuracy: 0.0068\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0696 - accuracy: 0.0068\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0693 - accuracy: 0.0068\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0690 - accuracy: 0.0068\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0687 - accuracy: 0.0068\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0683 - accuracy: 0.0068\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0680 - accuracy: 0.0068\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0677 - accuracy: 0.0068\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0674 - accuracy: 0.0068\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0670 - accuracy: 0.0068\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0666 - accuracy: 0.0068\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0662 - accuracy: 0.0068\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0659 - accuracy: 0.0068\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0655 - accuracy: 0.0068\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0650 - accuracy: 0.0068\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0646 - accuracy: 0.0068\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0642 - accuracy: 0.0068\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0637 - accuracy: 0.0068\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0632 - accuracy: 0.0068\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0628 - accuracy: 0.0068\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0623 - accuracy: 0.0068\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0617 - accuracy: 0.0068\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0612 - accuracy: 0.0068\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0607 - accuracy: 0.0068\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0601 - accuracy: 0.0068\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0595 - accuracy: 0.0068\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0589 - accuracy: 0.0068\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0582 - accuracy: 0.0068\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0576 - accuracy: 0.0068\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0569 - accuracy: 0.0068\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0561 - accuracy: 0.0068\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0554 - accuracy: 0.0068\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0546 - accuracy: 0.0068\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0537 - accuracy: 0.0068\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0528 - accuracy: 0.0068\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0518 - accuracy: 0.0068\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0509 - accuracy: 0.0068\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0499 - accuracy: 0.0068\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0490 - accuracy: 0.0068\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0479 - accuracy: 0.0068\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0469 - accuracy: 0.0068\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0459 - accuracy: 0.0068\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0448 - accuracy: 0.0270\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0437 - accuracy: 0.0405\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0427 - accuracy: 0.0405\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0416 - accuracy: 0.0405\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0718 - accuracy: 0.0068\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0717 - accuracy: 0.0068\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0716 - accuracy: 0.0068\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0715 - accuracy: 0.0068\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0714 - accuracy: 0.0068\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0713 - accuracy: 0.0068\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0712 - accuracy: 0.0068\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0711 - accuracy: 0.0068\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0711 - accuracy: 0.0068\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0710 - accuracy: 0.0068\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0709 - accuracy: 0.0068\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0708 - accuracy: 0.0068\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0707 - accuracy: 0.0068\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0707 - accuracy: 0.0068\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0706 - accuracy: 0.0068\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0705 - accuracy: 0.0068\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0704 - accuracy: 0.0068\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0704 - accuracy: 0.0068\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0703 - accuracy: 0.0068\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0702 - accuracy: 0.0068\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0701 - accuracy: 0.0068\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0701 - accuracy: 0.0068\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0700 - accuracy: 0.0068\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0699 - accuracy: 0.0068\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0699 - accuracy: 0.0068\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0698 - accuracy: 0.0068\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0697 - accuracy: 0.0068\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0697 - accuracy: 0.0068\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0696 - accuracy: 0.0068\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0695 - accuracy: 0.0068\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0695 - accuracy: 0.0068\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0694 - accuracy: 0.0068\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0693 - accuracy: 0.0068\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0693 - accuracy: 0.0068\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0692 - accuracy: 0.0068\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0692 - accuracy: 0.0068\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0691 - accuracy: 0.0068\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0690 - accuracy: 0.0068\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0690 - accuracy: 0.0068\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0689 - accuracy: 0.0068\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0689 - accuracy: 0.0068\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0688 - accuracy: 0.0068\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0688 - accuracy: 0.0068\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0687 - accuracy: 0.0068\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0687 - accuracy: 0.0068\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0686 - accuracy: 0.0068\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0686 - accuracy: 0.0068\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0685 - accuracy: 0.0068\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0685 - accuracy: 0.0068\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0684 - accuracy: 0.0068\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 1s 4ms/step - loss: 0.0721 - accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0720 - accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0719 - accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0718 - accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0717 - accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0715 - accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0714 - accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0713 - accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0712 - accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0711 - accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0710 - accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0709 - accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0708 - accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0707 - accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0706 - accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0705 - accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0704 - accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0703 - accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0702 - accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0701 - accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0700 - accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0699 - accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0698 - accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0697 - accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0696 - accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0695 - accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0695 - accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0694 - accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0693 - accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0692 - accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0691 - accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0690 - accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0690 - accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0689 - accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0688 - accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0687 - accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0686 - accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0686 - accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0685 - accuracy: 0.0000e+00\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0684 - accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0683 - accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0683 - accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0682 - accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0681 - accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0681 - accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0680 - accuracy: 0.0000e+00\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0679 - accuracy: 0.0000e+00\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0679 - accuracy: 0.0000e+00\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0678 - accuracy: 0.0000e+00\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0677 - accuracy: 0.0000e+00\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0655 - accuracy: 0.0068\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0654 - accuracy: 0.0068\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0652 - accuracy: 0.0068\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0651 - accuracy: 0.0068\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0648 - accuracy: 0.0068\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0646 - accuracy: 0.0068\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0645 - accuracy: 0.0068\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0643 - accuracy: 0.0068\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0642 - accuracy: 0.0068\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0640 - accuracy: 0.0068\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0639 - accuracy: 0.0068\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0638 - accuracy: 0.0068\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0636 - accuracy: 0.0068\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0635 - accuracy: 0.0068\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0634 - accuracy: 0.0068\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0632 - accuracy: 0.0068\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0631 - accuracy: 0.0068\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0630 - accuracy: 0.0068\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0628 - accuracy: 0.0068\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0627 - accuracy: 0.0068\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0626 - accuracy: 0.0068\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0625 - accuracy: 0.0068\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0624 - accuracy: 0.0068\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0622 - accuracy: 0.0068\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0621 - accuracy: 0.0068\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0620 - accuracy: 0.0068\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0619 - accuracy: 0.0068\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0618 - accuracy: 0.0068\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0617 - accuracy: 0.0068\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0615 - accuracy: 0.0068\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0614 - accuracy: 0.0068\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0613 - accuracy: 0.0068\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0612 - accuracy: 0.0068\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0611 - accuracy: 0.0068\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0610 - accuracy: 0.0068\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0609 - accuracy: 0.0068\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0608 - accuracy: 0.0068\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0607 - accuracy: 0.0068\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0606 - accuracy: 0.0068\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0605 - accuracy: 0.0068\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0604 - accuracy: 0.0068\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0603 - accuracy: 0.0068\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0602 - accuracy: 0.0068\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0601 - accuracy: 0.0068\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0601 - accuracy: 0.0068\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0600 - accuracy: 0.0068\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0599 - accuracy: 0.0068\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0598 - accuracy: 0.0068\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0597 - accuracy: 0.0068\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0698 - accuracy: 0.0068\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0697 - accuracy: 0.0068\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0696 - accuracy: 0.0068\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0695 - accuracy: 0.0068\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0694 - accuracy: 0.0068\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0693 - accuracy: 0.0068\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0693 - accuracy: 0.0068\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0692 - accuracy: 0.0068\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0691 - accuracy: 0.0068\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0690 - accuracy: 0.0068\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0689 - accuracy: 0.0068\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0688 - accuracy: 0.0068\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0687 - accuracy: 0.0068\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0686 - accuracy: 0.0068\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0685 - accuracy: 0.0068\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0685 - accuracy: 0.0068\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0684 - accuracy: 0.0068\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0683 - accuracy: 0.0068\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0682 - accuracy: 0.0068\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0681 - accuracy: 0.0068\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0681 - accuracy: 0.0068\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0680 - accuracy: 0.0068\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0679 - accuracy: 0.0068\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0678 - accuracy: 0.0068\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0678 - accuracy: 0.0068\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0677 - accuracy: 0.0068\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0676 - accuracy: 0.0068\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0675 - accuracy: 0.0068\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0675 - accuracy: 0.0068\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0674 - accuracy: 0.0068\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0673 - accuracy: 0.0068\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0673 - accuracy: 0.0068\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0672 - accuracy: 0.0068\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0671 - accuracy: 0.0068\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0671 - accuracy: 0.0068\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0670 - accuracy: 0.0068\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0669 - accuracy: 0.0068\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0669 - accuracy: 0.0068\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0668 - accuracy: 0.0068\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0667 - accuracy: 0.0068\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0667 - accuracy: 0.0068\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0666 - accuracy: 0.0068\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0666 - accuracy: 0.0068\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0665 - accuracy: 0.0068\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0664 - accuracy: 0.0068\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0664 - accuracy: 0.0068\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0663 - accuracy: 0.0068\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0663 - accuracy: 0.0068\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0662 - accuracy: 0.0068\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0662 - accuracy: 0.0068\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "5/5 [==============================] - 1s 3ms/step - loss: 0.0711 - accuracy: 0.0068\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0709 - accuracy: 0.0068\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0707 - accuracy: 0.0068\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0705 - accuracy: 0.0068\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0704 - accuracy: 0.0068\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0702 - accuracy: 0.0068\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0700 - accuracy: 0.0068\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0699 - accuracy: 0.0068\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0697 - accuracy: 0.0068\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0696 - accuracy: 0.0068\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0694 - accuracy: 0.0068\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0693 - accuracy: 0.0068\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0691 - accuracy: 0.0068\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0690 - accuracy: 0.0068\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0688 - accuracy: 0.0068\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0687 - accuracy: 0.0068\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0685 - accuracy: 0.0068\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0684 - accuracy: 0.0068\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0682 - accuracy: 0.0068\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0681 - accuracy: 0.0068\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0680 - accuracy: 0.0068\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0678 - accuracy: 0.0068\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0677 - accuracy: 0.0068\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0676 - accuracy: 0.0068\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0674 - accuracy: 0.0068\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0673 - accuracy: 0.0068\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0672 - accuracy: 0.0068\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0670 - accuracy: 0.0068\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0669 - accuracy: 0.0068\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0668 - accuracy: 0.0068\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0667 - accuracy: 0.0068\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0666 - accuracy: 0.0068\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0664 - accuracy: 0.0068\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0663 - accuracy: 0.0068\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0662 - accuracy: 0.0068\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0661 - accuracy: 0.0068\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0660 - accuracy: 0.0068\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0659 - accuracy: 0.0068\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0658 - accuracy: 0.0068\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0657 - accuracy: 0.0068\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0655 - accuracy: 0.0068\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0654 - accuracy: 0.0068\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0653 - accuracy: 0.0068\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0652 - accuracy: 0.0068\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0651 - accuracy: 0.0068\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0650 - accuracy: 0.0068\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0648 - accuracy: 0.0068\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0646 - accuracy: 0.0068\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0717 - accuracy: 0.0204\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0715 - accuracy: 0.0068\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0713 - accuracy: 0.0068\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0710 - accuracy: 0.0068\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0709 - accuracy: 0.0068\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0706 - accuracy: 0.0068\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0704 - accuracy: 0.0068\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0702 - accuracy: 0.0068\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0700 - accuracy: 0.0068\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0697 - accuracy: 0.0068\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0694 - accuracy: 0.0068\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0692 - accuracy: 0.0068\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0689 - accuracy: 0.0068\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0686 - accuracy: 0.0068\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0683 - accuracy: 0.0068\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0679 - accuracy: 0.0068\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0675 - accuracy: 0.0068\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0672 - accuracy: 0.0068\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0668 - accuracy: 0.0068\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0663 - accuracy: 0.0068\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0658 - accuracy: 0.0068\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0653 - accuracy: 0.0068\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0648 - accuracy: 0.0068\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0642 - accuracy: 0.0068\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0636 - accuracy: 0.0068\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0631 - accuracy: 0.0068\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0623 - accuracy: 0.0068\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0616 - accuracy: 0.0068\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0609 - accuracy: 0.0068\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0601 - accuracy: 0.0068\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0593 - accuracy: 0.0068\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0583 - accuracy: 0.0068\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0574 - accuracy: 0.0068\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0564 - accuracy: 0.0068\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0554 - accuracy: 0.0068\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0544 - accuracy: 0.0068\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0533 - accuracy: 0.0272\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0522 - accuracy: 0.0408\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0511 - accuracy: 0.0408\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0501 - accuracy: 0.0476\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0488 - accuracy: 0.0476\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0477 - accuracy: 0.0476\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0464 - accuracy: 0.0476\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0453 - accuracy: 0.0476\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0441 - accuracy: 0.0476\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0430 - accuracy: 0.0476\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0417 - accuracy: 0.0476\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0405 - accuracy: 0.0476\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0394 - accuracy: 0.0476\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0382 - accuracy: 0.0476\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0371 - accuracy: 0.0476\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0359 - accuracy: 0.0476\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0348 - accuracy: 0.0476\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0337 - accuracy: 0.0476\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0326 - accuracy: 0.0476\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0315 - accuracy: 0.0476\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0304 - accuracy: 0.0476\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0294 - accuracy: 0.0476\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0284 - accuracy: 0.0476\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0274 - accuracy: 0.0476\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0265 - accuracy: 0.0476\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0255 - accuracy: 0.0476\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0246 - accuracy: 0.0476\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0239 - accuracy: 0.0476\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0230 - accuracy: 0.0476\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0223 - accuracy: 0.0476\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0216 - accuracy: 0.0476\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0209 - accuracy: 0.0476\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0202 - accuracy: 0.0476\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0196 - accuracy: 0.0476\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0190 - accuracy: 0.0476\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0184 - accuracy: 0.0476\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0179 - accuracy: 0.0476\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0174 - accuracy: 0.0476\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0169 - accuracy: 0.0476\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0165 - accuracy: 0.0476\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0161 - accuracy: 0.0476\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0156 - accuracy: 0.0476\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0152 - accuracy: 0.0476\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0149 - accuracy: 0.0476\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0145 - accuracy: 0.0476\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0142 - accuracy: 0.0476\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0139 - accuracy: 0.0476\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0136 - accuracy: 0.0476\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0133 - accuracy: 0.0476\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0130 - accuracy: 0.0476\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0128 - accuracy: 0.0476\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0125 - accuracy: 0.0476\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - accuracy: 0.0476\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0121 - accuracy: 0.0476\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0119 - accuracy: 0.0476\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0116 - accuracy: 0.0476\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0115 - accuracy: 0.0476\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0113 - accuracy: 0.0476\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0111 - accuracy: 0.0476\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0109 - accuracy: 0.0476\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0107 - accuracy: 0.0476\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0106 - accuracy: 0.0476\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0104 - accuracy: 0.0476\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0103 - accuracy: 0.0476\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "5/5 [==============================] - 1s 5ms/step - loss: 0.0721 - accuracy: 0.0000e+00\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0718 - accuracy: 0.0000e+00\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0715 - accuracy: 0.0000e+00\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0713 - accuracy: 0.0000e+00\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0710 - accuracy: 0.0000e+00\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0707 - accuracy: 0.0000e+00\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0704 - accuracy: 0.0000e+00\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0700 - accuracy: 0.0000e+00\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0697 - accuracy: 0.0000e+00\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0693 - accuracy: 0.0000e+00\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0689 - accuracy: 0.0000e+00\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0684 - accuracy: 0.0000e+00\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0680 - accuracy: 0.0000e+00\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0675 - accuracy: 0.0000e+00\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0669 - accuracy: 0.0000e+00\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0664 - accuracy: 0.0000e+00\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0658 - accuracy: 0.0000e+00\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0651 - accuracy: 0.0000e+00\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0645 - accuracy: 0.0000e+00\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0638 - accuracy: 0.0000e+00\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0630 - accuracy: 0.0000e+00\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0622 - accuracy: 0.0000e+00\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0615 - accuracy: 0.0000e+00\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0606 - accuracy: 0.0000e+00\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0597 - accuracy: 0.0000e+00\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0588 - accuracy: 0.0000e+00\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0579 - accuracy: 0.0000e+00\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0570 - accuracy: 0.0000e+00\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0562 - accuracy: 0.0000e+00\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0551 - accuracy: 0.0000e+00\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0542 - accuracy: 0.0000e+00\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0533 - accuracy: 0.0000e+00\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0524 - accuracy: 0.0000e+00\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0515 - accuracy: 0.0000e+00\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0506 - accuracy: 0.0000e+00\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0498 - accuracy: 0.0000e+00\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0490 - accuracy: 0.0000e+00\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0482 - accuracy: 0.0000e+00\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0474 - accuracy: 0.0000e+00\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0468 - accuracy: 0.0000e+00\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0460 - accuracy: 0.0000e+00\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0454 - accuracy: 0.0000e+00\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0449 - accuracy: 0.0000e+00\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0444 - accuracy: 0.0000e+00\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0438 - accuracy: 0.0000e+00\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0433 - accuracy: 0.0000e+00\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0428 - accuracy: 0.0000e+00\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0424 - accuracy: 0.0000e+00\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0420 - accuracy: 0.0000e+00\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0416 - accuracy: 0.0000e+00\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0412 - accuracy: 0.0000e+00\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0408 - accuracy: 0.0000e+00\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0404 - accuracy: 0.0000e+00\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0400 - accuracy: 0.0000e+00\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0397 - accuracy: 0.0000e+00\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0393 - accuracy: 0.0000e+00\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0389 - accuracy: 0.0000e+00\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0385 - accuracy: 0.0000e+00\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0382 - accuracy: 0.0000e+00\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0379 - accuracy: 0.0000e+00\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0375 - accuracy: 0.0000e+00\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0372 - accuracy: 0.0000e+00\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0369 - accuracy: 0.0000e+00\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0366 - accuracy: 0.0000e+00\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0364 - accuracy: 0.0000e+00\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0361 - accuracy: 0.0000e+00\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0358 - accuracy: 0.0000e+00\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0355 - accuracy: 0.0000e+00\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0353 - accuracy: 0.0000e+00\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0350 - accuracy: 0.0000e+00\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0347 - accuracy: 0.0000e+00\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0345 - accuracy: 0.0000e+00\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0342 - accuracy: 0.0000e+00\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0340 - accuracy: 0.0000e+00\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0337 - accuracy: 0.0000e+00\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0335 - accuracy: 0.0000e+00\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0333 - accuracy: 0.0000e+00\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0330 - accuracy: 0.0340\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0328 - accuracy: 0.0340\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0325 - accuracy: 0.0340\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0323 - accuracy: 0.0340\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0321 - accuracy: 0.0340\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0319 - accuracy: 0.0340\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0316 - accuracy: 0.0340\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0315 - accuracy: 0.0340\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0312 - accuracy: 0.0340\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0310 - accuracy: 0.0340\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0308 - accuracy: 0.0340\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0305 - accuracy: 0.0340\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0303 - accuracy: 0.0340\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0301 - accuracy: 0.0340\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0299 - accuracy: 0.0340\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0297 - accuracy: 0.0340\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0295 - accuracy: 0.0340\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0293 - accuracy: 0.0340\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0290 - accuracy: 0.0340\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0288 - accuracy: 0.0340\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0286 - accuracy: 0.0340\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0284 - accuracy: 0.0340\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0282 - accuracy: 0.0340\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 1s 4ms/step - loss: 0.0655 - accuracy: 0.0068\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0652 - accuracy: 0.0068\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0650 - accuracy: 0.0068\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0644 - accuracy: 0.0068\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0641 - accuracy: 0.0068\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0638 - accuracy: 0.0068\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0635 - accuracy: 0.0068\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0632 - accuracy: 0.0068\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0629 - accuracy: 0.0068\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0626 - accuracy: 0.0068\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0622 - accuracy: 0.0068\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0618 - accuracy: 0.0068\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0615 - accuracy: 0.0068\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0611 - accuracy: 0.0068\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0606 - accuracy: 0.0068\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0602 - accuracy: 0.0068\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0597 - accuracy: 0.0068\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0592 - accuracy: 0.0068\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0587 - accuracy: 0.0068\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0582 - accuracy: 0.0068\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0577 - accuracy: 0.0068\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0570 - accuracy: 0.0068\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0565 - accuracy: 0.0068\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0559 - accuracy: 0.0068\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0552 - accuracy: 0.0068\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0547 - accuracy: 0.0068\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0540 - accuracy: 0.0068\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0534 - accuracy: 0.0068\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0528 - accuracy: 0.0068\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0522 - accuracy: 0.0068\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0515 - accuracy: 0.0068\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0508 - accuracy: 0.0068\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0503 - accuracy: 0.0068\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0495 - accuracy: 0.0068\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0490 - accuracy: 0.0068\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0484 - accuracy: 0.0068\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0478 - accuracy: 0.0068\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0472 - accuracy: 0.0068\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0467 - accuracy: 0.0068\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0462 - accuracy: 0.0068\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0458 - accuracy: 0.0068\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0453 - accuracy: 0.0068\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0450 - accuracy: 0.0068\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0445 - accuracy: 0.0068\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0442 - accuracy: 0.0068\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0438 - accuracy: 0.0068\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0435 - accuracy: 0.0068\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0431 - accuracy: 0.0068\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0428 - accuracy: 0.0068\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0425 - accuracy: 0.0068\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0422 - accuracy: 0.0068\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0419 - accuracy: 0.0068\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0416 - accuracy: 0.0068\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0413 - accuracy: 0.0068\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0410 - accuracy: 0.0068\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0407 - accuracy: 0.0068\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0404 - accuracy: 0.0068\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0402 - accuracy: 0.0068\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0399 - accuracy: 0.0068\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0396 - accuracy: 0.0068\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0394 - accuracy: 0.0068\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0391 - accuracy: 0.0068\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0388 - accuracy: 0.0068\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0385 - accuracy: 0.0068\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0383 - accuracy: 0.0068\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0380 - accuracy: 0.0068\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0377 - accuracy: 0.0068\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0374 - accuracy: 0.0068\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0371 - accuracy: 0.0068\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0368 - accuracy: 0.0068\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0366 - accuracy: 0.0068\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0363 - accuracy: 0.0068\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0360 - accuracy: 0.0068\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0357 - accuracy: 0.0068\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0354 - accuracy: 0.0068\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0352 - accuracy: 0.0068\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0349 - accuracy: 0.0068\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0346 - accuracy: 0.0068\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0343 - accuracy: 0.0068\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0341 - accuracy: 0.0068\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0338 - accuracy: 0.0068\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0335 - accuracy: 0.0068\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0333 - accuracy: 0.0068\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0330 - accuracy: 0.0068\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0328 - accuracy: 0.0068\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0325 - accuracy: 0.0068\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0322 - accuracy: 0.0068\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0320 - accuracy: 0.0068\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0318 - accuracy: 0.0068\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0315 - accuracy: 0.0068\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0313 - accuracy: 0.0068\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0311 - accuracy: 0.0068\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0309 - accuracy: 0.0068\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0307 - accuracy: 0.0068\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0305 - accuracy: 0.0068\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0303 - accuracy: 0.0068\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0302 - accuracy: 0.0068\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0300 - accuracy: 0.0068\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0298 - accuracy: 0.0068\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 1s 5ms/step - loss: 0.0698 - accuracy: 0.0068\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0696 - accuracy: 0.0068\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0693 - accuracy: 0.0068\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0691 - accuracy: 0.0068\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0689 - accuracy: 0.0068\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0687 - accuracy: 0.0068\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0685 - accuracy: 0.0068\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0683 - accuracy: 0.0068\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0681 - accuracy: 0.0068\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0679 - accuracy: 0.0068\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0677 - accuracy: 0.0068\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0675 - accuracy: 0.0068\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0673 - accuracy: 0.0068\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0671 - accuracy: 0.0068\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0669 - accuracy: 0.0068\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0666 - accuracy: 0.0068\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0664 - accuracy: 0.0068\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0662 - accuracy: 0.0068\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0660 - accuracy: 0.0068\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0658 - accuracy: 0.0068\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0656 - accuracy: 0.0068\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0653 - accuracy: 0.0068\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0651 - accuracy: 0.0068\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0648 - accuracy: 0.0068\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0646 - accuracy: 0.0068\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0643 - accuracy: 0.0068\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0640 - accuracy: 0.0068\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0638 - accuracy: 0.0068\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0635 - accuracy: 0.0068\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0632 - accuracy: 0.0068\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0629 - accuracy: 0.0068\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0626 - accuracy: 0.0068\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0622 - accuracy: 0.0068\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0618 - accuracy: 0.0068\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0614 - accuracy: 0.0068\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0609 - accuracy: 0.0068\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0604 - accuracy: 0.0068\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0600 - accuracy: 0.0068\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0594 - accuracy: 0.0068\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0589 - accuracy: 0.0068\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0583 - accuracy: 0.0068\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0578 - accuracy: 0.0068\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0572 - accuracy: 0.0068\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0566 - accuracy: 0.0068\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0561 - accuracy: 0.0068\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0555 - accuracy: 0.0068\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0548 - accuracy: 0.0068\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0543 - accuracy: 0.0068\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0537 - accuracy: 0.0068\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0531 - accuracy: 0.0068\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0525 - accuracy: 0.0068\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0520 - accuracy: 0.0068\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0514 - accuracy: 0.0068\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0508 - accuracy: 0.0068\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0503 - accuracy: 0.0068\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0497 - accuracy: 0.0068\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0492 - accuracy: 0.0068\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0487 - accuracy: 0.0068\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0482 - accuracy: 0.0068\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0478 - accuracy: 0.0068\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0473 - accuracy: 0.0068\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0468 - accuracy: 0.0068\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0464 - accuracy: 0.0068\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0460 - accuracy: 0.0068\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0456 - accuracy: 0.0068\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0451 - accuracy: 0.0068\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0447 - accuracy: 0.0068\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0443 - accuracy: 0.0068\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0439 - accuracy: 0.0068\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0435 - accuracy: 0.0068\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0431 - accuracy: 0.0068\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0427 - accuracy: 0.0068\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0423 - accuracy: 0.0068\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0420 - accuracy: 0.0068\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0416 - accuracy: 0.0068\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0412 - accuracy: 0.0068\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0408 - accuracy: 0.0068\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0405 - accuracy: 0.0068\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0402 - accuracy: 0.0068\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0398 - accuracy: 0.0068\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0395 - accuracy: 0.0068\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0392 - accuracy: 0.0068\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0389 - accuracy: 0.0068\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0386 - accuracy: 0.0068\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0383 - accuracy: 0.0068\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0380 - accuracy: 0.0068\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0377 - accuracy: 0.0068\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0374 - accuracy: 0.0068\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0372 - accuracy: 0.0068\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0369 - accuracy: 0.0068\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0366 - accuracy: 0.0068\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0363 - accuracy: 0.0068\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0361 - accuracy: 0.0068\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0358 - accuracy: 0.0068\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0356 - accuracy: 0.0068\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0353 - accuracy: 0.0068\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0351 - accuracy: 0.0068\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0348 - accuracy: 0.0068\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0346 - accuracy: 0.0068\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0343 - accuracy: 0.0068\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "5/5 [==============================] - 1s 5ms/step - loss: 0.0710 - accuracy: 0.0203\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0707 - accuracy: 0.0068\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0704 - accuracy: 0.0068\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0701 - accuracy: 0.0068\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0698 - accuracy: 0.0068\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0695 - accuracy: 0.0068\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0692 - accuracy: 0.0068\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0689 - accuracy: 0.0068\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0686 - accuracy: 0.0068\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0682 - accuracy: 0.0068\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0679 - accuracy: 0.0068\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0676 - accuracy: 0.0068\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0672 - accuracy: 0.0068\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0669 - accuracy: 0.0068\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0665 - accuracy: 0.0068\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0661 - accuracy: 0.0068\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0657 - accuracy: 0.0068\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0653 - accuracy: 0.0068\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0648 - accuracy: 0.0068\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0643 - accuracy: 0.0068\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0639 - accuracy: 0.0068\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0634 - accuracy: 0.0068\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0628 - accuracy: 0.0068\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0623 - accuracy: 0.0068\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0617 - accuracy: 0.0068\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0610 - accuracy: 0.0068\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0604 - accuracy: 0.0068\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0598 - accuracy: 0.0068\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0591 - accuracy: 0.0068\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0584 - accuracy: 0.0068\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0577 - accuracy: 0.0068\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0569 - accuracy: 0.0068\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0561 - accuracy: 0.0068\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0553 - accuracy: 0.0068\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0546 - accuracy: 0.0068\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0536 - accuracy: 0.0068\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0528 - accuracy: 0.0068\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0519 - accuracy: 0.0068\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0509 - accuracy: 0.0068\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0500 - accuracy: 0.0068\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0489 - accuracy: 0.0068\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0479 - accuracy: 0.0270\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0469 - accuracy: 0.0405\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0458 - accuracy: 0.0405\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0445 - accuracy: 0.0473\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0433 - accuracy: 0.0473\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0421 - accuracy: 0.0473\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0409 - accuracy: 0.0473\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0396 - accuracy: 0.0473\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0382 - accuracy: 0.0473\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0369 - accuracy: 0.0473\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0356 - accuracy: 0.0473\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0343 - accuracy: 0.0473\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0330 - accuracy: 0.0473\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0316 - accuracy: 0.0473\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0305 - accuracy: 0.0473\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0292 - accuracy: 0.0473\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0279 - accuracy: 0.0473\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0267 - accuracy: 0.0473\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0256 - accuracy: 0.0473\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0246 - accuracy: 0.0473\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0235 - accuracy: 0.0473\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0226 - accuracy: 0.0473\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0216 - accuracy: 0.0473\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0207 - accuracy: 0.0473\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0200 - accuracy: 0.0473\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0192 - accuracy: 0.0473\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0185 - accuracy: 0.0473\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0178 - accuracy: 0.0473\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0172 - accuracy: 0.0473\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0166 - accuracy: 0.0473\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0161 - accuracy: 0.0473\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0155 - accuracy: 0.0473\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0151 - accuracy: 0.0473\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0147 - accuracy: 0.0473\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0142 - accuracy: 0.0473\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0139 - accuracy: 0.0473\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0135 - accuracy: 0.0473\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0132 - accuracy: 0.0473\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0129 - accuracy: 0.0473\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0126 - accuracy: 0.0473\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0124 - accuracy: 0.0473\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0121 - accuracy: 0.0473\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0119 - accuracy: 0.0473\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0117 - accuracy: 0.0473\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0115 - accuracy: 0.0473\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0113 - accuracy: 0.0473\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0111 - accuracy: 0.0473\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0109 - accuracy: 0.0473\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0108 - accuracy: 0.0473\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0106 - accuracy: 0.0473\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0105 - accuracy: 0.0473\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0104 - accuracy: 0.0473\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0102 - accuracy: 0.0473\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0101 - accuracy: 0.0473\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0100 - accuracy: 0.0473\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0099 - accuracy: 0.0473\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0097 - accuracy: 0.0473\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0096 - accuracy: 0.0473\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0095 - accuracy: 0.0473\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0718 - accuracy: 0.0204\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0717 - accuracy: 0.0068\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0716 - accuracy: 0.0068\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0715 - accuracy: 0.0068\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0714 - accuracy: 0.0068\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0713 - accuracy: 0.0068\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0712 - accuracy: 0.0068\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0711 - accuracy: 0.0068\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0711 - accuracy: 0.0068\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0710 - accuracy: 0.0068\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0709 - accuracy: 0.0068\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0708 - accuracy: 0.0068\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0707 - accuracy: 0.0068\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0707 - accuracy: 0.0068\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0706 - accuracy: 0.0068\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0705 - accuracy: 0.0068\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0704 - accuracy: 0.0068\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0704 - accuracy: 0.0068\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0703 - accuracy: 0.0068\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0702 - accuracy: 0.0068\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0701 - accuracy: 0.0068\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0701 - accuracy: 0.0068\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0700 - accuracy: 0.0068\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0699 - accuracy: 0.0068\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0699 - accuracy: 0.0068\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0698 - accuracy: 0.0068\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0697 - accuracy: 0.0068\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0697 - accuracy: 0.0068\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0696 - accuracy: 0.0068\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0695 - accuracy: 0.0068\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0695 - accuracy: 0.0068\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0694 - accuracy: 0.0068\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0693 - accuracy: 0.0068\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0693 - accuracy: 0.0068\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0692 - accuracy: 0.0068\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0692 - accuracy: 0.0068\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0691 - accuracy: 0.0068\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0691 - accuracy: 0.0068\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0690 - accuracy: 0.0068\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0689 - accuracy: 0.0068\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0689 - accuracy: 0.0068\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0688 - accuracy: 0.0068\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0688 - accuracy: 0.0068\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0687 - accuracy: 0.0068\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0687 - accuracy: 0.0068\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0686 - accuracy: 0.0068\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0686 - accuracy: 0.0068\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0685 - accuracy: 0.0068\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0685 - accuracy: 0.0068\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0684 - accuracy: 0.0068\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0684 - accuracy: 0.0068\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0683 - accuracy: 0.0068\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0683 - accuracy: 0.0068\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0682 - accuracy: 0.0068\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0682 - accuracy: 0.0068\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0681 - accuracy: 0.0068\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0681 - accuracy: 0.0068\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0680 - accuracy: 0.0068\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0680 - accuracy: 0.0068\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0679 - accuracy: 0.0068\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0679 - accuracy: 0.0068\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0679 - accuracy: 0.0068\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0678 - accuracy: 0.0068\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0678 - accuracy: 0.0068\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0677 - accuracy: 0.0068\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0677 - accuracy: 0.0068\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0677 - accuracy: 0.0068\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0676 - accuracy: 0.0068\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0676 - accuracy: 0.0068\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0675 - accuracy: 0.0068\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0675 - accuracy: 0.0068\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0675 - accuracy: 0.0068\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0674 - accuracy: 0.0068\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0674 - accuracy: 0.0068\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0674 - accuracy: 0.0068\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0673 - accuracy: 0.0068\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0673 - accuracy: 0.0068\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0672 - accuracy: 0.0068\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0672 - accuracy: 0.0068\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0672 - accuracy: 0.0068\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0671 - accuracy: 0.0068\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0671 - accuracy: 0.0068\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0671 - accuracy: 0.0068\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0670 - accuracy: 0.0068\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0670 - accuracy: 0.0068\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0670 - accuracy: 0.0068\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0669 - accuracy: 0.0068\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0669 - accuracy: 0.0068\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0669 - accuracy: 0.0068\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0669 - accuracy: 0.0068\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0668 - accuracy: 0.0068\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0668 - accuracy: 0.0068\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0668 - accuracy: 0.0068\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0667 - accuracy: 0.0068\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0667 - accuracy: 0.0068\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0667 - accuracy: 0.0068\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0667 - accuracy: 0.0068\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0666 - accuracy: 0.0068\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0666 - accuracy: 0.0068\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0666 - accuracy: 0.0068\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0721 - accuracy: 0.0000e+00\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0720 - accuracy: 0.0000e+00\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0719 - accuracy: 0.0000e+00\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0718 - accuracy: 0.0000e+00\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0717 - accuracy: 0.0000e+00\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0715 - accuracy: 0.0000e+00\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0714 - accuracy: 0.0000e+00\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0713 - accuracy: 0.0000e+00\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0712 - accuracy: 0.0000e+00\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0711 - accuracy: 0.0000e+00\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0710 - accuracy: 0.0000e+00\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0709 - accuracy: 0.0000e+00\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0708 - accuracy: 0.0000e+00\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0707 - accuracy: 0.0000e+00\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0706 - accuracy: 0.0000e+00\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0705 - accuracy: 0.0000e+00\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0704 - accuracy: 0.0000e+00\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0703 - accuracy: 0.0000e+00\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0702 - accuracy: 0.0000e+00\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0701 - accuracy: 0.0000e+00\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0700 - accuracy: 0.0000e+00\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0699 - accuracy: 0.0000e+00\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0698 - accuracy: 0.0000e+00\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0697 - accuracy: 0.0000e+00\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0696 - accuracy: 0.0000e+00\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0695 - accuracy: 0.0000e+00\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0695 - accuracy: 0.0000e+00\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0694 - accuracy: 0.0000e+00\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0693 - accuracy: 0.0000e+00\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0692 - accuracy: 0.0000e+00\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0691 - accuracy: 0.0000e+00\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0690 - accuracy: 0.0000e+00\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0689 - accuracy: 0.0000e+00\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0689 - accuracy: 0.0000e+00\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0688 - accuracy: 0.0000e+00\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0687 - accuracy: 0.0000e+00\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0686 - accuracy: 0.0000e+00\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0686 - accuracy: 0.0000e+00\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0685 - accuracy: 0.0000e+00\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0684 - accuracy: 0.0000e+00\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0683 - accuracy: 0.0000e+00\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0683 - accuracy: 0.0000e+00\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0682 - accuracy: 0.0000e+00\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0681 - accuracy: 0.0000e+00\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0680 - accuracy: 0.0000e+00\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0680 - accuracy: 0.0000e+00\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0679 - accuracy: 0.0000e+00\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0678 - accuracy: 0.0000e+00\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0678 - accuracy: 0.0000e+00\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0677 - accuracy: 0.0000e+00\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0676 - accuracy: 0.0000e+00\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0676 - accuracy: 0.0000e+00\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0675 - accuracy: 0.0000e+00\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0675 - accuracy: 0.0000e+00\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0674 - accuracy: 0.0000e+00\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0673 - accuracy: 0.0000e+00\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0673 - accuracy: 0.0000e+00\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0672 - accuracy: 0.0000e+00\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0672 - accuracy: 0.0000e+00\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0671 - accuracy: 0.0000e+00\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0670 - accuracy: 0.0000e+00\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0670 - accuracy: 0.0000e+00\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0669 - accuracy: 0.0000e+00\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0669 - accuracy: 0.0000e+00\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0668 - accuracy: 0.0000e+00\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0668 - accuracy: 0.0000e+00\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0667 - accuracy: 0.0000e+00\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0667 - accuracy: 0.0000e+00\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0666 - accuracy: 0.0000e+00\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0666 - accuracy: 0.0000e+00\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0665 - accuracy: 0.0000e+00\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0665 - accuracy: 0.0000e+00\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0664 - accuracy: 0.0000e+00\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0664 - accuracy: 0.0000e+00\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0663 - accuracy: 0.0000e+00\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0663 - accuracy: 0.0000e+00\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0662 - accuracy: 0.0000e+00\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0662 - accuracy: 0.0000e+00\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0661 - accuracy: 0.0000e+00\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0661 - accuracy: 0.0000e+00\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0660 - accuracy: 0.0000e+00\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0660 - accuracy: 0.0000e+00\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0660 - accuracy: 0.0000e+00\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0659 - accuracy: 0.0000e+00\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0659 - accuracy: 0.0000e+00\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0658 - accuracy: 0.0000e+00\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0658 - accuracy: 0.0000e+00\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0658 - accuracy: 0.0000e+00\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0657 - accuracy: 0.0000e+00\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0657 - accuracy: 0.0000e+00\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0656 - accuracy: 0.0000e+00\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0656 - accuracy: 0.0000e+00\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0656 - accuracy: 0.0000e+00\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0655 - accuracy: 0.0000e+00\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0655 - accuracy: 0.0000e+00\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0654 - accuracy: 0.0000e+00\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0654 - accuracy: 0.0000e+00\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0654 - accuracy: 0.0000e+00\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0653 - accuracy: 0.0000e+00\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0653 - accuracy: 0.0000e+00\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0656 - accuracy: 0.0136\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0654 - accuracy: 0.0068\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0652 - accuracy: 0.0068\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0651 - accuracy: 0.0068\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0648 - accuracy: 0.0068\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0646 - accuracy: 0.0068\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0645 - accuracy: 0.0068\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0643 - accuracy: 0.0068\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0642 - accuracy: 0.0068\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0640 - accuracy: 0.0068\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0639 - accuracy: 0.0068\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0638 - accuracy: 0.0068\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0636 - accuracy: 0.0068\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0635 - accuracy: 0.0068\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0634 - accuracy: 0.0068\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0632 - accuracy: 0.0068\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0631 - accuracy: 0.0068\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0630 - accuracy: 0.0068\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0628 - accuracy: 0.0068\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0627 - accuracy: 0.0068\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0626 - accuracy: 0.0068\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0625 - accuracy: 0.0068\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0624 - accuracy: 0.0068\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0622 - accuracy: 0.0068\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0621 - accuracy: 0.0068\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0620 - accuracy: 0.0068\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0619 - accuracy: 0.0068\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0618 - accuracy: 0.0068\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0617 - accuracy: 0.0068\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0616 - accuracy: 0.0068\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0614 - accuracy: 0.0068\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0613 - accuracy: 0.0068\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0612 - accuracy: 0.0068\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0611 - accuracy: 0.0068\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0610 - accuracy: 0.0068\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0609 - accuracy: 0.0068\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0608 - accuracy: 0.0068\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0607 - accuracy: 0.0068\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0606 - accuracy: 0.0068\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0605 - accuracy: 0.0068\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0604 - accuracy: 0.0068\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0603 - accuracy: 0.0068\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0602 - accuracy: 0.0068\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0601 - accuracy: 0.0068\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0601 - accuracy: 0.0068\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0600 - accuracy: 0.0068\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0599 - accuracy: 0.0068\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0598 - accuracy: 0.0068\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0597 - accuracy: 0.0068\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0596 - accuracy: 0.0068\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0595 - accuracy: 0.0068\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0595 - accuracy: 0.0068\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0594 - accuracy: 0.0068\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0593 - accuracy: 0.0068\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0592 - accuracy: 0.0068\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0591 - accuracy: 0.0068\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0591 - accuracy: 0.0068\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0590 - accuracy: 0.0068\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0589 - accuracy: 0.0068\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0588 - accuracy: 0.0068\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0587 - accuracy: 0.0068\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0587 - accuracy: 0.0068\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0586 - accuracy: 0.0068\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0585 - accuracy: 0.0068\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0585 - accuracy: 0.0068\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0584 - accuracy: 0.0068\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0583 - accuracy: 0.0068\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0583 - accuracy: 0.0068\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0582 - accuracy: 0.0068\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0581 - accuracy: 0.0068\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0581 - accuracy: 0.0068\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0580 - accuracy: 0.0068\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0579 - accuracy: 0.0068\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0579 - accuracy: 0.0068\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0578 - accuracy: 0.0068\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0577 - accuracy: 0.0068\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0577 - accuracy: 0.0068\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0576 - accuracy: 0.0068\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0576 - accuracy: 0.0068\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0575 - accuracy: 0.0068\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0574 - accuracy: 0.0068\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0574 - accuracy: 0.0068\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0573 - accuracy: 0.0068\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0573 - accuracy: 0.0068\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0572 - accuracy: 0.0068\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0572 - accuracy: 0.0068\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0571 - accuracy: 0.0068\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0571 - accuracy: 0.0068\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0570 - accuracy: 0.0068\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0570 - accuracy: 0.0068\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0569 - accuracy: 0.0068\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0569 - accuracy: 0.0068\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0568 - accuracy: 0.0068\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0568 - accuracy: 0.0068\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0567 - accuracy: 0.0068\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0567 - accuracy: 0.0068\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0566 - accuracy: 0.0068\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0566 - accuracy: 0.0068\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0565 - accuracy: 0.0068\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0698 - accuracy: 0.0068\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0697 - accuracy: 0.0068\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0696 - accuracy: 0.0068\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0695 - accuracy: 0.0068\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0694 - accuracy: 0.0068\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0693 - accuracy: 0.0068\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0693 - accuracy: 0.0068\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0692 - accuracy: 0.0068\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0691 - accuracy: 0.0068\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0690 - accuracy: 0.0068\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0689 - accuracy: 0.0068\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0688 - accuracy: 0.0068\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0687 - accuracy: 0.0068\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0686 - accuracy: 0.0068\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0685 - accuracy: 0.0068\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0685 - accuracy: 0.0068\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0684 - accuracy: 0.0068\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0683 - accuracy: 0.0068\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0682 - accuracy: 0.0068\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0681 - accuracy: 0.0068\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0681 - accuracy: 0.0068\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0680 - accuracy: 0.0068\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0679 - accuracy: 0.0068\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0678 - accuracy: 0.0068\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0678 - accuracy: 0.0068\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0677 - accuracy: 0.0068\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0676 - accuracy: 0.0068\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0675 - accuracy: 0.0068\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0675 - accuracy: 0.0068\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0674 - accuracy: 0.0068\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0673 - accuracy: 0.0068\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0673 - accuracy: 0.0068\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0672 - accuracy: 0.0068\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0671 - accuracy: 0.0068\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0671 - accuracy: 0.0068\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0670 - accuracy: 0.0068\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0669 - accuracy: 0.0068\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0669 - accuracy: 0.0068\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0668 - accuracy: 0.0068\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0667 - accuracy: 0.0068\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0667 - accuracy: 0.0068\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0666 - accuracy: 0.0068\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0666 - accuracy: 0.0068\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0665 - accuracy: 0.0068\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0664 - accuracy: 0.0068\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0664 - accuracy: 0.0068\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0663 - accuracy: 0.0068\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0663 - accuracy: 0.0068\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0662 - accuracy: 0.0068\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0662 - accuracy: 0.0068\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0661 - accuracy: 0.0068\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0661 - accuracy: 0.0068\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0660 - accuracy: 0.0068\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0660 - accuracy: 0.0068\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0659 - accuracy: 0.0068\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0659 - accuracy: 0.0068\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0658 - accuracy: 0.0068\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0658 - accuracy: 0.0068\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0657 - accuracy: 0.0068\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0657 - accuracy: 0.0068\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0656 - accuracy: 0.0068\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0656 - accuracy: 0.0068\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0655 - accuracy: 0.0068\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0655 - accuracy: 0.0068\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0654 - accuracy: 0.0068\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0654 - accuracy: 0.0068\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0653 - accuracy: 0.0068\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0653 - accuracy: 0.0068\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0653 - accuracy: 0.0068\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0652 - accuracy: 0.0068\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0652 - accuracy: 0.0068\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0651 - accuracy: 0.0068\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0651 - accuracy: 0.0068\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0650 - accuracy: 0.0068\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0650 - accuracy: 0.0068\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0650 - accuracy: 0.0068\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0648 - accuracy: 0.0068\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0648 - accuracy: 0.0068\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0646 - accuracy: 0.0068\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0646 - accuracy: 0.0068\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0646 - accuracy: 0.0068\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0645 - accuracy: 0.0068\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0645 - accuracy: 0.0068\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0645 - accuracy: 0.0068\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0644 - accuracy: 0.0068\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0644 - accuracy: 0.0068\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0644 - accuracy: 0.0068\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0643 - accuracy: 0.0068\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0643 - accuracy: 0.0068\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0643 - accuracy: 0.0068\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0643 - accuracy: 0.0068\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0642 - accuracy: 0.0068\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0642 - accuracy: 0.0068\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0642 - accuracy: 0.0068\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 1s 4ms/step - loss: 0.0711 - accuracy: 0.0068\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0709 - accuracy: 0.0068\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0707 - accuracy: 0.0068\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0705 - accuracy: 0.0068\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0704 - accuracy: 0.0068\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0702 - accuracy: 0.0068\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0700 - accuracy: 0.0068\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0699 - accuracy: 0.0068\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0697 - accuracy: 0.0068\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0696 - accuracy: 0.0068\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0694 - accuracy: 0.0068\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0693 - accuracy: 0.0068\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0691 - accuracy: 0.0068\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0690 - accuracy: 0.0068\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0688 - accuracy: 0.0068\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0687 - accuracy: 0.0068\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0685 - accuracy: 0.0068\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0684 - accuracy: 0.0068\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0682 - accuracy: 0.0068\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0681 - accuracy: 0.0068\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0680 - accuracy: 0.0068\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0678 - accuracy: 0.0068\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0677 - accuracy: 0.0068\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0676 - accuracy: 0.0068\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0674 - accuracy: 0.0068\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0673 - accuracy: 0.0068\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0672 - accuracy: 0.0068\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0670 - accuracy: 0.0068\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0669 - accuracy: 0.0068\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0668 - accuracy: 0.0068\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0667 - accuracy: 0.0068\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0666 - accuracy: 0.0068\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0664 - accuracy: 0.0068\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0663 - accuracy: 0.0068\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0662 - accuracy: 0.0068\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0661 - accuracy: 0.0068\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0660 - accuracy: 0.0068\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0659 - accuracy: 0.0068\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0658 - accuracy: 0.0068\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0657 - accuracy: 0.0068\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0655 - accuracy: 0.0068\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0654 - accuracy: 0.0068\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0653 - accuracy: 0.0068\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0652 - accuracy: 0.0068\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0651 - accuracy: 0.0068\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0650 - accuracy: 0.0068\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0648 - accuracy: 0.0068\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0646 - accuracy: 0.0068\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0645 - accuracy: 0.0068\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0645 - accuracy: 0.0068\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0644 - accuracy: 0.0068\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0643 - accuracy: 0.0068\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0642 - accuracy: 0.0068\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0641 - accuracy: 0.0068\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0640 - accuracy: 0.0068\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0639 - accuracy: 0.0068\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0638 - accuracy: 0.0068\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0638 - accuracy: 0.0068\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0637 - accuracy: 0.0068\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0636 - accuracy: 0.0068\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0635 - accuracy: 0.0068\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0634 - accuracy: 0.0068\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0633 - accuracy: 0.0068\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0633 - accuracy: 0.0068\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0632 - accuracy: 0.0068\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0631 - accuracy: 0.0068\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0630 - accuracy: 0.0068\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0630 - accuracy: 0.0068\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0629 - accuracy: 0.0068\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0628 - accuracy: 0.0068\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0628 - accuracy: 0.0068\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0627 - accuracy: 0.0068\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0626 - accuracy: 0.0068\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0625 - accuracy: 0.0068\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0625 - accuracy: 0.0068\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0624 - accuracy: 0.0068\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0623 - accuracy: 0.0068\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0623 - accuracy: 0.0068\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0622 - accuracy: 0.0068\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0622 - accuracy: 0.0068\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0621 - accuracy: 0.0068\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0620 - accuracy: 0.0068\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0620 - accuracy: 0.0068\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0619 - accuracy: 0.0068\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0619 - accuracy: 0.0068\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0618 - accuracy: 0.0068\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0617 - accuracy: 0.0068\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0617 - accuracy: 0.0068\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0616 - accuracy: 0.0068\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0616 - accuracy: 0.0068\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0615 - accuracy: 0.0068\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0615 - accuracy: 0.0068\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0614 - accuracy: 0.0068\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0614 - accuracy: 0.0068\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0613 - accuracy: 0.0068\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0612 - accuracy: 0.0068\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0612 - accuracy: 0.0068\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0611 - accuracy: 0.0068\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0717 - accuracy: 0.0204\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0715 - accuracy: 0.0068\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0713 - accuracy: 0.0068\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0710 - accuracy: 0.0068\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0709 - accuracy: 0.0068\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0707 - accuracy: 0.0068\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0705 - accuracy: 0.0068\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0703 - accuracy: 0.0068\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0701 - accuracy: 0.0068\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0698 - accuracy: 0.0068\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0697 - accuracy: 0.0068\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0695 - accuracy: 0.0068\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0693 - accuracy: 0.0068\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0690 - accuracy: 0.0068\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0688 - accuracy: 0.0068\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0686 - accuracy: 0.0068\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0683 - accuracy: 0.0068\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0681 - accuracy: 0.0068\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0679 - accuracy: 0.0068\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0676 - accuracy: 0.0068\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0673 - accuracy: 0.0068\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0670 - accuracy: 0.0068\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0667 - accuracy: 0.0068\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0664 - accuracy: 0.0068\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0660 - accuracy: 0.0068\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0657 - accuracy: 0.0068\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0653 - accuracy: 0.0068\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0644 - accuracy: 0.0068\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0640 - accuracy: 0.0068\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0635 - accuracy: 0.0068\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0630 - accuracy: 0.0068\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0624 - accuracy: 0.0068\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0618 - accuracy: 0.0476\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0612 - accuracy: 0.0476\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0606 - accuracy: 0.0476\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0599 - accuracy: 0.0476\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0592 - accuracy: 0.0476\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0585 - accuracy: 0.0476\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0578 - accuracy: 0.0476\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0570 - accuracy: 0.0476\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0562 - accuracy: 0.0476\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0554 - accuracy: 0.0476\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0546 - accuracy: 0.0476\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0537 - accuracy: 0.0476\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0529 - accuracy: 0.0476\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0520 - accuracy: 0.0476\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0511 - accuracy: 0.0476\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0502 - accuracy: 0.0476\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0492 - accuracy: 0.0476\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0483 - accuracy: 0.0476\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0473 - accuracy: 0.0476\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0464 - accuracy: 0.0476\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0454 - accuracy: 0.0476\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0445 - accuracy: 0.0476\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0435 - accuracy: 0.0476\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0426 - accuracy: 0.0476\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0417 - accuracy: 0.0476\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0408 - accuracy: 0.0476\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0398 - accuracy: 0.0476\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0390 - accuracy: 0.0476\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0381 - accuracy: 0.0476\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0372 - accuracy: 0.0476\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0363 - accuracy: 0.0476\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0355 - accuracy: 0.0476\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0346 - accuracy: 0.0476\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0339 - accuracy: 0.0476\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0330 - accuracy: 0.0476\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0323 - accuracy: 0.0476\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0315 - accuracy: 0.0476\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0308 - accuracy: 0.0476\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0300 - accuracy: 0.0476\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0293 - accuracy: 0.0476\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0286 - accuracy: 0.0476\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0280 - accuracy: 0.0476\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0273 - accuracy: 0.0476\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0267 - accuracy: 0.0476\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0260 - accuracy: 0.0476\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0255 - accuracy: 0.0476\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0249 - accuracy: 0.0476\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0243 - accuracy: 0.0476\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0238 - accuracy: 0.0476\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0233 - accuracy: 0.0476\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0228 - accuracy: 0.0476\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0223 - accuracy: 0.0476\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0218 - accuracy: 0.0476\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0213 - accuracy: 0.0476\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0209 - accuracy: 0.0476\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0205 - accuracy: 0.0476\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0201 - accuracy: 0.0476\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0196 - accuracy: 0.0476\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0193 - accuracy: 0.0476\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0189 - accuracy: 0.0476\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0185 - accuracy: 0.0476\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0182 - accuracy: 0.0476\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0179 - accuracy: 0.0476\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0175 - accuracy: 0.0476\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0172 - accuracy: 0.0476\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0169 - accuracy: 0.0476\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0166 - accuracy: 0.0476\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 1s 4ms/step - loss: 0.0721 - accuracy: 0.0000e+00\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0718 - accuracy: 0.0000e+00\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0715 - accuracy: 0.0000e+00\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0713 - accuracy: 0.0000e+00\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0710 - accuracy: 0.0000e+00\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0707 - accuracy: 0.0000e+00\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0704 - accuracy: 0.0000e+00\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0701 - accuracy: 0.0000e+00\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0697 - accuracy: 0.0000e+00\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0694 - accuracy: 0.0000e+00\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0690 - accuracy: 0.0000e+00\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0686 - accuracy: 0.0000e+00\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0681 - accuracy: 0.0000e+00\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0676 - accuracy: 0.0000e+00\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0670 - accuracy: 0.0000e+00\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0664 - accuracy: 0.0000e+00\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0657 - accuracy: 0.0000e+00\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0650 - accuracy: 0.0000e+00\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0642 - accuracy: 0.0000e+00\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0633 - accuracy: 0.0000e+00\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0625 - accuracy: 0.0000e+00\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0616 - accuracy: 0.0000e+00\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0607 - accuracy: 0.0000e+00\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0597 - accuracy: 0.0000e+00\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0588 - accuracy: 0.0000e+00\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0576 - accuracy: 0.0000e+00\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0566 - accuracy: 0.0000e+00\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0556 - accuracy: 0.0000e+00\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0546 - accuracy: 0.0000e+00\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0535 - accuracy: 0.0000e+00\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0525 - accuracy: 0.0000e+00\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0514 - accuracy: 0.0000e+00\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0504 - accuracy: 0.0000e+00\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0494 - accuracy: 0.0000e+00\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0484 - accuracy: 0.0000e+00\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0475 - accuracy: 0.0000e+00\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0467 - accuracy: 0.0000e+00\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0460 - accuracy: 0.0000e+00\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0453 - accuracy: 0.0000e+00\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0446 - accuracy: 0.0000e+00\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0440 - accuracy: 0.0000e+00\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0435 - accuracy: 0.0000e+00\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0429 - accuracy: 0.0000e+00\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0425 - accuracy: 0.0000e+00\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0421 - accuracy: 0.0000e+00\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0416 - accuracy: 0.0000e+00\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0412 - accuracy: 0.0000e+00\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0408 - accuracy: 0.0000e+00\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0404 - accuracy: 0.0000e+00\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0400 - accuracy: 0.0000e+00\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0396 - accuracy: 0.0000e+00\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0392 - accuracy: 0.0000e+00\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0388 - accuracy: 0.0000e+00\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0384 - accuracy: 0.0000e+00\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0381 - accuracy: 0.0000e+00\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0378 - accuracy: 0.0000e+00\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0375 - accuracy: 0.0000e+00\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0371 - accuracy: 0.0000e+00\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0368 - accuracy: 0.0000e+00\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0365 - accuracy: 0.0000e+00\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0362 - accuracy: 0.0000e+00\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0360 - accuracy: 0.0000e+00\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0357 - accuracy: 0.0000e+00\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0354 - accuracy: 0.0000e+00\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0351 - accuracy: 0.0000e+00\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0348 - accuracy: 0.0000e+00\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0346 - accuracy: 0.0000e+00\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0343 - accuracy: 0.0000e+00\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0341 - accuracy: 0.0000e+00\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0338 - accuracy: 0.0000e+00\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0335 - accuracy: 0.0000e+00\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0333 - accuracy: 0.0000e+00\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0331 - accuracy: 0.0068\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0328 - accuracy: 0.0340\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0326 - accuracy: 0.0340\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0323 - accuracy: 0.0340\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0321 - accuracy: 0.0340\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0319 - accuracy: 0.0340\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0316 - accuracy: 0.0340\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0314 - accuracy: 0.0340\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0311 - accuracy: 0.0340\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0309 - accuracy: 0.0340\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0307 - accuracy: 0.0340\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0305 - accuracy: 0.0340\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0302 - accuracy: 0.0340\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0300 - accuracy: 0.0340\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0298 - accuracy: 0.0340\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0295 - accuracy: 0.0340\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0293 - accuracy: 0.0340\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0291 - accuracy: 0.0340\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0289 - accuracy: 0.0340\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0286 - accuracy: 0.0340\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0285 - accuracy: 0.0340\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0282 - accuracy: 0.0340\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0280 - accuracy: 0.0340\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0278 - accuracy: 0.0340\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0276 - accuracy: 0.0340\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0274 - accuracy: 0.0340\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0272 - accuracy: 0.0340\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0269 - accuracy: 0.0340\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 1s 4ms/step - loss: 0.0655 - accuracy: 0.0136\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0652 - accuracy: 0.0068\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0646 - accuracy: 0.0068\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0643 - accuracy: 0.0068\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0640 - accuracy: 0.0068\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0636 - accuracy: 0.0068\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0633 - accuracy: 0.0068\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0629 - accuracy: 0.0068\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0625 - accuracy: 0.0068\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0621 - accuracy: 0.0068\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0617 - accuracy: 0.0068\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0613 - accuracy: 0.0068\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0608 - accuracy: 0.0068\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0603 - accuracy: 0.0068\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0598 - accuracy: 0.0068\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0592 - accuracy: 0.0068\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0586 - accuracy: 0.0068\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0581 - accuracy: 0.0068\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0574 - accuracy: 0.0068\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0568 - accuracy: 0.0068\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0561 - accuracy: 0.0068\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0555 - accuracy: 0.0068\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0547 - accuracy: 0.0068\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0540 - accuracy: 0.0068\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0532 - accuracy: 0.0068\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0524 - accuracy: 0.0068\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0516 - accuracy: 0.0068\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0507 - accuracy: 0.0068\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0498 - accuracy: 0.0068\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0490 - accuracy: 0.0068\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0481 - accuracy: 0.0068\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0471 - accuracy: 0.0068\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0461 - accuracy: 0.0068\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0451 - accuracy: 0.0068\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0441 - accuracy: 0.0068\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0429 - accuracy: 0.0068\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0419 - accuracy: 0.0068\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0410 - accuracy: 0.0068\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0399 - accuracy: 0.0204\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0389 - accuracy: 0.0408\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0379 - accuracy: 0.0408\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0369 - accuracy: 0.0408\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0360 - accuracy: 0.0408\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0350 - accuracy: 0.0408\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0341 - accuracy: 0.0476\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0333 - accuracy: 0.0476\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0323 - accuracy: 0.0476\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0314 - accuracy: 0.0476\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0305 - accuracy: 0.0476\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0297 - accuracy: 0.0476\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0288 - accuracy: 0.0476\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0280 - accuracy: 0.0476\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0272 - accuracy: 0.0476\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0264 - accuracy: 0.0476\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0256 - accuracy: 0.0476\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0249 - accuracy: 0.0476\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0241 - accuracy: 0.0476\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0235 - accuracy: 0.0476\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0228 - accuracy: 0.0476\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0221 - accuracy: 0.0476\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0214 - accuracy: 0.0476\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0207 - accuracy: 0.0476\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0202 - accuracy: 0.0476\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0197 - accuracy: 0.0476\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0190 - accuracy: 0.0476\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0185 - accuracy: 0.0476\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0180 - accuracy: 0.0476\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0175 - accuracy: 0.0476\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0171 - accuracy: 0.0476\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0166 - accuracy: 0.0476\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0162 - accuracy: 0.0476\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0158 - accuracy: 0.0476\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0154 - accuracy: 0.0476\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0151 - accuracy: 0.0476\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0147 - accuracy: 0.0476\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0144 - accuracy: 0.0476\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0141 - accuracy: 0.0476\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0138 - accuracy: 0.0476\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0135 - accuracy: 0.0476\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0132 - accuracy: 0.0476\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0130 - accuracy: 0.0476\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0128 - accuracy: 0.0476\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0125 - accuracy: 0.0476\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0122 - accuracy: 0.0476\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0120 - accuracy: 0.0476\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0118 - accuracy: 0.0476\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0116 - accuracy: 0.0476\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0114 - accuracy: 0.0476\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0113 - accuracy: 0.0476\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0111 - accuracy: 0.0476\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0109 - accuracy: 0.0476\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0107 - accuracy: 0.0476\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0106 - accuracy: 0.0476\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0104 - accuracy: 0.0476\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0103 - accuracy: 0.0476\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0102 - accuracy: 0.0476\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0100 - accuracy: 0.0476\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0099 - accuracy: 0.0476\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0098 - accuracy: 0.0476\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "5/5 [==============================] - 1s 5ms/step - loss: 0.0698 - accuracy: 0.0068\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0696 - accuracy: 0.0068\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0693 - accuracy: 0.0068\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0692 - accuracy: 0.0068\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0689 - accuracy: 0.0068\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0687 - accuracy: 0.0068\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0685 - accuracy: 0.0068\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0682 - accuracy: 0.0068\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0680 - accuracy: 0.0068\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0677 - accuracy: 0.0068\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0675 - accuracy: 0.0068\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0672 - accuracy: 0.0068\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0669 - accuracy: 0.0068\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0666 - accuracy: 0.0068\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0663 - accuracy: 0.0068\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0659 - accuracy: 0.0068\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0656 - accuracy: 0.0068\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0652 - accuracy: 0.0068\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0648 - accuracy: 0.0068\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0643 - accuracy: 0.0068\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0640 - accuracy: 0.0068\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0634 - accuracy: 0.0068\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0629 - accuracy: 0.0068\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0624 - accuracy: 0.0068\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0618 - accuracy: 0.0068\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0612 - accuracy: 0.0068\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0607 - accuracy: 0.0068\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0600 - accuracy: 0.0068\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0594 - accuracy: 0.0068\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0589 - accuracy: 0.0068\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0581 - accuracy: 0.0068\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0575 - accuracy: 0.0068\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0570 - accuracy: 0.0068\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0565 - accuracy: 0.0068\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0558 - accuracy: 0.0068\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0553 - accuracy: 0.0068\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0547 - accuracy: 0.0068\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0542 - accuracy: 0.0068\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0537 - accuracy: 0.0068\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0532 - accuracy: 0.0068\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0526 - accuracy: 0.0068\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0521 - accuracy: 0.0068\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0517 - accuracy: 0.0068\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0512 - accuracy: 0.0068\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0507 - accuracy: 0.0068\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0502 - accuracy: 0.0068\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0498 - accuracy: 0.0068\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0493 - accuracy: 0.0068\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0489 - accuracy: 0.0068\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0484 - accuracy: 0.0068\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0479 - accuracy: 0.0068\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0474 - accuracy: 0.0068\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0470 - accuracy: 0.0068\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0465 - accuracy: 0.0068\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0461 - accuracy: 0.0068\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0456 - accuracy: 0.0068\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0450 - accuracy: 0.0068\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0446 - accuracy: 0.0068\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0442 - accuracy: 0.0068\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0437 - accuracy: 0.0068\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0433 - accuracy: 0.0068\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0428 - accuracy: 0.0068\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0424 - accuracy: 0.0068\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0419 - accuracy: 0.0068\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0415 - accuracy: 0.0068\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0411 - accuracy: 0.0068\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0407 - accuracy: 0.0068\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0403 - accuracy: 0.0068\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0398 - accuracy: 0.0068\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0394 - accuracy: 0.0068\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0390 - accuracy: 0.0068\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0386 - accuracy: 0.0068\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0382 - accuracy: 0.0068\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0379 - accuracy: 0.0068\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0376 - accuracy: 0.0068\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0373 - accuracy: 0.0068\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0371 - accuracy: 0.0068\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0368 - accuracy: 0.0068\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0365 - accuracy: 0.0068\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0362 - accuracy: 0.0068\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0360 - accuracy: 0.0068\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0357 - accuracy: 0.0272\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0354 - accuracy: 0.0408\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0352 - accuracy: 0.0408\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0349 - accuracy: 0.0408\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0347 - accuracy: 0.0408\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0344 - accuracy: 0.0408\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0341 - accuracy: 0.0408\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0339 - accuracy: 0.0408\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0337 - accuracy: 0.0408\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0334 - accuracy: 0.0408\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0332 - accuracy: 0.0408\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0330 - accuracy: 0.0408\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0327 - accuracy: 0.0408\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0325 - accuracy: 0.0408\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0322 - accuracy: 0.0408\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0320 - accuracy: 0.0408\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0317 - accuracy: 0.0408\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0315 - accuracy: 0.0408\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0313 - accuracy: 0.0408\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 1s 6ms/step - loss: 0.0710 - accuracy: 0.0068\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0707 - accuracy: 0.0068\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0704 - accuracy: 0.0068\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0701 - accuracy: 0.0068\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0698 - accuracy: 0.0068\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0695 - accuracy: 0.0068\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0692 - accuracy: 0.0068\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0689 - accuracy: 0.0068\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0686 - accuracy: 0.0068\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0682 - accuracy: 0.0068\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0679 - accuracy: 0.0068\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0675 - accuracy: 0.0068\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0671 - accuracy: 0.0068\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0667 - accuracy: 0.0068\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0663 - accuracy: 0.0068\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0660 - accuracy: 0.0068\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0655 - accuracy: 0.0068\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0651 - accuracy: 0.0068\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0642 - accuracy: 0.0068\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0637 - accuracy: 0.0068\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0632 - accuracy: 0.0068\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0628 - accuracy: 0.0068\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0623 - accuracy: 0.0068\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0618 - accuracy: 0.0068\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0612 - accuracy: 0.0068\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0607 - accuracy: 0.0068\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0601 - accuracy: 0.0068\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0595 - accuracy: 0.0068\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0589 - accuracy: 0.0068\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0584 - accuracy: 0.0068\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0577 - accuracy: 0.0068\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0570 - accuracy: 0.0068\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0564 - accuracy: 0.0068\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0557 - accuracy: 0.0068\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0550 - accuracy: 0.0068\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0543 - accuracy: 0.0068\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0535 - accuracy: 0.0068\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0528 - accuracy: 0.0068\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0520 - accuracy: 0.0068\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0512 - accuracy: 0.0068\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0503 - accuracy: 0.0068\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0495 - accuracy: 0.0068\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0487 - accuracy: 0.0068\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0479 - accuracy: 0.0068\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0470 - accuracy: 0.0068\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0462 - accuracy: 0.0068\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0454 - accuracy: 0.0068\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0446 - accuracy: 0.0068\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0437 - accuracy: 0.0068\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0429 - accuracy: 0.0068\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0421 - accuracy: 0.0068\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0412 - accuracy: 0.0068\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0404 - accuracy: 0.0068\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0395 - accuracy: 0.0338\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0386 - accuracy: 0.0473\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0377 - accuracy: 0.0473\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0369 - accuracy: 0.0473\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0360 - accuracy: 0.0473\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0351 - accuracy: 0.0473\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0342 - accuracy: 0.0473\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0333 - accuracy: 0.0473\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0325 - accuracy: 0.0473\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0316 - accuracy: 0.0473\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0307 - accuracy: 0.0473\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0299 - accuracy: 0.0473\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0290 - accuracy: 0.0473\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0282 - accuracy: 0.0473\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0273 - accuracy: 0.0473\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0265 - accuracy: 0.0473\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0257 - accuracy: 0.0473\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0249 - accuracy: 0.0473\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0242 - accuracy: 0.0473\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0234 - accuracy: 0.0473\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0226 - accuracy: 0.0473\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0220 - accuracy: 0.0473\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0213 - accuracy: 0.0473\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0207 - accuracy: 0.0473\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0201 - accuracy: 0.0473\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0194 - accuracy: 0.0473\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0189 - accuracy: 0.0473\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0183 - accuracy: 0.0473\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0179 - accuracy: 0.0473\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0173 - accuracy: 0.0473\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0169 - accuracy: 0.0473\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0164 - accuracy: 0.0473\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0160 - accuracy: 0.0473\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0156 - accuracy: 0.0473\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0152 - accuracy: 0.0473\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0149 - accuracy: 0.0473\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0145 - accuracy: 0.0473\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0142 - accuracy: 0.0473\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0139 - accuracy: 0.0473\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0136 - accuracy: 0.0473\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0133 - accuracy: 0.0473\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0131 - accuracy: 0.0473\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0128 - accuracy: 0.0473\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0126 - accuracy: 0.0473\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0124 - accuracy: 0.0473\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0122 - accuracy: 0.0473\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "5/5 [==============================] - 1s 4ms/step - loss: 0.0718 - accuracy: 0.0068\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0717 - accuracy: 0.0068\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0716 - accuracy: 0.0068\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0715 - accuracy: 0.0068\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0714 - accuracy: 0.0068\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0713 - accuracy: 0.0068\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0712 - accuracy: 0.0068\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0711 - accuracy: 0.0068\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0711 - accuracy: 0.0068\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0710 - accuracy: 0.0068\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0709 - accuracy: 0.0068\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0708 - accuracy: 0.0068\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0707 - accuracy: 0.0068\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0707 - accuracy: 0.0068\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0706 - accuracy: 0.0068\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0705 - accuracy: 0.0068\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0704 - accuracy: 0.0068\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0704 - accuracy: 0.0068\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0703 - accuracy: 0.0068\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0702 - accuracy: 0.0068\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0701 - accuracy: 0.0068\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0701 - accuracy: 0.0068\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0700 - accuracy: 0.0068\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0699 - accuracy: 0.0068\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0699 - accuracy: 0.0068\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0698 - accuracy: 0.0068\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0697 - accuracy: 0.0068\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0697 - accuracy: 0.0068\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0696 - accuracy: 0.0068\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0695 - accuracy: 0.0068\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0695 - accuracy: 0.0068\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0694 - accuracy: 0.0068\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0694 - accuracy: 0.0068\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0693 - accuracy: 0.0068\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0692 - accuracy: 0.0068\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0692 - accuracy: 0.0068\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0691 - accuracy: 0.0068\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0691 - accuracy: 0.0068\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0690 - accuracy: 0.0068\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0689 - accuracy: 0.0068\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0689 - accuracy: 0.0068\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0688 - accuracy: 0.0068\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0688 - accuracy: 0.0068\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0687 - accuracy: 0.0068\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0687 - accuracy: 0.0068\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0686 - accuracy: 0.0068\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0686 - accuracy: 0.0068\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0685 - accuracy: 0.0068\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0685 - accuracy: 0.0068\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0684 - accuracy: 0.0068\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0684 - accuracy: 0.0068\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0683 - accuracy: 0.0068\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0683 - accuracy: 0.0068\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0682 - accuracy: 0.0068\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0682 - accuracy: 0.0068\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0681 - accuracy: 0.0068\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0681 - accuracy: 0.0068\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0680 - accuracy: 0.0068\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0680 - accuracy: 0.0068\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0679 - accuracy: 0.0068\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0679 - accuracy: 0.0068\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0679 - accuracy: 0.0068\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0678 - accuracy: 0.0068\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0678 - accuracy: 0.0068\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0677 - accuracy: 0.0068\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0677 - accuracy: 0.0068\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0677 - accuracy: 0.0068\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0676 - accuracy: 0.0068\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0676 - accuracy: 0.0068\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0675 - accuracy: 0.0068\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0675 - accuracy: 0.0068\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0675 - accuracy: 0.0068\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0674 - accuracy: 0.0068\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0674 - accuracy: 0.0068\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0674 - accuracy: 0.0068\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0673 - accuracy: 0.0068\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0673 - accuracy: 0.0068\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0672 - accuracy: 0.0068\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0672 - accuracy: 0.0068\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0672 - accuracy: 0.0068\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0671 - accuracy: 0.0068\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0671 - accuracy: 0.0068\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0671 - accuracy: 0.0068\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0670 - accuracy: 0.0068\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0670 - accuracy: 0.0068\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0670 - accuracy: 0.0068\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0670 - accuracy: 0.0068\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0669 - accuracy: 0.0068\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0669 - accuracy: 0.0068\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0669 - accuracy: 0.0068\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0668 - accuracy: 0.0068\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0668 - accuracy: 0.0068\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0668 - accuracy: 0.0068\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0667 - accuracy: 0.0068\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0667 - accuracy: 0.0068\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0667 - accuracy: 0.0068\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0667 - accuracy: 0.0068\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0666 - accuracy: 0.0068\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0666 - accuracy: 0.0068\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0666 - accuracy: 0.0068\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 1s 5ms/step - loss: 0.0721 - accuracy: 0.0068\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0720 - accuracy: 0.0000e+00\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0719 - accuracy: 0.0000e+00\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0718 - accuracy: 0.0000e+00\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0717 - accuracy: 0.0000e+00\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0715 - accuracy: 0.0000e+00\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0714 - accuracy: 0.0000e+00\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0713 - accuracy: 0.0000e+00\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0712 - accuracy: 0.0000e+00\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0711 - accuracy: 0.0000e+00\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0710 - accuracy: 0.0000e+00\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0709 - accuracy: 0.0000e+00\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0708 - accuracy: 0.0000e+00\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0707 - accuracy: 0.0000e+00\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0706 - accuracy: 0.0000e+00\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0705 - accuracy: 0.0000e+00\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0704 - accuracy: 0.0000e+00\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0703 - accuracy: 0.0000e+00\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0702 - accuracy: 0.0000e+00\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0701 - accuracy: 0.0000e+00\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0700 - accuracy: 0.0000e+00\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0699 - accuracy: 0.0000e+00\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0698 - accuracy: 0.0000e+00\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0697 - accuracy: 0.0000e+00\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0696 - accuracy: 0.0000e+00\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0695 - accuracy: 0.0000e+00\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0695 - accuracy: 0.0000e+00\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0694 - accuracy: 0.0000e+00\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0693 - accuracy: 0.0000e+00\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0692 - accuracy: 0.0000e+00\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0691 - accuracy: 0.0000e+00\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0690 - accuracy: 0.0000e+00\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0690 - accuracy: 0.0000e+00\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0689 - accuracy: 0.0000e+00\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0688 - accuracy: 0.0000e+00\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0687 - accuracy: 0.0000e+00\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0686 - accuracy: 0.0000e+00\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0686 - accuracy: 0.0000e+00\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0685 - accuracy: 0.0000e+00\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0684 - accuracy: 0.0000e+00\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0683 - accuracy: 0.0000e+00\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0683 - accuracy: 0.0000e+00\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0682 - accuracy: 0.0000e+00\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0681 - accuracy: 0.0000e+00\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0681 - accuracy: 0.0000e+00\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0680 - accuracy: 0.0000e+00\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0679 - accuracy: 0.0000e+00\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0679 - accuracy: 0.0000e+00\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0678 - accuracy: 0.0000e+00\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0677 - accuracy: 0.0000e+00\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0677 - accuracy: 0.0000e+00\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0676 - accuracy: 0.0000e+00\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0675 - accuracy: 0.0000e+00\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0675 - accuracy: 0.0000e+00\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0674 - accuracy: 0.0000e+00\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0674 - accuracy: 0.0000e+00\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0673 - accuracy: 0.0000e+00\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0672 - accuracy: 0.0000e+00\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0672 - accuracy: 0.0000e+00\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0671 - accuracy: 0.0000e+00\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0671 - accuracy: 0.0000e+00\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0670 - accuracy: 0.0000e+00\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0669 - accuracy: 0.0000e+00\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0669 - accuracy: 0.0000e+00\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0668 - accuracy: 0.0000e+00\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0668 - accuracy: 0.0000e+00\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0667 - accuracy: 0.0000e+00\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0667 - accuracy: 0.0000e+00\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0666 - accuracy: 0.0000e+00\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0666 - accuracy: 0.0000e+00\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0665 - accuracy: 0.0000e+00\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0665 - accuracy: 0.0000e+00\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0664 - accuracy: 0.0000e+00\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0664 - accuracy: 0.0000e+00\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0663 - accuracy: 0.0000e+00\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0663 - accuracy: 0.0000e+00\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0662 - accuracy: 0.0000e+00\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0662 - accuracy: 0.0000e+00\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0662 - accuracy: 0.0000e+00\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0661 - accuracy: 0.0000e+00\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0661 - accuracy: 0.0000e+00\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0660 - accuracy: 0.0000e+00\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0660 - accuracy: 0.0000e+00\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0659 - accuracy: 0.0000e+00\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0659 - accuracy: 0.0000e+00\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0658 - accuracy: 0.0000e+00\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0658 - accuracy: 0.0000e+00\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0658 - accuracy: 0.0000e+00\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0657 - accuracy: 0.0000e+00\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0657 - accuracy: 0.0000e+00\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0656 - accuracy: 0.0000e+00\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0656 - accuracy: 0.0000e+00\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0656 - accuracy: 0.0000e+00\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0655 - accuracy: 0.0000e+00\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0655 - accuracy: 0.0000e+00\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0655 - accuracy: 0.0000e+00\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0654 - accuracy: 0.0000e+00\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0654 - accuracy: 0.0000e+00\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0654 - accuracy: 0.0000e+00\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0653 - accuracy: 0.0000e+00\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 1s 4ms/step - loss: 0.0656 - accuracy: 0.0136\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0654 - accuracy: 0.0068\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0652 - accuracy: 0.0068\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0651 - accuracy: 0.0068\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0648 - accuracy: 0.0068\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0646 - accuracy: 0.0068\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0645 - accuracy: 0.0068\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0643 - accuracy: 0.0068\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0642 - accuracy: 0.0068\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0640 - accuracy: 0.0068\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0639 - accuracy: 0.0068\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0638 - accuracy: 0.0068\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0636 - accuracy: 0.0068\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0635 - accuracy: 0.0068\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0634 - accuracy: 0.0068\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0632 - accuracy: 0.0068\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0631 - accuracy: 0.0068\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0630 - accuracy: 0.0068\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0628 - accuracy: 0.0068\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0627 - accuracy: 0.0068\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0626 - accuracy: 0.0068\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0625 - accuracy: 0.0068\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0624 - accuracy: 0.0068\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0622 - accuracy: 0.0068\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0621 - accuracy: 0.0068\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0620 - accuracy: 0.0068\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0619 - accuracy: 0.0068\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0618 - accuracy: 0.0068\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0617 - accuracy: 0.0068\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0616 - accuracy: 0.0068\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0614 - accuracy: 0.0068\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0613 - accuracy: 0.0068\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0612 - accuracy: 0.0068\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0611 - accuracy: 0.0068\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0610 - accuracy: 0.0068\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0609 - accuracy: 0.0068\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0608 - accuracy: 0.0068\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0607 - accuracy: 0.0068\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0606 - accuracy: 0.0068\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0605 - accuracy: 0.0068\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0604 - accuracy: 0.0068\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0603 - accuracy: 0.0068\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0602 - accuracy: 0.0068\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0601 - accuracy: 0.0068\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0601 - accuracy: 0.0068\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0600 - accuracy: 0.0068\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0599 - accuracy: 0.0068\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0598 - accuracy: 0.0068\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0597 - accuracy: 0.0068\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0596 - accuracy: 0.0068\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0595 - accuracy: 0.0068\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0594 - accuracy: 0.0068\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0594 - accuracy: 0.0068\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0593 - accuracy: 0.0068\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0592 - accuracy: 0.0068\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0591 - accuracy: 0.0068\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0590 - accuracy: 0.0068\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0590 - accuracy: 0.0068\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0589 - accuracy: 0.0068\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0588 - accuracy: 0.0068\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0587 - accuracy: 0.0068\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0587 - accuracy: 0.0068\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0586 - accuracy: 0.0068\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0585 - accuracy: 0.0068\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0584 - accuracy: 0.0068\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0584 - accuracy: 0.0068\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0583 - accuracy: 0.0068\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0582 - accuracy: 0.0068\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0582 - accuracy: 0.0068\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0581 - accuracy: 0.0068\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0580 - accuracy: 0.0068\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0580 - accuracy: 0.0068\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0579 - accuracy: 0.0068\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0579 - accuracy: 0.0068\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0578 - accuracy: 0.0068\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0577 - accuracy: 0.0068\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0577 - accuracy: 0.0068\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0576 - accuracy: 0.0068\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0575 - accuracy: 0.0068\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0575 - accuracy: 0.0068\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0574 - accuracy: 0.0068\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0574 - accuracy: 0.0068\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0573 - accuracy: 0.0068\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0573 - accuracy: 0.0068\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0572 - accuracy: 0.0068\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0572 - accuracy: 0.0068\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0571 - accuracy: 0.0068\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0570 - accuracy: 0.0068\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0570 - accuracy: 0.0068\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0569 - accuracy: 0.0068\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0569 - accuracy: 0.0068\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0568 - accuracy: 0.0068\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0568 - accuracy: 0.0068\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0567 - accuracy: 0.0068\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0567 - accuracy: 0.0068\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0566 - accuracy: 0.0068\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0566 - accuracy: 0.0068\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0566 - accuracy: 0.0068\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0565 - accuracy: 0.0068\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0698 - accuracy: 0.0272\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0697 - accuracy: 0.0068\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0696 - accuracy: 0.0068\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0695 - accuracy: 0.0068\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0694 - accuracy: 0.0068\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0693 - accuracy: 0.0068\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0693 - accuracy: 0.0068\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0692 - accuracy: 0.0068\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0691 - accuracy: 0.0068\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0690 - accuracy: 0.0068\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0689 - accuracy: 0.0068\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0688 - accuracy: 0.0068\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0687 - accuracy: 0.0068\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0686 - accuracy: 0.0068\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0685 - accuracy: 0.0068\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0685 - accuracy: 0.0068\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0684 - accuracy: 0.0068\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0683 - accuracy: 0.0068\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0682 - accuracy: 0.0068\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0681 - accuracy: 0.0068\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0681 - accuracy: 0.0068\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0680 - accuracy: 0.0068\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0679 - accuracy: 0.0068\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0678 - accuracy: 0.0068\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0678 - accuracy: 0.0068\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0677 - accuracy: 0.0068\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0676 - accuracy: 0.0068\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0675 - accuracy: 0.0068\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0675 - accuracy: 0.0068\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0674 - accuracy: 0.0068\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0673 - accuracy: 0.0068\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0673 - accuracy: 0.0068\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0672 - accuracy: 0.0068\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0671 - accuracy: 0.0068\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0671 - accuracy: 0.0068\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0670 - accuracy: 0.0068\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0669 - accuracy: 0.0068\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0669 - accuracy: 0.0068\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0668 - accuracy: 0.0068\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0667 - accuracy: 0.0068\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0667 - accuracy: 0.0068\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0666 - accuracy: 0.0068\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0666 - accuracy: 0.0068\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0665 - accuracy: 0.0068\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0665 - accuracy: 0.0068\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0664 - accuracy: 0.0068\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0663 - accuracy: 0.0068\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0663 - accuracy: 0.0068\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0662 - accuracy: 0.0068\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0662 - accuracy: 0.0068\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0661 - accuracy: 0.0068\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0661 - accuracy: 0.0068\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0660 - accuracy: 0.0068\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0660 - accuracy: 0.0068\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0659 - accuracy: 0.0068\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0659 - accuracy: 0.0068\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0658 - accuracy: 0.0068\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0658 - accuracy: 0.0068\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0657 - accuracy: 0.0068\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0657 - accuracy: 0.0068\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0656 - accuracy: 0.0068\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0656 - accuracy: 0.0068\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0655 - accuracy: 0.0068\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0655 - accuracy: 0.0068\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0654 - accuracy: 0.0068\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0654 - accuracy: 0.0068\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0653 - accuracy: 0.0068\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0653 - accuracy: 0.0068\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0653 - accuracy: 0.0068\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0652 - accuracy: 0.0068\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0652 - accuracy: 0.0068\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0651 - accuracy: 0.0068\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0651 - accuracy: 0.0068\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0650 - accuracy: 0.0068\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0650 - accuracy: 0.0068\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0650 - accuracy: 0.0068\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0648 - accuracy: 0.0068\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0648 - accuracy: 0.0068\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0646 - accuracy: 0.0068\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0646 - accuracy: 0.0068\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0646 - accuracy: 0.0068\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0645 - accuracy: 0.0068\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0645 - accuracy: 0.0068\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0645 - accuracy: 0.0068\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0644 - accuracy: 0.0068\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0644 - accuracy: 0.0068\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0644 - accuracy: 0.0068\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0643 - accuracy: 0.0068\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0643 - accuracy: 0.0068\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0643 - accuracy: 0.0068\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0643 - accuracy: 0.0068\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0642 - accuracy: 0.0068\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0642 - accuracy: 0.0068\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0642 - accuracy: 0.0068\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0711 - accuracy: 0.0135\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0709 - accuracy: 0.0068\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0707 - accuracy: 0.0068\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0705 - accuracy: 0.0068\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0704 - accuracy: 0.0068\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0702 - accuracy: 0.0068\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0700 - accuracy: 0.0068\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0699 - accuracy: 0.0068\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0697 - accuracy: 0.0068\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0696 - accuracy: 0.0068\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0694 - accuracy: 0.0068\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0693 - accuracy: 0.0068\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0691 - accuracy: 0.0068\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0690 - accuracy: 0.0068\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0688 - accuracy: 0.0068\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0687 - accuracy: 0.0068\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0685 - accuracy: 0.0068\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0684 - accuracy: 0.0068\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0682 - accuracy: 0.0068\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0681 - accuracy: 0.0068\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0680 - accuracy: 0.0068\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0678 - accuracy: 0.0068\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0677 - accuracy: 0.0068\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0676 - accuracy: 0.0068\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0674 - accuracy: 0.0068\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0673 - accuracy: 0.0068\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0672 - accuracy: 0.0068\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0670 - accuracy: 0.0068\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0669 - accuracy: 0.0068\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0668 - accuracy: 0.0068\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0667 - accuracy: 0.0068\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0666 - accuracy: 0.0068\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0664 - accuracy: 0.0068\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0663 - accuracy: 0.0068\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0662 - accuracy: 0.0068\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0661 - accuracy: 0.0068\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0660 - accuracy: 0.0068\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0659 - accuracy: 0.0068\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0658 - accuracy: 0.0068\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0657 - accuracy: 0.0068\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0656 - accuracy: 0.0068\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0654 - accuracy: 0.0068\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0653 - accuracy: 0.0068\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0652 - accuracy: 0.0068\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0651 - accuracy: 0.0068\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0650 - accuracy: 0.0068\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0648 - accuracy: 0.0068\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0646 - accuracy: 0.0068\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0645 - accuracy: 0.0068\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0645 - accuracy: 0.0068\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0644 - accuracy: 0.0068\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0643 - accuracy: 0.0068\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0642 - accuracy: 0.0068\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0641 - accuracy: 0.0068\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0640 - accuracy: 0.0068\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0639 - accuracy: 0.0068\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0638 - accuracy: 0.0068\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0638 - accuracy: 0.0068\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0637 - accuracy: 0.0068\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0636 - accuracy: 0.0068\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0635 - accuracy: 0.0068\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0634 - accuracy: 0.0068\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0634 - accuracy: 0.0068\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0633 - accuracy: 0.0068\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0632 - accuracy: 0.0068\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0631 - accuracy: 0.0068\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0630 - accuracy: 0.0068\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0630 - accuracy: 0.0068\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0629 - accuracy: 0.0068\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0628 - accuracy: 0.0068\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0628 - accuracy: 0.0068\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0627 - accuracy: 0.0068\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0626 - accuracy: 0.0068\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0626 - accuracy: 0.0068\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0625 - accuracy: 0.0068\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0624 - accuracy: 0.0068\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0624 - accuracy: 0.0068\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0623 - accuracy: 0.0068\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0622 - accuracy: 0.0068\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0622 - accuracy: 0.0068\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0621 - accuracy: 0.0068\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0620 - accuracy: 0.0068\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0620 - accuracy: 0.0068\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0619 - accuracy: 0.0068\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0619 - accuracy: 0.0068\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0618 - accuracy: 0.0068\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0617 - accuracy: 0.0068\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0617 - accuracy: 0.0068\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0616 - accuracy: 0.0068\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0616 - accuracy: 0.0068\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0615 - accuracy: 0.0068\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0615 - accuracy: 0.0068\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0614 - accuracy: 0.0068\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0614 - accuracy: 0.0068\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0613 - accuracy: 0.0068\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0612 - accuracy: 0.0068\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0612 - accuracy: 0.0068\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0611 - accuracy: 0.0068\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the train scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
            "  category=UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "19/19 [==============================] - 1s 3ms/step - loss: 0.0697 - accuracy: 0.0054\n",
            "Epoch 2/50\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0688 - accuracy: 0.0054\n",
            "Epoch 3/50\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0675 - accuracy: 0.0054\n",
            "Epoch 4/50\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0660 - accuracy: 0.0054\n",
            "Epoch 5/50\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0640 - accuracy: 0.0054\n",
            "Epoch 6/50\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0614 - accuracy: 0.0054\n",
            "Epoch 7/50\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0584 - accuracy: 0.0054\n",
            "Epoch 8/50\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0551 - accuracy: 0.0054\n",
            "Epoch 9/50\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0514 - accuracy: 0.0054\n",
            "Epoch 10/50\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0479 - accuracy: 0.0054\n",
            "Epoch 11/50\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0447 - accuracy: 0.0054\n",
            "Epoch 12/50\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0424 - accuracy: 0.0054\n",
            "Epoch 13/50\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0407 - accuracy: 0.0054\n",
            "Epoch 14/50\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0395 - accuracy: 0.0054\n",
            "Epoch 15/50\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0383 - accuracy: 0.0054\n",
            "Epoch 16/50\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0373 - accuracy: 0.0054\n",
            "Epoch 17/50\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0363 - accuracy: 0.0054\n",
            "Epoch 18/50\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0355 - accuracy: 0.0054\n",
            "Epoch 19/50\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0347 - accuracy: 0.0054\n",
            "Epoch 20/50\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0340 - accuracy: 0.0054\n",
            "Epoch 21/50\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0333 - accuracy: 0.0054\n",
            "Epoch 22/50\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0325 - accuracy: 0.0054\n",
            "Epoch 23/50\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0319 - accuracy: 0.0380\n",
            "Epoch 24/50\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0312 - accuracy: 0.0435\n",
            "Epoch 25/50\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0307 - accuracy: 0.0435\n",
            "Epoch 26/50\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0300 - accuracy: 0.0435\n",
            "Epoch 27/50\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0294 - accuracy: 0.0435\n",
            "Epoch 28/50\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0288 - accuracy: 0.0435\n",
            "Epoch 29/50\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0282 - accuracy: 0.0435\n",
            "Epoch 30/50\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0276 - accuracy: 0.0435\n",
            "Epoch 31/50\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0270 - accuracy: 0.0435\n",
            "Epoch 32/50\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0265 - accuracy: 0.0435\n",
            "Epoch 33/50\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0259 - accuracy: 0.0435\n",
            "Epoch 34/50\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0254 - accuracy: 0.0435\n",
            "Epoch 35/50\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0249 - accuracy: 0.0435\n",
            "Epoch 36/50\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0244 - accuracy: 0.0435\n",
            "Epoch 37/50\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0238 - accuracy: 0.0435\n",
            "Epoch 38/50\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0233 - accuracy: 0.0435\n",
            "Epoch 39/50\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0228 - accuracy: 0.0435\n",
            "Epoch 40/50\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0224 - accuracy: 0.0435\n",
            "Epoch 41/50\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0220 - accuracy: 0.0435\n",
            "Epoch 42/50\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0214 - accuracy: 0.0435\n",
            "Epoch 43/50\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0211 - accuracy: 0.0435\n",
            "Epoch 44/50\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0207 - accuracy: 0.0435\n",
            "Epoch 45/50\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0203 - accuracy: 0.0435\n",
            "Epoch 46/50\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0199 - accuracy: 0.0435\n",
            "Epoch 47/50\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0195 - accuracy: 0.0435\n",
            "Epoch 48/50\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0191 - accuracy: 0.0435\n",
            "Epoch 49/50\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0188 - accuracy: 0.0435\n",
            "Epoch 50/50\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0184 - accuracy: 0.0435\n",
            "Epoch 1/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0716 - accuracy: 0.0136\n",
            "Epoch 2/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0710 - accuracy: 0.0068\n",
            "Epoch 3/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0706 - accuracy: 0.0068\n",
            "Epoch 4/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0701 - accuracy: 0.0068\n",
            "Epoch 5/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0696 - accuracy: 0.0068\n",
            "Epoch 6/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0690 - accuracy: 0.0068\n",
            "Epoch 7/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0683 - accuracy: 0.0068\n",
            "Epoch 8/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0674 - accuracy: 0.0068\n",
            "Epoch 9/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0665 - accuracy: 0.0068\n",
            "Epoch 10/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0655 - accuracy: 0.0068\n",
            "Epoch 11/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0642 - accuracy: 0.0272\n",
            "Epoch 12/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0627 - accuracy: 0.0476\n",
            "Epoch 13/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0610 - accuracy: 0.0476\n",
            "Epoch 14/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0591 - accuracy: 0.0476\n",
            "Epoch 15/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0572 - accuracy: 0.0476\n",
            "Epoch 16/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0550 - accuracy: 0.0476\n",
            "Epoch 17/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0528 - accuracy: 0.0476\n",
            "Epoch 18/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0502 - accuracy: 0.0476\n",
            "Epoch 19/50\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0477 - accuracy: 0.0476\n",
            "Epoch 20/50\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0451 - accuracy: 0.0476\n",
            "Epoch 21/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0422 - accuracy: 0.0476\n",
            "Epoch 22/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0397 - accuracy: 0.0476\n",
            "Epoch 23/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0370 - accuracy: 0.0476\n",
            "Epoch 24/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0346 - accuracy: 0.0476\n",
            "Epoch 25/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0323 - accuracy: 0.0476\n",
            "Epoch 26/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0303 - accuracy: 0.0476\n",
            "Epoch 27/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0283 - accuracy: 0.0476\n",
            "Epoch 28/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0266 - accuracy: 0.0476\n",
            "Epoch 29/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0249 - accuracy: 0.0476\n",
            "Epoch 30/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0236 - accuracy: 0.0476\n",
            "Epoch 31/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0222 - accuracy: 0.0476\n",
            "Epoch 32/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0209 - accuracy: 0.0476\n",
            "Epoch 33/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0199 - accuracy: 0.0476\n",
            "Epoch 34/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0189 - accuracy: 0.0476\n",
            "Epoch 35/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0180 - accuracy: 0.0476\n",
            "Epoch 36/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0172 - accuracy: 0.0476\n",
            "Epoch 37/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0164 - accuracy: 0.0476\n",
            "Epoch 38/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0158 - accuracy: 0.0476\n",
            "Epoch 39/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0151 - accuracy: 0.0476\n",
            "Epoch 40/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0145 - accuracy: 0.0476\n",
            "Epoch 41/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0140 - accuracy: 0.0476\n",
            "Epoch 42/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0135 - accuracy: 0.0476\n",
            "Epoch 43/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0130 - accuracy: 0.0476\n",
            "Epoch 44/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0126 - accuracy: 0.0476\n",
            "Epoch 45/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0123 - accuracy: 0.0476\n",
            "Epoch 46/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0119 - accuracy: 0.0476\n",
            "Epoch 47/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0115 - accuracy: 0.0476\n",
            "Epoch 48/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0112 - accuracy: 0.0476\n",
            "Epoch 49/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0110 - accuracy: 0.0476\n",
            "Epoch 50/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0108 - accuracy: 0.0476\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 1s 3ms/step - loss: 0.0719 - accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0712 - accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0705 - accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0697 - accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0688 - accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0677 - accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0665 - accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0651 - accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0634 - accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0618 - accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0597 - accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0577 - accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0552 - accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0526 - accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0498 - accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0469 - accuracy: 0.0272\n",
            "Epoch 17/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0443 - accuracy: 0.0340\n",
            "Epoch 18/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0416 - accuracy: 0.0340\n",
            "Epoch 19/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0389 - accuracy: 0.0340\n",
            "Epoch 20/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0364 - accuracy: 0.0340\n",
            "Epoch 21/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0339 - accuracy: 0.0340\n",
            "Epoch 22/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0314 - accuracy: 0.0340\n",
            "Epoch 23/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0290 - accuracy: 0.0340\n",
            "Epoch 24/50\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0268 - accuracy: 0.0340\n",
            "Epoch 25/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0247 - accuracy: 0.0340\n",
            "Epoch 26/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0228 - accuracy: 0.0340\n",
            "Epoch 27/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0211 - accuracy: 0.0340\n",
            "Epoch 28/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0197 - accuracy: 0.0340\n",
            "Epoch 29/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0183 - accuracy: 0.0340\n",
            "Epoch 30/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0172 - accuracy: 0.0340\n",
            "Epoch 31/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0162 - accuracy: 0.0340\n",
            "Epoch 32/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0153 - accuracy: 0.0340\n",
            "Epoch 33/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0146 - accuracy: 0.0340\n",
            "Epoch 34/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0138 - accuracy: 0.0340\n",
            "Epoch 35/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0131 - accuracy: 0.0340\n",
            "Epoch 36/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0126 - accuracy: 0.0340\n",
            "Epoch 37/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0120 - accuracy: 0.0340\n",
            "Epoch 38/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0116 - accuracy: 0.0340\n",
            "Epoch 39/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0111 - accuracy: 0.0340\n",
            "Epoch 40/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0107 - accuracy: 0.0340\n",
            "Epoch 41/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0104 - accuracy: 0.0340\n",
            "Epoch 42/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0100 - accuracy: 0.0340\n",
            "Epoch 43/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0097 - accuracy: 0.0340\n",
            "Epoch 44/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0095 - accuracy: 0.0340\n",
            "Epoch 45/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0093 - accuracy: 0.0340\n",
            "Epoch 46/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0090 - accuracy: 0.0340\n",
            "Epoch 47/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0088 - accuracy: 0.0340\n",
            "Epoch 48/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0086 - accuracy: 0.0340\n",
            "Epoch 49/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0084 - accuracy: 0.0340\n",
            "Epoch 50/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0082 - accuracy: 0.0340\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 1s 3ms/step - loss: 0.0652 - accuracy: 0.0068\n",
            "Epoch 2/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0643 - accuracy: 0.0068\n",
            "Epoch 3/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0633 - accuracy: 0.0068\n",
            "Epoch 4/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0621 - accuracy: 0.0068\n",
            "Epoch 5/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0607 - accuracy: 0.0068\n",
            "Epoch 6/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0592 - accuracy: 0.0068\n",
            "Epoch 7/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0575 - accuracy: 0.0068\n",
            "Epoch 8/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0557 - accuracy: 0.0068\n",
            "Epoch 9/50\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0541 - accuracy: 0.0068\n",
            "Epoch 10/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0523 - accuracy: 0.0068\n",
            "Epoch 11/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0507 - accuracy: 0.0068\n",
            "Epoch 12/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0490 - accuracy: 0.0068\n",
            "Epoch 13/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0473 - accuracy: 0.0068\n",
            "Epoch 14/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0452 - accuracy: 0.0068\n",
            "Epoch 15/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0433 - accuracy: 0.0068\n",
            "Epoch 16/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0414 - accuracy: 0.0068\n",
            "Epoch 17/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0399 - accuracy: 0.0068\n",
            "Epoch 18/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0382 - accuracy: 0.0068\n",
            "Epoch 19/50\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0371 - accuracy: 0.0068\n",
            "Epoch 20/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0361 - accuracy: 0.0068\n",
            "Epoch 21/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0353 - accuracy: 0.0068\n",
            "Epoch 22/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0345 - accuracy: 0.0068\n",
            "Epoch 23/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0338 - accuracy: 0.0068\n",
            "Epoch 24/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0332 - accuracy: 0.0068\n",
            "Epoch 25/50\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0325 - accuracy: 0.0068\n",
            "Epoch 26/50\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0318 - accuracy: 0.0068\n",
            "Epoch 27/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0312 - accuracy: 0.0068\n",
            "Epoch 28/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0307 - accuracy: 0.0068\n",
            "Epoch 29/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0302 - accuracy: 0.0068\n",
            "Epoch 30/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0297 - accuracy: 0.0068\n",
            "Epoch 31/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0292 - accuracy: 0.0068\n",
            "Epoch 32/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0288 - accuracy: 0.0068\n",
            "Epoch 33/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0284 - accuracy: 0.0068\n",
            "Epoch 34/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0280 - accuracy: 0.0068\n",
            "Epoch 35/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0276 - accuracy: 0.0068\n",
            "Epoch 36/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0272 - accuracy: 0.0068\n",
            "Epoch 37/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0269 - accuracy: 0.0068\n",
            "Epoch 38/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0265 - accuracy: 0.0340\n",
            "Epoch 39/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0261 - accuracy: 0.0476\n",
            "Epoch 40/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0258 - accuracy: 0.0476\n",
            "Epoch 41/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0254 - accuracy: 0.0476\n",
            "Epoch 42/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0251 - accuracy: 0.0476\n",
            "Epoch 43/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0248 - accuracy: 0.0476\n",
            "Epoch 44/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0244 - accuracy: 0.0476\n",
            "Epoch 45/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0241 - accuracy: 0.0476\n",
            "Epoch 46/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0238 - accuracy: 0.0476\n",
            "Epoch 47/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0235 - accuracy: 0.0476\n",
            "Epoch 48/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0231 - accuracy: 0.0476\n",
            "Epoch 49/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0229 - accuracy: 0.0476\n",
            "Epoch 50/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0225 - accuracy: 0.0476\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 1s 2ms/step - loss: 0.0696 - accuracy: 0.0068\n",
            "Epoch 2/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0691 - accuracy: 0.0068\n",
            "Epoch 3/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0684 - accuracy: 0.0068\n",
            "Epoch 4/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0678 - accuracy: 0.0068\n",
            "Epoch 5/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0672 - accuracy: 0.0068\n",
            "Epoch 6/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0664 - accuracy: 0.0068\n",
            "Epoch 7/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0656 - accuracy: 0.0068\n",
            "Epoch 8/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 9/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0636 - accuracy: 0.0068\n",
            "Epoch 10/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0623 - accuracy: 0.0068\n",
            "Epoch 11/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0608 - accuracy: 0.0068\n",
            "Epoch 12/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0592 - accuracy: 0.0068\n",
            "Epoch 13/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0576 - accuracy: 0.0068\n",
            "Epoch 14/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0558 - accuracy: 0.0068\n",
            "Epoch 15/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0540 - accuracy: 0.0068\n",
            "Epoch 16/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0524 - accuracy: 0.0068\n",
            "Epoch 17/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0508 - accuracy: 0.0068\n",
            "Epoch 18/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0493 - accuracy: 0.0068\n",
            "Epoch 19/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0480 - accuracy: 0.0068\n",
            "Epoch 20/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0466 - accuracy: 0.0068\n",
            "Epoch 21/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0454 - accuracy: 0.0068\n",
            "Epoch 22/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0443 - accuracy: 0.0068\n",
            "Epoch 23/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0433 - accuracy: 0.0068\n",
            "Epoch 24/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0423 - accuracy: 0.0068\n",
            "Epoch 25/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0413 - accuracy: 0.0068\n",
            "Epoch 26/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0404 - accuracy: 0.0068\n",
            "Epoch 27/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0396 - accuracy: 0.0068\n",
            "Epoch 28/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0388 - accuracy: 0.0068\n",
            "Epoch 29/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0381 - accuracy: 0.0068\n",
            "Epoch 30/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0374 - accuracy: 0.0068\n",
            "Epoch 31/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0367 - accuracy: 0.0068\n",
            "Epoch 32/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0361 - accuracy: 0.0068\n",
            "Epoch 33/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0355 - accuracy: 0.0068\n",
            "Epoch 34/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0349 - accuracy: 0.0068\n",
            "Epoch 35/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0343 - accuracy: 0.0068\n",
            "Epoch 36/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0337 - accuracy: 0.0068\n",
            "Epoch 37/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0332 - accuracy: 0.0408\n",
            "Epoch 38/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0327 - accuracy: 0.0408\n",
            "Epoch 39/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0321 - accuracy: 0.0408\n",
            "Epoch 40/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0316 - accuracy: 0.0408\n",
            "Epoch 41/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0312 - accuracy: 0.0408\n",
            "Epoch 42/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0306 - accuracy: 0.0408\n",
            "Epoch 43/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0301 - accuracy: 0.0408\n",
            "Epoch 44/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0296 - accuracy: 0.0408\n",
            "Epoch 45/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0291 - accuracy: 0.0408\n",
            "Epoch 46/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0287 - accuracy: 0.0408\n",
            "Epoch 47/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0282 - accuracy: 0.0408\n",
            "Epoch 48/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0277 - accuracy: 0.0408\n",
            "Epoch 49/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0273 - accuracy: 0.0408\n",
            "Epoch 50/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0268 - accuracy: 0.0408\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 1s 2ms/step - loss: 0.0707 - accuracy: 0.0068\n",
            "Epoch 2/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0699 - accuracy: 0.0068\n",
            "Epoch 3/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0691 - accuracy: 0.0068\n",
            "Epoch 4/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0683 - accuracy: 0.0068\n",
            "Epoch 5/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0675 - accuracy: 0.0068\n",
            "Epoch 6/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0667 - accuracy: 0.0068\n",
            "Epoch 7/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0656 - accuracy: 0.0068\n",
            "Epoch 8/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 9/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0636 - accuracy: 0.0068\n",
            "Epoch 10/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0625 - accuracy: 0.0068\n",
            "Epoch 11/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0613 - accuracy: 0.0068\n",
            "Epoch 12/50\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0602 - accuracy: 0.0068\n",
            "Epoch 13/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0588 - accuracy: 0.0068\n",
            "Epoch 14/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0574 - accuracy: 0.0068\n",
            "Epoch 15/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0559 - accuracy: 0.0068\n",
            "Epoch 16/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0543 - accuracy: 0.0068\n",
            "Epoch 17/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0525 - accuracy: 0.0068\n",
            "Epoch 18/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0506 - accuracy: 0.0068\n",
            "Epoch 19/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0486 - accuracy: 0.0068\n",
            "Epoch 20/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0465 - accuracy: 0.0068\n",
            "Epoch 21/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0444 - accuracy: 0.0405\n",
            "Epoch 22/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0421 - accuracy: 0.0473\n",
            "Epoch 23/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0401 - accuracy: 0.0473\n",
            "Epoch 24/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0379 - accuracy: 0.0473\n",
            "Epoch 25/50\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0357 - accuracy: 0.0473\n",
            "Epoch 26/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0335 - accuracy: 0.0473\n",
            "Epoch 27/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0314 - accuracy: 0.0473\n",
            "Epoch 28/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0293 - accuracy: 0.0473\n",
            "Epoch 29/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0273 - accuracy: 0.0473\n",
            "Epoch 30/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0253 - accuracy: 0.0473\n",
            "Epoch 31/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0236 - accuracy: 0.0473\n",
            "Epoch 32/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0218 - accuracy: 0.0473\n",
            "Epoch 33/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0204 - accuracy: 0.0473\n",
            "Epoch 34/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0191 - accuracy: 0.0473\n",
            "Epoch 35/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0179 - accuracy: 0.0473\n",
            "Epoch 36/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0169 - accuracy: 0.0473\n",
            "Epoch 37/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0159 - accuracy: 0.0473\n",
            "Epoch 38/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0152 - accuracy: 0.0473\n",
            "Epoch 39/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0144 - accuracy: 0.0473\n",
            "Epoch 40/50\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0138 - accuracy: 0.0473\n",
            "Epoch 41/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0131 - accuracy: 0.0473\n",
            "Epoch 42/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0127 - accuracy: 0.0473\n",
            "Epoch 43/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0122 - accuracy: 0.0473\n",
            "Epoch 44/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0118 - accuracy: 0.0473\n",
            "Epoch 45/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0115 - accuracy: 0.0473\n",
            "Epoch 46/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0111 - accuracy: 0.0473\n",
            "Epoch 47/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0108 - accuracy: 0.0473\n",
            "Epoch 48/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0105 - accuracy: 0.0473\n",
            "Epoch 49/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0103 - accuracy: 0.0473\n",
            "Epoch 50/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0101 - accuracy: 0.0473\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0717 - accuracy: 0.0068\n",
            "Epoch 2/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0714 - accuracy: 0.0068\n",
            "Epoch 3/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0711 - accuracy: 0.0068\n",
            "Epoch 4/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0709 - accuracy: 0.0068\n",
            "Epoch 5/50\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0707 - accuracy: 0.0068\n",
            "Epoch 6/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0704 - accuracy: 0.0068\n",
            "Epoch 7/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0702 - accuracy: 0.0068\n",
            "Epoch 8/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0700 - accuracy: 0.0068\n",
            "Epoch 9/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0698 - accuracy: 0.0068\n",
            "Epoch 10/50\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0696 - accuracy: 0.0068\n",
            "Epoch 11/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0694 - accuracy: 0.0068\n",
            "Epoch 12/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0692 - accuracy: 0.0068\n",
            "Epoch 13/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0690 - accuracy: 0.0068\n",
            "Epoch 14/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0689 - accuracy: 0.0068\n",
            "Epoch 15/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0687 - accuracy: 0.0068\n",
            "Epoch 16/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0685 - accuracy: 0.0068\n",
            "Epoch 17/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0684 - accuracy: 0.0068\n",
            "Epoch 18/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0682 - accuracy: 0.0068\n",
            "Epoch 19/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0681 - accuracy: 0.0068\n",
            "Epoch 20/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0680 - accuracy: 0.0068\n",
            "Epoch 21/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0679 - accuracy: 0.0068\n",
            "Epoch 22/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0677 - accuracy: 0.0068\n",
            "Epoch 23/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0676 - accuracy: 0.0068\n",
            "Epoch 24/50\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0675 - accuracy: 0.0068\n",
            "Epoch 25/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0674 - accuracy: 0.0068\n",
            "Epoch 26/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0673 - accuracy: 0.0068\n",
            "Epoch 27/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0672 - accuracy: 0.0068\n",
            "Epoch 28/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0671 - accuracy: 0.0068\n",
            "Epoch 29/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0670 - accuracy: 0.0068\n",
            "Epoch 30/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0669 - accuracy: 0.0068\n",
            "Epoch 31/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0668 - accuracy: 0.0068\n",
            "Epoch 32/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0667 - accuracy: 0.0068\n",
            "Epoch 33/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0666 - accuracy: 0.0068\n",
            "Epoch 34/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0665 - accuracy: 0.0068\n",
            "Epoch 35/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0665 - accuracy: 0.0068\n",
            "Epoch 36/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0664 - accuracy: 0.0068\n",
            "Epoch 37/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0663 - accuracy: 0.0068\n",
            "Epoch 38/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0662 - accuracy: 0.0068\n",
            "Epoch 39/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0662 - accuracy: 0.0068\n",
            "Epoch 40/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0661 - accuracy: 0.0068\n",
            "Epoch 41/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0661 - accuracy: 0.0068\n",
            "Epoch 42/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0660 - accuracy: 0.0068\n",
            "Epoch 43/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0659 - accuracy: 0.0068\n",
            "Epoch 44/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0659 - accuracy: 0.0068\n",
            "Epoch 45/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0658 - accuracy: 0.0068\n",
            "Epoch 46/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0658 - accuracy: 0.0068\n",
            "Epoch 47/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0657 - accuracy: 0.0068\n",
            "Epoch 48/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0657 - accuracy: 0.0068\n",
            "Epoch 49/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0657 - accuracy: 0.0068\n",
            "Epoch 50/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0656 - accuracy: 0.0068\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0720 - accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0717 - accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0713 - accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0710 - accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0707 - accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0704 - accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0701 - accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0698 - accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0696 - accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0693 - accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0690 - accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0688 - accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0686 - accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0684 - accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0681 - accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0679 - accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0677 - accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0676 - accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0674 - accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0672 - accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0670 - accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0669 - accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0667 - accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0665 - accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0664 - accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0663 - accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0661 - accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0660 - accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0659 - accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0657 - accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0656 - accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0655 - accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0654 - accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0653 - accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0652 - accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0651 - accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0650 - accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0649 - accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0648 - accuracy: 0.0000e+00\n",
            "Epoch 40/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0647 - accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0647 - accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0646 - accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0645 - accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0644 - accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0644 - accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0643 - accuracy: 0.0000e+00\n",
            "Epoch 47/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0642 - accuracy: 0.0000e+00\n",
            "Epoch 48/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0642 - accuracy: 0.0000e+00\n",
            "Epoch 49/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0641 - accuracy: 0.0000e+00\n",
            "Epoch 50/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0641 - accuracy: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0654 - accuracy: 0.0068\n",
            "Epoch 2/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 3/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0645 - accuracy: 0.0068\n",
            "Epoch 4/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0641 - accuracy: 0.0068\n",
            "Epoch 5/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0637 - accuracy: 0.0068\n",
            "Epoch 6/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0633 - accuracy: 0.0068\n",
            "Epoch 7/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0629 - accuracy: 0.0068\n",
            "Epoch 8/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0625 - accuracy: 0.0068\n",
            "Epoch 9/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0622 - accuracy: 0.0068\n",
            "Epoch 10/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0618 - accuracy: 0.0068\n",
            "Epoch 11/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0615 - accuracy: 0.0068\n",
            "Epoch 12/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0611 - accuracy: 0.0068\n",
            "Epoch 13/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0608 - accuracy: 0.0068\n",
            "Epoch 14/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0605 - accuracy: 0.0068\n",
            "Epoch 15/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0603 - accuracy: 0.0068\n",
            "Epoch 16/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0600 - accuracy: 0.0068\n",
            "Epoch 17/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0597 - accuracy: 0.0068\n",
            "Epoch 18/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0595 - accuracy: 0.0068\n",
            "Epoch 19/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0592 - accuracy: 0.0068\n",
            "Epoch 20/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0590 - accuracy: 0.0068\n",
            "Epoch 21/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0588 - accuracy: 0.0068\n",
            "Epoch 22/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0585 - accuracy: 0.0068\n",
            "Epoch 23/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0583 - accuracy: 0.0068\n",
            "Epoch 24/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0581 - accuracy: 0.0068\n",
            "Epoch 25/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0579 - accuracy: 0.0068\n",
            "Epoch 26/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0577 - accuracy: 0.0068\n",
            "Epoch 27/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0576 - accuracy: 0.0068\n",
            "Epoch 28/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0574 - accuracy: 0.0068\n",
            "Epoch 29/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0572 - accuracy: 0.0068\n",
            "Epoch 30/50\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0571 - accuracy: 0.0068\n",
            "Epoch 31/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0569 - accuracy: 0.0068\n",
            "Epoch 32/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0568 - accuracy: 0.0068\n",
            "Epoch 33/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0566 - accuracy: 0.0068\n",
            "Epoch 34/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0565 - accuracy: 0.0068\n",
            "Epoch 35/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0563 - accuracy: 0.0068\n",
            "Epoch 36/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0562 - accuracy: 0.0068\n",
            "Epoch 37/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0561 - accuracy: 0.0068\n",
            "Epoch 38/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0560 - accuracy: 0.0068\n",
            "Epoch 39/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0558 - accuracy: 0.0068\n",
            "Epoch 40/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0557 - accuracy: 0.0068\n",
            "Epoch 41/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0556 - accuracy: 0.0068\n",
            "Epoch 42/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0555 - accuracy: 0.0068\n",
            "Epoch 43/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0554 - accuracy: 0.0068\n",
            "Epoch 44/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0553 - accuracy: 0.0068\n",
            "Epoch 45/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0552 - accuracy: 0.0068\n",
            "Epoch 46/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0552 - accuracy: 0.0068\n",
            "Epoch 47/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0551 - accuracy: 0.0068\n",
            "Epoch 48/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0550 - accuracy: 0.0068\n",
            "Epoch 49/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0549 - accuracy: 0.0068\n",
            "Epoch 50/50\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0548 - accuracy: 0.0068\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0697 - accuracy: 0.0068\n",
            "Epoch 2/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0694 - accuracy: 0.0068\n",
            "Epoch 3/50\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0692 - accuracy: 0.0068\n",
            "Epoch 4/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0689 - accuracy: 0.0068\n",
            "Epoch 5/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0686 - accuracy: 0.0068\n",
            "Epoch 6/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0684 - accuracy: 0.0068\n",
            "Epoch 7/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0682 - accuracy: 0.0068\n",
            "Epoch 8/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0679 - accuracy: 0.0068\n",
            "Epoch 9/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0677 - accuracy: 0.0068\n",
            "Epoch 10/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0674 - accuracy: 0.0068\n",
            "Epoch 11/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0672 - accuracy: 0.0068\n",
            "Epoch 12/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0670 - accuracy: 0.0068\n",
            "Epoch 13/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0669 - accuracy: 0.0068\n",
            "Epoch 14/50\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0667 - accuracy: 0.0068\n",
            "Epoch 15/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0665 - accuracy: 0.0068\n",
            "Epoch 16/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0663 - accuracy: 0.0068\n",
            "Epoch 17/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0662 - accuracy: 0.0068\n",
            "Epoch 18/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0660 - accuracy: 0.0068\n",
            "Epoch 19/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0658 - accuracy: 0.0068\n",
            "Epoch 20/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0657 - accuracy: 0.0068\n",
            "Epoch 21/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0656 - accuracy: 0.0068\n",
            "Epoch 22/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0654 - accuracy: 0.0068\n",
            "Epoch 23/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0653 - accuracy: 0.0068\n",
            "Epoch 24/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0652 - accuracy: 0.0068\n",
            "Epoch 25/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0650 - accuracy: 0.0068\n",
            "Epoch 26/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 27/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0648 - accuracy: 0.0068\n",
            "Epoch 28/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 29/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0646 - accuracy: 0.0068\n",
            "Epoch 30/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0645 - accuracy: 0.0068\n",
            "Epoch 31/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0644 - accuracy: 0.0068\n",
            "Epoch 32/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0643 - accuracy: 0.0068\n",
            "Epoch 33/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0642 - accuracy: 0.0068\n",
            "Epoch 34/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0642 - accuracy: 0.0068\n",
            "Epoch 35/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0641 - accuracy: 0.0068\n",
            "Epoch 36/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0640 - accuracy: 0.0068\n",
            "Epoch 37/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0639 - accuracy: 0.0068\n",
            "Epoch 38/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0638 - accuracy: 0.0068\n",
            "Epoch 39/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0638 - accuracy: 0.0068\n",
            "Epoch 40/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0637 - accuracy: 0.0068\n",
            "Epoch 41/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0636 - accuracy: 0.0068\n",
            "Epoch 42/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0636 - accuracy: 0.0068\n",
            "Epoch 43/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0635 - accuracy: 0.0068\n",
            "Epoch 44/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0634 - accuracy: 0.0068\n",
            "Epoch 45/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0634 - accuracy: 0.0068\n",
            "Epoch 46/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0633 - accuracy: 0.0068\n",
            "Epoch 47/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0633 - accuracy: 0.0068\n",
            "Epoch 48/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0632 - accuracy: 0.0068\n",
            "Epoch 49/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0632 - accuracy: 0.0068\n",
            "Epoch 50/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0631 - accuracy: 0.0068\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0709 - accuracy: 0.0135\n",
            "Epoch 2/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0704 - accuracy: 0.0068\n",
            "Epoch 3/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0699 - accuracy: 0.0068\n",
            "Epoch 4/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0694 - accuracy: 0.0068\n",
            "Epoch 5/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0689 - accuracy: 0.0068\n",
            "Epoch 6/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0685 - accuracy: 0.0068\n",
            "Epoch 7/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0681 - accuracy: 0.0068\n",
            "Epoch 8/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0677 - accuracy: 0.0068\n",
            "Epoch 9/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0673 - accuracy: 0.0068\n",
            "Epoch 10/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0669 - accuracy: 0.0068\n",
            "Epoch 11/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0665 - accuracy: 0.0068\n",
            "Epoch 12/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0662 - accuracy: 0.0068\n",
            "Epoch 13/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0658 - accuracy: 0.0068\n",
            "Epoch 14/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0655 - accuracy: 0.0068\n",
            "Epoch 15/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0652 - accuracy: 0.0068\n",
            "Epoch 16/50\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 17/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0646 - accuracy: 0.0068\n",
            "Epoch 18/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0643 - accuracy: 0.0068\n",
            "Epoch 19/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0641 - accuracy: 0.0068\n",
            "Epoch 20/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0638 - accuracy: 0.0068\n",
            "Epoch 21/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0636 - accuracy: 0.0068\n",
            "Epoch 22/50\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0633 - accuracy: 0.0068\n",
            "Epoch 23/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0631 - accuracy: 0.0068\n",
            "Epoch 24/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0629 - accuracy: 0.0068\n",
            "Epoch 25/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0627 - accuracy: 0.0068\n",
            "Epoch 26/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0625 - accuracy: 0.0068\n",
            "Epoch 27/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0623 - accuracy: 0.0068\n",
            "Epoch 28/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0621 - accuracy: 0.0068\n",
            "Epoch 29/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0619 - accuracy: 0.0068\n",
            "Epoch 30/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0617 - accuracy: 0.0068\n",
            "Epoch 31/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0615 - accuracy: 0.0068\n",
            "Epoch 32/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0614 - accuracy: 0.0068\n",
            "Epoch 33/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0612 - accuracy: 0.0068\n",
            "Epoch 34/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0611 - accuracy: 0.0068\n",
            "Epoch 35/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0609 - accuracy: 0.0068\n",
            "Epoch 36/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0608 - accuracy: 0.0068\n",
            "Epoch 37/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0606 - accuracy: 0.0068\n",
            "Epoch 38/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0605 - accuracy: 0.0068\n",
            "Epoch 39/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0604 - accuracy: 0.0068\n",
            "Epoch 40/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0603 - accuracy: 0.0068\n",
            "Epoch 41/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0602 - accuracy: 0.0068\n",
            "Epoch 42/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0600 - accuracy: 0.0068\n",
            "Epoch 43/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0599 - accuracy: 0.0068\n",
            "Epoch 44/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0598 - accuracy: 0.0068\n",
            "Epoch 45/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0597 - accuracy: 0.0068\n",
            "Epoch 46/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0596 - accuracy: 0.0068\n",
            "Epoch 47/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0595 - accuracy: 0.0068\n",
            "Epoch 48/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0595 - accuracy: 0.0068\n",
            "Epoch 49/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0594 - accuracy: 0.0068\n",
            "Epoch 50/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0593 - accuracy: 0.0068\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "15/15 [==============================] - 1s 3ms/step - loss: 0.0716 - accuracy: 0.0068\n",
            "Epoch 2/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0711 - accuracy: 0.0068\n",
            "Epoch 3/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0706 - accuracy: 0.0068\n",
            "Epoch 4/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0702 - accuracy: 0.0068\n",
            "Epoch 5/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0696 - accuracy: 0.0068\n",
            "Epoch 6/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0691 - accuracy: 0.0068\n",
            "Epoch 7/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0683 - accuracy: 0.0068\n",
            "Epoch 8/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0676 - accuracy: 0.0068\n",
            "Epoch 9/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0666 - accuracy: 0.0068\n",
            "Epoch 10/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0655 - accuracy: 0.0068\n",
            "Epoch 11/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0643 - accuracy: 0.0068\n",
            "Epoch 12/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0627 - accuracy: 0.0068\n",
            "Epoch 13/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0610 - accuracy: 0.0068\n",
            "Epoch 14/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0591 - accuracy: 0.0068\n",
            "Epoch 15/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0572 - accuracy: 0.0068\n",
            "Epoch 16/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0548 - accuracy: 0.0068\n",
            "Epoch 17/50\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0524 - accuracy: 0.0136\n",
            "Epoch 18/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0501 - accuracy: 0.0408\n",
            "Epoch 19/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0472 - accuracy: 0.0476\n",
            "Epoch 20/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0445 - accuracy: 0.0476\n",
            "Epoch 21/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0416 - accuracy: 0.0476\n",
            "Epoch 22/50\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.0389 - accuracy: 0.0476\n",
            "Epoch 23/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0361 - accuracy: 0.0476\n",
            "Epoch 24/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0332 - accuracy: 0.0476\n",
            "Epoch 25/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0307 - accuracy: 0.0476\n",
            "Epoch 26/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0283 - accuracy: 0.0476\n",
            "Epoch 27/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0261 - accuracy: 0.0476\n",
            "Epoch 28/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0243 - accuracy: 0.0476\n",
            "Epoch 29/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0226 - accuracy: 0.0476\n",
            "Epoch 30/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0212 - accuracy: 0.0476\n",
            "Epoch 31/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0198 - accuracy: 0.0476\n",
            "Epoch 32/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0186 - accuracy: 0.0476\n",
            "Epoch 33/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0176 - accuracy: 0.0476\n",
            "Epoch 34/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0166 - accuracy: 0.0476\n",
            "Epoch 35/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0158 - accuracy: 0.0476\n",
            "Epoch 36/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0151 - accuracy: 0.0476\n",
            "Epoch 37/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0144 - accuracy: 0.0476\n",
            "Epoch 38/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0139 - accuracy: 0.0476\n",
            "Epoch 39/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0134 - accuracy: 0.0476\n",
            "Epoch 40/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0128 - accuracy: 0.0476\n",
            "Epoch 41/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0124 - accuracy: 0.0476\n",
            "Epoch 42/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0119 - accuracy: 0.0476\n",
            "Epoch 43/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0115 - accuracy: 0.0476\n",
            "Epoch 44/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0113 - accuracy: 0.0476\n",
            "Epoch 45/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0110 - accuracy: 0.0476\n",
            "Epoch 46/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0106 - accuracy: 0.0476\n",
            "Epoch 47/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0103 - accuracy: 0.0476\n",
            "Epoch 48/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0100 - accuracy: 0.0476\n",
            "Epoch 49/50\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0097 - accuracy: 0.0476\n",
            "Epoch 50/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0095 - accuracy: 0.0476\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 1s 2ms/step - loss: 0.0719 - accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0713 - accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0706 - accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0699 - accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0691 - accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0681 - accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0669 - accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0655 - accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0638 - accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0619 - accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0596 - accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0573 - accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0550 - accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.0523 - accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0498 - accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0474 - accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0453 - accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0431 - accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0413 - accuracy: 0.0136\n",
            "Epoch 20/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0398 - accuracy: 0.0340\n",
            "Epoch 21/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0378 - accuracy: 0.0340\n",
            "Epoch 22/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0362 - accuracy: 0.0340\n",
            "Epoch 23/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0343 - accuracy: 0.0340\n",
            "Epoch 24/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0327 - accuracy: 0.0340\n",
            "Epoch 25/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0309 - accuracy: 0.0340\n",
            "Epoch 26/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0293 - accuracy: 0.0340\n",
            "Epoch 27/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0277 - accuracy: 0.0340\n",
            "Epoch 28/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0260 - accuracy: 0.0340\n",
            "Epoch 29/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0246 - accuracy: 0.0340\n",
            "Epoch 30/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0233 - accuracy: 0.0340\n",
            "Epoch 31/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0218 - accuracy: 0.0340\n",
            "Epoch 32/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0205 - accuracy: 0.0340\n",
            "Epoch 33/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0193 - accuracy: 0.0340\n",
            "Epoch 34/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0182 - accuracy: 0.0340\n",
            "Epoch 35/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0172 - accuracy: 0.0340\n",
            "Epoch 36/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0163 - accuracy: 0.0340\n",
            "Epoch 37/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0154 - accuracy: 0.0340\n",
            "Epoch 38/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0146 - accuracy: 0.0340\n",
            "Epoch 39/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0140 - accuracy: 0.0340\n",
            "Epoch 40/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0134 - accuracy: 0.0340\n",
            "Epoch 41/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0126 - accuracy: 0.0340\n",
            "Epoch 42/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0122 - accuracy: 0.0340\n",
            "Epoch 43/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0117 - accuracy: 0.0340\n",
            "Epoch 44/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0111 - accuracy: 0.0340\n",
            "Epoch 45/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0107 - accuracy: 0.0340\n",
            "Epoch 46/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0104 - accuracy: 0.0340\n",
            "Epoch 47/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0101 - accuracy: 0.0340\n",
            "Epoch 48/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0097 - accuracy: 0.0340\n",
            "Epoch 49/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0094 - accuracy: 0.0340\n",
            "Epoch 50/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0092 - accuracy: 0.0340\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 1s 3ms/step - loss: 0.0652 - accuracy: 0.0068\n",
            "Epoch 2/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0645 - accuracy: 0.0068\n",
            "Epoch 3/50\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0637 - accuracy: 0.0068\n",
            "Epoch 4/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0628 - accuracy: 0.0068\n",
            "Epoch 5/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0619 - accuracy: 0.0068\n",
            "Epoch 6/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0609 - accuracy: 0.0068\n",
            "Epoch 7/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0599 - accuracy: 0.0068\n",
            "Epoch 8/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0588 - accuracy: 0.0068\n",
            "Epoch 9/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0576 - accuracy: 0.0068\n",
            "Epoch 10/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0565 - accuracy: 0.0068\n",
            "Epoch 11/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0554 - accuracy: 0.0068\n",
            "Epoch 12/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0543 - accuracy: 0.0068\n",
            "Epoch 13/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0533 - accuracy: 0.0068\n",
            "Epoch 14/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0523 - accuracy: 0.0068\n",
            "Epoch 15/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0514 - accuracy: 0.0068\n",
            "Epoch 16/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0506 - accuracy: 0.0068\n",
            "Epoch 17/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0497 - accuracy: 0.0068\n",
            "Epoch 18/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0488 - accuracy: 0.0068\n",
            "Epoch 19/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0479 - accuracy: 0.0068\n",
            "Epoch 20/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0470 - accuracy: 0.0068\n",
            "Epoch 21/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0464 - accuracy: 0.0068\n",
            "Epoch 22/50\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0457 - accuracy: 0.0068\n",
            "Epoch 23/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0451 - accuracy: 0.0068\n",
            "Epoch 24/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0445 - accuracy: 0.0068\n",
            "Epoch 25/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0440 - accuracy: 0.0068\n",
            "Epoch 26/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0435 - accuracy: 0.0068\n",
            "Epoch 27/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0429 - accuracy: 0.0068\n",
            "Epoch 28/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0423 - accuracy: 0.0068\n",
            "Epoch 29/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0418 - accuracy: 0.0068\n",
            "Epoch 30/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0413 - accuracy: 0.0068\n",
            "Epoch 31/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0408 - accuracy: 0.0068\n",
            "Epoch 32/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0402 - accuracy: 0.0068\n",
            "Epoch 33/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0397 - accuracy: 0.0068\n",
            "Epoch 34/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0392 - accuracy: 0.0068\n",
            "Epoch 35/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0386 - accuracy: 0.0068\n",
            "Epoch 36/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0381 - accuracy: 0.0068\n",
            "Epoch 37/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0376 - accuracy: 0.0068\n",
            "Epoch 38/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0371 - accuracy: 0.0068\n",
            "Epoch 39/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0365 - accuracy: 0.0068\n",
            "Epoch 40/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0360 - accuracy: 0.0068\n",
            "Epoch 41/50\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0355 - accuracy: 0.0068\n",
            "Epoch 42/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0350 - accuracy: 0.0068\n",
            "Epoch 43/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0345 - accuracy: 0.0068\n",
            "Epoch 44/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0339 - accuracy: 0.0068\n",
            "Epoch 45/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0335 - accuracy: 0.0068\n",
            "Epoch 46/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0330 - accuracy: 0.0068\n",
            "Epoch 47/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0325 - accuracy: 0.0068\n",
            "Epoch 48/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0320 - accuracy: 0.0068\n",
            "Epoch 49/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0316 - accuracy: 0.0068\n",
            "Epoch 50/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0311 - accuracy: 0.0068\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "15/15 [==============================] - 1s 3ms/step - loss: 0.0696 - accuracy: 0.0068\n",
            "Epoch 2/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0690 - accuracy: 0.0068\n",
            "Epoch 3/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0684 - accuracy: 0.0068\n",
            "Epoch 4/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0678 - accuracy: 0.0068\n",
            "Epoch 5/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0672 - accuracy: 0.0068\n",
            "Epoch 6/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0664 - accuracy: 0.0068\n",
            "Epoch 7/50\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0655 - accuracy: 0.0068\n",
            "Epoch 8/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0646 - accuracy: 0.0068\n",
            "Epoch 9/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0635 - accuracy: 0.0068\n",
            "Epoch 10/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0622 - accuracy: 0.0068\n",
            "Epoch 11/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0609 - accuracy: 0.0068\n",
            "Epoch 12/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0594 - accuracy: 0.0068\n",
            "Epoch 13/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0578 - accuracy: 0.0068\n",
            "Epoch 14/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0562 - accuracy: 0.0068\n",
            "Epoch 15/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0543 - accuracy: 0.0068\n",
            "Epoch 16/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0523 - accuracy: 0.0068\n",
            "Epoch 17/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0502 - accuracy: 0.0068\n",
            "Epoch 18/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0479 - accuracy: 0.0068\n",
            "Epoch 19/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0459 - accuracy: 0.0340\n",
            "Epoch 20/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0430 - accuracy: 0.0408\n",
            "Epoch 21/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0403 - accuracy: 0.0408\n",
            "Epoch 22/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0377 - accuracy: 0.0408\n",
            "Epoch 23/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0350 - accuracy: 0.0408\n",
            "Epoch 24/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0323 - accuracy: 0.0408\n",
            "Epoch 25/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0299 - accuracy: 0.0408\n",
            "Epoch 26/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0278 - accuracy: 0.0408\n",
            "Epoch 27/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0260 - accuracy: 0.0408\n",
            "Epoch 28/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0242 - accuracy: 0.0408\n",
            "Epoch 29/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0227 - accuracy: 0.0408\n",
            "Epoch 30/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0212 - accuracy: 0.0408\n",
            "Epoch 31/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0199 - accuracy: 0.0408\n",
            "Epoch 32/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0189 - accuracy: 0.0408\n",
            "Epoch 33/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0178 - accuracy: 0.0408\n",
            "Epoch 34/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0169 - accuracy: 0.0408\n",
            "Epoch 35/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0162 - accuracy: 0.0408\n",
            "Epoch 36/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0153 - accuracy: 0.0408\n",
            "Epoch 37/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0145 - accuracy: 0.0408\n",
            "Epoch 38/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0139 - accuracy: 0.0408\n",
            "Epoch 39/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0135 - accuracy: 0.0408\n",
            "Epoch 40/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0131 - accuracy: 0.0408\n",
            "Epoch 41/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0124 - accuracy: 0.0408\n",
            "Epoch 42/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0120 - accuracy: 0.0408\n",
            "Epoch 43/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0116 - accuracy: 0.0408\n",
            "Epoch 44/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0112 - accuracy: 0.0408\n",
            "Epoch 45/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0109 - accuracy: 0.0408\n",
            "Epoch 46/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0106 - accuracy: 0.0408\n",
            "Epoch 47/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0103 - accuracy: 0.0408\n",
            "Epoch 48/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0101 - accuracy: 0.0408\n",
            "Epoch 49/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0097 - accuracy: 0.0408\n",
            "Epoch 50/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0097 - accuracy: 0.0408\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 1s 3ms/step - loss: 0.0707 - accuracy: 0.0135\n",
            "Epoch 2/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0699 - accuracy: 0.0068\n",
            "Epoch 3/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0691 - accuracy: 0.0068\n",
            "Epoch 4/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0681 - accuracy: 0.0068\n",
            "Epoch 5/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0670 - accuracy: 0.0068\n",
            "Epoch 6/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0659 - accuracy: 0.0068\n",
            "Epoch 7/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0646 - accuracy: 0.0068\n",
            "Epoch 8/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0632 - accuracy: 0.0068\n",
            "Epoch 9/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0618 - accuracy: 0.0068\n",
            "Epoch 10/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0601 - accuracy: 0.0068\n",
            "Epoch 11/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0583 - accuracy: 0.0068\n",
            "Epoch 12/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0565 - accuracy: 0.0068\n",
            "Epoch 13/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0546 - accuracy: 0.0068\n",
            "Epoch 14/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0524 - accuracy: 0.0068\n",
            "Epoch 15/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0502 - accuracy: 0.0068\n",
            "Epoch 16/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0480 - accuracy: 0.0068\n",
            "Epoch 17/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0459 - accuracy: 0.0068\n",
            "Epoch 18/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0438 - accuracy: 0.0068\n",
            "Epoch 19/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0420 - accuracy: 0.0068\n",
            "Epoch 20/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0402 - accuracy: 0.0068\n",
            "Epoch 21/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0385 - accuracy: 0.0068\n",
            "Epoch 22/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0368 - accuracy: 0.0068\n",
            "Epoch 23/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0353 - accuracy: 0.0068\n",
            "Epoch 24/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0336 - accuracy: 0.0473\n",
            "Epoch 25/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0320 - accuracy: 0.0473\n",
            "Epoch 26/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0304 - accuracy: 0.0473\n",
            "Epoch 27/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0286 - accuracy: 0.0473\n",
            "Epoch 28/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0270 - accuracy: 0.0473\n",
            "Epoch 29/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0252 - accuracy: 0.0473\n",
            "Epoch 30/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0235 - accuracy: 0.0473\n",
            "Epoch 31/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0215 - accuracy: 0.0473\n",
            "Epoch 32/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0199 - accuracy: 0.0473\n",
            "Epoch 33/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0186 - accuracy: 0.0473\n",
            "Epoch 34/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0173 - accuracy: 0.0473\n",
            "Epoch 35/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0161 - accuracy: 0.0473\n",
            "Epoch 36/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0151 - accuracy: 0.0473\n",
            "Epoch 37/50\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0143 - accuracy: 0.0473\n",
            "Epoch 38/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0135 - accuracy: 0.0473\n",
            "Epoch 39/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0129 - accuracy: 0.0473\n",
            "Epoch 40/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0123 - accuracy: 0.0473\n",
            "Epoch 41/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0119 - accuracy: 0.0473\n",
            "Epoch 42/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0115 - accuracy: 0.0473\n",
            "Epoch 43/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0110 - accuracy: 0.0473\n",
            "Epoch 44/50\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0106 - accuracy: 0.0473\n",
            "Epoch 45/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0105 - accuracy: 0.0473\n",
            "Epoch 46/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0100 - accuracy: 0.0473\n",
            "Epoch 47/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0098 - accuracy: 0.0473\n",
            "Epoch 48/50\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0095 - accuracy: 0.0473\n",
            "Epoch 49/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0093 - accuracy: 0.0473\n",
            "Epoch 50/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0092 - accuracy: 0.0473\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 1s 2ms/step - loss: 0.0717 - accuracy: 0.0068\n",
            "Epoch 2/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0714 - accuracy: 0.0068\n",
            "Epoch 3/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0712 - accuracy: 0.0068\n",
            "Epoch 4/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0709 - accuracy: 0.0068\n",
            "Epoch 5/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0707 - accuracy: 0.0068\n",
            "Epoch 6/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0704 - accuracy: 0.0068\n",
            "Epoch 7/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0702 - accuracy: 0.0068\n",
            "Epoch 8/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0700 - accuracy: 0.0068\n",
            "Epoch 9/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0698 - accuracy: 0.0068\n",
            "Epoch 10/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0696 - accuracy: 0.0068\n",
            "Epoch 11/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0694 - accuracy: 0.0068\n",
            "Epoch 12/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0692 - accuracy: 0.0068\n",
            "Epoch 13/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0691 - accuracy: 0.0068\n",
            "Epoch 14/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0689 - accuracy: 0.0068\n",
            "Epoch 15/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0687 - accuracy: 0.0068\n",
            "Epoch 16/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0686 - accuracy: 0.0068\n",
            "Epoch 17/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0684 - accuracy: 0.0068\n",
            "Epoch 18/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0683 - accuracy: 0.0068\n",
            "Epoch 19/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0681 - accuracy: 0.0068\n",
            "Epoch 20/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0680 - accuracy: 0.0068\n",
            "Epoch 21/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0679 - accuracy: 0.0068\n",
            "Epoch 22/50\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0677 - accuracy: 0.0068\n",
            "Epoch 23/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0676 - accuracy: 0.0068\n",
            "Epoch 24/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0675 - accuracy: 0.0068\n",
            "Epoch 25/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0674 - accuracy: 0.0068\n",
            "Epoch 26/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0673 - accuracy: 0.0068\n",
            "Epoch 27/50\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0672 - accuracy: 0.0068\n",
            "Epoch 28/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0671 - accuracy: 0.0068\n",
            "Epoch 29/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0670 - accuracy: 0.0068\n",
            "Epoch 30/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0669 - accuracy: 0.0068\n",
            "Epoch 31/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0668 - accuracy: 0.0068\n",
            "Epoch 32/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0667 - accuracy: 0.0068\n",
            "Epoch 33/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0666 - accuracy: 0.0068\n",
            "Epoch 34/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0665 - accuracy: 0.0068\n",
            "Epoch 35/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0665 - accuracy: 0.0068\n",
            "Epoch 36/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0664 - accuracy: 0.0068\n",
            "Epoch 37/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0663 - accuracy: 0.0068\n",
            "Epoch 38/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0663 - accuracy: 0.0068\n",
            "Epoch 39/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0662 - accuracy: 0.0068\n",
            "Epoch 40/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0661 - accuracy: 0.0068\n",
            "Epoch 41/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0661 - accuracy: 0.0068\n",
            "Epoch 42/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0660 - accuracy: 0.0068\n",
            "Epoch 43/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0660 - accuracy: 0.0068\n",
            "Epoch 44/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0659 - accuracy: 0.0068\n",
            "Epoch 45/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0659 - accuracy: 0.0068\n",
            "Epoch 46/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0658 - accuracy: 0.0068\n",
            "Epoch 47/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0658 - accuracy: 0.0068\n",
            "Epoch 48/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0657 - accuracy: 0.0068\n",
            "Epoch 49/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0657 - accuracy: 0.0068\n",
            "Epoch 50/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0656 - accuracy: 0.0068\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0720 - accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0717 - accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0713 - accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0710 - accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0707 - accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0704 - accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0701 - accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0698 - accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0695 - accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0693 - accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0690 - accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0688 - accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0686 - accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0684 - accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0681 - accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0679 - accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0677 - accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0676 - accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0674 - accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0672 - accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0670 - accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0668 - accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0667 - accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0665 - accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0664 - accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0662 - accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0661 - accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0660 - accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0659 - accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0657 - accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0656 - accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0655 - accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0654 - accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0653 - accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0652 - accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0651 - accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0650 - accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0649 - accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0648 - accuracy: 0.0000e+00\n",
            "Epoch 40/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0647 - accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0647 - accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0646 - accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0645 - accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0644 - accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0644 - accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0643 - accuracy: 0.0000e+00\n",
            "Epoch 47/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0642 - accuracy: 0.0000e+00\n",
            "Epoch 48/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0642 - accuracy: 0.0000e+00\n",
            "Epoch 49/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0641 - accuracy: 0.0000e+00\n",
            "Epoch 50/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0641 - accuracy: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "15/15 [==============================] - 1s 2ms/step - loss: 0.0654 - accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 3/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0645 - accuracy: 0.0068\n",
            "Epoch 4/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0640 - accuracy: 0.0068\n",
            "Epoch 5/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0636 - accuracy: 0.0068\n",
            "Epoch 6/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0632 - accuracy: 0.0068\n",
            "Epoch 7/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0628 - accuracy: 0.0068\n",
            "Epoch 8/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0625 - accuracy: 0.0068\n",
            "Epoch 9/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0621 - accuracy: 0.0068\n",
            "Epoch 10/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0618 - accuracy: 0.0068\n",
            "Epoch 11/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0615 - accuracy: 0.0068\n",
            "Epoch 12/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0611 - accuracy: 0.0068\n",
            "Epoch 13/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0608 - accuracy: 0.0068\n",
            "Epoch 14/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0605 - accuracy: 0.0068\n",
            "Epoch 15/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0602 - accuracy: 0.0068\n",
            "Epoch 16/50\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0600 - accuracy: 0.0068\n",
            "Epoch 17/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0597 - accuracy: 0.0068\n",
            "Epoch 18/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0594 - accuracy: 0.0068\n",
            "Epoch 19/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0592 - accuracy: 0.0068\n",
            "Epoch 20/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0590 - accuracy: 0.0068\n",
            "Epoch 21/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0587 - accuracy: 0.0068\n",
            "Epoch 22/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0585 - accuracy: 0.0068\n",
            "Epoch 23/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0583 - accuracy: 0.0068\n",
            "Epoch 24/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0581 - accuracy: 0.0068\n",
            "Epoch 25/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0579 - accuracy: 0.0068\n",
            "Epoch 26/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0577 - accuracy: 0.0068\n",
            "Epoch 27/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0576 - accuracy: 0.0068\n",
            "Epoch 28/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0574 - accuracy: 0.0068\n",
            "Epoch 29/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0572 - accuracy: 0.0068\n",
            "Epoch 30/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0571 - accuracy: 0.0068\n",
            "Epoch 31/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0569 - accuracy: 0.0068\n",
            "Epoch 32/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0568 - accuracy: 0.0068\n",
            "Epoch 33/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0566 - accuracy: 0.0068\n",
            "Epoch 34/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0565 - accuracy: 0.0068\n",
            "Epoch 35/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0563 - accuracy: 0.0068\n",
            "Epoch 36/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0562 - accuracy: 0.0068\n",
            "Epoch 37/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0561 - accuracy: 0.0068\n",
            "Epoch 38/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0560 - accuracy: 0.0068\n",
            "Epoch 39/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0559 - accuracy: 0.0068\n",
            "Epoch 40/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0557 - accuracy: 0.0068\n",
            "Epoch 41/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0556 - accuracy: 0.0068\n",
            "Epoch 42/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0555 - accuracy: 0.0068\n",
            "Epoch 43/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0554 - accuracy: 0.0068\n",
            "Epoch 44/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0553 - accuracy: 0.0068\n",
            "Epoch 45/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0552 - accuracy: 0.0068\n",
            "Epoch 46/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0552 - accuracy: 0.0068\n",
            "Epoch 47/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0551 - accuracy: 0.0068\n",
            "Epoch 48/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0550 - accuracy: 0.0068\n",
            "Epoch 49/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0549 - accuracy: 0.0068\n",
            "Epoch 50/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0548 - accuracy: 0.0068\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "15/15 [==============================] - 1s 3ms/step - loss: 0.0697 - accuracy: 0.0068\n",
            "Epoch 2/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0694 - accuracy: 0.0068\n",
            "Epoch 3/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0692 - accuracy: 0.0068\n",
            "Epoch 4/50\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.0689 - accuracy: 0.0068\n",
            "Epoch 5/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0686 - accuracy: 0.0068\n",
            "Epoch 6/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0684 - accuracy: 0.0068\n",
            "Epoch 7/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0681 - accuracy: 0.0068\n",
            "Epoch 8/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0679 - accuracy: 0.0068\n",
            "Epoch 9/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0677 - accuracy: 0.0068\n",
            "Epoch 10/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0675 - accuracy: 0.0068\n",
            "Epoch 11/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0672 - accuracy: 0.0068\n",
            "Epoch 12/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0671 - accuracy: 0.0068\n",
            "Epoch 13/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0669 - accuracy: 0.0068\n",
            "Epoch 14/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0667 - accuracy: 0.0068\n",
            "Epoch 15/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0665 - accuracy: 0.0068\n",
            "Epoch 16/50\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.0663 - accuracy: 0.0068\n",
            "Epoch 17/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0662 - accuracy: 0.0068\n",
            "Epoch 18/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0660 - accuracy: 0.0068\n",
            "Epoch 19/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0659 - accuracy: 0.0068\n",
            "Epoch 20/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0657 - accuracy: 0.0068\n",
            "Epoch 21/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0656 - accuracy: 0.0068\n",
            "Epoch 22/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0654 - accuracy: 0.0068\n",
            "Epoch 23/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0653 - accuracy: 0.0068\n",
            "Epoch 24/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0652 - accuracy: 0.0068\n",
            "Epoch 25/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0651 - accuracy: 0.0068\n",
            "Epoch 26/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 27/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0648 - accuracy: 0.0068\n",
            "Epoch 28/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 29/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0646 - accuracy: 0.0068\n",
            "Epoch 30/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0645 - accuracy: 0.0068\n",
            "Epoch 31/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0644 - accuracy: 0.0068\n",
            "Epoch 32/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0643 - accuracy: 0.0068\n",
            "Epoch 33/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0642 - accuracy: 0.0068\n",
            "Epoch 34/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0641 - accuracy: 0.0068\n",
            "Epoch 35/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0640 - accuracy: 0.0068\n",
            "Epoch 36/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0640 - accuracy: 0.0068\n",
            "Epoch 37/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0639 - accuracy: 0.0068\n",
            "Epoch 38/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0638 - accuracy: 0.0068\n",
            "Epoch 39/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0637 - accuracy: 0.0068\n",
            "Epoch 40/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0637 - accuracy: 0.0068\n",
            "Epoch 41/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0636 - accuracy: 0.0068\n",
            "Epoch 42/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0635 - accuracy: 0.0068\n",
            "Epoch 43/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0635 - accuracy: 0.0068\n",
            "Epoch 44/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0634 - accuracy: 0.0068\n",
            "Epoch 45/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0634 - accuracy: 0.0068\n",
            "Epoch 46/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0633 - accuracy: 0.0068\n",
            "Epoch 47/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0632 - accuracy: 0.0068\n",
            "Epoch 48/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0632 - accuracy: 0.0068\n",
            "Epoch 49/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0632 - accuracy: 0.0068\n",
            "Epoch 50/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0631 - accuracy: 0.0068\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0709 - accuracy: 0.0068\n",
            "Epoch 2/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0704 - accuracy: 0.0068\n",
            "Epoch 3/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0699 - accuracy: 0.0068\n",
            "Epoch 4/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0694 - accuracy: 0.0068\n",
            "Epoch 5/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0690 - accuracy: 0.0068\n",
            "Epoch 6/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0685 - accuracy: 0.0068\n",
            "Epoch 7/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0681 - accuracy: 0.0068\n",
            "Epoch 8/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0677 - accuracy: 0.0068\n",
            "Epoch 9/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0673 - accuracy: 0.0068\n",
            "Epoch 10/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0669 - accuracy: 0.0068\n",
            "Epoch 11/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0665 - accuracy: 0.0068\n",
            "Epoch 12/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0662 - accuracy: 0.0068\n",
            "Epoch 13/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0658 - accuracy: 0.0068\n",
            "Epoch 14/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0655 - accuracy: 0.0068\n",
            "Epoch 15/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0652 - accuracy: 0.0068\n",
            "Epoch 16/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 17/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0646 - accuracy: 0.0068\n",
            "Epoch 18/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0643 - accuracy: 0.0068\n",
            "Epoch 19/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0641 - accuracy: 0.0068\n",
            "Epoch 20/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0638 - accuracy: 0.0068\n",
            "Epoch 21/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0636 - accuracy: 0.0068\n",
            "Epoch 22/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0633 - accuracy: 0.0068\n",
            "Epoch 23/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0631 - accuracy: 0.0068\n",
            "Epoch 24/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0629 - accuracy: 0.0068\n",
            "Epoch 25/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0627 - accuracy: 0.0068\n",
            "Epoch 26/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0625 - accuracy: 0.0068\n",
            "Epoch 27/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0623 - accuracy: 0.0068\n",
            "Epoch 28/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0621 - accuracy: 0.0068\n",
            "Epoch 29/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0619 - accuracy: 0.0068\n",
            "Epoch 30/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0617 - accuracy: 0.0068\n",
            "Epoch 31/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0616 - accuracy: 0.0068\n",
            "Epoch 32/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0614 - accuracy: 0.0068\n",
            "Epoch 33/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0612 - accuracy: 0.0068\n",
            "Epoch 34/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0611 - accuracy: 0.0068\n",
            "Epoch 35/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0609 - accuracy: 0.0068\n",
            "Epoch 36/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0608 - accuracy: 0.0068\n",
            "Epoch 37/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0607 - accuracy: 0.0068\n",
            "Epoch 38/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0605 - accuracy: 0.0068\n",
            "Epoch 39/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0604 - accuracy: 0.0068\n",
            "Epoch 40/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0603 - accuracy: 0.0068\n",
            "Epoch 41/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0602 - accuracy: 0.0068\n",
            "Epoch 42/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0601 - accuracy: 0.0068\n",
            "Epoch 43/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0599 - accuracy: 0.0068\n",
            "Epoch 44/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0598 - accuracy: 0.0068\n",
            "Epoch 45/50\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0597 - accuracy: 0.0068\n",
            "Epoch 46/50\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0597 - accuracy: 0.0068\n",
            "Epoch 47/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0596 - accuracy: 0.0068\n",
            "Epoch 48/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0595 - accuracy: 0.0068\n",
            "Epoch 49/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0594 - accuracy: 0.0068\n",
            "Epoch 50/50\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0593 - accuracy: 0.0068\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "15/15 [==============================] - 1s 3ms/step - loss: 0.0715 - accuracy: 0.0068\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0709 - accuracy: 0.0068\n",
            "Epoch 3/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0704 - accuracy: 0.0068\n",
            "Epoch 4/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0699 - accuracy: 0.0068\n",
            "Epoch 5/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0694 - accuracy: 0.0068\n",
            "Epoch 6/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0689 - accuracy: 0.0068\n",
            "Epoch 7/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0681 - accuracy: 0.0068\n",
            "Epoch 8/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0672 - accuracy: 0.0068\n",
            "Epoch 9/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0661 - accuracy: 0.0068\n",
            "Epoch 10/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0648 - accuracy: 0.0068\n",
            "Epoch 11/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0633 - accuracy: 0.0068\n",
            "Epoch 12/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0619 - accuracy: 0.0068\n",
            "Epoch 13/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0602 - accuracy: 0.0068\n",
            "Epoch 14/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0586 - accuracy: 0.0068\n",
            "Epoch 15/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0572 - accuracy: 0.0068\n",
            "Epoch 16/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0558 - accuracy: 0.0068\n",
            "Epoch 17/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0545 - accuracy: 0.0068\n",
            "Epoch 18/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0532 - accuracy: 0.0068\n",
            "Epoch 19/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0521 - accuracy: 0.0068\n",
            "Epoch 20/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0510 - accuracy: 0.0068\n",
            "Epoch 21/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0500 - accuracy: 0.0068\n",
            "Epoch 22/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0489 - accuracy: 0.0068\n",
            "Epoch 23/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0479 - accuracy: 0.0068\n",
            "Epoch 24/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0469 - accuracy: 0.0068\n",
            "Epoch 25/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0460 - accuracy: 0.0068\n",
            "Epoch 26/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0450 - accuracy: 0.0068\n",
            "Epoch 27/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0441 - accuracy: 0.0068\n",
            "Epoch 28/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0432 - accuracy: 0.0068\n",
            "Epoch 29/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0422 - accuracy: 0.0068\n",
            "Epoch 30/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0414 - accuracy: 0.0068\n",
            "Epoch 31/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0406 - accuracy: 0.0068\n",
            "Epoch 32/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0398 - accuracy: 0.0068\n",
            "Epoch 33/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0393 - accuracy: 0.0068\n",
            "Epoch 34/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0387 - accuracy: 0.0136\n",
            "Epoch 35/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0382 - accuracy: 0.0476\n",
            "Epoch 36/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0377 - accuracy: 0.0476\n",
            "Epoch 37/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0371 - accuracy: 0.0476\n",
            "Epoch 38/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0367 - accuracy: 0.0476\n",
            "Epoch 39/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0362 - accuracy: 0.0476\n",
            "Epoch 40/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0356 - accuracy: 0.0476\n",
            "Epoch 41/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0351 - accuracy: 0.0476\n",
            "Epoch 42/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0347 - accuracy: 0.0476\n",
            "Epoch 43/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0342 - accuracy: 0.0476\n",
            "Epoch 44/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0337 - accuracy: 0.0476\n",
            "Epoch 45/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0333 - accuracy: 0.0476\n",
            "Epoch 46/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0328 - accuracy: 0.0476\n",
            "Epoch 47/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0323 - accuracy: 0.0476\n",
            "Epoch 48/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0319 - accuracy: 0.0476\n",
            "Epoch 49/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0315 - accuracy: 0.0476\n",
            "Epoch 50/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0310 - accuracy: 0.0476\n",
            "Epoch 51/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0306 - accuracy: 0.0476\n",
            "Epoch 52/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0302 - accuracy: 0.0476\n",
            "Epoch 53/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0298 - accuracy: 0.0476\n",
            "Epoch 54/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0293 - accuracy: 0.0476\n",
            "Epoch 55/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0289 - accuracy: 0.0476\n",
            "Epoch 56/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0284 - accuracy: 0.0476\n",
            "Epoch 57/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0280 - accuracy: 0.0476\n",
            "Epoch 58/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0276 - accuracy: 0.0476\n",
            "Epoch 59/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0272 - accuracy: 0.0476\n",
            "Epoch 60/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0268 - accuracy: 0.0476\n",
            "Epoch 61/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0264 - accuracy: 0.0476\n",
            "Epoch 62/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0259 - accuracy: 0.0476\n",
            "Epoch 63/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0256 - accuracy: 0.0476\n",
            "Epoch 64/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0252 - accuracy: 0.0476\n",
            "Epoch 65/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0247 - accuracy: 0.0476\n",
            "Epoch 66/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0243 - accuracy: 0.0476\n",
            "Epoch 67/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0240 - accuracy: 0.0476\n",
            "Epoch 68/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0236 - accuracy: 0.0476\n",
            "Epoch 69/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0234 - accuracy: 0.0476\n",
            "Epoch 70/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0228 - accuracy: 0.0476\n",
            "Epoch 71/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0225 - accuracy: 0.0476\n",
            "Epoch 72/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0221 - accuracy: 0.0476\n",
            "Epoch 73/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0218 - accuracy: 0.0476\n",
            "Epoch 74/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0214 - accuracy: 0.0476\n",
            "Epoch 75/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0211 - accuracy: 0.0476\n",
            "Epoch 76/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0208 - accuracy: 0.0476\n",
            "Epoch 77/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0204 - accuracy: 0.0476\n",
            "Epoch 78/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0201 - accuracy: 0.0476\n",
            "Epoch 79/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0197 - accuracy: 0.0476\n",
            "Epoch 80/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0196 - accuracy: 0.0476\n",
            "Epoch 81/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0192 - accuracy: 0.0476\n",
            "Epoch 82/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0189 - accuracy: 0.0476\n",
            "Epoch 83/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0185 - accuracy: 0.0476\n",
            "Epoch 84/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0183 - accuracy: 0.0476\n",
            "Epoch 85/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0180 - accuracy: 0.0476\n",
            "Epoch 86/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0177 - accuracy: 0.0476\n",
            "Epoch 87/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0175 - accuracy: 0.0476\n",
            "Epoch 88/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0172 - accuracy: 0.0476\n",
            "Epoch 89/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0169 - accuracy: 0.0476\n",
            "Epoch 90/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0166 - accuracy: 0.0476\n",
            "Epoch 91/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0164 - accuracy: 0.0476\n",
            "Epoch 92/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0164 - accuracy: 0.0476\n",
            "Epoch 93/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0159 - accuracy: 0.0476\n",
            "Epoch 94/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0157 - accuracy: 0.0476\n",
            "Epoch 95/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0155 - accuracy: 0.0476\n",
            "Epoch 96/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0152 - accuracy: 0.0476\n",
            "Epoch 97/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0150 - accuracy: 0.0476\n",
            "Epoch 98/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0148 - accuracy: 0.0476\n",
            "Epoch 99/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0146 - accuracy: 0.0476\n",
            "Epoch 100/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0143 - accuracy: 0.0476\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 1s 3ms/step - loss: 0.0719 - accuracy: 0.0000e+00\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0712 - accuracy: 0.0000e+00\n",
            "Epoch 3/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0706 - accuracy: 0.0000e+00\n",
            "Epoch 4/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0699 - accuracy: 0.0000e+00\n",
            "Epoch 5/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0691 - accuracy: 0.0000e+00\n",
            "Epoch 6/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0682 - accuracy: 0.0000e+00\n",
            "Epoch 7/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0671 - accuracy: 0.0000e+00\n",
            "Epoch 8/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0660 - accuracy: 0.0000e+00\n",
            "Epoch 9/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0646 - accuracy: 0.0000e+00\n",
            "Epoch 10/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0632 - accuracy: 0.0000e+00\n",
            "Epoch 11/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0613 - accuracy: 0.0000e+00\n",
            "Epoch 12/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0595 - accuracy: 0.0000e+00\n",
            "Epoch 13/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0575 - accuracy: 0.0000e+00\n",
            "Epoch 14/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0554 - accuracy: 0.0000e+00\n",
            "Epoch 15/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0529 - accuracy: 0.0000e+00\n",
            "Epoch 16/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0505 - accuracy: 0.0000e+00\n",
            "Epoch 17/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0479 - accuracy: 0.0000e+00\n",
            "Epoch 18/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0453 - accuracy: 0.0340\n",
            "Epoch 19/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0425 - accuracy: 0.0340\n",
            "Epoch 20/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0397 - accuracy: 0.0340\n",
            "Epoch 21/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0367 - accuracy: 0.0340\n",
            "Epoch 22/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0339 - accuracy: 0.0340\n",
            "Epoch 23/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0312 - accuracy: 0.0340\n",
            "Epoch 24/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0288 - accuracy: 0.0340\n",
            "Epoch 25/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0264 - accuracy: 0.0340\n",
            "Epoch 26/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0243 - accuracy: 0.0340\n",
            "Epoch 27/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0224 - accuracy: 0.0340\n",
            "Epoch 28/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0208 - accuracy: 0.0340\n",
            "Epoch 29/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0193 - accuracy: 0.0340\n",
            "Epoch 30/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0181 - accuracy: 0.0340\n",
            "Epoch 31/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0170 - accuracy: 0.0340\n",
            "Epoch 32/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0161 - accuracy: 0.0340\n",
            "Epoch 33/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0152 - accuracy: 0.0340\n",
            "Epoch 34/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0145 - accuracy: 0.0340\n",
            "Epoch 35/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0139 - accuracy: 0.0340\n",
            "Epoch 36/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0133 - accuracy: 0.0340\n",
            "Epoch 37/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0128 - accuracy: 0.0340\n",
            "Epoch 38/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0124 - accuracy: 0.0340\n",
            "Epoch 39/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0120 - accuracy: 0.0340\n",
            "Epoch 40/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0116 - accuracy: 0.0340\n",
            "Epoch 41/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0113 - accuracy: 0.0340\n",
            "Epoch 42/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0109 - accuracy: 0.0340\n",
            "Epoch 43/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0106 - accuracy: 0.0340\n",
            "Epoch 44/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0104 - accuracy: 0.0340\n",
            "Epoch 45/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0101 - accuracy: 0.0340\n",
            "Epoch 46/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0099 - accuracy: 0.0340\n",
            "Epoch 47/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0097 - accuracy: 0.0340\n",
            "Epoch 48/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0095 - accuracy: 0.0340\n",
            "Epoch 49/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0093 - accuracy: 0.0340\n",
            "Epoch 50/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0091 - accuracy: 0.0340\n",
            "Epoch 51/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0090 - accuracy: 0.0340\n",
            "Epoch 52/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0088 - accuracy: 0.0340\n",
            "Epoch 53/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0086 - accuracy: 0.0340\n",
            "Epoch 54/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0085 - accuracy: 0.0340\n",
            "Epoch 55/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0083 - accuracy: 0.0340\n",
            "Epoch 56/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0082 - accuracy: 0.0340\n",
            "Epoch 57/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0083 - accuracy: 0.0340\n",
            "Epoch 58/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0080 - accuracy: 0.0340\n",
            "Epoch 59/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0078 - accuracy: 0.0340\n",
            "Epoch 60/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0079 - accuracy: 0.0340\n",
            "Epoch 61/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0076 - accuracy: 0.0340\n",
            "Epoch 62/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0075 - accuracy: 0.0340\n",
            "Epoch 63/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0074 - accuracy: 0.0340\n",
            "Epoch 64/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0073 - accuracy: 0.0340\n",
            "Epoch 65/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0073 - accuracy: 0.0340\n",
            "Epoch 66/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0072 - accuracy: 0.0340\n",
            "Epoch 67/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0072 - accuracy: 0.0340\n",
            "Epoch 68/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0070 - accuracy: 0.0340\n",
            "Epoch 69/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0069 - accuracy: 0.0340\n",
            "Epoch 70/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0068 - accuracy: 0.0340\n",
            "Epoch 71/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0067 - accuracy: 0.0340\n",
            "Epoch 72/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0066 - accuracy: 0.0340\n",
            "Epoch 73/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0066 - accuracy: 0.0340\n",
            "Epoch 74/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0066 - accuracy: 0.0340\n",
            "Epoch 75/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0065 - accuracy: 0.0340\n",
            "Epoch 76/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0064 - accuracy: 0.0340\n",
            "Epoch 77/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0063 - accuracy: 0.0340\n",
            "Epoch 78/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0063 - accuracy: 0.0340\n",
            "Epoch 79/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0062 - accuracy: 0.0340\n",
            "Epoch 80/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0061 - accuracy: 0.0340\n",
            "Epoch 81/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0061 - accuracy: 0.0340\n",
            "Epoch 82/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0061 - accuracy: 0.0340\n",
            "Epoch 83/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0060 - accuracy: 0.0340\n",
            "Epoch 84/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0060 - accuracy: 0.0340\n",
            "Epoch 85/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0059 - accuracy: 0.0340\n",
            "Epoch 86/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0059 - accuracy: 0.0340\n",
            "Epoch 87/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 0.0340\n",
            "Epoch 88/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0059 - accuracy: 0.0340\n",
            "Epoch 89/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0058 - accuracy: 0.0340\n",
            "Epoch 90/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0058 - accuracy: 0.0340\n",
            "Epoch 91/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0057 - accuracy: 0.0340\n",
            "Epoch 92/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0057 - accuracy: 0.0340\n",
            "Epoch 93/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0057 - accuracy: 0.0340\n",
            "Epoch 94/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0056 - accuracy: 0.0340\n",
            "Epoch 95/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0056 - accuracy: 0.0340\n",
            "Epoch 96/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0056 - accuracy: 0.0340\n",
            "Epoch 97/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0056 - accuracy: 0.0340\n",
            "Epoch 98/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0055 - accuracy: 0.0340\n",
            "Epoch 99/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0055 - accuracy: 0.0340\n",
            "Epoch 100/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0057 - accuracy: 0.0340\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "15/15 [==============================] - 1s 3ms/step - loss: 0.0653 - accuracy: 0.0068 \n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0646 - accuracy: 0.0068\n",
            "Epoch 3/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0638 - accuracy: 0.0068\n",
            "Epoch 4/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0630 - accuracy: 0.0068\n",
            "Epoch 5/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0621 - accuracy: 0.0068\n",
            "Epoch 6/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0612 - accuracy: 0.0068\n",
            "Epoch 7/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0602 - accuracy: 0.0068\n",
            "Epoch 8/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0592 - accuracy: 0.0068\n",
            "Epoch 9/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0581 - accuracy: 0.0068\n",
            "Epoch 10/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0570 - accuracy: 0.0068\n",
            "Epoch 11/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0558 - accuracy: 0.0068\n",
            "Epoch 12/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0547 - accuracy: 0.0068\n",
            "Epoch 13/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0536 - accuracy: 0.0068\n",
            "Epoch 14/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0524 - accuracy: 0.0068\n",
            "Epoch 15/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0513 - accuracy: 0.0068\n",
            "Epoch 16/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0503 - accuracy: 0.0068\n",
            "Epoch 17/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0493 - accuracy: 0.0068\n",
            "Epoch 18/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0483 - accuracy: 0.0068\n",
            "Epoch 19/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0472 - accuracy: 0.0068\n",
            "Epoch 20/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0462 - accuracy: 0.0068\n",
            "Epoch 21/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0452 - accuracy: 0.0068\n",
            "Epoch 22/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0442 - accuracy: 0.0068\n",
            "Epoch 23/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0435 - accuracy: 0.0068\n",
            "Epoch 24/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0425 - accuracy: 0.0068\n",
            "Epoch 25/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0418 - accuracy: 0.0068\n",
            "Epoch 26/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0409 - accuracy: 0.0068\n",
            "Epoch 27/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0401 - accuracy: 0.0068\n",
            "Epoch 28/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0392 - accuracy: 0.0068\n",
            "Epoch 29/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0384 - accuracy: 0.0068\n",
            "Epoch 30/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0376 - accuracy: 0.0068\n",
            "Epoch 31/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0368 - accuracy: 0.0068\n",
            "Epoch 32/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0360 - accuracy: 0.0068\n",
            "Epoch 33/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0352 - accuracy: 0.0068\n",
            "Epoch 34/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0343 - accuracy: 0.0068\n",
            "Epoch 35/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0336 - accuracy: 0.0068\n",
            "Epoch 36/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0328 - accuracy: 0.0068\n",
            "Epoch 37/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0320 - accuracy: 0.0476\n",
            "Epoch 38/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0312 - accuracy: 0.0476\n",
            "Epoch 39/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0304 - accuracy: 0.0476\n",
            "Epoch 40/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0297 - accuracy: 0.0476\n",
            "Epoch 41/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0290 - accuracy: 0.0476\n",
            "Epoch 42/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0283 - accuracy: 0.0476\n",
            "Epoch 43/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0276 - accuracy: 0.0476\n",
            "Epoch 44/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0269 - accuracy: 0.0476\n",
            "Epoch 45/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0263 - accuracy: 0.0476\n",
            "Epoch 46/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0257 - accuracy: 0.0476\n",
            "Epoch 47/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0250 - accuracy: 0.0476\n",
            "Epoch 48/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0244 - accuracy: 0.0476\n",
            "Epoch 49/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0238 - accuracy: 0.0476\n",
            "Epoch 50/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0233 - accuracy: 0.0476\n",
            "Epoch 51/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0227 - accuracy: 0.0476\n",
            "Epoch 52/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0222 - accuracy: 0.0476\n",
            "Epoch 53/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0216 - accuracy: 0.0476\n",
            "Epoch 54/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0212 - accuracy: 0.0476\n",
            "Epoch 55/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0207 - accuracy: 0.0476\n",
            "Epoch 56/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0202 - accuracy: 0.0476\n",
            "Epoch 57/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0198 - accuracy: 0.0476\n",
            "Epoch 58/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0193 - accuracy: 0.0476\n",
            "Epoch 59/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0188 - accuracy: 0.0476\n",
            "Epoch 60/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0184 - accuracy: 0.0476\n",
            "Epoch 61/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0180 - accuracy: 0.0476\n",
            "Epoch 62/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0177 - accuracy: 0.0476\n",
            "Epoch 63/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0173 - accuracy: 0.0476\n",
            "Epoch 64/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0170 - accuracy: 0.0476\n",
            "Epoch 65/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0166 - accuracy: 0.0476\n",
            "Epoch 66/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0164 - accuracy: 0.0476\n",
            "Epoch 67/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0161 - accuracy: 0.0476\n",
            "Epoch 68/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0158 - accuracy: 0.0476\n",
            "Epoch 69/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0155 - accuracy: 0.0476\n",
            "Epoch 70/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0153 - accuracy: 0.0476\n",
            "Epoch 71/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0150 - accuracy: 0.0476\n",
            "Epoch 72/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0148 - accuracy: 0.0476\n",
            "Epoch 73/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0146 - accuracy: 0.0476\n",
            "Epoch 74/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0144 - accuracy: 0.0476\n",
            "Epoch 75/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0142 - accuracy: 0.0476\n",
            "Epoch 76/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0141 - accuracy: 0.0476\n",
            "Epoch 77/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0137 - accuracy: 0.0476\n",
            "Epoch 78/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0136 - accuracy: 0.0476\n",
            "Epoch 79/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0134 - accuracy: 0.0476\n",
            "Epoch 80/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0132 - accuracy: 0.0476\n",
            "Epoch 81/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0130 - accuracy: 0.0476\n",
            "Epoch 82/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0128 - accuracy: 0.0476\n",
            "Epoch 83/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0126 - accuracy: 0.0476\n",
            "Epoch 84/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0125 - accuracy: 0.0476\n",
            "Epoch 85/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0123 - accuracy: 0.0476\n",
            "Epoch 86/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0121 - accuracy: 0.0476\n",
            "Epoch 87/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0119 - accuracy: 0.0476\n",
            "Epoch 88/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0118 - accuracy: 0.0476\n",
            "Epoch 89/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0116 - accuracy: 0.0476\n",
            "Epoch 90/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0114 - accuracy: 0.0476\n",
            "Epoch 91/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0112 - accuracy: 0.0476\n",
            "Epoch 92/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0111 - accuracy: 0.0476\n",
            "Epoch 93/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0110 - accuracy: 0.0476\n",
            "Epoch 94/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0108 - accuracy: 0.0476\n",
            "Epoch 95/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0106 - accuracy: 0.0476\n",
            "Epoch 96/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0105 - accuracy: 0.0476\n",
            "Epoch 97/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0103 - accuracy: 0.0476\n",
            "Epoch 98/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0101 - accuracy: 0.0476\n",
            "Epoch 99/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0101 - accuracy: 0.0476\n",
            "Epoch 100/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0097 - accuracy: 0.0476\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "15/15 [==============================] - 1s 3ms/step - loss: 0.0696 - accuracy: 0.0068\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0690 - accuracy: 0.0068\n",
            "Epoch 3/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0683 - accuracy: 0.0068\n",
            "Epoch 4/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0674 - accuracy: 0.0068\n",
            "Epoch 5/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0664 - accuracy: 0.0068\n",
            "Epoch 6/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0653 - accuracy: 0.0068\n",
            "Epoch 7/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0638 - accuracy: 0.0068\n",
            "Epoch 8/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0623 - accuracy: 0.0068\n",
            "Epoch 9/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0607 - accuracy: 0.0068\n",
            "Epoch 10/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0588 - accuracy: 0.0068\n",
            "Epoch 11/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0570 - accuracy: 0.0068\n",
            "Epoch 12/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0554 - accuracy: 0.0068\n",
            "Epoch 13/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0537 - accuracy: 0.0068\n",
            "Epoch 14/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0524 - accuracy: 0.0068\n",
            "Epoch 15/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0508 - accuracy: 0.0068\n",
            "Epoch 16/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0496 - accuracy: 0.0068\n",
            "Epoch 17/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0483 - accuracy: 0.0068\n",
            "Epoch 18/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0473 - accuracy: 0.0068\n",
            "Epoch 19/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0458 - accuracy: 0.0068\n",
            "Epoch 20/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0445 - accuracy: 0.0068\n",
            "Epoch 21/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0433 - accuracy: 0.0068\n",
            "Epoch 22/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0418 - accuracy: 0.0068\n",
            "Epoch 23/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0404 - accuracy: 0.0068\n",
            "Epoch 24/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0391 - accuracy: 0.0068\n",
            "Epoch 25/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0378 - accuracy: 0.0204\n",
            "Epoch 26/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0366 - accuracy: 0.0408\n",
            "Epoch 27/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0353 - accuracy: 0.0408\n",
            "Epoch 28/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0340 - accuracy: 0.0408\n",
            "Epoch 29/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0329 - accuracy: 0.0408\n",
            "Epoch 30/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0319 - accuracy: 0.0408\n",
            "Epoch 31/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0311 - accuracy: 0.0408\n",
            "Epoch 32/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0300 - accuracy: 0.0408\n",
            "Epoch 33/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0291 - accuracy: 0.0408\n",
            "Epoch 34/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0282 - accuracy: 0.0408\n",
            "Epoch 35/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0274 - accuracy: 0.0408\n",
            "Epoch 36/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0266 - accuracy: 0.0408\n",
            "Epoch 37/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0258 - accuracy: 0.0408\n",
            "Epoch 38/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0250 - accuracy: 0.0408\n",
            "Epoch 39/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0243 - accuracy: 0.0408\n",
            "Epoch 40/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0237 - accuracy: 0.0408\n",
            "Epoch 41/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0229 - accuracy: 0.0408\n",
            "Epoch 42/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0221 - accuracy: 0.0408\n",
            "Epoch 43/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0215 - accuracy: 0.0408\n",
            "Epoch 44/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0208 - accuracy: 0.0408\n",
            "Epoch 45/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0202 - accuracy: 0.0408\n",
            "Epoch 46/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0196 - accuracy: 0.0408\n",
            "Epoch 47/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0191 - accuracy: 0.0408\n",
            "Epoch 48/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0183 - accuracy: 0.0408\n",
            "Epoch 49/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0176 - accuracy: 0.0408\n",
            "Epoch 50/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0169 - accuracy: 0.0408\n",
            "Epoch 51/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0162 - accuracy: 0.0408\n",
            "Epoch 52/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0158 - accuracy: 0.0408\n",
            "Epoch 53/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0151 - accuracy: 0.0408\n",
            "Epoch 54/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0144 - accuracy: 0.0408\n",
            "Epoch 55/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0139 - accuracy: 0.0408\n",
            "Epoch 56/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0135 - accuracy: 0.0408\n",
            "Epoch 57/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0129 - accuracy: 0.0408\n",
            "Epoch 58/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0124 - accuracy: 0.0408\n",
            "Epoch 59/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0120 - accuracy: 0.0408\n",
            "Epoch 60/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0114 - accuracy: 0.0408\n",
            "Epoch 61/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0110 - accuracy: 0.0408\n",
            "Epoch 62/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0106 - accuracy: 0.0408\n",
            "Epoch 63/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0104 - accuracy: 0.0408\n",
            "Epoch 64/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0100 - accuracy: 0.0408\n",
            "Epoch 65/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0098 - accuracy: 0.0408\n",
            "Epoch 66/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0095 - accuracy: 0.0408\n",
            "Epoch 67/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0090 - accuracy: 0.0408\n",
            "Epoch 68/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0089 - accuracy: 0.0408\n",
            "Epoch 69/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0085 - accuracy: 0.0408\n",
            "Epoch 70/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0083 - accuracy: 0.0408\n",
            "Epoch 71/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0082 - accuracy: 0.0408\n",
            "Epoch 72/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0079 - accuracy: 0.0408\n",
            "Epoch 73/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0077 - accuracy: 0.0408\n",
            "Epoch 74/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0075 - accuracy: 0.0408\n",
            "Epoch 75/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0073 - accuracy: 0.0408\n",
            "Epoch 76/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0072 - accuracy: 0.0408\n",
            "Epoch 77/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0070 - accuracy: 0.0408\n",
            "Epoch 78/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0069 - accuracy: 0.0408\n",
            "Epoch 79/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0068 - accuracy: 0.0408\n",
            "Epoch 80/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0068 - accuracy: 0.0408\n",
            "Epoch 81/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0066 - accuracy: 0.0408\n",
            "Epoch 82/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0063 - accuracy: 0.0408\n",
            "Epoch 83/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0062 - accuracy: 0.0408\n",
            "Epoch 84/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0061 - accuracy: 0.0408\n",
            "Epoch 85/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0060 - accuracy: 0.0408\n",
            "Epoch 86/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 0.0408\n",
            "Epoch 87/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0058 - accuracy: 0.0408\n",
            "Epoch 88/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0057 - accuracy: 0.0408\n",
            "Epoch 89/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0057 - accuracy: 0.0408\n",
            "Epoch 90/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0056 - accuracy: 0.0408\n",
            "Epoch 91/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0055 - accuracy: 0.0408\n",
            "Epoch 92/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0054 - accuracy: 0.0408\n",
            "Epoch 93/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0054 - accuracy: 0.0408\n",
            "Epoch 94/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0053 - accuracy: 0.0408\n",
            "Epoch 95/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0052 - accuracy: 0.0408\n",
            "Epoch 96/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0052 - accuracy: 0.0408\n",
            "Epoch 97/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0408\n",
            "Epoch 98/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0408\n",
            "Epoch 99/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0408\n",
            "Epoch 100/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0054 - accuracy: 0.0408\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 1s 3ms/step - loss: 0.0707 - accuracy: 0.0068\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0699 - accuracy: 0.0068\n",
            "Epoch 3/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0691 - accuracy: 0.0068\n",
            "Epoch 4/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0683 - accuracy: 0.0068\n",
            "Epoch 5/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0675 - accuracy: 0.0068\n",
            "Epoch 6/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0667 - accuracy: 0.0068\n",
            "Epoch 7/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0657 - accuracy: 0.0068\n",
            "Epoch 8/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 9/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0638 - accuracy: 0.0068\n",
            "Epoch 10/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0628 - accuracy: 0.0068\n",
            "Epoch 11/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0616 - accuracy: 0.0068\n",
            "Epoch 12/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0605 - accuracy: 0.0068\n",
            "Epoch 13/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0590 - accuracy: 0.0068\n",
            "Epoch 14/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0576 - accuracy: 0.0068\n",
            "Epoch 15/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0559 - accuracy: 0.0068\n",
            "Epoch 16/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0541 - accuracy: 0.0068\n",
            "Epoch 17/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0522 - accuracy: 0.0068\n",
            "Epoch 18/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0501 - accuracy: 0.0270\n",
            "Epoch 19/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0479 - accuracy: 0.0473\n",
            "Epoch 20/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0458 - accuracy: 0.0473\n",
            "Epoch 21/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0434 - accuracy: 0.0473\n",
            "Epoch 22/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0410 - accuracy: 0.0473\n",
            "Epoch 23/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0386 - accuracy: 0.0473\n",
            "Epoch 24/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0363 - accuracy: 0.0473\n",
            "Epoch 25/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0337 - accuracy: 0.0473\n",
            "Epoch 26/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0315 - accuracy: 0.0473\n",
            "Epoch 27/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0292 - accuracy: 0.0473\n",
            "Epoch 28/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0272 - accuracy: 0.0473\n",
            "Epoch 29/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0252 - accuracy: 0.0473\n",
            "Epoch 30/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0234 - accuracy: 0.0473\n",
            "Epoch 31/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0217 - accuracy: 0.0473\n",
            "Epoch 32/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0201 - accuracy: 0.0473\n",
            "Epoch 33/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0188 - accuracy: 0.0473\n",
            "Epoch 34/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0175 - accuracy: 0.0473\n",
            "Epoch 35/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0164 - accuracy: 0.0473\n",
            "Epoch 36/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0155 - accuracy: 0.0473\n",
            "Epoch 37/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0145 - accuracy: 0.0473\n",
            "Epoch 38/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0138 - accuracy: 0.0473\n",
            "Epoch 39/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0132 - accuracy: 0.0473\n",
            "Epoch 40/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0127 - accuracy: 0.0473\n",
            "Epoch 41/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0120 - accuracy: 0.0473\n",
            "Epoch 42/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0116 - accuracy: 0.0473\n",
            "Epoch 43/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0112 - accuracy: 0.0473\n",
            "Epoch 44/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0109 - accuracy: 0.0473\n",
            "Epoch 45/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0105 - accuracy: 0.0473\n",
            "Epoch 46/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0102 - accuracy: 0.0473\n",
            "Epoch 47/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0100 - accuracy: 0.0473\n",
            "Epoch 48/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0098 - accuracy: 0.0473\n",
            "Epoch 49/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0095 - accuracy: 0.0473\n",
            "Epoch 50/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0094 - accuracy: 0.0473\n",
            "Epoch 51/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0091 - accuracy: 0.0473\n",
            "Epoch 52/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0089 - accuracy: 0.0473\n",
            "Epoch 53/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0088 - accuracy: 0.0473\n",
            "Epoch 54/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0087 - accuracy: 0.0473\n",
            "Epoch 55/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0085 - accuracy: 0.0473\n",
            "Epoch 56/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0083 - accuracy: 0.0473\n",
            "Epoch 57/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0083 - accuracy: 0.0473\n",
            "Epoch 58/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0082 - accuracy: 0.0473\n",
            "Epoch 59/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0080 - accuracy: 0.0473\n",
            "Epoch 60/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0081 - accuracy: 0.0473\n",
            "Epoch 61/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0079 - accuracy: 0.0473\n",
            "Epoch 62/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0077 - accuracy: 0.0473\n",
            "Epoch 63/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0076 - accuracy: 0.0473\n",
            "Epoch 64/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0075 - accuracy: 0.0473\n",
            "Epoch 65/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0074 - accuracy: 0.0473\n",
            "Epoch 66/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0073 - accuracy: 0.0473\n",
            "Epoch 67/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0073 - accuracy: 0.0473\n",
            "Epoch 68/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0072 - accuracy: 0.0473\n",
            "Epoch 69/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0073 - accuracy: 0.0473\n",
            "Epoch 70/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0071 - accuracy: 0.0473\n",
            "Epoch 71/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0070 - accuracy: 0.0473\n",
            "Epoch 72/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0069 - accuracy: 0.0473\n",
            "Epoch 73/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0069 - accuracy: 0.0473\n",
            "Epoch 74/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0068 - accuracy: 0.0473\n",
            "Epoch 75/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0067 - accuracy: 0.0473\n",
            "Epoch 76/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0068 - accuracy: 0.0473\n",
            "Epoch 77/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0066 - accuracy: 0.0473\n",
            "Epoch 78/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0066 - accuracy: 0.0473\n",
            "Epoch 79/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0065 - accuracy: 0.0473\n",
            "Epoch 80/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0064 - accuracy: 0.0473\n",
            "Epoch 81/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0064 - accuracy: 0.0473\n",
            "Epoch 82/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0063 - accuracy: 0.0473\n",
            "Epoch 83/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0063 - accuracy: 0.0473\n",
            "Epoch 84/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0062 - accuracy: 0.0473\n",
            "Epoch 85/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0062 - accuracy: 0.0473\n",
            "Epoch 86/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0061 - accuracy: 0.0473\n",
            "Epoch 87/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0061 - accuracy: 0.0473\n",
            "Epoch 88/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0061 - accuracy: 0.0473\n",
            "Epoch 89/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0060 - accuracy: 0.0473\n",
            "Epoch 90/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0059 - accuracy: 0.0473\n",
            "Epoch 91/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0059 - accuracy: 0.0473\n",
            "Epoch 92/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0059 - accuracy: 0.0473\n",
            "Epoch 93/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0059 - accuracy: 0.0473\n",
            "Epoch 94/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0058 - accuracy: 0.0473\n",
            "Epoch 95/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0058 - accuracy: 0.0473\n",
            "Epoch 96/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0057 - accuracy: 0.0473\n",
            "Epoch 97/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0057 - accuracy: 0.0473\n",
            "Epoch 98/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0056 - accuracy: 0.0473\n",
            "Epoch 99/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0056 - accuracy: 0.0473\n",
            "Epoch 100/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0056 - accuracy: 0.0473\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0717 - accuracy: 0.0068\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0714 - accuracy: 0.0068\n",
            "Epoch 3/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0711 - accuracy: 0.0068\n",
            "Epoch 4/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0709 - accuracy: 0.0068\n",
            "Epoch 5/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0707 - accuracy: 0.0068\n",
            "Epoch 6/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0704 - accuracy: 0.0068\n",
            "Epoch 7/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0702 - accuracy: 0.0068\n",
            "Epoch 8/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0700 - accuracy: 0.0068\n",
            "Epoch 9/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0698 - accuracy: 0.0068\n",
            "Epoch 10/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0696 - accuracy: 0.0068\n",
            "Epoch 11/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0694 - accuracy: 0.0068\n",
            "Epoch 12/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0692 - accuracy: 0.0068\n",
            "Epoch 13/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0690 - accuracy: 0.0068\n",
            "Epoch 14/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0689 - accuracy: 0.0068\n",
            "Epoch 15/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0687 - accuracy: 0.0068\n",
            "Epoch 16/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0686 - accuracy: 0.0068\n",
            "Epoch 17/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0684 - accuracy: 0.0068\n",
            "Epoch 18/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0683 - accuracy: 0.0068\n",
            "Epoch 19/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0681 - accuracy: 0.0068\n",
            "Epoch 20/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0680 - accuracy: 0.0068\n",
            "Epoch 21/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0679 - accuracy: 0.0068\n",
            "Epoch 22/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0677 - accuracy: 0.0068\n",
            "Epoch 23/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0676 - accuracy: 0.0068\n",
            "Epoch 24/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0675 - accuracy: 0.0068\n",
            "Epoch 25/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0674 - accuracy: 0.0068\n",
            "Epoch 26/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0673 - accuracy: 0.0068\n",
            "Epoch 27/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0672 - accuracy: 0.0068\n",
            "Epoch 28/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0671 - accuracy: 0.0068\n",
            "Epoch 29/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0670 - accuracy: 0.0068\n",
            "Epoch 30/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0669 - accuracy: 0.0068\n",
            "Epoch 31/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0668 - accuracy: 0.0068\n",
            "Epoch 32/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0667 - accuracy: 0.0068\n",
            "Epoch 33/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0666 - accuracy: 0.0068\n",
            "Epoch 34/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0666 - accuracy: 0.0068\n",
            "Epoch 35/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0665 - accuracy: 0.0068\n",
            "Epoch 36/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0664 - accuracy: 0.0068\n",
            "Epoch 37/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0663 - accuracy: 0.0068\n",
            "Epoch 38/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0663 - accuracy: 0.0068\n",
            "Epoch 39/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0662 - accuracy: 0.0068\n",
            "Epoch 40/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0661 - accuracy: 0.0068\n",
            "Epoch 41/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0661 - accuracy: 0.0068\n",
            "Epoch 42/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0660 - accuracy: 0.0068\n",
            "Epoch 43/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0660 - accuracy: 0.0068\n",
            "Epoch 44/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0659 - accuracy: 0.0068\n",
            "Epoch 45/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0659 - accuracy: 0.0068\n",
            "Epoch 46/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0658 - accuracy: 0.0068\n",
            "Epoch 47/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0658 - accuracy: 0.0068\n",
            "Epoch 48/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0657 - accuracy: 0.0068\n",
            "Epoch 49/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0657 - accuracy: 0.0068\n",
            "Epoch 50/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0656 - accuracy: 0.0068\n",
            "Epoch 51/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0656 - accuracy: 0.0068\n",
            "Epoch 52/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0655 - accuracy: 0.0068\n",
            "Epoch 53/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0655 - accuracy: 0.0068\n",
            "Epoch 54/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0655 - accuracy: 0.0068\n",
            "Epoch 55/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0654 - accuracy: 0.0068\n",
            "Epoch 56/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0654 - accuracy: 0.0068\n",
            "Epoch 57/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0654 - accuracy: 0.0068\n",
            "Epoch 58/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0653 - accuracy: 0.0068\n",
            "Epoch 59/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0653 - accuracy: 0.0068\n",
            "Epoch 60/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0653 - accuracy: 0.0068\n",
            "Epoch 61/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0652 - accuracy: 0.0068\n",
            "Epoch 62/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0652 - accuracy: 0.0068\n",
            "Epoch 63/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0652 - accuracy: 0.0068\n",
            "Epoch 64/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0652 - accuracy: 0.0068\n",
            "Epoch 65/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0651 - accuracy: 0.0068\n",
            "Epoch 66/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0651 - accuracy: 0.0068\n",
            "Epoch 67/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0651 - accuracy: 0.0068\n",
            "Epoch 68/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0651 - accuracy: 0.0068\n",
            "Epoch 69/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0650 - accuracy: 0.0068\n",
            "Epoch 70/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0650 - accuracy: 0.0068\n",
            "Epoch 71/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0650 - accuracy: 0.0068\n",
            "Epoch 72/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0650 - accuracy: 0.0068\n",
            "Epoch 73/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0650 - accuracy: 0.0068\n",
            "Epoch 74/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 75/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 76/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 77/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 78/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 79/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 80/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 81/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0648 - accuracy: 0.0068\n",
            "Epoch 82/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0648 - accuracy: 0.0068\n",
            "Epoch 83/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0648 - accuracy: 0.0068\n",
            "Epoch 84/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0648 - accuracy: 0.0068\n",
            "Epoch 85/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0648 - accuracy: 0.0068\n",
            "Epoch 86/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0648 - accuracy: 0.0068\n",
            "Epoch 87/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0648 - accuracy: 0.0068\n",
            "Epoch 88/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0648 - accuracy: 0.0068\n",
            "Epoch 89/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 90/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 91/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 92/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 93/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 94/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 95/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 96/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 97/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 98/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 99/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 100/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0647 - accuracy: 0.0068\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "15/15 [==============================] - 1s 5ms/step - loss: 0.0720 - accuracy: 0.0068\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0717 - accuracy: 0.0000e+00\n",
            "Epoch 3/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0713 - accuracy: 0.0000e+00\n",
            "Epoch 4/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0710 - accuracy: 0.0000e+00\n",
            "Epoch 5/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0707 - accuracy: 0.0000e+00\n",
            "Epoch 6/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0704 - accuracy: 0.0000e+00\n",
            "Epoch 7/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0701 - accuracy: 0.0000e+00\n",
            "Epoch 8/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0698 - accuracy: 0.0000e+00\n",
            "Epoch 9/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0695 - accuracy: 0.0000e+00\n",
            "Epoch 10/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0693 - accuracy: 0.0000e+00\n",
            "Epoch 11/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0690 - accuracy: 0.0000e+00\n",
            "Epoch 12/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0688 - accuracy: 0.0000e+00\n",
            "Epoch 13/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0686 - accuracy: 0.0000e+00\n",
            "Epoch 14/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0684 - accuracy: 0.0000e+00\n",
            "Epoch 15/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0681 - accuracy: 0.0000e+00\n",
            "Epoch 16/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0679 - accuracy: 0.0000e+00\n",
            "Epoch 17/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0677 - accuracy: 0.0000e+00\n",
            "Epoch 18/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0675 - accuracy: 0.0000e+00\n",
            "Epoch 19/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0674 - accuracy: 0.0000e+00\n",
            "Epoch 20/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0672 - accuracy: 0.0000e+00\n",
            "Epoch 21/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0670 - accuracy: 0.0000e+00\n",
            "Epoch 22/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0669 - accuracy: 0.0000e+00\n",
            "Epoch 23/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0667 - accuracy: 0.0000e+00\n",
            "Epoch 24/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0665 - accuracy: 0.0000e+00\n",
            "Epoch 25/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0664 - accuracy: 0.0000e+00\n",
            "Epoch 26/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0662 - accuracy: 0.0000e+00\n",
            "Epoch 27/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0661 - accuracy: 0.0000e+00\n",
            "Epoch 28/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0660 - accuracy: 0.0000e+00\n",
            "Epoch 29/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0658 - accuracy: 0.0000e+00\n",
            "Epoch 30/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0657 - accuracy: 0.0000e+00\n",
            "Epoch 31/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0656 - accuracy: 0.0000e+00\n",
            "Epoch 32/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0655 - accuracy: 0.0000e+00\n",
            "Epoch 33/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0654 - accuracy: 0.0000e+00\n",
            "Epoch 34/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0653 - accuracy: 0.0000e+00\n",
            "Epoch 35/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0652 - accuracy: 0.0000e+00\n",
            "Epoch 36/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0651 - accuracy: 0.0000e+00\n",
            "Epoch 37/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0650 - accuracy: 0.0000e+00\n",
            "Epoch 38/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0649 - accuracy: 0.0000e+00\n",
            "Epoch 39/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0648 - accuracy: 0.0000e+00\n",
            "Epoch 40/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0647 - accuracy: 0.0000e+00\n",
            "Epoch 41/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0647 - accuracy: 0.0000e+00\n",
            "Epoch 42/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0646 - accuracy: 0.0000e+00\n",
            "Epoch 43/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0645 - accuracy: 0.0000e+00\n",
            "Epoch 44/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0644 - accuracy: 0.0000e+00\n",
            "Epoch 45/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0644 - accuracy: 0.0000e+00\n",
            "Epoch 46/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0643 - accuracy: 0.0000e+00\n",
            "Epoch 47/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0642 - accuracy: 0.0000e+00\n",
            "Epoch 48/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0642 - accuracy: 0.0000e+00\n",
            "Epoch 49/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0641 - accuracy: 0.0000e+00\n",
            "Epoch 50/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0640 - accuracy: 0.0000e+00\n",
            "Epoch 51/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0640 - accuracy: 0.0000e+00\n",
            "Epoch 52/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0639 - accuracy: 0.0000e+00\n",
            "Epoch 53/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0639 - accuracy: 0.0000e+00\n",
            "Epoch 54/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0638 - accuracy: 0.0000e+00\n",
            "Epoch 55/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0638 - accuracy: 0.0000e+00\n",
            "Epoch 56/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0637 - accuracy: 0.0000e+00\n",
            "Epoch 57/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0637 - accuracy: 0.0000e+00\n",
            "Epoch 58/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0637 - accuracy: 0.0000e+00\n",
            "Epoch 59/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0636 - accuracy: 0.0000e+00\n",
            "Epoch 60/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0636 - accuracy: 0.0000e+00\n",
            "Epoch 61/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0635 - accuracy: 0.0000e+00\n",
            "Epoch 62/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0635 - accuracy: 0.0000e+00\n",
            "Epoch 63/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0635 - accuracy: 0.0000e+00\n",
            "Epoch 64/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0634 - accuracy: 0.0000e+00\n",
            "Epoch 65/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0634 - accuracy: 0.0000e+00\n",
            "Epoch 66/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0634 - accuracy: 0.0000e+00\n",
            "Epoch 67/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0633 - accuracy: 0.0000e+00\n",
            "Epoch 68/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0633 - accuracy: 0.0000e+00\n",
            "Epoch 69/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0633 - accuracy: 0.0000e+00\n",
            "Epoch 70/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0632 - accuracy: 0.0000e+00\n",
            "Epoch 71/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0632 - accuracy: 0.0000e+00\n",
            "Epoch 72/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0632 - accuracy: 0.0000e+00\n",
            "Epoch 73/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0632 - accuracy: 0.0000e+00\n",
            "Epoch 74/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0632 - accuracy: 0.0000e+00\n",
            "Epoch 75/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0631 - accuracy: 0.0000e+00\n",
            "Epoch 76/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0631 - accuracy: 0.0000e+00\n",
            "Epoch 77/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0631 - accuracy: 0.0000e+00\n",
            "Epoch 78/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0631 - accuracy: 0.0000e+00\n",
            "Epoch 79/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0630 - accuracy: 0.0000e+00\n",
            "Epoch 80/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0630 - accuracy: 0.0000e+00\n",
            "Epoch 81/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0630 - accuracy: 0.0000e+00\n",
            "Epoch 82/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0630 - accuracy: 0.0000e+00\n",
            "Epoch 83/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0630 - accuracy: 0.0000e+00\n",
            "Epoch 84/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0630 - accuracy: 0.0000e+00\n",
            "Epoch 85/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0629 - accuracy: 0.0000e+00\n",
            "Epoch 86/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0629 - accuracy: 0.0000e+00\n",
            "Epoch 87/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0629 - accuracy: 0.0000e+00\n",
            "Epoch 88/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0629 - accuracy: 0.0000e+00\n",
            "Epoch 89/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0629 - accuracy: 0.0000e+00\n",
            "Epoch 90/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0629 - accuracy: 0.0000e+00\n",
            "Epoch 91/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0629 - accuracy: 0.0000e+00\n",
            "Epoch 92/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0628 - accuracy: 0.0000e+00\n",
            "Epoch 93/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0628 - accuracy: 0.0000e+00\n",
            "Epoch 94/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0628 - accuracy: 0.0000e+00\n",
            "Epoch 95/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0628 - accuracy: 0.0000e+00\n",
            "Epoch 96/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0628 - accuracy: 0.0000e+00\n",
            "Epoch 97/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0628 - accuracy: 0.0000e+00\n",
            "Epoch 98/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0628 - accuracy: 0.0000e+00\n",
            "Epoch 99/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0628 - accuracy: 0.0000e+00\n",
            "Epoch 100/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0628 - accuracy: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "15/15 [==============================] - 1s 3ms/step - loss: 0.0654 - accuracy: 0.0068\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 3/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0645 - accuracy: 0.0068\n",
            "Epoch 4/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0641 - accuracy: 0.0068\n",
            "Epoch 5/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0636 - accuracy: 0.0068\n",
            "Epoch 6/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0632 - accuracy: 0.0068\n",
            "Epoch 7/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0628 - accuracy: 0.0068\n",
            "Epoch 8/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0625 - accuracy: 0.0068\n",
            "Epoch 9/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0621 - accuracy: 0.0068\n",
            "Epoch 10/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0618 - accuracy: 0.0068\n",
            "Epoch 11/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0614 - accuracy: 0.0068\n",
            "Epoch 12/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0611 - accuracy: 0.0068\n",
            "Epoch 13/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0608 - accuracy: 0.0068\n",
            "Epoch 14/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0605 - accuracy: 0.0068\n",
            "Epoch 15/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0602 - accuracy: 0.0068\n",
            "Epoch 16/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0599 - accuracy: 0.0068\n",
            "Epoch 17/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0597 - accuracy: 0.0068\n",
            "Epoch 18/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0594 - accuracy: 0.0068\n",
            "Epoch 19/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0592 - accuracy: 0.0068\n",
            "Epoch 20/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0590 - accuracy: 0.0068\n",
            "Epoch 21/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0587 - accuracy: 0.0068\n",
            "Epoch 22/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0585 - accuracy: 0.0068\n",
            "Epoch 23/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0583 - accuracy: 0.0068\n",
            "Epoch 24/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0581 - accuracy: 0.0068\n",
            "Epoch 25/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0579 - accuracy: 0.0068\n",
            "Epoch 26/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0577 - accuracy: 0.0068\n",
            "Epoch 27/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0575 - accuracy: 0.0068\n",
            "Epoch 28/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0573 - accuracy: 0.0068\n",
            "Epoch 29/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0572 - accuracy: 0.0068\n",
            "Epoch 30/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0570 - accuracy: 0.0068\n",
            "Epoch 31/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0569 - accuracy: 0.0068\n",
            "Epoch 32/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0567 - accuracy: 0.0068\n",
            "Epoch 33/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0566 - accuracy: 0.0068\n",
            "Epoch 34/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0564 - accuracy: 0.0068\n",
            "Epoch 35/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0563 - accuracy: 0.0068\n",
            "Epoch 36/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0562 - accuracy: 0.0068\n",
            "Epoch 37/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0560 - accuracy: 0.0068\n",
            "Epoch 38/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0559 - accuracy: 0.0068\n",
            "Epoch 39/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0558 - accuracy: 0.0068\n",
            "Epoch 40/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0557 - accuracy: 0.0068\n",
            "Epoch 41/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0556 - accuracy: 0.0068\n",
            "Epoch 42/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0555 - accuracy: 0.0068\n",
            "Epoch 43/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0554 - accuracy: 0.0068\n",
            "Epoch 44/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0553 - accuracy: 0.0068\n",
            "Epoch 45/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0552 - accuracy: 0.0068\n",
            "Epoch 46/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0551 - accuracy: 0.0068\n",
            "Epoch 47/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0550 - accuracy: 0.0068\n",
            "Epoch 48/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0550 - accuracy: 0.0068\n",
            "Epoch 49/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0549 - accuracy: 0.0068\n",
            "Epoch 50/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0548 - accuracy: 0.0068\n",
            "Epoch 51/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0547 - accuracy: 0.0068\n",
            "Epoch 52/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0546 - accuracy: 0.0068\n",
            "Epoch 53/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0546 - accuracy: 0.0068\n",
            "Epoch 54/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0545 - accuracy: 0.0068\n",
            "Epoch 55/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0545 - accuracy: 0.0068\n",
            "Epoch 56/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0544 - accuracy: 0.0068\n",
            "Epoch 57/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0543 - accuracy: 0.0068\n",
            "Epoch 58/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0543 - accuracy: 0.0068\n",
            "Epoch 59/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0542 - accuracy: 0.0068\n",
            "Epoch 60/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0542 - accuracy: 0.0068\n",
            "Epoch 61/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0541 - accuracy: 0.0068\n",
            "Epoch 62/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0541 - accuracy: 0.0068\n",
            "Epoch 63/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0540 - accuracy: 0.0068\n",
            "Epoch 64/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0540 - accuracy: 0.0068\n",
            "Epoch 65/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0539 - accuracy: 0.0068\n",
            "Epoch 66/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0539 - accuracy: 0.0068\n",
            "Epoch 67/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0539 - accuracy: 0.0068\n",
            "Epoch 68/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0538 - accuracy: 0.0068\n",
            "Epoch 69/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0538 - accuracy: 0.0068\n",
            "Epoch 70/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0538 - accuracy: 0.0068\n",
            "Epoch 71/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0537 - accuracy: 0.0068\n",
            "Epoch 72/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0537 - accuracy: 0.0068\n",
            "Epoch 73/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0537 - accuracy: 0.0068\n",
            "Epoch 74/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0536 - accuracy: 0.0068\n",
            "Epoch 75/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0536 - accuracy: 0.0068\n",
            "Epoch 76/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0536 - accuracy: 0.0068\n",
            "Epoch 77/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0535 - accuracy: 0.0068\n",
            "Epoch 78/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0535 - accuracy: 0.0068\n",
            "Epoch 79/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0535 - accuracy: 0.0068\n",
            "Epoch 80/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0535 - accuracy: 0.0068\n",
            "Epoch 81/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0534 - accuracy: 0.0068\n",
            "Epoch 82/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0534 - accuracy: 0.0068\n",
            "Epoch 83/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0534 - accuracy: 0.0068\n",
            "Epoch 84/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0534 - accuracy: 0.0068\n",
            "Epoch 85/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0534 - accuracy: 0.0068\n",
            "Epoch 86/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0533 - accuracy: 0.0068\n",
            "Epoch 87/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0533 - accuracy: 0.0068\n",
            "Epoch 88/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0533 - accuracy: 0.0068\n",
            "Epoch 89/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0533 - accuracy: 0.0068\n",
            "Epoch 90/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0533 - accuracy: 0.0068\n",
            "Epoch 91/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0532 - accuracy: 0.0068\n",
            "Epoch 92/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0532 - accuracy: 0.0068\n",
            "Epoch 93/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0532 - accuracy: 0.0068\n",
            "Epoch 94/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0532 - accuracy: 0.0068\n",
            "Epoch 95/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0532 - accuracy: 0.0068\n",
            "Epoch 96/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0532 - accuracy: 0.0068\n",
            "Epoch 97/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0532 - accuracy: 0.0068\n",
            "Epoch 98/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0531 - accuracy: 0.0068\n",
            "Epoch 99/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0531 - accuracy: 0.0068\n",
            "Epoch 100/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0531 - accuracy: 0.0068\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "15/15 [==============================] - 1s 3ms/step - loss: 0.0697 - accuracy: 0.0136 \n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0694 - accuracy: 0.0068\n",
            "Epoch 3/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0692 - accuracy: 0.0068\n",
            "Epoch 4/100\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.0689 - accuracy: 0.0068\n",
            "Epoch 5/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0687 - accuracy: 0.0068\n",
            "Epoch 6/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0684 - accuracy: 0.0068\n",
            "Epoch 7/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0682 - accuracy: 0.0068\n",
            "Epoch 8/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0679 - accuracy: 0.0068\n",
            "Epoch 9/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0677 - accuracy: 0.0068\n",
            "Epoch 10/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0675 - accuracy: 0.0068\n",
            "Epoch 11/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0673 - accuracy: 0.0068\n",
            "Epoch 12/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0671 - accuracy: 0.0068\n",
            "Epoch 13/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0669 - accuracy: 0.0068\n",
            "Epoch 14/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0667 - accuracy: 0.0068\n",
            "Epoch 15/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0665 - accuracy: 0.0068\n",
            "Epoch 16/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0664 - accuracy: 0.0068\n",
            "Epoch 17/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0662 - accuracy: 0.0068\n",
            "Epoch 18/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0660 - accuracy: 0.0068\n",
            "Epoch 19/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0659 - accuracy: 0.0068\n",
            "Epoch 20/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0657 - accuracy: 0.0068\n",
            "Epoch 21/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0656 - accuracy: 0.0068\n",
            "Epoch 22/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0655 - accuracy: 0.0068\n",
            "Epoch 23/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0653 - accuracy: 0.0068\n",
            "Epoch 24/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0652 - accuracy: 0.0068\n",
            "Epoch 25/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0651 - accuracy: 0.0068\n",
            "Epoch 26/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0650 - accuracy: 0.0068\n",
            "Epoch 27/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 28/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 29/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0646 - accuracy: 0.0068\n",
            "Epoch 30/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0645 - accuracy: 0.0068\n",
            "Epoch 31/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0644 - accuracy: 0.0068\n",
            "Epoch 32/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0643 - accuracy: 0.0068\n",
            "Epoch 33/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0642 - accuracy: 0.0068\n",
            "Epoch 34/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0642 - accuracy: 0.0068\n",
            "Epoch 35/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0641 - accuracy: 0.0068\n",
            "Epoch 36/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0640 - accuracy: 0.0068\n",
            "Epoch 37/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0639 - accuracy: 0.0068\n",
            "Epoch 38/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0638 - accuracy: 0.0068\n",
            "Epoch 39/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0638 - accuracy: 0.0068\n",
            "Epoch 40/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0637 - accuracy: 0.0068\n",
            "Epoch 41/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0636 - accuracy: 0.0068\n",
            "Epoch 42/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0636 - accuracy: 0.0068\n",
            "Epoch 43/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0635 - accuracy: 0.0068\n",
            "Epoch 44/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0634 - accuracy: 0.0068\n",
            "Epoch 45/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0634 - accuracy: 0.0068\n",
            "Epoch 46/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0633 - accuracy: 0.0068\n",
            "Epoch 47/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0633 - accuracy: 0.0068\n",
            "Epoch 48/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0632 - accuracy: 0.0068\n",
            "Epoch 49/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0632 - accuracy: 0.0068\n",
            "Epoch 50/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0631 - accuracy: 0.0068\n",
            "Epoch 51/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0631 - accuracy: 0.0068\n",
            "Epoch 52/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0630 - accuracy: 0.0068\n",
            "Epoch 53/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0630 - accuracy: 0.0068\n",
            "Epoch 54/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0629 - accuracy: 0.0068\n",
            "Epoch 55/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0629 - accuracy: 0.0068\n",
            "Epoch 56/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0629 - accuracy: 0.0068\n",
            "Epoch 57/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0628 - accuracy: 0.0068\n",
            "Epoch 58/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0628 - accuracy: 0.0068\n",
            "Epoch 59/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0628 - accuracy: 0.0068\n",
            "Epoch 60/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0627 - accuracy: 0.0068\n",
            "Epoch 61/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0627 - accuracy: 0.0068\n",
            "Epoch 62/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0627 - accuracy: 0.0068\n",
            "Epoch 63/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0626 - accuracy: 0.0068\n",
            "Epoch 64/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0626 - accuracy: 0.0068\n",
            "Epoch 65/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0626 - accuracy: 0.0068\n",
            "Epoch 66/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0626 - accuracy: 0.0068\n",
            "Epoch 67/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0625 - accuracy: 0.0068\n",
            "Epoch 68/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0625 - accuracy: 0.0068\n",
            "Epoch 69/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0625 - accuracy: 0.0068\n",
            "Epoch 70/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0625 - accuracy: 0.0068\n",
            "Epoch 71/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0624 - accuracy: 0.0068\n",
            "Epoch 72/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0624 - accuracy: 0.0068\n",
            "Epoch 73/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0624 - accuracy: 0.0068\n",
            "Epoch 74/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0624 - accuracy: 0.0068\n",
            "Epoch 75/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0624 - accuracy: 0.0068\n",
            "Epoch 76/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0623 - accuracy: 0.0068\n",
            "Epoch 77/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0623 - accuracy: 0.0068\n",
            "Epoch 78/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0623 - accuracy: 0.0068\n",
            "Epoch 79/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0623 - accuracy: 0.0068\n",
            "Epoch 80/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0623 - accuracy: 0.0068\n",
            "Epoch 81/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0622 - accuracy: 0.0068\n",
            "Epoch 82/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0622 - accuracy: 0.0068\n",
            "Epoch 83/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0622 - accuracy: 0.0068\n",
            "Epoch 84/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0622 - accuracy: 0.0068\n",
            "Epoch 85/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0622 - accuracy: 0.0068\n",
            "Epoch 86/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0622 - accuracy: 0.0068\n",
            "Epoch 87/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0622 - accuracy: 0.0068\n",
            "Epoch 88/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0622 - accuracy: 0.0068\n",
            "Epoch 89/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0621 - accuracy: 0.0068\n",
            "Epoch 90/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0621 - accuracy: 0.0068\n",
            "Epoch 91/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0621 - accuracy: 0.0068\n",
            "Epoch 92/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0621 - accuracy: 0.0068\n",
            "Epoch 93/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0621 - accuracy: 0.0068\n",
            "Epoch 94/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0621 - accuracy: 0.0068\n",
            "Epoch 95/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0621 - accuracy: 0.0068\n",
            "Epoch 96/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0621 - accuracy: 0.0068\n",
            "Epoch 97/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0621 - accuracy: 0.0068\n",
            "Epoch 98/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0621 - accuracy: 0.0068\n",
            "Epoch 99/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0621 - accuracy: 0.0068\n",
            "Epoch 100/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0620 - accuracy: 0.0068\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "15/15 [==============================] - 1s 4ms/step - loss: 0.0709 - accuracy: 0.0068\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0704 - accuracy: 0.0068\n",
            "Epoch 3/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0699 - accuracy: 0.0068\n",
            "Epoch 4/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0694 - accuracy: 0.0068\n",
            "Epoch 5/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0689 - accuracy: 0.0068\n",
            "Epoch 6/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0685 - accuracy: 0.0068\n",
            "Epoch 7/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0681 - accuracy: 0.0068\n",
            "Epoch 8/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0677 - accuracy: 0.0068\n",
            "Epoch 9/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0673 - accuracy: 0.0068\n",
            "Epoch 10/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0669 - accuracy: 0.0068\n",
            "Epoch 11/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0666 - accuracy: 0.0068\n",
            "Epoch 12/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0662 - accuracy: 0.0068\n",
            "Epoch 13/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0659 - accuracy: 0.0068\n",
            "Epoch 14/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0656 - accuracy: 0.0068\n",
            "Epoch 15/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0653 - accuracy: 0.0068\n",
            "Epoch 16/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0650 - accuracy: 0.0068\n",
            "Epoch 17/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 18/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0644 - accuracy: 0.0068\n",
            "Epoch 19/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0641 - accuracy: 0.0068\n",
            "Epoch 20/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0639 - accuracy: 0.0068\n",
            "Epoch 21/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0636 - accuracy: 0.0068\n",
            "Epoch 22/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0634 - accuracy: 0.0068\n",
            "Epoch 23/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0631 - accuracy: 0.0068\n",
            "Epoch 24/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0629 - accuracy: 0.0068\n",
            "Epoch 25/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0627 - accuracy: 0.0068\n",
            "Epoch 26/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0625 - accuracy: 0.0068\n",
            "Epoch 27/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0623 - accuracy: 0.0068\n",
            "Epoch 28/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0621 - accuracy: 0.0068\n",
            "Epoch 29/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0619 - accuracy: 0.0068\n",
            "Epoch 30/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0618 - accuracy: 0.0068\n",
            "Epoch 31/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0616 - accuracy: 0.0068\n",
            "Epoch 32/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0614 - accuracy: 0.0068\n",
            "Epoch 33/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0613 - accuracy: 0.0068\n",
            "Epoch 34/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0611 - accuracy: 0.0068\n",
            "Epoch 35/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0610 - accuracy: 0.0068\n",
            "Epoch 36/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0608 - accuracy: 0.0068\n",
            "Epoch 37/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0607 - accuracy: 0.0068\n",
            "Epoch 38/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0606 - accuracy: 0.0068\n",
            "Epoch 39/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0604 - accuracy: 0.0068\n",
            "Epoch 40/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0603 - accuracy: 0.0068\n",
            "Epoch 41/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0602 - accuracy: 0.0068\n",
            "Epoch 42/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0601 - accuracy: 0.0068\n",
            "Epoch 43/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0600 - accuracy: 0.0068\n",
            "Epoch 44/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0599 - accuracy: 0.0068\n",
            "Epoch 45/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0598 - accuracy: 0.0068\n",
            "Epoch 46/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0597 - accuracy: 0.0068\n",
            "Epoch 47/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0596 - accuracy: 0.0068\n",
            "Epoch 48/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0595 - accuracy: 0.0068\n",
            "Epoch 49/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0594 - accuracy: 0.0068\n",
            "Epoch 50/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0593 - accuracy: 0.0068\n",
            "Epoch 51/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0592 - accuracy: 0.0068\n",
            "Epoch 52/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0591 - accuracy: 0.0068\n",
            "Epoch 53/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0591 - accuracy: 0.0068\n",
            "Epoch 54/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0590 - accuracy: 0.0068\n",
            "Epoch 55/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0589 - accuracy: 0.0068\n",
            "Epoch 56/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0589 - accuracy: 0.0068\n",
            "Epoch 57/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0588 - accuracy: 0.0068\n",
            "Epoch 58/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0587 - accuracy: 0.0068\n",
            "Epoch 59/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0587 - accuracy: 0.0068\n",
            "Epoch 60/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0586 - accuracy: 0.0068\n",
            "Epoch 61/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0586 - accuracy: 0.0068\n",
            "Epoch 62/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0585 - accuracy: 0.0068\n",
            "Epoch 63/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0585 - accuracy: 0.0068\n",
            "Epoch 64/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0584 - accuracy: 0.0068\n",
            "Epoch 65/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0584 - accuracy: 0.0068\n",
            "Epoch 66/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0583 - accuracy: 0.0068\n",
            "Epoch 67/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0583 - accuracy: 0.0068\n",
            "Epoch 68/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0582 - accuracy: 0.0068\n",
            "Epoch 69/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0582 - accuracy: 0.0068\n",
            "Epoch 70/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0581 - accuracy: 0.0068\n",
            "Epoch 71/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0581 - accuracy: 0.0068\n",
            "Epoch 72/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0581 - accuracy: 0.0068\n",
            "Epoch 73/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0580 - accuracy: 0.0068\n",
            "Epoch 74/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0580 - accuracy: 0.0068\n",
            "Epoch 75/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0580 - accuracy: 0.0068\n",
            "Epoch 76/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0579 - accuracy: 0.0068\n",
            "Epoch 77/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0579 - accuracy: 0.0068\n",
            "Epoch 78/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0579 - accuracy: 0.0068\n",
            "Epoch 79/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0578 - accuracy: 0.0068\n",
            "Epoch 80/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0578 - accuracy: 0.0068\n",
            "Epoch 81/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0578 - accuracy: 0.0068\n",
            "Epoch 82/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0578 - accuracy: 0.0068\n",
            "Epoch 83/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0577 - accuracy: 0.0068\n",
            "Epoch 84/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0577 - accuracy: 0.0068\n",
            "Epoch 85/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0577 - accuracy: 0.0068\n",
            "Epoch 86/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0577 - accuracy: 0.0068\n",
            "Epoch 87/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0576 - accuracy: 0.0068\n",
            "Epoch 88/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0576 - accuracy: 0.0068\n",
            "Epoch 89/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0576 - accuracy: 0.0068\n",
            "Epoch 90/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0576 - accuracy: 0.0068\n",
            "Epoch 91/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0576 - accuracy: 0.0068\n",
            "Epoch 92/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0575 - accuracy: 0.0068\n",
            "Epoch 93/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0575 - accuracy: 0.0068\n",
            "Epoch 94/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0575 - accuracy: 0.0068\n",
            "Epoch 95/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0575 - accuracy: 0.0068\n",
            "Epoch 96/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0575 - accuracy: 0.0068\n",
            "Epoch 97/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0575 - accuracy: 0.0068\n",
            "Epoch 98/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0575 - accuracy: 0.0068\n",
            "Epoch 99/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0574 - accuracy: 0.0068\n",
            "Epoch 100/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0574 - accuracy: 0.0068\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "15/15 [==============================] - 1s 4ms/step - loss: 0.0715 - accuracy: 0.0068\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0710 - accuracy: 0.0068\n",
            "Epoch 3/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0705 - accuracy: 0.0068\n",
            "Epoch 4/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0698 - accuracy: 0.0068\n",
            "Epoch 5/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0692 - accuracy: 0.0068\n",
            "Epoch 6/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0685 - accuracy: 0.0068\n",
            "Epoch 7/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0677 - accuracy: 0.0068\n",
            "Epoch 8/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0668 - accuracy: 0.0068\n",
            "Epoch 9/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0657 - accuracy: 0.0068\n",
            "Epoch 10/100\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.0645 - accuracy: 0.0068\n",
            "Epoch 11/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0632 - accuracy: 0.0068\n",
            "Epoch 12/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0619 - accuracy: 0.0068\n",
            "Epoch 13/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0605 - accuracy: 0.0068\n",
            "Epoch 14/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0591 - accuracy: 0.0068\n",
            "Epoch 15/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0579 - accuracy: 0.0068\n",
            "Epoch 16/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0567 - accuracy: 0.0068\n",
            "Epoch 17/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0557 - accuracy: 0.0068\n",
            "Epoch 18/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0545 - accuracy: 0.0068\n",
            "Epoch 19/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0534 - accuracy: 0.0068\n",
            "Epoch 20/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0525 - accuracy: 0.0068\n",
            "Epoch 21/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0514 - accuracy: 0.0068\n",
            "Epoch 22/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0506 - accuracy: 0.0068\n",
            "Epoch 23/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0496 - accuracy: 0.0068\n",
            "Epoch 24/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0487 - accuracy: 0.0068\n",
            "Epoch 25/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0478 - accuracy: 0.0068\n",
            "Epoch 26/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0469 - accuracy: 0.0068\n",
            "Epoch 27/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0460 - accuracy: 0.0068\n",
            "Epoch 28/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0451 - accuracy: 0.0068\n",
            "Epoch 29/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0442 - accuracy: 0.0068\n",
            "Epoch 30/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0433 - accuracy: 0.0068\n",
            "Epoch 31/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0423 - accuracy: 0.0068\n",
            "Epoch 32/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0415 - accuracy: 0.0068\n",
            "Epoch 33/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0406 - accuracy: 0.0068\n",
            "Epoch 34/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0399 - accuracy: 0.0068\n",
            "Epoch 35/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0393 - accuracy: 0.0068\n",
            "Epoch 36/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0388 - accuracy: 0.0408\n",
            "Epoch 37/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0382 - accuracy: 0.0476\n",
            "Epoch 38/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0377 - accuracy: 0.0476\n",
            "Epoch 39/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0373 - accuracy: 0.0476\n",
            "Epoch 40/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0368 - accuracy: 0.0476\n",
            "Epoch 41/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0363 - accuracy: 0.0476\n",
            "Epoch 42/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0358 - accuracy: 0.0476\n",
            "Epoch 43/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0353 - accuracy: 0.0476\n",
            "Epoch 44/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0349 - accuracy: 0.0476\n",
            "Epoch 45/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0344 - accuracy: 0.0476\n",
            "Epoch 46/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0339 - accuracy: 0.0476\n",
            "Epoch 47/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0334 - accuracy: 0.0476\n",
            "Epoch 48/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0330 - accuracy: 0.0476\n",
            "Epoch 49/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0325 - accuracy: 0.0476\n",
            "Epoch 50/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0321 - accuracy: 0.0476\n",
            "Epoch 51/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0317 - accuracy: 0.0476\n",
            "Epoch 52/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0312 - accuracy: 0.0476\n",
            "Epoch 53/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0308 - accuracy: 0.0476\n",
            "Epoch 54/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0305 - accuracy: 0.0476\n",
            "Epoch 55/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0299 - accuracy: 0.0476\n",
            "Epoch 56/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0295 - accuracy: 0.0476\n",
            "Epoch 57/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0291 - accuracy: 0.0476\n",
            "Epoch 58/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0286 - accuracy: 0.0476\n",
            "Epoch 59/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0282 - accuracy: 0.0476\n",
            "Epoch 60/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0278 - accuracy: 0.0476\n",
            "Epoch 61/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0274 - accuracy: 0.0476\n",
            "Epoch 62/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0270 - accuracy: 0.0476\n",
            "Epoch 63/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0266 - accuracy: 0.0476\n",
            "Epoch 64/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0262 - accuracy: 0.0476\n",
            "Epoch 65/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0259 - accuracy: 0.0476\n",
            "Epoch 66/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0255 - accuracy: 0.0476\n",
            "Epoch 67/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0251 - accuracy: 0.0476\n",
            "Epoch 68/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0247 - accuracy: 0.0476\n",
            "Epoch 69/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0243 - accuracy: 0.0476\n",
            "Epoch 70/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0239 - accuracy: 0.0476\n",
            "Epoch 71/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0236 - accuracy: 0.0476\n",
            "Epoch 72/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0232 - accuracy: 0.0476\n",
            "Epoch 73/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0228 - accuracy: 0.0476\n",
            "Epoch 74/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0225 - accuracy: 0.0476\n",
            "Epoch 75/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0221 - accuracy: 0.0476\n",
            "Epoch 76/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0218 - accuracy: 0.0476\n",
            "Epoch 77/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0215 - accuracy: 0.0476\n",
            "Epoch 78/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0212 - accuracy: 0.0476\n",
            "Epoch 79/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0208 - accuracy: 0.0476\n",
            "Epoch 80/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0204 - accuracy: 0.0476\n",
            "Epoch 81/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0202 - accuracy: 0.0476\n",
            "Epoch 82/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0198 - accuracy: 0.0476\n",
            "Epoch 83/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0196 - accuracy: 0.0476\n",
            "Epoch 84/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0192 - accuracy: 0.0476\n",
            "Epoch 85/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0189 - accuracy: 0.0476\n",
            "Epoch 86/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0187 - accuracy: 0.0476\n",
            "Epoch 87/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0184 - accuracy: 0.0476\n",
            "Epoch 88/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0181 - accuracy: 0.0476\n",
            "Epoch 89/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0178 - accuracy: 0.0476\n",
            "Epoch 90/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0176 - accuracy: 0.0476\n",
            "Epoch 91/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0173 - accuracy: 0.0476\n",
            "Epoch 92/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0170 - accuracy: 0.0476\n",
            "Epoch 93/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0167 - accuracy: 0.0476\n",
            "Epoch 94/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0165 - accuracy: 0.0476\n",
            "Epoch 95/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0163 - accuracy: 0.0476\n",
            "Epoch 96/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0160 - accuracy: 0.0476\n",
            "Epoch 97/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0158 - accuracy: 0.0476\n",
            "Epoch 98/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0155 - accuracy: 0.0476\n",
            "Epoch 99/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0153 - accuracy: 0.0476\n",
            "Epoch 100/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0151 - accuracy: 0.0476\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "15/15 [==============================] - 1s 4ms/step - loss: 0.0719 - accuracy: 0.0000e+00\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0711 - accuracy: 0.0000e+00\n",
            "Epoch 3/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0704 - accuracy: 0.0000e+00\n",
            "Epoch 4/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0695 - accuracy: 0.0000e+00\n",
            "Epoch 5/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0685 - accuracy: 0.0000e+00\n",
            "Epoch 6/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0674 - accuracy: 0.0000e+00\n",
            "Epoch 7/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0662 - accuracy: 0.0000e+00\n",
            "Epoch 8/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0646 - accuracy: 0.0000e+00\n",
            "Epoch 9/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0630 - accuracy: 0.0000e+00\n",
            "Epoch 10/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0610 - accuracy: 0.0000e+00\n",
            "Epoch 11/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0588 - accuracy: 0.0000e+00\n",
            "Epoch 12/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0563 - accuracy: 0.0000e+00\n",
            "Epoch 13/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0537 - accuracy: 0.0000e+00\n",
            "Epoch 14/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0510 - accuracy: 0.0000e+00\n",
            "Epoch 15/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0483 - accuracy: 0.0000e+00\n",
            "Epoch 16/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0460 - accuracy: 0.0000e+00\n",
            "Epoch 17/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0436 - accuracy: 0.0000e+00\n",
            "Epoch 18/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0414 - accuracy: 0.0340\n",
            "Epoch 19/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0395 - accuracy: 0.0340\n",
            "Epoch 20/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0376 - accuracy: 0.0340\n",
            "Epoch 21/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0357 - accuracy: 0.0340\n",
            "Epoch 22/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0339 - accuracy: 0.0340\n",
            "Epoch 23/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0322 - accuracy: 0.0340\n",
            "Epoch 24/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0306 - accuracy: 0.0340\n",
            "Epoch 25/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0289 - accuracy: 0.0340\n",
            "Epoch 26/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0274 - accuracy: 0.0340\n",
            "Epoch 27/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0258 - accuracy: 0.0340\n",
            "Epoch 28/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0244 - accuracy: 0.0340\n",
            "Epoch 29/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0231 - accuracy: 0.0340\n",
            "Epoch 30/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0217 - accuracy: 0.0340\n",
            "Epoch 31/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0207 - accuracy: 0.0340\n",
            "Epoch 32/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0194 - accuracy: 0.0340\n",
            "Epoch 33/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0184 - accuracy: 0.0340\n",
            "Epoch 34/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0174 - accuracy: 0.0340\n",
            "Epoch 35/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0166 - accuracy: 0.0340\n",
            "Epoch 36/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0157 - accuracy: 0.0340\n",
            "Epoch 37/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0149 - accuracy: 0.0340\n",
            "Epoch 38/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0142 - accuracy: 0.0340\n",
            "Epoch 39/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0136 - accuracy: 0.0340\n",
            "Epoch 40/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0130 - accuracy: 0.0340\n",
            "Epoch 41/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0124 - accuracy: 0.0340\n",
            "Epoch 42/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0119 - accuracy: 0.0340\n",
            "Epoch 43/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0115 - accuracy: 0.0340\n",
            "Epoch 44/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0111 - accuracy: 0.0340\n",
            "Epoch 45/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0107 - accuracy: 0.0340\n",
            "Epoch 46/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0104 - accuracy: 0.0340\n",
            "Epoch 47/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0100 - accuracy: 0.0340\n",
            "Epoch 48/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0097 - accuracy: 0.0340\n",
            "Epoch 49/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0095 - accuracy: 0.0340\n",
            "Epoch 50/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0092 - accuracy: 0.0340\n",
            "Epoch 51/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0091 - accuracy: 0.0340\n",
            "Epoch 52/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0089 - accuracy: 0.0340\n",
            "Epoch 53/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0087 - accuracy: 0.0340\n",
            "Epoch 54/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0084 - accuracy: 0.0340\n",
            "Epoch 55/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0084 - accuracy: 0.0340\n",
            "Epoch 56/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0081 - accuracy: 0.0340\n",
            "Epoch 57/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0080 - accuracy: 0.0340\n",
            "Epoch 58/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0078 - accuracy: 0.0340\n",
            "Epoch 59/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0077 - accuracy: 0.0340\n",
            "Epoch 60/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0075 - accuracy: 0.0340\n",
            "Epoch 61/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0075 - accuracy: 0.0340\n",
            "Epoch 62/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0075 - accuracy: 0.0340\n",
            "Epoch 63/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0072 - accuracy: 0.0340\n",
            "Epoch 64/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0073 - accuracy: 0.0340\n",
            "Epoch 65/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0071 - accuracy: 0.0340\n",
            "Epoch 66/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0070 - accuracy: 0.0340\n",
            "Epoch 67/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0069 - accuracy: 0.0340\n",
            "Epoch 68/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0068 - accuracy: 0.0340\n",
            "Epoch 69/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0067 - accuracy: 0.0340\n",
            "Epoch 70/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0067 - accuracy: 0.0340\n",
            "Epoch 71/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0066 - accuracy: 0.0340\n",
            "Epoch 72/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0065 - accuracy: 0.0340\n",
            "Epoch 73/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0065 - accuracy: 0.0340\n",
            "Epoch 74/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0064 - accuracy: 0.0340\n",
            "Epoch 75/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0064 - accuracy: 0.0340\n",
            "Epoch 76/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0063 - accuracy: 0.0340\n",
            "Epoch 77/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0062 - accuracy: 0.0340\n",
            "Epoch 78/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0062 - accuracy: 0.0340\n",
            "Epoch 79/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0063 - accuracy: 0.0340\n",
            "Epoch 80/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0061 - accuracy: 0.0340\n",
            "Epoch 81/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0061 - accuracy: 0.0340\n",
            "Epoch 82/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0060 - accuracy: 0.0340\n",
            "Epoch 83/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0060 - accuracy: 0.0340\n",
            "Epoch 84/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0061 - accuracy: 0.0340\n",
            "Epoch 85/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0059 - accuracy: 0.0340\n",
            "Epoch 86/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0059 - accuracy: 0.0340\n",
            "Epoch 87/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0058 - accuracy: 0.0340\n",
            "Epoch 88/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0058 - accuracy: 0.0340\n",
            "Epoch 89/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0057 - accuracy: 0.0340\n",
            "Epoch 90/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0057 - accuracy: 0.0340\n",
            "Epoch 91/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0056 - accuracy: 0.0340\n",
            "Epoch 92/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0056 - accuracy: 0.0340\n",
            "Epoch 93/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0056 - accuracy: 0.0340\n",
            "Epoch 94/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 0.0340\n",
            "Epoch 95/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 0.0340\n",
            "Epoch 96/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0054 - accuracy: 0.0340\n",
            "Epoch 97/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0055 - accuracy: 0.0340\n",
            "Epoch 98/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0053 - accuracy: 0.0340\n",
            "Epoch 99/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0054 - accuracy: 0.0340\n",
            "Epoch 100/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0053 - accuracy: 0.0340\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "15/15 [==============================] - 1s 3ms/step - loss: 0.0652 - accuracy: 0.0068\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0644 - accuracy: 0.0068\n",
            "Epoch 3/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0636 - accuracy: 0.0068\n",
            "Epoch 4/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0626 - accuracy: 0.0068\n",
            "Epoch 5/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0616 - accuracy: 0.0068\n",
            "Epoch 6/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0605 - accuracy: 0.0068\n",
            "Epoch 7/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0595 - accuracy: 0.0068\n",
            "Epoch 8/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0582 - accuracy: 0.0068\n",
            "Epoch 9/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0569 - accuracy: 0.0068\n",
            "Epoch 10/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0559 - accuracy: 0.0068\n",
            "Epoch 11/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0548 - accuracy: 0.0068\n",
            "Epoch 12/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0536 - accuracy: 0.0068\n",
            "Epoch 13/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0526 - accuracy: 0.0068\n",
            "Epoch 14/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0517 - accuracy: 0.0068\n",
            "Epoch 15/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0509 - accuracy: 0.0068\n",
            "Epoch 16/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0499 - accuracy: 0.0068\n",
            "Epoch 17/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0492 - accuracy: 0.0068\n",
            "Epoch 18/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0483 - accuracy: 0.0068\n",
            "Epoch 19/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0476 - accuracy: 0.0068\n",
            "Epoch 20/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0467 - accuracy: 0.0068\n",
            "Epoch 21/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0459 - accuracy: 0.0068\n",
            "Epoch 22/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0450 - accuracy: 0.0068\n",
            "Epoch 23/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0441 - accuracy: 0.0068\n",
            "Epoch 24/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0433 - accuracy: 0.0068\n",
            "Epoch 25/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0424 - accuracy: 0.0068\n",
            "Epoch 26/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0414 - accuracy: 0.0068\n",
            "Epoch 27/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0404 - accuracy: 0.0068\n",
            "Epoch 28/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0395 - accuracy: 0.0068\n",
            "Epoch 29/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0386 - accuracy: 0.0068\n",
            "Epoch 30/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0377 - accuracy: 0.0068\n",
            "Epoch 31/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0368 - accuracy: 0.0068\n",
            "Epoch 32/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0359 - accuracy: 0.0068\n",
            "Epoch 33/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0350 - accuracy: 0.0068\n",
            "Epoch 34/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0342 - accuracy: 0.0068\n",
            "Epoch 35/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0332 - accuracy: 0.0272\n",
            "Epoch 36/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0324 - accuracy: 0.0476\n",
            "Epoch 37/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0315 - accuracy: 0.0476\n",
            "Epoch 38/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0307 - accuracy: 0.0476\n",
            "Epoch 39/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0300 - accuracy: 0.0476\n",
            "Epoch 40/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0292 - accuracy: 0.0476\n",
            "Epoch 41/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0285 - accuracy: 0.0476\n",
            "Epoch 42/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0278 - accuracy: 0.0476\n",
            "Epoch 43/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0271 - accuracy: 0.0476\n",
            "Epoch 44/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0263 - accuracy: 0.0476\n",
            "Epoch 45/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0256 - accuracy: 0.0476\n",
            "Epoch 46/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0250 - accuracy: 0.0476\n",
            "Epoch 47/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0243 - accuracy: 0.0476\n",
            "Epoch 48/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0237 - accuracy: 0.0476\n",
            "Epoch 49/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0230 - accuracy: 0.0476\n",
            "Epoch 50/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0224 - accuracy: 0.0476\n",
            "Epoch 51/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0218 - accuracy: 0.0476\n",
            "Epoch 52/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0212 - accuracy: 0.0476\n",
            "Epoch 53/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0206 - accuracy: 0.0476\n",
            "Epoch 54/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0200 - accuracy: 0.0476\n",
            "Epoch 55/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0195 - accuracy: 0.0476\n",
            "Epoch 56/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0189 - accuracy: 0.0476\n",
            "Epoch 57/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0184 - accuracy: 0.0476\n",
            "Epoch 58/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0178 - accuracy: 0.0476\n",
            "Epoch 59/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0173 - accuracy: 0.0476\n",
            "Epoch 60/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0169 - accuracy: 0.0476\n",
            "Epoch 61/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0164 - accuracy: 0.0476\n",
            "Epoch 62/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0160 - accuracy: 0.0476\n",
            "Epoch 63/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0155 - accuracy: 0.0476\n",
            "Epoch 64/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0150 - accuracy: 0.0476\n",
            "Epoch 65/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0146 - accuracy: 0.0476\n",
            "Epoch 66/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0142 - accuracy: 0.0476\n",
            "Epoch 67/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0138 - accuracy: 0.0476\n",
            "Epoch 68/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0134 - accuracy: 0.0476\n",
            "Epoch 69/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0131 - accuracy: 0.0476\n",
            "Epoch 70/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0127 - accuracy: 0.0476\n",
            "Epoch 71/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0123 - accuracy: 0.0476\n",
            "Epoch 72/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0121 - accuracy: 0.0476\n",
            "Epoch 73/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0117 - accuracy: 0.0476\n",
            "Epoch 74/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0114 - accuracy: 0.0476\n",
            "Epoch 75/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0111 - accuracy: 0.0476\n",
            "Epoch 76/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0109 - accuracy: 0.0476\n",
            "Epoch 77/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0106 - accuracy: 0.0476\n",
            "Epoch 78/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0103 - accuracy: 0.0476\n",
            "Epoch 79/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0101 - accuracy: 0.0476\n",
            "Epoch 80/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0098 - accuracy: 0.0476\n",
            "Epoch 81/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0096 - accuracy: 0.0476\n",
            "Epoch 82/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0095 - accuracy: 0.0476\n",
            "Epoch 83/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0092 - accuracy: 0.0476\n",
            "Epoch 84/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0089 - accuracy: 0.0476\n",
            "Epoch 85/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0087 - accuracy: 0.0476\n",
            "Epoch 86/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0085 - accuracy: 0.0476\n",
            "Epoch 87/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0084 - accuracy: 0.0476\n",
            "Epoch 88/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0082 - accuracy: 0.0476\n",
            "Epoch 89/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0081 - accuracy: 0.0476\n",
            "Epoch 90/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0079 - accuracy: 0.0476\n",
            "Epoch 91/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0077 - accuracy: 0.0476\n",
            "Epoch 92/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0077 - accuracy: 0.0476\n",
            "Epoch 93/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0074 - accuracy: 0.0476\n",
            "Epoch 94/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0074 - accuracy: 0.0476\n",
            "Epoch 95/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0071 - accuracy: 0.0476\n",
            "Epoch 96/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0070 - accuracy: 0.0476\n",
            "Epoch 97/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0069 - accuracy: 0.0476\n",
            "Epoch 98/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0067 - accuracy: 0.0476\n",
            "Epoch 99/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0068 - accuracy: 0.0476\n",
            "Epoch 100/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0067 - accuracy: 0.0476\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "15/15 [==============================] - 1s 4ms/step - loss: 0.0697 - accuracy: 0.0068\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0692 - accuracy: 0.0068\n",
            "Epoch 3/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0687 - accuracy: 0.0068\n",
            "Epoch 4/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0681 - accuracy: 0.0068\n",
            "Epoch 5/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0675 - accuracy: 0.0068\n",
            "Epoch 6/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0669 - accuracy: 0.0068\n",
            "Epoch 7/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0661 - accuracy: 0.0068\n",
            "Epoch 8/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0654 - accuracy: 0.0068\n",
            "Epoch 9/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0643 - accuracy: 0.0068\n",
            "Epoch 10/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0633 - accuracy: 0.0068\n",
            "Epoch 11/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0620 - accuracy: 0.0068\n",
            "Epoch 12/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0604 - accuracy: 0.0068\n",
            "Epoch 13/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0584 - accuracy: 0.0068\n",
            "Epoch 14/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0559 - accuracy: 0.0068\n",
            "Epoch 15/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0531 - accuracy: 0.0068\n",
            "Epoch 16/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0501 - accuracy: 0.0136\n",
            "Epoch 17/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0470 - accuracy: 0.0340\n",
            "Epoch 18/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0437 - accuracy: 0.0408\n",
            "Epoch 19/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0404 - accuracy: 0.0408\n",
            "Epoch 20/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0375 - accuracy: 0.0408\n",
            "Epoch 21/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0346 - accuracy: 0.0408\n",
            "Epoch 22/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0315 - accuracy: 0.0408\n",
            "Epoch 23/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0287 - accuracy: 0.0408\n",
            "Epoch 24/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0262 - accuracy: 0.0408\n",
            "Epoch 25/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0240 - accuracy: 0.0408\n",
            "Epoch 26/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0218 - accuracy: 0.0408\n",
            "Epoch 27/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0201 - accuracy: 0.0408\n",
            "Epoch 28/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0185 - accuracy: 0.0408\n",
            "Epoch 29/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0172 - accuracy: 0.0408\n",
            "Epoch 30/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0161 - accuracy: 0.0408\n",
            "Epoch 31/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0153 - accuracy: 0.0408\n",
            "Epoch 32/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0144 - accuracy: 0.0408\n",
            "Epoch 33/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0137 - accuracy: 0.0408\n",
            "Epoch 34/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0131 - accuracy: 0.0408\n",
            "Epoch 35/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0125 - accuracy: 0.0408\n",
            "Epoch 36/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0120 - accuracy: 0.0408\n",
            "Epoch 37/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0115 - accuracy: 0.0408\n",
            "Epoch 38/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0111 - accuracy: 0.0408\n",
            "Epoch 39/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0107 - accuracy: 0.0408\n",
            "Epoch 40/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0104 - accuracy: 0.0408\n",
            "Epoch 41/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0100 - accuracy: 0.0408\n",
            "Epoch 42/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0098 - accuracy: 0.0408\n",
            "Epoch 43/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0095 - accuracy: 0.0408\n",
            "Epoch 44/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0092 - accuracy: 0.0408\n",
            "Epoch 45/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0089 - accuracy: 0.0408\n",
            "Epoch 46/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0087 - accuracy: 0.0408\n",
            "Epoch 47/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0085 - accuracy: 0.0408\n",
            "Epoch 48/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0083 - accuracy: 0.0408\n",
            "Epoch 49/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0080 - accuracy: 0.0408\n",
            "Epoch 50/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0080 - accuracy: 0.0408\n",
            "Epoch 51/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0077 - accuracy: 0.0408\n",
            "Epoch 52/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0076 - accuracy: 0.0408\n",
            "Epoch 53/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0074 - accuracy: 0.0408\n",
            "Epoch 54/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0074 - accuracy: 0.0408\n",
            "Epoch 55/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0072 - accuracy: 0.0408\n",
            "Epoch 56/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0071 - accuracy: 0.0408\n",
            "Epoch 57/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0069 - accuracy: 0.0408\n",
            "Epoch 58/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0069 - accuracy: 0.0408\n",
            "Epoch 59/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0068 - accuracy: 0.0408\n",
            "Epoch 60/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0066 - accuracy: 0.0408\n",
            "Epoch 61/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0065 - accuracy: 0.0408\n",
            "Epoch 62/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0064 - accuracy: 0.0408\n",
            "Epoch 63/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0063 - accuracy: 0.0408\n",
            "Epoch 64/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0062 - accuracy: 0.0408\n",
            "Epoch 65/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0061 - accuracy: 0.0408\n",
            "Epoch 66/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0061 - accuracy: 0.0408\n",
            "Epoch 67/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0060 - accuracy: 0.0408\n",
            "Epoch 68/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0059 - accuracy: 0.0408\n",
            "Epoch 69/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0058 - accuracy: 0.0408\n",
            "Epoch 70/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0058 - accuracy: 0.0408\n",
            "Epoch 71/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0058 - accuracy: 0.0408\n",
            "Epoch 72/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0057 - accuracy: 0.0408\n",
            "Epoch 73/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0056 - accuracy: 0.0408\n",
            "Epoch 74/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0056 - accuracy: 0.0408\n",
            "Epoch 75/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0055 - accuracy: 0.0408\n",
            "Epoch 76/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0054 - accuracy: 0.0408\n",
            "Epoch 77/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0054 - accuracy: 0.0408\n",
            "Epoch 78/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0053 - accuracy: 0.0408\n",
            "Epoch 79/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0053 - accuracy: 0.0408\n",
            "Epoch 80/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0052 - accuracy: 0.0408\n",
            "Epoch 81/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0052 - accuracy: 0.0408\n",
            "Epoch 82/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0052 - accuracy: 0.0408\n",
            "Epoch 83/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0052 - accuracy: 0.0408\n",
            "Epoch 84/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0408\n",
            "Epoch 85/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0408\n",
            "Epoch 86/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0408\n",
            "Epoch 87/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0050 - accuracy: 0.0408\n",
            "Epoch 88/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0050 - accuracy: 0.0408\n",
            "Epoch 89/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0050 - accuracy: 0.0408\n",
            "Epoch 90/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0050 - accuracy: 0.0408\n",
            "Epoch 91/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0049 - accuracy: 0.0408\n",
            "Epoch 92/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0050 - accuracy: 0.0408\n",
            "Epoch 93/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0050 - accuracy: 0.0408\n",
            "Epoch 94/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0049 - accuracy: 0.0408\n",
            "Epoch 95/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0048 - accuracy: 0.0408\n",
            "Epoch 96/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0049 - accuracy: 0.0408\n",
            "Epoch 97/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0048 - accuracy: 0.0408\n",
            "Epoch 98/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0048 - accuracy: 0.0408\n",
            "Epoch 99/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0049 - accuracy: 0.0408\n",
            "Epoch 100/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0049 - accuracy: 0.0408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "15/15 [==============================] - 1s 3ms/step - loss: 0.0708 - accuracy: 0.0135\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0701 - accuracy: 0.0068\n",
            "Epoch 3/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0694 - accuracy: 0.0068\n",
            "Epoch 4/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0687 - accuracy: 0.0068\n",
            "Epoch 5/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0681 - accuracy: 0.0068\n",
            "Epoch 6/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0675 - accuracy: 0.0068\n",
            "Epoch 7/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0669 - accuracy: 0.0068\n",
            "Epoch 8/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0663 - accuracy: 0.0068\n",
            "Epoch 9/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0657 - accuracy: 0.0068\n",
            "Epoch 10/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0650 - accuracy: 0.0068\n",
            "Epoch 11/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0643 - accuracy: 0.0068\n",
            "Epoch 12/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0636 - accuracy: 0.0068\n",
            "Epoch 13/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0628 - accuracy: 0.0068\n",
            "Epoch 14/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0620 - accuracy: 0.0068\n",
            "Epoch 15/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0609 - accuracy: 0.0068\n",
            "Epoch 16/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0597 - accuracy: 0.0135\n",
            "Epoch 17/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0586 - accuracy: 0.0473\n",
            "Epoch 18/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0573 - accuracy: 0.0473\n",
            "Epoch 19/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0560 - accuracy: 0.0473\n",
            "Epoch 20/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0545 - accuracy: 0.0473\n",
            "Epoch 21/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0531 - accuracy: 0.0473\n",
            "Epoch 22/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0515 - accuracy: 0.0473\n",
            "Epoch 23/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0499 - accuracy: 0.0473\n",
            "Epoch 24/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0484 - accuracy: 0.0473\n",
            "Epoch 25/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0467 - accuracy: 0.0473\n",
            "Epoch 26/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0451 - accuracy: 0.0473\n",
            "Epoch 27/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0436 - accuracy: 0.0473\n",
            "Epoch 28/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0422 - accuracy: 0.0473\n",
            "Epoch 29/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0408 - accuracy: 0.0473\n",
            "Epoch 30/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0394 - accuracy: 0.0473\n",
            "Epoch 31/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0383 - accuracy: 0.0473\n",
            "Epoch 32/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0370 - accuracy: 0.0473\n",
            "Epoch 33/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0358 - accuracy: 0.0473\n",
            "Epoch 34/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0349 - accuracy: 0.0473\n",
            "Epoch 35/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0336 - accuracy: 0.0473\n",
            "Epoch 36/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0327 - accuracy: 0.0473\n",
            "Epoch 37/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0317 - accuracy: 0.0473\n",
            "Epoch 38/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0309 - accuracy: 0.0473\n",
            "Epoch 39/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0300 - accuracy: 0.0473\n",
            "Epoch 40/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0293 - accuracy: 0.0473\n",
            "Epoch 41/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0285 - accuracy: 0.0473\n",
            "Epoch 42/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0278 - accuracy: 0.0473\n",
            "Epoch 43/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0272 - accuracy: 0.0473\n",
            "Epoch 44/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0266 - accuracy: 0.0473\n",
            "Epoch 45/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0260 - accuracy: 0.0473\n",
            "Epoch 46/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0254 - accuracy: 0.0473\n",
            "Epoch 47/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0249 - accuracy: 0.0473\n",
            "Epoch 48/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0244 - accuracy: 0.0473\n",
            "Epoch 49/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0240 - accuracy: 0.0473\n",
            "Epoch 50/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0235 - accuracy: 0.0473\n",
            "Epoch 51/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0231 - accuracy: 0.0473\n",
            "Epoch 52/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0227 - accuracy: 0.0473\n",
            "Epoch 53/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0223 - accuracy: 0.0473\n",
            "Epoch 54/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0219 - accuracy: 0.0473\n",
            "Epoch 55/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0215 - accuracy: 0.0473\n",
            "Epoch 56/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0212 - accuracy: 0.0473\n",
            "Epoch 57/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0208 - accuracy: 0.0473\n",
            "Epoch 58/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0207 - accuracy: 0.0473\n",
            "Epoch 59/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0203 - accuracy: 0.0473\n",
            "Epoch 60/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0198 - accuracy: 0.0473\n",
            "Epoch 61/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0196 - accuracy: 0.0473\n",
            "Epoch 62/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0193 - accuracy: 0.0473\n",
            "Epoch 63/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0190 - accuracy: 0.0473\n",
            "Epoch 64/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0187 - accuracy: 0.0473\n",
            "Epoch 65/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0185 - accuracy: 0.0473\n",
            "Epoch 66/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0182 - accuracy: 0.0473\n",
            "Epoch 67/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0179 - accuracy: 0.0473\n",
            "Epoch 68/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0178 - accuracy: 0.0473\n",
            "Epoch 69/100\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.0175 - accuracy: 0.0473\n",
            "Epoch 70/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0172 - accuracy: 0.0473\n",
            "Epoch 71/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0170 - accuracy: 0.0473\n",
            "Epoch 72/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0167 - accuracy: 0.0473\n",
            "Epoch 73/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0165 - accuracy: 0.0473\n",
            "Epoch 74/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0163 - accuracy: 0.0473\n",
            "Epoch 75/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0160 - accuracy: 0.0473\n",
            "Epoch 76/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0158 - accuracy: 0.0473\n",
            "Epoch 77/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0156 - accuracy: 0.0473\n",
            "Epoch 78/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0154 - accuracy: 0.0473\n",
            "Epoch 79/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0151 - accuracy: 0.0473\n",
            "Epoch 80/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0149 - accuracy: 0.0473\n",
            "Epoch 81/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0147 - accuracy: 0.0473\n",
            "Epoch 82/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0145 - accuracy: 0.0473\n",
            "Epoch 83/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0143 - accuracy: 0.0473\n",
            "Epoch 84/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0141 - accuracy: 0.0473\n",
            "Epoch 85/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0139 - accuracy: 0.0473\n",
            "Epoch 86/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0138 - accuracy: 0.0473\n",
            "Epoch 87/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0136 - accuracy: 0.0473\n",
            "Epoch 88/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0134 - accuracy: 0.0473\n",
            "Epoch 89/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0133 - accuracy: 0.0473\n",
            "Epoch 90/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0130 - accuracy: 0.0473\n",
            "Epoch 91/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0129 - accuracy: 0.0473\n",
            "Epoch 92/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0127 - accuracy: 0.0473\n",
            "Epoch 93/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0126 - accuracy: 0.0473\n",
            "Epoch 94/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0124 - accuracy: 0.0473\n",
            "Epoch 95/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0122 - accuracy: 0.0473\n",
            "Epoch 96/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0121 - accuracy: 0.0473\n",
            "Epoch 97/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0120 - accuracy: 0.0473\n",
            "Epoch 98/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0118 - accuracy: 0.0473\n",
            "Epoch 99/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0117 - accuracy: 0.0473\n",
            "Epoch 100/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0115 - accuracy: 0.0473\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "15/15 [==============================] - 1s 3ms/step - loss: 0.0717 - accuracy: 0.0068\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0714 - accuracy: 0.0068\n",
            "Epoch 3/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0711 - accuracy: 0.0068\n",
            "Epoch 4/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0709 - accuracy: 0.0068\n",
            "Epoch 5/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0706 - accuracy: 0.0068\n",
            "Epoch 6/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0704 - accuracy: 0.0068\n",
            "Epoch 7/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0702 - accuracy: 0.0068\n",
            "Epoch 8/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0700 - accuracy: 0.0068\n",
            "Epoch 9/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0698 - accuracy: 0.0068\n",
            "Epoch 10/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0696 - accuracy: 0.0068\n",
            "Epoch 11/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0694 - accuracy: 0.0068\n",
            "Epoch 12/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0692 - accuracy: 0.0068\n",
            "Epoch 13/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0690 - accuracy: 0.0068\n",
            "Epoch 14/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0689 - accuracy: 0.0068\n",
            "Epoch 15/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0687 - accuracy: 0.0068\n",
            "Epoch 16/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0686 - accuracy: 0.0068\n",
            "Epoch 17/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0684 - accuracy: 0.0068\n",
            "Epoch 18/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0683 - accuracy: 0.0068\n",
            "Epoch 19/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0681 - accuracy: 0.0068\n",
            "Epoch 20/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0680 - accuracy: 0.0068\n",
            "Epoch 21/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0679 - accuracy: 0.0068\n",
            "Epoch 22/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0678 - accuracy: 0.0068\n",
            "Epoch 23/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0676 - accuracy: 0.0068\n",
            "Epoch 24/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0675 - accuracy: 0.0068\n",
            "Epoch 25/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0674 - accuracy: 0.0068\n",
            "Epoch 26/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0673 - accuracy: 0.0068\n",
            "Epoch 27/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0672 - accuracy: 0.0068\n",
            "Epoch 28/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0671 - accuracy: 0.0068\n",
            "Epoch 29/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0670 - accuracy: 0.0068\n",
            "Epoch 30/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0669 - accuracy: 0.0068\n",
            "Epoch 31/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0668 - accuracy: 0.0068\n",
            "Epoch 32/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0667 - accuracy: 0.0068\n",
            "Epoch 33/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0666 - accuracy: 0.0068\n",
            "Epoch 34/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0666 - accuracy: 0.0068\n",
            "Epoch 35/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0665 - accuracy: 0.0068\n",
            "Epoch 36/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0664 - accuracy: 0.0068\n",
            "Epoch 37/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0663 - accuracy: 0.0068\n",
            "Epoch 38/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0663 - accuracy: 0.0068\n",
            "Epoch 39/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0662 - accuracy: 0.0068\n",
            "Epoch 40/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0661 - accuracy: 0.0068\n",
            "Epoch 41/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0661 - accuracy: 0.0068\n",
            "Epoch 42/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0660 - accuracy: 0.0068\n",
            "Epoch 43/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0660 - accuracy: 0.0068\n",
            "Epoch 44/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0659 - accuracy: 0.0068\n",
            "Epoch 45/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0659 - accuracy: 0.0068\n",
            "Epoch 46/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0658 - accuracy: 0.0068\n",
            "Epoch 47/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0658 - accuracy: 0.0068\n",
            "Epoch 48/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0657 - accuracy: 0.0068\n",
            "Epoch 49/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0657 - accuracy: 0.0068\n",
            "Epoch 50/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0656 - accuracy: 0.0068\n",
            "Epoch 51/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0656 - accuracy: 0.0068\n",
            "Epoch 52/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0655 - accuracy: 0.0068\n",
            "Epoch 53/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0655 - accuracy: 0.0068\n",
            "Epoch 54/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0655 - accuracy: 0.0068\n",
            "Epoch 55/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0654 - accuracy: 0.0068\n",
            "Epoch 56/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0654 - accuracy: 0.0068\n",
            "Epoch 57/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0654 - accuracy: 0.0068\n",
            "Epoch 58/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0653 - accuracy: 0.0068\n",
            "Epoch 59/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0653 - accuracy: 0.0068\n",
            "Epoch 60/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0653 - accuracy: 0.0068\n",
            "Epoch 61/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0652 - accuracy: 0.0068\n",
            "Epoch 62/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0652 - accuracy: 0.0068\n",
            "Epoch 63/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0652 - accuracy: 0.0068\n",
            "Epoch 64/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0652 - accuracy: 0.0068\n",
            "Epoch 65/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0651 - accuracy: 0.0068\n",
            "Epoch 66/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0651 - accuracy: 0.0068\n",
            "Epoch 67/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0651 - accuracy: 0.0068\n",
            "Epoch 68/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0651 - accuracy: 0.0068\n",
            "Epoch 69/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0650 - accuracy: 0.0068\n",
            "Epoch 70/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0650 - accuracy: 0.0068\n",
            "Epoch 71/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0650 - accuracy: 0.0068\n",
            "Epoch 72/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0650 - accuracy: 0.0068\n",
            "Epoch 73/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0650 - accuracy: 0.0068\n",
            "Epoch 74/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 75/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 76/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 77/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 78/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 79/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0648 - accuracy: 0.0068\n",
            "Epoch 80/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0648 - accuracy: 0.0068\n",
            "Epoch 81/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0648 - accuracy: 0.0068\n",
            "Epoch 82/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0648 - accuracy: 0.0068\n",
            "Epoch 83/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0648 - accuracy: 0.0068\n",
            "Epoch 84/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0648 - accuracy: 0.0068\n",
            "Epoch 85/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0648 - accuracy: 0.0068\n",
            "Epoch 86/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0648 - accuracy: 0.0068\n",
            "Epoch 87/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 88/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 89/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 90/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 91/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 92/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 93/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 94/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 95/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 96/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 97/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0646 - accuracy: 0.0068\n",
            "Epoch 98/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0646 - accuracy: 0.0068\n",
            "Epoch 99/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0646 - accuracy: 0.0068\n",
            "Epoch 100/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0646 - accuracy: 0.0068\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "15/15 [==============================] - 1s 3ms/step - loss: 0.0720 - accuracy: 0.0000e+00\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0717 - accuracy: 0.0000e+00\n",
            "Epoch 3/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0713 - accuracy: 0.0000e+00\n",
            "Epoch 4/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0710 - accuracy: 0.0000e+00\n",
            "Epoch 5/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0707 - accuracy: 0.0000e+00\n",
            "Epoch 6/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0704 - accuracy: 0.0000e+00\n",
            "Epoch 7/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0701 - accuracy: 0.0000e+00\n",
            "Epoch 8/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0698 - accuracy: 0.0000e+00\n",
            "Epoch 9/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0695 - accuracy: 0.0000e+00\n",
            "Epoch 10/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0693 - accuracy: 0.0000e+00\n",
            "Epoch 11/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0690 - accuracy: 0.0000e+00\n",
            "Epoch 12/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0688 - accuracy: 0.0000e+00\n",
            "Epoch 13/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0686 - accuracy: 0.0000e+00\n",
            "Epoch 14/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0684 - accuracy: 0.0000e+00\n",
            "Epoch 15/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0681 - accuracy: 0.0000e+00\n",
            "Epoch 16/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0679 - accuracy: 0.0000e+00\n",
            "Epoch 17/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0677 - accuracy: 0.0000e+00\n",
            "Epoch 18/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0675 - accuracy: 0.0000e+00\n",
            "Epoch 19/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0674 - accuracy: 0.0000e+00\n",
            "Epoch 20/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0672 - accuracy: 0.0000e+00\n",
            "Epoch 21/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0670 - accuracy: 0.0000e+00\n",
            "Epoch 22/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0668 - accuracy: 0.0000e+00\n",
            "Epoch 23/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0667 - accuracy: 0.0000e+00\n",
            "Epoch 24/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0665 - accuracy: 0.0000e+00\n",
            "Epoch 25/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0664 - accuracy: 0.0000e+00\n",
            "Epoch 26/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0663 - accuracy: 0.0000e+00\n",
            "Epoch 27/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0661 - accuracy: 0.0000e+00\n",
            "Epoch 28/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0660 - accuracy: 0.0000e+00\n",
            "Epoch 29/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0659 - accuracy: 0.0000e+00\n",
            "Epoch 30/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0657 - accuracy: 0.0000e+00\n",
            "Epoch 31/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0656 - accuracy: 0.0000e+00\n",
            "Epoch 32/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0655 - accuracy: 0.0000e+00\n",
            "Epoch 33/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0654 - accuracy: 0.0000e+00\n",
            "Epoch 34/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0653 - accuracy: 0.0000e+00\n",
            "Epoch 35/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0652 - accuracy: 0.0000e+00\n",
            "Epoch 36/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0651 - accuracy: 0.0000e+00\n",
            "Epoch 37/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0650 - accuracy: 0.0000e+00\n",
            "Epoch 38/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0649 - accuracy: 0.0000e+00\n",
            "Epoch 39/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0648 - accuracy: 0.0000e+00\n",
            "Epoch 40/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0647 - accuracy: 0.0000e+00\n",
            "Epoch 41/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0647 - accuracy: 0.0000e+00\n",
            "Epoch 42/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0646 - accuracy: 0.0000e+00\n",
            "Epoch 43/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0645 - accuracy: 0.0000e+00\n",
            "Epoch 44/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0645 - accuracy: 0.0000e+00\n",
            "Epoch 45/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0644 - accuracy: 0.0000e+00\n",
            "Epoch 46/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0643 - accuracy: 0.0000e+00\n",
            "Epoch 47/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0642 - accuracy: 0.0000e+00\n",
            "Epoch 48/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0642 - accuracy: 0.0000e+00\n",
            "Epoch 49/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0641 - accuracy: 0.0000e+00\n",
            "Epoch 50/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0641 - accuracy: 0.0000e+00\n",
            "Epoch 51/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0640 - accuracy: 0.0000e+00\n",
            "Epoch 52/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0639 - accuracy: 0.0000e+00\n",
            "Epoch 53/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0639 - accuracy: 0.0000e+00\n",
            "Epoch 54/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0639 - accuracy: 0.0000e+00\n",
            "Epoch 55/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0638 - accuracy: 0.0000e+00\n",
            "Epoch 56/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0638 - accuracy: 0.0000e+00\n",
            "Epoch 57/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0637 - accuracy: 0.0000e+00\n",
            "Epoch 58/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0637 - accuracy: 0.0000e+00\n",
            "Epoch 59/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0636 - accuracy: 0.0000e+00\n",
            "Epoch 60/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0636 - accuracy: 0.0000e+00\n",
            "Epoch 61/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0635 - accuracy: 0.0000e+00\n",
            "Epoch 62/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0635 - accuracy: 0.0000e+00\n",
            "Epoch 63/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0635 - accuracy: 0.0000e+00\n",
            "Epoch 64/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0634 - accuracy: 0.0000e+00\n",
            "Epoch 65/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0634 - accuracy: 0.0000e+00\n",
            "Epoch 66/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0634 - accuracy: 0.0000e+00\n",
            "Epoch 67/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0633 - accuracy: 0.0000e+00\n",
            "Epoch 68/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0633 - accuracy: 0.0000e+00\n",
            "Epoch 69/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0633 - accuracy: 0.0000e+00\n",
            "Epoch 70/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0633 - accuracy: 0.0000e+00\n",
            "Epoch 71/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0632 - accuracy: 0.0000e+00\n",
            "Epoch 72/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0632 - accuracy: 0.0000e+00\n",
            "Epoch 73/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0632 - accuracy: 0.0000e+00\n",
            "Epoch 74/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0632 - accuracy: 0.0000e+00\n",
            "Epoch 75/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0631 - accuracy: 0.0000e+00\n",
            "Epoch 76/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0631 - accuracy: 0.0000e+00\n",
            "Epoch 77/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0631 - accuracy: 0.0000e+00\n",
            "Epoch 78/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0631 - accuracy: 0.0000e+00\n",
            "Epoch 79/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0631 - accuracy: 0.0000e+00\n",
            "Epoch 80/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0630 - accuracy: 0.0000e+00\n",
            "Epoch 81/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0630 - accuracy: 0.0000e+00\n",
            "Epoch 82/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0630 - accuracy: 0.0000e+00\n",
            "Epoch 83/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0630 - accuracy: 0.0000e+00\n",
            "Epoch 84/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0630 - accuracy: 0.0000e+00\n",
            "Epoch 85/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0630 - accuracy: 0.0000e+00\n",
            "Epoch 86/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0629 - accuracy: 0.0000e+00\n",
            "Epoch 87/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0629 - accuracy: 0.0000e+00\n",
            "Epoch 88/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0629 - accuracy: 0.0000e+00\n",
            "Epoch 89/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0629 - accuracy: 0.0000e+00\n",
            "Epoch 90/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0629 - accuracy: 0.0000e+00\n",
            "Epoch 91/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0629 - accuracy: 0.0000e+00\n",
            "Epoch 92/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0629 - accuracy: 0.0000e+00\n",
            "Epoch 93/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0628 - accuracy: 0.0000e+00\n",
            "Epoch 94/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0628 - accuracy: 0.0000e+00\n",
            "Epoch 95/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0628 - accuracy: 0.0000e+00\n",
            "Epoch 96/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0628 - accuracy: 0.0000e+00\n",
            "Epoch 97/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0628 - accuracy: 0.0000e+00\n",
            "Epoch 98/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0628 - accuracy: 0.0000e+00\n",
            "Epoch 99/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0628 - accuracy: 0.0000e+00\n",
            "Epoch 100/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0628 - accuracy: 0.0000e+00\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0654 - accuracy: 0.0068\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 3/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0645 - accuracy: 0.0068\n",
            "Epoch 4/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0641 - accuracy: 0.0068\n",
            "Epoch 5/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0636 - accuracy: 0.0068\n",
            "Epoch 6/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0633 - accuracy: 0.0068\n",
            "Epoch 7/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0629 - accuracy: 0.0068\n",
            "Epoch 8/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0625 - accuracy: 0.0068\n",
            "Epoch 9/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0621 - accuracy: 0.0068\n",
            "Epoch 10/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0618 - accuracy: 0.0068\n",
            "Epoch 11/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0615 - accuracy: 0.0068\n",
            "Epoch 12/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0612 - accuracy: 0.0068\n",
            "Epoch 13/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0608 - accuracy: 0.0068\n",
            "Epoch 14/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0605 - accuracy: 0.0068\n",
            "Epoch 15/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0602 - accuracy: 0.0068\n",
            "Epoch 16/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0600 - accuracy: 0.0068\n",
            "Epoch 17/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0597 - accuracy: 0.0068\n",
            "Epoch 18/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0594 - accuracy: 0.0068\n",
            "Epoch 19/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0592 - accuracy: 0.0068\n",
            "Epoch 20/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0590 - accuracy: 0.0068\n",
            "Epoch 21/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0588 - accuracy: 0.0068\n",
            "Epoch 22/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0585 - accuracy: 0.0068\n",
            "Epoch 23/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0583 - accuracy: 0.0068\n",
            "Epoch 24/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0581 - accuracy: 0.0068\n",
            "Epoch 25/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0579 - accuracy: 0.0068\n",
            "Epoch 26/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0577 - accuracy: 0.0068\n",
            "Epoch 27/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0576 - accuracy: 0.0068\n",
            "Epoch 28/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0574 - accuracy: 0.0068\n",
            "Epoch 29/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0572 - accuracy: 0.0068\n",
            "Epoch 30/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0571 - accuracy: 0.0068\n",
            "Epoch 31/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0569 - accuracy: 0.0068\n",
            "Epoch 32/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0568 - accuracy: 0.0068\n",
            "Epoch 33/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0566 - accuracy: 0.0068\n",
            "Epoch 34/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0565 - accuracy: 0.0068\n",
            "Epoch 35/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0563 - accuracy: 0.0068\n",
            "Epoch 36/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0562 - accuracy: 0.0068\n",
            "Epoch 37/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0561 - accuracy: 0.0068\n",
            "Epoch 38/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0560 - accuracy: 0.0068\n",
            "Epoch 39/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0558 - accuracy: 0.0068\n",
            "Epoch 40/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0557 - accuracy: 0.0068\n",
            "Epoch 41/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0556 - accuracy: 0.0068\n",
            "Epoch 42/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0555 - accuracy: 0.0068\n",
            "Epoch 43/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0554 - accuracy: 0.0068\n",
            "Epoch 44/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0553 - accuracy: 0.0068\n",
            "Epoch 45/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0552 - accuracy: 0.0068\n",
            "Epoch 46/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0551 - accuracy: 0.0068\n",
            "Epoch 47/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0551 - accuracy: 0.0068\n",
            "Epoch 48/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0550 - accuracy: 0.0068\n",
            "Epoch 49/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0549 - accuracy: 0.0068\n",
            "Epoch 50/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0548 - accuracy: 0.0068\n",
            "Epoch 51/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0548 - accuracy: 0.0068\n",
            "Epoch 52/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0547 - accuracy: 0.0068\n",
            "Epoch 53/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0546 - accuracy: 0.0068\n",
            "Epoch 54/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0545 - accuracy: 0.0068\n",
            "Epoch 55/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0545 - accuracy: 0.0068\n",
            "Epoch 56/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0544 - accuracy: 0.0068\n",
            "Epoch 57/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0544 - accuracy: 0.0068\n",
            "Epoch 58/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0543 - accuracy: 0.0068\n",
            "Epoch 59/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0543 - accuracy: 0.0068\n",
            "Epoch 60/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0542 - accuracy: 0.0068\n",
            "Epoch 61/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0541 - accuracy: 0.0068\n",
            "Epoch 62/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0541 - accuracy: 0.0068\n",
            "Epoch 63/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0540 - accuracy: 0.0068\n",
            "Epoch 64/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0540 - accuracy: 0.0068\n",
            "Epoch 65/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0540 - accuracy: 0.0068\n",
            "Epoch 66/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0539 - accuracy: 0.0068\n",
            "Epoch 67/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0539 - accuracy: 0.0068\n",
            "Epoch 68/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0538 - accuracy: 0.0068\n",
            "Epoch 69/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0538 - accuracy: 0.0068\n",
            "Epoch 70/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0538 - accuracy: 0.0068\n",
            "Epoch 71/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0537 - accuracy: 0.0068\n",
            "Epoch 72/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0537 - accuracy: 0.0068\n",
            "Epoch 73/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0537 - accuracy: 0.0068\n",
            "Epoch 74/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0536 - accuracy: 0.0068\n",
            "Epoch 75/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0536 - accuracy: 0.0068\n",
            "Epoch 76/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0536 - accuracy: 0.0068\n",
            "Epoch 77/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0535 - accuracy: 0.0068\n",
            "Epoch 78/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0535 - accuracy: 0.0068\n",
            "Epoch 79/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0535 - accuracy: 0.0068\n",
            "Epoch 80/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0535 - accuracy: 0.0068\n",
            "Epoch 81/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0534 - accuracy: 0.0068\n",
            "Epoch 82/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0534 - accuracy: 0.0068\n",
            "Epoch 83/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0534 - accuracy: 0.0068\n",
            "Epoch 84/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0534 - accuracy: 0.0068\n",
            "Epoch 85/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0534 - accuracy: 0.0068\n",
            "Epoch 86/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0533 - accuracy: 0.0068\n",
            "Epoch 87/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0533 - accuracy: 0.0068\n",
            "Epoch 88/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0533 - accuracy: 0.0068\n",
            "Epoch 89/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0533 - accuracy: 0.0068\n",
            "Epoch 90/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0533 - accuracy: 0.0068\n",
            "Epoch 91/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0532 - accuracy: 0.0068\n",
            "Epoch 92/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0532 - accuracy: 0.0068\n",
            "Epoch 93/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0532 - accuracy: 0.0068\n",
            "Epoch 94/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0532 - accuracy: 0.0068\n",
            "Epoch 95/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0532 - accuracy: 0.0068\n",
            "Epoch 96/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0532 - accuracy: 0.0068\n",
            "Epoch 97/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0532 - accuracy: 0.0068\n",
            "Epoch 98/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0531 - accuracy: 0.0068\n",
            "Epoch 99/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0531 - accuracy: 0.0068\n",
            "Epoch 100/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0531 - accuracy: 0.0068\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 1s 4ms/step - loss: 0.0697 - accuracy: 0.0068\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0694 - accuracy: 0.0068\n",
            "Epoch 3/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0692 - accuracy: 0.0068\n",
            "Epoch 4/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0689 - accuracy: 0.0068\n",
            "Epoch 5/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0686 - accuracy: 0.0068\n",
            "Epoch 6/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0684 - accuracy: 0.0068\n",
            "Epoch 7/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0681 - accuracy: 0.0068\n",
            "Epoch 8/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0679 - accuracy: 0.0068\n",
            "Epoch 9/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0677 - accuracy: 0.0068\n",
            "Epoch 10/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0675 - accuracy: 0.0068\n",
            "Epoch 11/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0673 - accuracy: 0.0068\n",
            "Epoch 12/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0671 - accuracy: 0.0068\n",
            "Epoch 13/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0669 - accuracy: 0.0068\n",
            "Epoch 14/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0667 - accuracy: 0.0068\n",
            "Epoch 15/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0665 - accuracy: 0.0068\n",
            "Epoch 16/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0663 - accuracy: 0.0068\n",
            "Epoch 17/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0662 - accuracy: 0.0068\n",
            "Epoch 18/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0660 - accuracy: 0.0068\n",
            "Epoch 19/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0659 - accuracy: 0.0068\n",
            "Epoch 20/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0657 - accuracy: 0.0068\n",
            "Epoch 21/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0656 - accuracy: 0.0068\n",
            "Epoch 22/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0654 - accuracy: 0.0068\n",
            "Epoch 23/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0653 - accuracy: 0.0068\n",
            "Epoch 24/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0652 - accuracy: 0.0068\n",
            "Epoch 25/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0651 - accuracy: 0.0068\n",
            "Epoch 26/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 27/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0648 - accuracy: 0.0068\n",
            "Epoch 28/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 29/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0646 - accuracy: 0.0068\n",
            "Epoch 30/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0645 - accuracy: 0.0068\n",
            "Epoch 31/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0644 - accuracy: 0.0068\n",
            "Epoch 32/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0643 - accuracy: 0.0068\n",
            "Epoch 33/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0642 - accuracy: 0.0068\n",
            "Epoch 34/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0641 - accuracy: 0.0068\n",
            "Epoch 35/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0641 - accuracy: 0.0068\n",
            "Epoch 36/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0640 - accuracy: 0.0068\n",
            "Epoch 37/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0639 - accuracy: 0.0068\n",
            "Epoch 38/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0638 - accuracy: 0.0068\n",
            "Epoch 39/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0638 - accuracy: 0.0068\n",
            "Epoch 40/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0637 - accuracy: 0.0068\n",
            "Epoch 41/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0636 - accuracy: 0.0068\n",
            "Epoch 42/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0635 - accuracy: 0.0068\n",
            "Epoch 43/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0635 - accuracy: 0.0068\n",
            "Epoch 44/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0634 - accuracy: 0.0068\n",
            "Epoch 45/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0634 - accuracy: 0.0068\n",
            "Epoch 46/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0633 - accuracy: 0.0068\n",
            "Epoch 47/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0632 - accuracy: 0.0068\n",
            "Epoch 48/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0632 - accuracy: 0.0068\n",
            "Epoch 49/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0631 - accuracy: 0.0068\n",
            "Epoch 50/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0631 - accuracy: 0.0068\n",
            "Epoch 51/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0631 - accuracy: 0.0068\n",
            "Epoch 52/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0630 - accuracy: 0.0068\n",
            "Epoch 53/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0630 - accuracy: 0.0068\n",
            "Epoch 54/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0629 - accuracy: 0.0068\n",
            "Epoch 55/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0629 - accuracy: 0.0068\n",
            "Epoch 56/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0628 - accuracy: 0.0068\n",
            "Epoch 57/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0628 - accuracy: 0.0068\n",
            "Epoch 58/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0628 - accuracy: 0.0068\n",
            "Epoch 59/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0627 - accuracy: 0.0068\n",
            "Epoch 60/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0627 - accuracy: 0.0068\n",
            "Epoch 61/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0627 - accuracy: 0.0068\n",
            "Epoch 62/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0627 - accuracy: 0.0068\n",
            "Epoch 63/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0626 - accuracy: 0.0068\n",
            "Epoch 64/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0626 - accuracy: 0.0068\n",
            "Epoch 65/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0626 - accuracy: 0.0068\n",
            "Epoch 66/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0625 - accuracy: 0.0068\n",
            "Epoch 67/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0625 - accuracy: 0.0068\n",
            "Epoch 68/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0625 - accuracy: 0.0068\n",
            "Epoch 69/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0625 - accuracy: 0.0068\n",
            "Epoch 70/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0624 - accuracy: 0.0068\n",
            "Epoch 71/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0624 - accuracy: 0.0068\n",
            "Epoch 72/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0624 - accuracy: 0.0068\n",
            "Epoch 73/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0624 - accuracy: 0.0068\n",
            "Epoch 74/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0624 - accuracy: 0.0068\n",
            "Epoch 75/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0623 - accuracy: 0.0068\n",
            "Epoch 76/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0623 - accuracy: 0.0068\n",
            "Epoch 77/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0623 - accuracy: 0.0068\n",
            "Epoch 78/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0623 - accuracy: 0.0068\n",
            "Epoch 79/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0623 - accuracy: 0.0068\n",
            "Epoch 80/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0623 - accuracy: 0.0068\n",
            "Epoch 81/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0622 - accuracy: 0.0068\n",
            "Epoch 82/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0622 - accuracy: 0.0068\n",
            "Epoch 83/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0622 - accuracy: 0.0068\n",
            "Epoch 84/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0622 - accuracy: 0.0068\n",
            "Epoch 85/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0622 - accuracy: 0.0068\n",
            "Epoch 86/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0622 - accuracy: 0.0068\n",
            "Epoch 87/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0622 - accuracy: 0.0068\n",
            "Epoch 88/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0622 - accuracy: 0.0068\n",
            "Epoch 89/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0621 - accuracy: 0.0068\n",
            "Epoch 90/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0621 - accuracy: 0.0068\n",
            "Epoch 91/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0621 - accuracy: 0.0068\n",
            "Epoch 92/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0621 - accuracy: 0.0068\n",
            "Epoch 93/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0621 - accuracy: 0.0068\n",
            "Epoch 94/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0621 - accuracy: 0.0068\n",
            "Epoch 95/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0621 - accuracy: 0.0068\n",
            "Epoch 96/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0621 - accuracy: 0.0068\n",
            "Epoch 97/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0621 - accuracy: 0.0068\n",
            "Epoch 98/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0621 - accuracy: 0.0068\n",
            "Epoch 99/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0620 - accuracy: 0.0068\n",
            "Epoch 100/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0620 - accuracy: 0.0068\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "15/15 [==============================] - 1s 3ms/step - loss: 0.0709 - accuracy: 0.0068\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0704 - accuracy: 0.0068\n",
            "Epoch 3/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0699 - accuracy: 0.0068\n",
            "Epoch 4/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0694 - accuracy: 0.0068\n",
            "Epoch 5/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0690 - accuracy: 0.0068\n",
            "Epoch 6/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0685 - accuracy: 0.0068\n",
            "Epoch 7/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0681 - accuracy: 0.0068\n",
            "Epoch 8/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0677 - accuracy: 0.0068\n",
            "Epoch 9/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0673 - accuracy: 0.0068\n",
            "Epoch 10/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0669 - accuracy: 0.0068\n",
            "Epoch 11/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0665 - accuracy: 0.0068\n",
            "Epoch 12/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0662 - accuracy: 0.0068\n",
            "Epoch 13/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0659 - accuracy: 0.0068\n",
            "Epoch 14/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0655 - accuracy: 0.0068\n",
            "Epoch 15/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0652 - accuracy: 0.0068\n",
            "Epoch 16/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 17/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0646 - accuracy: 0.0068\n",
            "Epoch 18/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0644 - accuracy: 0.0068\n",
            "Epoch 19/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0641 - accuracy: 0.0068\n",
            "Epoch 20/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0638 - accuracy: 0.0068\n",
            "Epoch 21/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0636 - accuracy: 0.0068\n",
            "Epoch 22/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0634 - accuracy: 0.0068\n",
            "Epoch 23/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0631 - accuracy: 0.0068\n",
            "Epoch 24/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0629 - accuracy: 0.0068\n",
            "Epoch 25/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0627 - accuracy: 0.0068\n",
            "Epoch 26/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0625 - accuracy: 0.0068\n",
            "Epoch 27/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0623 - accuracy: 0.0068\n",
            "Epoch 28/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0621 - accuracy: 0.0068\n",
            "Epoch 29/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0619 - accuracy: 0.0068\n",
            "Epoch 30/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0617 - accuracy: 0.0068\n",
            "Epoch 31/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0616 - accuracy: 0.0068\n",
            "Epoch 32/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0614 - accuracy: 0.0068\n",
            "Epoch 33/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0612 - accuracy: 0.0068\n",
            "Epoch 34/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0611 - accuracy: 0.0068\n",
            "Epoch 35/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0609 - accuracy: 0.0068\n",
            "Epoch 36/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0608 - accuracy: 0.0068\n",
            "Epoch 37/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0607 - accuracy: 0.0068\n",
            "Epoch 38/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0605 - accuracy: 0.0068\n",
            "Epoch 39/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0604 - accuracy: 0.0068\n",
            "Epoch 40/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0603 - accuracy: 0.0068\n",
            "Epoch 41/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0602 - accuracy: 0.0068\n",
            "Epoch 42/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0601 - accuracy: 0.0068\n",
            "Epoch 43/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0600 - accuracy: 0.0068\n",
            "Epoch 44/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0598 - accuracy: 0.0068\n",
            "Epoch 45/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0597 - accuracy: 0.0068\n",
            "Epoch 46/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0597 - accuracy: 0.0068\n",
            "Epoch 47/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0596 - accuracy: 0.0068\n",
            "Epoch 48/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0595 - accuracy: 0.0068\n",
            "Epoch 49/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0594 - accuracy: 0.0068\n",
            "Epoch 50/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0593 - accuracy: 0.0068\n",
            "Epoch 51/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0592 - accuracy: 0.0068\n",
            "Epoch 52/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0591 - accuracy: 0.0068\n",
            "Epoch 53/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0591 - accuracy: 0.0068\n",
            "Epoch 54/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0590 - accuracy: 0.0068\n",
            "Epoch 55/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0589 - accuracy: 0.0068\n",
            "Epoch 56/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0589 - accuracy: 0.0068\n",
            "Epoch 57/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0588 - accuracy: 0.0068\n",
            "Epoch 58/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0587 - accuracy: 0.0068\n",
            "Epoch 59/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0587 - accuracy: 0.0068\n",
            "Epoch 60/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0586 - accuracy: 0.0068\n",
            "Epoch 61/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0586 - accuracy: 0.0068\n",
            "Epoch 62/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0585 - accuracy: 0.0068\n",
            "Epoch 63/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0585 - accuracy: 0.0068\n",
            "Epoch 64/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0584 - accuracy: 0.0068\n",
            "Epoch 65/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0584 - accuracy: 0.0068\n",
            "Epoch 66/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0583 - accuracy: 0.0068\n",
            "Epoch 67/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0583 - accuracy: 0.0068\n",
            "Epoch 68/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0582 - accuracy: 0.0068\n",
            "Epoch 69/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0582 - accuracy: 0.0068\n",
            "Epoch 70/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0581 - accuracy: 0.0068\n",
            "Epoch 71/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0581 - accuracy: 0.0068\n",
            "Epoch 72/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0581 - accuracy: 0.0068\n",
            "Epoch 73/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0580 - accuracy: 0.0068\n",
            "Epoch 74/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0580 - accuracy: 0.0068\n",
            "Epoch 75/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0580 - accuracy: 0.0068\n",
            "Epoch 76/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0579 - accuracy: 0.0068\n",
            "Epoch 77/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0579 - accuracy: 0.0068\n",
            "Epoch 78/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0579 - accuracy: 0.0068\n",
            "Epoch 79/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0578 - accuracy: 0.0068\n",
            "Epoch 80/100\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0578 - accuracy: 0.0068\n",
            "Epoch 81/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0578 - accuracy: 0.0068\n",
            "Epoch 82/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0578 - accuracy: 0.0068\n",
            "Epoch 83/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0577 - accuracy: 0.0068\n",
            "Epoch 84/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0577 - accuracy: 0.0068\n",
            "Epoch 85/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0577 - accuracy: 0.0068\n",
            "Epoch 86/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0577 - accuracy: 0.0068\n",
            "Epoch 87/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0577 - accuracy: 0.0068\n",
            "Epoch 88/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0576 - accuracy: 0.0068\n",
            "Epoch 89/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0576 - accuracy: 0.0068\n",
            "Epoch 90/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0576 - accuracy: 0.0068\n",
            "Epoch 91/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0576 - accuracy: 0.0068\n",
            "Epoch 92/100\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0576 - accuracy: 0.0068\n",
            "Epoch 93/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0575 - accuracy: 0.0068\n",
            "Epoch 94/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0575 - accuracy: 0.0068\n",
            "Epoch 95/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0575 - accuracy: 0.0068\n",
            "Epoch 96/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0575 - accuracy: 0.0068\n",
            "Epoch 97/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0575 - accuracy: 0.0068\n",
            "Epoch 98/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0575 - accuracy: 0.0068\n",
            "Epoch 99/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0574 - accuracy: 0.0068\n",
            "Epoch 100/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0574 - accuracy: 0.0068\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 1s 4ms/step - loss: 0.0717 - accuracy: 0.0068\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0715 - accuracy: 0.0068\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0713 - accuracy: 0.0068\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0711 - accuracy: 0.0068\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0709 - accuracy: 0.0068\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0707 - accuracy: 0.0068\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0705 - accuracy: 0.0068\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0703 - accuracy: 0.0068\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0701 - accuracy: 0.0068\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0699 - accuracy: 0.0068\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0697 - accuracy: 0.0068\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0695 - accuracy: 0.0068\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0692 - accuracy: 0.0068\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0690 - accuracy: 0.0068\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0688 - accuracy: 0.0068\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0685 - accuracy: 0.0068\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0682 - accuracy: 0.0068\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0679 - accuracy: 0.0068\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0676 - accuracy: 0.0068\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0673 - accuracy: 0.0068\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0669 - accuracy: 0.0068\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0666 - accuracy: 0.0068\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0662 - accuracy: 0.0068\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0657 - accuracy: 0.0068\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0653 - accuracy: 0.0068\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0648 - accuracy: 0.0068\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0643 - accuracy: 0.0068\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0637 - accuracy: 0.0068\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0631 - accuracy: 0.0068\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0625 - accuracy: 0.0068\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0619 - accuracy: 0.0068\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0612 - accuracy: 0.0068\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0606 - accuracy: 0.0068\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0599 - accuracy: 0.0068\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0591 - accuracy: 0.0068\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0583 - accuracy: 0.0068\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0575 - accuracy: 0.0068\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0567 - accuracy: 0.0068\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0558 - accuracy: 0.0068\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0550 - accuracy: 0.0068\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0540 - accuracy: 0.0068\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0531 - accuracy: 0.0068\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0522 - accuracy: 0.0204\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0513 - accuracy: 0.0408\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0504 - accuracy: 0.0408\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0494 - accuracy: 0.0408\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0485 - accuracy: 0.0476\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0475 - accuracy: 0.0476\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0465 - accuracy: 0.0476\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0456 - accuracy: 0.0476\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "5/5 [==============================] - 1s 5ms/step - loss: 0.0721 - accuracy: 0.0136\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0718 - accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0716 - accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0713 - accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0711 - accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0708 - accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0706 - accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0703 - accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0700 - accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0698 - accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0695 - accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0692 - accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0689 - accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0686 - accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0683 - accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0680 - accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0676 - accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0673 - accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0669 - accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0665 - accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0661 - accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0657 - accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0653 - accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0649 - accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0643 - accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0639 - accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0634 - accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0628 - accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0623 - accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0617 - accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0611 - accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0604 - accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0598 - accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0590 - accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0583 - accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0575 - accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0568 - accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0560 - accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0552 - accuracy: 0.0000e+00\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0543 - accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0535 - accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0526 - accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0518 - accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0509 - accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0500 - accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0491 - accuracy: 0.0000e+00\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0483 - accuracy: 0.0000e+00\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0473 - accuracy: 0.0136\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0465 - accuracy: 0.0340\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0455 - accuracy: 0.0340\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "5/5 [==============================] - 1s 5ms/step - loss: 0.0655 - accuracy: 0.0068\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0653 - accuracy: 0.0068\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0650 - accuracy: 0.0068\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0644 - accuracy: 0.0068\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0641 - accuracy: 0.0068\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0638 - accuracy: 0.0068\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0634 - accuracy: 0.0068\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0631 - accuracy: 0.0068\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0628 - accuracy: 0.0068\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0624 - accuracy: 0.0068\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0620 - accuracy: 0.0068\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0616 - accuracy: 0.0068\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0613 - accuracy: 0.0068\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0608 - accuracy: 0.0068\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0604 - accuracy: 0.0068\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0600 - accuracy: 0.0068\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0595 - accuracy: 0.0068\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0591 - accuracy: 0.0068\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0585 - accuracy: 0.0068\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0581 - accuracy: 0.0068\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0575 - accuracy: 0.0068\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0570 - accuracy: 0.0068\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0564 - accuracy: 0.0068\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0559 - accuracy: 0.0068\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0554 - accuracy: 0.0068\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0547 - accuracy: 0.0068\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0541 - accuracy: 0.0068\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0535 - accuracy: 0.0068\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0528 - accuracy: 0.0068\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0522 - accuracy: 0.0068\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0515 - accuracy: 0.0068\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0509 - accuracy: 0.0068\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0502 - accuracy: 0.0068\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0495 - accuracy: 0.0068\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0488 - accuracy: 0.0068\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0481 - accuracy: 0.0068\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0474 - accuracy: 0.0068\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0466 - accuracy: 0.0068\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0459 - accuracy: 0.0068\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0452 - accuracy: 0.0068\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0445 - accuracy: 0.0068\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0439 - accuracy: 0.0068\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0433 - accuracy: 0.0068\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0427 - accuracy: 0.0068\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0421 - accuracy: 0.0068\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0416 - accuracy: 0.0068\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0411 - accuracy: 0.0068\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0407 - accuracy: 0.0068\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0402 - accuracy: 0.0068\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 1s 4ms/step - loss: 0.0698 - accuracy: 0.0136\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0695 - accuracy: 0.0068\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0693 - accuracy: 0.0068\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0691 - accuracy: 0.0068\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0688 - accuracy: 0.0068\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0686 - accuracy: 0.0068\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0683 - accuracy: 0.0068\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0681 - accuracy: 0.0068\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0678 - accuracy: 0.0068\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0675 - accuracy: 0.0068\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0672 - accuracy: 0.0068\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0669 - accuracy: 0.0068\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0666 - accuracy: 0.0068\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0662 - accuracy: 0.0068\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0658 - accuracy: 0.0068\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0654 - accuracy: 0.0068\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0650 - accuracy: 0.0068\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0646 - accuracy: 0.0068\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0641 - accuracy: 0.0068\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0635 - accuracy: 0.0068\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0629 - accuracy: 0.0068\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0623 - accuracy: 0.0068\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0617 - accuracy: 0.0068\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0610 - accuracy: 0.0068\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0602 - accuracy: 0.0068\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0594 - accuracy: 0.0068\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0586 - accuracy: 0.0068\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0577 - accuracy: 0.0068\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0568 - accuracy: 0.0068\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0557 - accuracy: 0.0068\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0547 - accuracy: 0.0272\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0536 - accuracy: 0.0340\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0524 - accuracy: 0.0408\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0511 - accuracy: 0.0408\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0499 - accuracy: 0.0408\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0486 - accuracy: 0.0408\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0471 - accuracy: 0.0408\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0457 - accuracy: 0.0408\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0444 - accuracy: 0.0408\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0428 - accuracy: 0.0408\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0414 - accuracy: 0.0408\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0399 - accuracy: 0.0408\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0384 - accuracy: 0.0408\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0370 - accuracy: 0.0408\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0355 - accuracy: 0.0408\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0341 - accuracy: 0.0408\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0328 - accuracy: 0.0408\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0316 - accuracy: 0.0408\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0301 - accuracy: 0.0408\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0289 - accuracy: 0.0408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "5/5 [==============================] - 1s 4ms/step - loss: 0.0710 - accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0707 - accuracy: 0.0068\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0705 - accuracy: 0.0068\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0702 - accuracy: 0.0068\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0699 - accuracy: 0.0068\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0697 - accuracy: 0.0068\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0694 - accuracy: 0.0068\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0691 - accuracy: 0.0068\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0689 - accuracy: 0.0068\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0686 - accuracy: 0.0068\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0684 - accuracy: 0.0068\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0681 - accuracy: 0.0068\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0679 - accuracy: 0.0068\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0676 - accuracy: 0.0068\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0674 - accuracy: 0.0068\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0672 - accuracy: 0.0068\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0670 - accuracy: 0.0068\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0667 - accuracy: 0.0068\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0665 - accuracy: 0.0068\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0662 - accuracy: 0.0068\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0660 - accuracy: 0.0068\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0658 - accuracy: 0.0068\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0655 - accuracy: 0.0068\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0653 - accuracy: 0.0068\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0650 - accuracy: 0.0068\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0648 - accuracy: 0.0068\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0645 - accuracy: 0.0068\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0643 - accuracy: 0.0068\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0640 - accuracy: 0.0068\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0637 - accuracy: 0.0068\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0634 - accuracy: 0.0068\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0632 - accuracy: 0.0068\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0629 - accuracy: 0.0068\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0626 - accuracy: 0.0068\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0623 - accuracy: 0.0068\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0619 - accuracy: 0.0068\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0616 - accuracy: 0.0068\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0613 - accuracy: 0.0068\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0609 - accuracy: 0.0068\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0606 - accuracy: 0.0068\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0602 - accuracy: 0.0068\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0598 - accuracy: 0.0068\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0594 - accuracy: 0.0068\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0590 - accuracy: 0.0068\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0586 - accuracy: 0.0068\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0581 - accuracy: 0.0270\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0577 - accuracy: 0.0473\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0572 - accuracy: 0.0473\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0567 - accuracy: 0.0473\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0563 - accuracy: 0.0473\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 1s 5ms/step - loss: 0.0718 - accuracy: 0.0068\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0717 - accuracy: 0.0068\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0716 - accuracy: 0.0068\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0715 - accuracy: 0.0068\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0714 - accuracy: 0.0068\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0713 - accuracy: 0.0068\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0712 - accuracy: 0.0068\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0711 - accuracy: 0.0068\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0711 - accuracy: 0.0068\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0710 - accuracy: 0.0068\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0709 - accuracy: 0.0068\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0708 - accuracy: 0.0068\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0707 - accuracy: 0.0068\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0707 - accuracy: 0.0068\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0706 - accuracy: 0.0068\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0705 - accuracy: 0.0068\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0704 - accuracy: 0.0068\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0704 - accuracy: 0.0068\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0703 - accuracy: 0.0068\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0702 - accuracy: 0.0068\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0701 - accuracy: 0.0068\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0701 - accuracy: 0.0068\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0700 - accuracy: 0.0068\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0699 - accuracy: 0.0068\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0699 - accuracy: 0.0068\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0698 - accuracy: 0.0068\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0697 - accuracy: 0.0068\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0697 - accuracy: 0.0068\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0696 - accuracy: 0.0068\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0695 - accuracy: 0.0068\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0695 - accuracy: 0.0068\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0694 - accuracy: 0.0068\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0693 - accuracy: 0.0068\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0693 - accuracy: 0.0068\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0692 - accuracy: 0.0068\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0692 - accuracy: 0.0068\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0691 - accuracy: 0.0068\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0691 - accuracy: 0.0068\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0690 - accuracy: 0.0068\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0689 - accuracy: 0.0068\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0689 - accuracy: 0.0068\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0688 - accuracy: 0.0068\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0688 - accuracy: 0.0068\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0687 - accuracy: 0.0068\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0687 - accuracy: 0.0068\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0686 - accuracy: 0.0068\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0686 - accuracy: 0.0068\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0685 - accuracy: 0.0068\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0685 - accuracy: 0.0068\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0684 - accuracy: 0.0068\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "5/5 [==============================] - 1s 4ms/step - loss: 0.0721 - accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0720 - accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0719 - accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0718 - accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0716 - accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0715 - accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0714 - accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0713 - accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0712 - accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0711 - accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0710 - accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0709 - accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0708 - accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0707 - accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0706 - accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0705 - accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0704 - accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0703 - accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0702 - accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0701 - accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0700 - accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0699 - accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0698 - accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0697 - accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0696 - accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0695 - accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0695 - accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0694 - accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0693 - accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0692 - accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0691 - accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0690 - accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0690 - accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0689 - accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0688 - accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0687 - accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0686 - accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0686 - accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0685 - accuracy: 0.0000e+00\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0684 - accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0683 - accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0683 - accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0682 - accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0681 - accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0681 - accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0680 - accuracy: 0.0000e+00\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0679 - accuracy: 0.0000e+00\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0679 - accuracy: 0.0000e+00\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0678 - accuracy: 0.0000e+00\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0677 - accuracy: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "5/5 [==============================] - 1s 4ms/step - loss: 0.0656 - accuracy: 0.0136\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0654 - accuracy: 0.0068\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0652 - accuracy: 0.0068\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0651 - accuracy: 0.0068\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0648 - accuracy: 0.0068\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0646 - accuracy: 0.0068\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0645 - accuracy: 0.0068\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0643 - accuracy: 0.0068\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0642 - accuracy: 0.0068\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0640 - accuracy: 0.0068\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0639 - accuracy: 0.0068\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0638 - accuracy: 0.0068\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0636 - accuracy: 0.0068\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0635 - accuracy: 0.0068\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0634 - accuracy: 0.0068\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0632 - accuracy: 0.0068\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0631 - accuracy: 0.0068\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0630 - accuracy: 0.0068\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0629 - accuracy: 0.0068\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0627 - accuracy: 0.0068\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0626 - accuracy: 0.0068\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0625 - accuracy: 0.0068\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0624 - accuracy: 0.0068\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0622 - accuracy: 0.0068\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0621 - accuracy: 0.0068\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0620 - accuracy: 0.0068\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0619 - accuracy: 0.0068\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0618 - accuracy: 0.0068\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0617 - accuracy: 0.0068\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0616 - accuracy: 0.0068\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0615 - accuracy: 0.0068\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0613 - accuracy: 0.0068\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0612 - accuracy: 0.0068\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0611 - accuracy: 0.0068\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0610 - accuracy: 0.0068\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0609 - accuracy: 0.0068\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0608 - accuracy: 0.0068\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0607 - accuracy: 0.0068\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0606 - accuracy: 0.0068\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0605 - accuracy: 0.0068\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0604 - accuracy: 0.0068\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0603 - accuracy: 0.0068\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0603 - accuracy: 0.0068\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0602 - accuracy: 0.0068\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0601 - accuracy: 0.0068\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0600 - accuracy: 0.0068\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0599 - accuracy: 0.0068\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0598 - accuracy: 0.0068\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0597 - accuracy: 0.0068\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "5/5 [==============================] - 1s 5ms/step - loss: 0.0698 - accuracy: 0.0204\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0697 - accuracy: 0.0068\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0696 - accuracy: 0.0068\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0695 - accuracy: 0.0068\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0694 - accuracy: 0.0068\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0693 - accuracy: 0.0068\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0693 - accuracy: 0.0068\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0692 - accuracy: 0.0068\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0691 - accuracy: 0.0068\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0690 - accuracy: 0.0068\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0689 - accuracy: 0.0068\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0688 - accuracy: 0.0068\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0687 - accuracy: 0.0068\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0686 - accuracy: 0.0068\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0685 - accuracy: 0.0068\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0685 - accuracy: 0.0068\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0684 - accuracy: 0.0068\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0683 - accuracy: 0.0068\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0682 - accuracy: 0.0068\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0681 - accuracy: 0.0068\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0681 - accuracy: 0.0068\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0680 - accuracy: 0.0068\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0679 - accuracy: 0.0068\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0678 - accuracy: 0.0068\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0678 - accuracy: 0.0068\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0677 - accuracy: 0.0068\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0676 - accuracy: 0.0068\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0675 - accuracy: 0.0068\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0675 - accuracy: 0.0068\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0674 - accuracy: 0.0068\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0673 - accuracy: 0.0068\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0673 - accuracy: 0.0068\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0672 - accuracy: 0.0068\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0671 - accuracy: 0.0068\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0671 - accuracy: 0.0068\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0670 - accuracy: 0.0068\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0669 - accuracy: 0.0068\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0669 - accuracy: 0.0068\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0668 - accuracy: 0.0068\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0667 - accuracy: 0.0068\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0667 - accuracy: 0.0068\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0666 - accuracy: 0.0068\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0666 - accuracy: 0.0068\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0665 - accuracy: 0.0068\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0664 - accuracy: 0.0068\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0664 - accuracy: 0.0068\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0663 - accuracy: 0.0068\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0663 - accuracy: 0.0068\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0662 - accuracy: 0.0068\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0662 - accuracy: 0.0068\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 1s 5ms/step - loss: 0.0711 - accuracy: 0.0068\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0709 - accuracy: 0.0068\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0707 - accuracy: 0.0068\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0705 - accuracy: 0.0068\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0704 - accuracy: 0.0068\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0702 - accuracy: 0.0068\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0700 - accuracy: 0.0068\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0699 - accuracy: 0.0068\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0697 - accuracy: 0.0068\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0696 - accuracy: 0.0068\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0694 - accuracy: 0.0068\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0693 - accuracy: 0.0068\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0691 - accuracy: 0.0068\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0689 - accuracy: 0.0068\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0688 - accuracy: 0.0068\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0687 - accuracy: 0.0068\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0685 - accuracy: 0.0068\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0684 - accuracy: 0.0068\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0682 - accuracy: 0.0068\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0681 - accuracy: 0.0068\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0679 - accuracy: 0.0068\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0678 - accuracy: 0.0068\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0677 - accuracy: 0.0068\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0675 - accuracy: 0.0068\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0674 - accuracy: 0.0068\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0673 - accuracy: 0.0068\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0672 - accuracy: 0.0068\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0670 - accuracy: 0.0068\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0669 - accuracy: 0.0068\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0668 - accuracy: 0.0068\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0667 - accuracy: 0.0068\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0665 - accuracy: 0.0068\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0664 - accuracy: 0.0068\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0663 - accuracy: 0.0068\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0662 - accuracy: 0.0068\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0661 - accuracy: 0.0068\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0660 - accuracy: 0.0068\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0659 - accuracy: 0.0068\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0657 - accuracy: 0.0068\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0656 - accuracy: 0.0068\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0655 - accuracy: 0.0068\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0654 - accuracy: 0.0068\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0653 - accuracy: 0.0068\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0652 - accuracy: 0.0068\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0651 - accuracy: 0.0068\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0650 - accuracy: 0.0068\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0648 - accuracy: 0.0068\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0646 - accuracy: 0.0068\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "5/5 [==============================] - 1s 5ms/step - loss: 0.0717 - accuracy: 0.0068\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0715 - accuracy: 0.0068\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0713 - accuracy: 0.0068\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0712 - accuracy: 0.0068\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0710 - accuracy: 0.0068\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0708 - accuracy: 0.0068\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0706 - accuracy: 0.0068\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0703 - accuracy: 0.0068\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0701 - accuracy: 0.0068\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0699 - accuracy: 0.0068\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0697 - accuracy: 0.0068\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0694 - accuracy: 0.0068\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0691 - accuracy: 0.0068\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0688 - accuracy: 0.0068\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0686 - accuracy: 0.0068\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0682 - accuracy: 0.0068\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0679 - accuracy: 0.0068\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0675 - accuracy: 0.0068\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0671 - accuracy: 0.0068\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0667 - accuracy: 0.0068\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0663 - accuracy: 0.0068\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0659 - accuracy: 0.0068\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0654 - accuracy: 0.0068\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0644 - accuracy: 0.0068\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0640 - accuracy: 0.0068\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0634 - accuracy: 0.0068\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0630 - accuracy: 0.0068\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0624 - accuracy: 0.0068\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0618 - accuracy: 0.0068\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0614 - accuracy: 0.0068\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0609 - accuracy: 0.0068\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0604 - accuracy: 0.0068\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0599 - accuracy: 0.0068\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0594 - accuracy: 0.0068\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0589 - accuracy: 0.0068\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0584 - accuracy: 0.0068\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0580 - accuracy: 0.0068\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0575 - accuracy: 0.0068\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0570 - accuracy: 0.0068\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0566 - accuracy: 0.0068\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0561 - accuracy: 0.0068\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0557 - accuracy: 0.0068\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0553 - accuracy: 0.0068\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0548 - accuracy: 0.0068\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0544 - accuracy: 0.0068\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0539 - accuracy: 0.0068\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0534 - accuracy: 0.0068\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0530 - accuracy: 0.0068\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0525 - accuracy: 0.0068\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 1s 5ms/step - loss: 0.0721 - accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0719 - accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0717 - accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0715 - accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0713 - accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0711 - accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0709 - accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0707 - accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0705 - accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0703 - accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0701 - accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0699 - accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0697 - accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0695 - accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0693 - accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0692 - accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0690 - accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0688 - accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0686 - accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0684 - accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0682 - accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0680 - accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0678 - accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0676 - accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0674 - accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0672 - accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0670 - accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0668 - accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0666 - accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0663 - accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0661 - accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0659 - accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0656 - accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0653 - accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0651 - accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0648 - accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0645 - accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0642 - accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0639 - accuracy: 0.0000e+00\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0636 - accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0633 - accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0629 - accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0626 - accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0622 - accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0619 - accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0615 - accuracy: 0.0136\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0610 - accuracy: 0.0340\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0607 - accuracy: 0.0340\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0602 - accuracy: 0.0340\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0598 - accuracy: 0.0340\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "5/5 [==============================] - 1s 5ms/step - loss: 0.0655 - accuracy: 0.0136\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0652 - accuracy: 0.0068\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0650 - accuracy: 0.0068\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0644 - accuracy: 0.0068\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0642 - accuracy: 0.0068\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0639 - accuracy: 0.0068\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0636 - accuracy: 0.0068\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0633 - accuracy: 0.0068\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0630 - accuracy: 0.0068\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0628 - accuracy: 0.0068\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0624 - accuracy: 0.0068\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0621 - accuracy: 0.0068\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0618 - accuracy: 0.0068\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0615 - accuracy: 0.0068\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0612 - accuracy: 0.0068\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0608 - accuracy: 0.0068\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0604 - accuracy: 0.0068\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0601 - accuracy: 0.0068\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0597 - accuracy: 0.0068\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0593 - accuracy: 0.0068\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0589 - accuracy: 0.0068\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0584 - accuracy: 0.0068\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0580 - accuracy: 0.0068\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0575 - accuracy: 0.0068\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0570 - accuracy: 0.0068\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0565 - accuracy: 0.0068\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0559 - accuracy: 0.0068\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0554 - accuracy: 0.0068\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0547 - accuracy: 0.0068\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0541 - accuracy: 0.0068\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0535 - accuracy: 0.0068\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0528 - accuracy: 0.0068\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0521 - accuracy: 0.0272\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0514 - accuracy: 0.0408\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0506 - accuracy: 0.0476\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0499 - accuracy: 0.0476\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0490 - accuracy: 0.0476\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0482 - accuracy: 0.0476\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0474 - accuracy: 0.0476\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0466 - accuracy: 0.0476\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0457 - accuracy: 0.0476\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0448 - accuracy: 0.0476\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0439 - accuracy: 0.0476\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0430 - accuracy: 0.0476\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0421 - accuracy: 0.0476\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0412 - accuracy: 0.0476\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0402 - accuracy: 0.0476\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0393 - accuracy: 0.0476\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0383 - accuracy: 0.0476\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "5/5 [==============================] - 1s 6ms/step - loss: 0.0698 - accuracy: 0.0068\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0696 - accuracy: 0.0068\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0694 - accuracy: 0.0068\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0691 - accuracy: 0.0068\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0690 - accuracy: 0.0068\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0687 - accuracy: 0.0068\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0685 - accuracy: 0.0068\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0683 - accuracy: 0.0068\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0681 - accuracy: 0.0068\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0679 - accuracy: 0.0068\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0677 - accuracy: 0.0068\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0674 - accuracy: 0.0068\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0672 - accuracy: 0.0068\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0671 - accuracy: 0.0068\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0668 - accuracy: 0.0068\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0666 - accuracy: 0.0068\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0663 - accuracy: 0.0068\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0661 - accuracy: 0.0068\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0658 - accuracy: 0.0068\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0656 - accuracy: 0.0068\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0654 - accuracy: 0.0068\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0651 - accuracy: 0.0068\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0648 - accuracy: 0.0068\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0646 - accuracy: 0.0068\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0643 - accuracy: 0.0068\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0640 - accuracy: 0.0068\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0637 - accuracy: 0.0068\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0633 - accuracy: 0.0068\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0630 - accuracy: 0.0068\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0627 - accuracy: 0.0068\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0624 - accuracy: 0.0068\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0620 - accuracy: 0.0068\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0616 - accuracy: 0.0068\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0612 - accuracy: 0.0068\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0608 - accuracy: 0.0068\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0603 - accuracy: 0.0068\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0599 - accuracy: 0.0068\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0594 - accuracy: 0.0068\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0589 - accuracy: 0.0068\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0583 - accuracy: 0.0068\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0578 - accuracy: 0.0068\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0571 - accuracy: 0.0068\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0565 - accuracy: 0.0068\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0558 - accuracy: 0.0068\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0551 - accuracy: 0.0068\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0544 - accuracy: 0.0068\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0537 - accuracy: 0.0204\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0529 - accuracy: 0.0340\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0521 - accuracy: 0.0408\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0512 - accuracy: 0.0408\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 1s 5ms/step - loss: 0.0710 - accuracy: 0.0203\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0707 - accuracy: 0.0068\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0704 - accuracy: 0.0068\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0701 - accuracy: 0.0068\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0698 - accuracy: 0.0068\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0695 - accuracy: 0.0068\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0692 - accuracy: 0.0068\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0689 - accuracy: 0.0068\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0686 - accuracy: 0.0068\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0682 - accuracy: 0.0068\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0679 - accuracy: 0.0068\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0676 - accuracy: 0.0068\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0672 - accuracy: 0.0068\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0668 - accuracy: 0.0068\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0664 - accuracy: 0.0068\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0660 - accuracy: 0.0068\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0656 - accuracy: 0.0068\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0651 - accuracy: 0.0068\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0641 - accuracy: 0.0068\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0636 - accuracy: 0.0068\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0631 - accuracy: 0.0068\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0625 - accuracy: 0.0068\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0619 - accuracy: 0.0068\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0613 - accuracy: 0.0068\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0606 - accuracy: 0.0068\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0599 - accuracy: 0.0068\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0592 - accuracy: 0.0068\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0584 - accuracy: 0.0068\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0577 - accuracy: 0.0068\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0568 - accuracy: 0.0068\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0560 - accuracy: 0.0068\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0551 - accuracy: 0.0068\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0542 - accuracy: 0.0068\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0533 - accuracy: 0.0068\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0523 - accuracy: 0.0068\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0513 - accuracy: 0.0068\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0503 - accuracy: 0.0068\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0492 - accuracy: 0.0135\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0480 - accuracy: 0.0405\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0469 - accuracy: 0.0405\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0458 - accuracy: 0.0473\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0445 - accuracy: 0.0473\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0433 - accuracy: 0.0473\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0421 - accuracy: 0.0473\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0408 - accuracy: 0.0473\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0396 - accuracy: 0.0473\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0383 - accuracy: 0.0473\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0370 - accuracy: 0.0473\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0357 - accuracy: 0.0473\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "5/5 [==============================] - 1s 5ms/step - loss: 0.0718 - accuracy: 0.0204\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0717 - accuracy: 0.0068\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0716 - accuracy: 0.0068\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0715 - accuracy: 0.0068\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0714 - accuracy: 0.0068\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0713 - accuracy: 0.0068\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0712 - accuracy: 0.0068\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0711 - accuracy: 0.0068\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0711 - accuracy: 0.0068\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0710 - accuracy: 0.0068\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0709 - accuracy: 0.0068\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0708 - accuracy: 0.0068\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0707 - accuracy: 0.0068\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0707 - accuracy: 0.0068\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0706 - accuracy: 0.0068\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0705 - accuracy: 0.0068\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0704 - accuracy: 0.0068\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0704 - accuracy: 0.0068\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0703 - accuracy: 0.0068\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0702 - accuracy: 0.0068\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0701 - accuracy: 0.0068\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0701 - accuracy: 0.0068\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0700 - accuracy: 0.0068\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0699 - accuracy: 0.0068\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0699 - accuracy: 0.0068\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0698 - accuracy: 0.0068\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0697 - accuracy: 0.0068\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0697 - accuracy: 0.0068\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0696 - accuracy: 0.0068\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0695 - accuracy: 0.0068\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0695 - accuracy: 0.0068\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0694 - accuracy: 0.0068\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0693 - accuracy: 0.0068\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0693 - accuracy: 0.0068\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0692 - accuracy: 0.0068\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0692 - accuracy: 0.0068\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0691 - accuracy: 0.0068\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0690 - accuracy: 0.0068\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0690 - accuracy: 0.0068\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0689 - accuracy: 0.0068\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0689 - accuracy: 0.0068\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0688 - accuracy: 0.0068\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0688 - accuracy: 0.0068\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0687 - accuracy: 0.0068\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0687 - accuracy: 0.0068\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0686 - accuracy: 0.0068\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0686 - accuracy: 0.0068\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0685 - accuracy: 0.0068\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0685 - accuracy: 0.0068\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0684 - accuracy: 0.0068\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 1s 4ms/step - loss: 0.0721 - accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0720 - accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0719 - accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0718 - accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0717 - accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0715 - accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0714 - accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0713 - accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0712 - accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0711 - accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0710 - accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0709 - accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0708 - accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0707 - accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0706 - accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0705 - accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0704 - accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0703 - accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0702 - accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0701 - accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0700 - accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0699 - accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0698 - accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0697 - accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0696 - accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0695 - accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0695 - accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0694 - accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0693 - accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0692 - accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0691 - accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0690 - accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0689 - accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0689 - accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0688 - accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0687 - accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0686 - accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0686 - accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0685 - accuracy: 0.0000e+00\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0684 - accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0683 - accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0683 - accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0682 - accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0681 - accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0681 - accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0680 - accuracy: 0.0000e+00\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0679 - accuracy: 0.0000e+00\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0679 - accuracy: 0.0000e+00\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0678 - accuracy: 0.0000e+00\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0677 - accuracy: 0.0000e+00\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 1s 4ms/step - loss: 0.0656 - accuracy: 0.0408\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0654 - accuracy: 0.0068\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0652 - accuracy: 0.0068\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0651 - accuracy: 0.0068\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0648 - accuracy: 0.0068\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0646 - accuracy: 0.0068\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0645 - accuracy: 0.0068\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0643 - accuracy: 0.0068\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0642 - accuracy: 0.0068\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0640 - accuracy: 0.0068\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0639 - accuracy: 0.0068\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0638 - accuracy: 0.0068\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0636 - accuracy: 0.0068\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0635 - accuracy: 0.0068\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0634 - accuracy: 0.0068\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0632 - accuracy: 0.0068\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0631 - accuracy: 0.0068\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0630 - accuracy: 0.0068\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0628 - accuracy: 0.0068\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0627 - accuracy: 0.0068\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0626 - accuracy: 0.0068\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0625 - accuracy: 0.0068\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0623 - accuracy: 0.0068\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0622 - accuracy: 0.0068\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0621 - accuracy: 0.0068\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0620 - accuracy: 0.0068\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0619 - accuracy: 0.0068\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0618 - accuracy: 0.0068\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0616 - accuracy: 0.0068\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0615 - accuracy: 0.0068\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0614 - accuracy: 0.0068\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0613 - accuracy: 0.0068\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0612 - accuracy: 0.0068\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0611 - accuracy: 0.0068\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0610 - accuracy: 0.0068\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0609 - accuracy: 0.0068\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0608 - accuracy: 0.0068\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0607 - accuracy: 0.0068\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0606 - accuracy: 0.0068\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0605 - accuracy: 0.0068\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0604 - accuracy: 0.0068\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0603 - accuracy: 0.0068\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0602 - accuracy: 0.0068\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0601 - accuracy: 0.0068\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0600 - accuracy: 0.0068\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0600 - accuracy: 0.0068\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0599 - accuracy: 0.0068\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0598 - accuracy: 0.0068\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0597 - accuracy: 0.0068\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 1s 6ms/step - loss: 0.0698 - accuracy: 0.0136\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0697 - accuracy: 0.0068\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0696 - accuracy: 0.0068\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0695 - accuracy: 0.0068\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0694 - accuracy: 0.0068\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0693 - accuracy: 0.0068\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0693 - accuracy: 0.0068\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0692 - accuracy: 0.0068\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0691 - accuracy: 0.0068\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0690 - accuracy: 0.0068\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0689 - accuracy: 0.0068\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0688 - accuracy: 0.0068\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0687 - accuracy: 0.0068\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0686 - accuracy: 0.0068\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0685 - accuracy: 0.0068\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0685 - accuracy: 0.0068\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0684 - accuracy: 0.0068\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0683 - accuracy: 0.0068\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0682 - accuracy: 0.0068\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0681 - accuracy: 0.0068\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0681 - accuracy: 0.0068\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0680 - accuracy: 0.0068\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0679 - accuracy: 0.0068\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0678 - accuracy: 0.0068\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0678 - accuracy: 0.0068\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0677 - accuracy: 0.0068\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0676 - accuracy: 0.0068\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0675 - accuracy: 0.0068\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0675 - accuracy: 0.0068\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0674 - accuracy: 0.0068\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0673 - accuracy: 0.0068\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0673 - accuracy: 0.0068\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0672 - accuracy: 0.0068\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0671 - accuracy: 0.0068\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0671 - accuracy: 0.0068\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0670 - accuracy: 0.0068\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0669 - accuracy: 0.0068\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0669 - accuracy: 0.0068\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0668 - accuracy: 0.0068\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0668 - accuracy: 0.0068\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0667 - accuracy: 0.0068\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0666 - accuracy: 0.0068\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0666 - accuracy: 0.0068\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0665 - accuracy: 0.0068\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0665 - accuracy: 0.0068\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0664 - accuracy: 0.0068\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0663 - accuracy: 0.0068\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0663 - accuracy: 0.0068\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0662 - accuracy: 0.0068\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0662 - accuracy: 0.0068\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "5/5 [==============================] - 1s 5ms/step - loss: 0.0711 - accuracy: 0.0068\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0709 - accuracy: 0.0068\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0707 - accuracy: 0.0068\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0705 - accuracy: 0.0068\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0704 - accuracy: 0.0068\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0702 - accuracy: 0.0068\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0700 - accuracy: 0.0068\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0699 - accuracy: 0.0068\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0697 - accuracy: 0.0068\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0696 - accuracy: 0.0068\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0694 - accuracy: 0.0068\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0693 - accuracy: 0.0068\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0691 - accuracy: 0.0068\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0690 - accuracy: 0.0068\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0688 - accuracy: 0.0068\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0687 - accuracy: 0.0068\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0685 - accuracy: 0.0068\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0684 - accuracy: 0.0068\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0682 - accuracy: 0.0068\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0681 - accuracy: 0.0068\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0679 - accuracy: 0.0068\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0678 - accuracy: 0.0068\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0677 - accuracy: 0.0068\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0675 - accuracy: 0.0068\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0674 - accuracy: 0.0068\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0673 - accuracy: 0.0068\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0672 - accuracy: 0.0068\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0670 - accuracy: 0.0068\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0669 - accuracy: 0.0068\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0668 - accuracy: 0.0068\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0667 - accuracy: 0.0068\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0665 - accuracy: 0.0068\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0664 - accuracy: 0.0068\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0663 - accuracy: 0.0068\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0662 - accuracy: 0.0068\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0661 - accuracy: 0.0068\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0660 - accuracy: 0.0068\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0659 - accuracy: 0.0068\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0657 - accuracy: 0.0068\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0656 - accuracy: 0.0068\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0655 - accuracy: 0.0068\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0654 - accuracy: 0.0068\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0653 - accuracy: 0.0068\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0652 - accuracy: 0.0068\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0651 - accuracy: 0.0068\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0650 - accuracy: 0.0068\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0648 - accuracy: 0.0068\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0646 - accuracy: 0.0068\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "5/5 [==============================] - 1s 5ms/step - loss: 0.0717 - accuracy: 0.0136\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0715 - accuracy: 0.0068\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0713 - accuracy: 0.0068\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0711 - accuracy: 0.0068\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0709 - accuracy: 0.0068\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0707 - accuracy: 0.0068\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0704 - accuracy: 0.0068\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0702 - accuracy: 0.0068\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0700 - accuracy: 0.0068\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0697 - accuracy: 0.0068\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0695 - accuracy: 0.0068\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0692 - accuracy: 0.0068\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0689 - accuracy: 0.0068\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0686 - accuracy: 0.0068\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0683 - accuracy: 0.0068\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0679 - accuracy: 0.0068\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0675 - accuracy: 0.0068\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0671 - accuracy: 0.0068\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0667 - accuracy: 0.0068\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0662 - accuracy: 0.0068\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0657 - accuracy: 0.0068\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0652 - accuracy: 0.0068\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0645 - accuracy: 0.0068\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0640 - accuracy: 0.0068\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0633 - accuracy: 0.0068\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0626 - accuracy: 0.0068\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0618 - accuracy: 0.0068\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0610 - accuracy: 0.0068\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0602 - accuracy: 0.0068\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0593 - accuracy: 0.0136\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0584 - accuracy: 0.0408\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0575 - accuracy: 0.0476\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0565 - accuracy: 0.0476\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0555 - accuracy: 0.0476\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0545 - accuracy: 0.0476\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0534 - accuracy: 0.0476\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0522 - accuracy: 0.0476\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0512 - accuracy: 0.0476\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0500 - accuracy: 0.0476\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0488 - accuracy: 0.0476\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0475 - accuracy: 0.0476\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0463 - accuracy: 0.0476\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0450 - accuracy: 0.0476\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0439 - accuracy: 0.0476\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0425 - accuracy: 0.0476\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0412 - accuracy: 0.0476\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0398 - accuracy: 0.0476\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0386 - accuracy: 0.0476\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0373 - accuracy: 0.0476\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0360 - accuracy: 0.0476\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0347 - accuracy: 0.0476\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0335 - accuracy: 0.0476\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0323 - accuracy: 0.0476\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0311 - accuracy: 0.0476\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0298 - accuracy: 0.0476\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0288 - accuracy: 0.0476\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0276 - accuracy: 0.0476\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0266 - accuracy: 0.0476\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0256 - accuracy: 0.0476\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0246 - accuracy: 0.0476\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0237 - accuracy: 0.0476\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0228 - accuracy: 0.0476\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0219 - accuracy: 0.0476\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0211 - accuracy: 0.0476\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0203 - accuracy: 0.0476\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - accuracy: 0.0476\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0190 - accuracy: 0.0476\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0183 - accuracy: 0.0476\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0177 - accuracy: 0.0476\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0171 - accuracy: 0.0476\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0166 - accuracy: 0.0476\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0161 - accuracy: 0.0476\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0156 - accuracy: 0.0476\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0152 - accuracy: 0.0476\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0148 - accuracy: 0.0476\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0144 - accuracy: 0.0476\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0140 - accuracy: 0.0476\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0137 - accuracy: 0.0476\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0134 - accuracy: 0.0476\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0131 - accuracy: 0.0476\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0128 - accuracy: 0.0476\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0125 - accuracy: 0.0476\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0123 - accuracy: 0.0476\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0120 - accuracy: 0.0476\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0118 - accuracy: 0.0476\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0116 - accuracy: 0.0476\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0114 - accuracy: 0.0476\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0112 - accuracy: 0.0476\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0110 - accuracy: 0.0476\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0109 - accuracy: 0.0476\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0107 - accuracy: 0.0476\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0105 - accuracy: 0.0476\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0104 - accuracy: 0.0476\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0102 - accuracy: 0.0476\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0101 - accuracy: 0.0476\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0100 - accuracy: 0.0476\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0099 - accuracy: 0.0476\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0097 - accuracy: 0.0476\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0096 - accuracy: 0.0476\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0095 - accuracy: 0.0476\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "5/5 [==============================] - 1s 4ms/step - loss: 0.0721 - accuracy: 0.0000e+00\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0718 - accuracy: 0.0000e+00\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0716 - accuracy: 0.0000e+00\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0714 - accuracy: 0.0000e+00\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0711 - accuracy: 0.0000e+00\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0708 - accuracy: 0.0000e+00\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0706 - accuracy: 0.0000e+00\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0704 - accuracy: 0.0000e+00\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0701 - accuracy: 0.0000e+00\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0698 - accuracy: 0.0000e+00\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0695 - accuracy: 0.0000e+00\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0693 - accuracy: 0.0000e+00\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0690 - accuracy: 0.0000e+00\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0686 - accuracy: 0.0000e+00\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0683 - accuracy: 0.0000e+00\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0680 - accuracy: 0.0000e+00\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0677 - accuracy: 0.0000e+00\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0673 - accuracy: 0.0000e+00\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0670 - accuracy: 0.0000e+00\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0666 - accuracy: 0.0000e+00\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0662 - accuracy: 0.0000e+00\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0658 - accuracy: 0.0000e+00\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0654 - accuracy: 0.0000e+00\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0650 - accuracy: 0.0000e+00\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0645 - accuracy: 0.0000e+00\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0641 - accuracy: 0.0000e+00\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0636 - accuracy: 0.0000e+00\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0631 - accuracy: 0.0000e+00\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0626 - accuracy: 0.0000e+00\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0621 - accuracy: 0.0000e+00\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0615 - accuracy: 0.0000e+00\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0610 - accuracy: 0.0000e+00\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0604 - accuracy: 0.0000e+00\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0598 - accuracy: 0.0000e+00\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0592 - accuracy: 0.0000e+00\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0586 - accuracy: 0.0000e+00\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0580 - accuracy: 0.0000e+00\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0573 - accuracy: 0.0000e+00\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0567 - accuracy: 0.0000e+00\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0561 - accuracy: 0.0000e+00\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0556 - accuracy: 0.0000e+00\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0549 - accuracy: 0.0000e+00\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0543 - accuracy: 0.0000e+00\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0538 - accuracy: 0.0000e+00\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0532 - accuracy: 0.0000e+00\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0527 - accuracy: 0.0000e+00\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0520 - accuracy: 0.0000e+00\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0515 - accuracy: 0.0000e+00\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0510 - accuracy: 0.0000e+00\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0504 - accuracy: 0.0000e+00\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0499 - accuracy: 0.0000e+00\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0494 - accuracy: 0.0000e+00\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0489 - accuracy: 0.0000e+00\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0484 - accuracy: 0.0000e+00\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0479 - accuracy: 0.0000e+00\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0474 - accuracy: 0.0000e+00\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0470 - accuracy: 0.0000e+00\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0465 - accuracy: 0.0000e+00\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0461 - accuracy: 0.0000e+00\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0457 - accuracy: 0.0000e+00\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0453 - accuracy: 0.0000e+00\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0449 - accuracy: 0.0000e+00\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0446 - accuracy: 0.0000e+00\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0442 - accuracy: 0.0000e+00\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0438 - accuracy: 0.0000e+00\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0435 - accuracy: 0.0000e+00\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0431 - accuracy: 0.0000e+00\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0428 - accuracy: 0.0000e+00\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0425 - accuracy: 0.0000e+00\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0421 - accuracy: 0.0000e+00\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0418 - accuracy: 0.0000e+00\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0415 - accuracy: 0.0000e+00\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0411 - accuracy: 0.0000e+00\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0408 - accuracy: 0.0000e+00\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0405 - accuracy: 0.0000e+00\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0402 - accuracy: 0.0000e+00\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0398 - accuracy: 0.0000e+00\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0395 - accuracy: 0.0000e+00\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0392 - accuracy: 0.0000e+00\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0389 - accuracy: 0.0000e+00\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0386 - accuracy: 0.0000e+00\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0384 - accuracy: 0.0000e+00\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0381 - accuracy: 0.0000e+00\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0378 - accuracy: 0.0000e+00\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0375 - accuracy: 0.0000e+00\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0373 - accuracy: 0.0000e+00\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0370 - accuracy: 0.0000e+00\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0368 - accuracy: 0.0000e+00\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0365 - accuracy: 0.0000e+00\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0363 - accuracy: 0.0000e+00\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0360 - accuracy: 0.0000e+00\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0358 - accuracy: 0.0000e+00\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0355 - accuracy: 0.0000e+00\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0353 - accuracy: 0.0000e+00\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0351 - accuracy: 0.0000e+00\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0348 - accuracy: 0.0000e+00\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0346 - accuracy: 0.0000e+00\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0344 - accuracy: 0.0000e+00\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0342 - accuracy: 0.0000e+00\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0339 - accuracy: 0.0000e+00\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 1s 5ms/step - loss: 0.0655 - accuracy: 0.0136\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0652 - accuracy: 0.0068\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0650 - accuracy: 0.0068\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0646 - accuracy: 0.0068\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0643 - accuracy: 0.0068\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0640 - accuracy: 0.0068\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0636 - accuracy: 0.0068\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0633 - accuracy: 0.0068\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0629 - accuracy: 0.0068\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0625 - accuracy: 0.0068\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0621 - accuracy: 0.0068\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0617 - accuracy: 0.0068\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0612 - accuracy: 0.0068\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0606 - accuracy: 0.0068\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0601 - accuracy: 0.0068\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0595 - accuracy: 0.0068\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0590 - accuracy: 0.0068\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0584 - accuracy: 0.0068\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0577 - accuracy: 0.0068\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0571 - accuracy: 0.0068\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0564 - accuracy: 0.0068\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0557 - accuracy: 0.0068\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0551 - accuracy: 0.0068\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0544 - accuracy: 0.0068\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0537 - accuracy: 0.0068\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0529 - accuracy: 0.0068\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0521 - accuracy: 0.0068\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0515 - accuracy: 0.0068\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0506 - accuracy: 0.0068\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0499 - accuracy: 0.0068\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0491 - accuracy: 0.0068\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0484 - accuracy: 0.0068\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0475 - accuracy: 0.0068\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0466 - accuracy: 0.0068\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0458 - accuracy: 0.0068\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0448 - accuracy: 0.0068\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0439 - accuracy: 0.0068\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0430 - accuracy: 0.0068\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0421 - accuracy: 0.0068\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0410 - accuracy: 0.0068\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0401 - accuracy: 0.0068\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0392 - accuracy: 0.0068\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0385 - accuracy: 0.0068\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0376 - accuracy: 0.0068\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0369 - accuracy: 0.0068\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0361 - accuracy: 0.0068\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0354 - accuracy: 0.0068\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0347 - accuracy: 0.0408\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0340 - accuracy: 0.0408\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0333 - accuracy: 0.0476\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0326 - accuracy: 0.0476\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0320 - accuracy: 0.0476\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0314 - accuracy: 0.0476\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0307 - accuracy: 0.0476\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0301 - accuracy: 0.0476\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0295 - accuracy: 0.0476\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0290 - accuracy: 0.0476\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0283 - accuracy: 0.0476\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0278 - accuracy: 0.0476\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0272 - accuracy: 0.0476\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0267 - accuracy: 0.0476\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0261 - accuracy: 0.0476\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0256 - accuracy: 0.0476\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0250 - accuracy: 0.0476\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0245 - accuracy: 0.0476\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0240 - accuracy: 0.0476\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0235 - accuracy: 0.0476\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0230 - accuracy: 0.0476\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0224 - accuracy: 0.0476\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0219 - accuracy: 0.0476\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0215 - accuracy: 0.0476\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0210 - accuracy: 0.0476\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0205 - accuracy: 0.0476\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0201 - accuracy: 0.0476\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0196 - accuracy: 0.0476\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0193 - accuracy: 0.0476\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0188 - accuracy: 0.0476\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0184 - accuracy: 0.0476\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0180 - accuracy: 0.0476\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0177 - accuracy: 0.0476\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0173 - accuracy: 0.0476\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0169 - accuracy: 0.0476\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0166 - accuracy: 0.0476\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0162 - accuracy: 0.0476\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0159 - accuracy: 0.0476\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0156 - accuracy: 0.0476\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0153 - accuracy: 0.0476\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0150 - accuracy: 0.0476\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0147 - accuracy: 0.0476\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0144 - accuracy: 0.0476\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0142 - accuracy: 0.0476\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0139 - accuracy: 0.0476\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0136 - accuracy: 0.0476\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0134 - accuracy: 0.0476\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0132 - accuracy: 0.0476\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0129 - accuracy: 0.0476\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0127 - accuracy: 0.0476\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0125 - accuracy: 0.0476\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0122 - accuracy: 0.0476\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0121 - accuracy: 0.0476\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "5/5 [==============================] - 1s 4ms/step - loss: 0.0698 - accuracy: 0.0068\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0696 - accuracy: 0.0068\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0693 - accuracy: 0.0068\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0691 - accuracy: 0.0068\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0689 - accuracy: 0.0068\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0687 - accuracy: 0.0068\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0685 - accuracy: 0.0068\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0682 - accuracy: 0.0068\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0680 - accuracy: 0.0068\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0678 - accuracy: 0.0068\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0675 - accuracy: 0.0068\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0673 - accuracy: 0.0068\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0670 - accuracy: 0.0068\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0668 - accuracy: 0.0068\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0665 - accuracy: 0.0068\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0662 - accuracy: 0.0068\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0659 - accuracy: 0.0068\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0656 - accuracy: 0.0068\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0652 - accuracy: 0.0068\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0646 - accuracy: 0.0068\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0642 - accuracy: 0.0068\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0638 - accuracy: 0.0068\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0633 - accuracy: 0.0068\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0629 - accuracy: 0.0068\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0624 - accuracy: 0.0068\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0619 - accuracy: 0.0068\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0614 - accuracy: 0.0068\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0608 - accuracy: 0.0068\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0603 - accuracy: 0.0068\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0597 - accuracy: 0.0068\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0591 - accuracy: 0.0068\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0584 - accuracy: 0.0068\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0577 - accuracy: 0.0068\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0570 - accuracy: 0.0068\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0563 - accuracy: 0.0068\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0555 - accuracy: 0.0068\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0547 - accuracy: 0.0204\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0538 - accuracy: 0.0340\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0530 - accuracy: 0.0340\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0521 - accuracy: 0.0408\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0510 - accuracy: 0.0408\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0501 - accuracy: 0.0408\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0491 - accuracy: 0.0408\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0481 - accuracy: 0.0408\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0471 - accuracy: 0.0408\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0459 - accuracy: 0.0408\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0449 - accuracy: 0.0408\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0437 - accuracy: 0.0408\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0425 - accuracy: 0.0408\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0414 - accuracy: 0.0408\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0403 - accuracy: 0.0408\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0392 - accuracy: 0.0408\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0381 - accuracy: 0.0408\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0370 - accuracy: 0.0408\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0358 - accuracy: 0.0408\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0348 - accuracy: 0.0408\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0337 - accuracy: 0.0408\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0326 - accuracy: 0.0408\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0315 - accuracy: 0.0408\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0306 - accuracy: 0.0408\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0296 - accuracy: 0.0408\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0287 - accuracy: 0.0408\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0277 - accuracy: 0.0408\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0268 - accuracy: 0.0408\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0259 - accuracy: 0.0408\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0251 - accuracy: 0.0408\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0243 - accuracy: 0.0408\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0235 - accuracy: 0.0408\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0228 - accuracy: 0.0408\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0221 - accuracy: 0.0408\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0214 - accuracy: 0.0408\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0208 - accuracy: 0.0408\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0201 - accuracy: 0.0408\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0196 - accuracy: 0.0408\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0190 - accuracy: 0.0408\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0185 - accuracy: 0.0408\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0180 - accuracy: 0.0408\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0175 - accuracy: 0.0408\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0171 - accuracy: 0.0408\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0167 - accuracy: 0.0408\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0163 - accuracy: 0.0408\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0160 - accuracy: 0.0408\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0156 - accuracy: 0.0408\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0152 - accuracy: 0.0408\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0149 - accuracy: 0.0408\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0146 - accuracy: 0.0408\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0144 - accuracy: 0.0408\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0141 - accuracy: 0.0408\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0138 - accuracy: 0.0408\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0135 - accuracy: 0.0408\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0133 - accuracy: 0.0408\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0131 - accuracy: 0.0408\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0129 - accuracy: 0.0408\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0127 - accuracy: 0.0408\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0125 - accuracy: 0.0408\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0123 - accuracy: 0.0408\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0121 - accuracy: 0.0408\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0119 - accuracy: 0.0408\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0118 - accuracy: 0.0408\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 1s 4ms/step - loss: 0.0710 - accuracy: 0.0270\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0707 - accuracy: 0.0068\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0704 - accuracy: 0.0068\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0701 - accuracy: 0.0068\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0697 - accuracy: 0.0068\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0694 - accuracy: 0.0068\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0690 - accuracy: 0.0068\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0687 - accuracy: 0.0068\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0683 - accuracy: 0.0068\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0679 - accuracy: 0.0068\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0675 - accuracy: 0.0068\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0672 - accuracy: 0.0068\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0667 - accuracy: 0.0068\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0663 - accuracy: 0.0068\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0658 - accuracy: 0.0068\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0654 - accuracy: 0.0068\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0644 - accuracy: 0.0068\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0639 - accuracy: 0.0068\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0633 - accuracy: 0.0068\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0628 - accuracy: 0.0068\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0622 - accuracy: 0.0068\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0616 - accuracy: 0.0068\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0610 - accuracy: 0.0068\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0604 - accuracy: 0.0068\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0598 - accuracy: 0.0068\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0591 - accuracy: 0.0068\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0584 - accuracy: 0.0068\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0577 - accuracy: 0.0068\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0570 - accuracy: 0.0068\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0564 - accuracy: 0.0068\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0557 - accuracy: 0.0068\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0549 - accuracy: 0.0068\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0541 - accuracy: 0.0068\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0534 - accuracy: 0.0068\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0526 - accuracy: 0.0068\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0517 - accuracy: 0.0068\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0509 - accuracy: 0.0068\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0501 - accuracy: 0.0068\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0492 - accuracy: 0.0068\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0484 - accuracy: 0.0068\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0475 - accuracy: 0.0068\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0467 - accuracy: 0.0068\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0459 - accuracy: 0.0068\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0451 - accuracy: 0.0068\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0443 - accuracy: 0.0068\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0435 - accuracy: 0.0068\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0428 - accuracy: 0.0068\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0421 - accuracy: 0.0068\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0414 - accuracy: 0.0068\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0406 - accuracy: 0.0068\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0399 - accuracy: 0.0068\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0391 - accuracy: 0.0068\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0384 - accuracy: 0.0068\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0378 - accuracy: 0.0068\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0371 - accuracy: 0.0068\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0364 - accuracy: 0.0203\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0357 - accuracy: 0.0473\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0351 - accuracy: 0.0473\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0344 - accuracy: 0.0473\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0338 - accuracy: 0.0473\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0332 - accuracy: 0.0473\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0325 - accuracy: 0.0473\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0318 - accuracy: 0.0473\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0312 - accuracy: 0.0473\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0306 - accuracy: 0.0473\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0300 - accuracy: 0.0473\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0293 - accuracy: 0.0473\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0286 - accuracy: 0.0473\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0280 - accuracy: 0.0473\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0275 - accuracy: 0.0473\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0268 - accuracy: 0.0473\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0262 - accuracy: 0.0473\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0256 - accuracy: 0.0473\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0250 - accuracy: 0.0473\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0245 - accuracy: 0.0473\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0239 - accuracy: 0.0473\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0233 - accuracy: 0.0473\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0228 - accuracy: 0.0473\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0222 - accuracy: 0.0473\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0218 - accuracy: 0.0473\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0212 - accuracy: 0.0473\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0208 - accuracy: 0.0473\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0203 - accuracy: 0.0473\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0198 - accuracy: 0.0473\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0194 - accuracy: 0.0473\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0189 - accuracy: 0.0473\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0185 - accuracy: 0.0473\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0181 - accuracy: 0.0473\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0178 - accuracy: 0.0473\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0173 - accuracy: 0.0473\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0169 - accuracy: 0.0473\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0166 - accuracy: 0.0473\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0162 - accuracy: 0.0473\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0159 - accuracy: 0.0473\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0156 - accuracy: 0.0473\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0153 - accuracy: 0.0473\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0149 - accuracy: 0.0473\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0146 - accuracy: 0.0473\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0144 - accuracy: 0.0473\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 1s 5ms/step - loss: 0.0718 - accuracy: 0.0204\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0717 - accuracy: 0.0068\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0716 - accuracy: 0.0068\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0715 - accuracy: 0.0068\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0714 - accuracy: 0.0068\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0713 - accuracy: 0.0068\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0712 - accuracy: 0.0068\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0712 - accuracy: 0.0068\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0711 - accuracy: 0.0068\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0710 - accuracy: 0.0068\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0709 - accuracy: 0.0068\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0708 - accuracy: 0.0068\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0707 - accuracy: 0.0068\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0707 - accuracy: 0.0068\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0706 - accuracy: 0.0068\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0705 - accuracy: 0.0068\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0704 - accuracy: 0.0068\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0704 - accuracy: 0.0068\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0703 - accuracy: 0.0068\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0702 - accuracy: 0.0068\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0701 - accuracy: 0.0068\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0701 - accuracy: 0.0068\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0700 - accuracy: 0.0068\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0699 - accuracy: 0.0068\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0699 - accuracy: 0.0068\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0698 - accuracy: 0.0068\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0697 - accuracy: 0.0068\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0697 - accuracy: 0.0068\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0696 - accuracy: 0.0068\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0695 - accuracy: 0.0068\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0695 - accuracy: 0.0068\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0694 - accuracy: 0.0068\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0694 - accuracy: 0.0068\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0693 - accuracy: 0.0068\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0692 - accuracy: 0.0068\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0692 - accuracy: 0.0068\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0691 - accuracy: 0.0068\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0691 - accuracy: 0.0068\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0690 - accuracy: 0.0068\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0689 - accuracy: 0.0068\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0689 - accuracy: 0.0068\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0688 - accuracy: 0.0068\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0688 - accuracy: 0.0068\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0687 - accuracy: 0.0068\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0687 - accuracy: 0.0068\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0686 - accuracy: 0.0068\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0686 - accuracy: 0.0068\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0685 - accuracy: 0.0068\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0685 - accuracy: 0.0068\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0684 - accuracy: 0.0068\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0684 - accuracy: 0.0068\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0683 - accuracy: 0.0068\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0683 - accuracy: 0.0068\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0682 - accuracy: 0.0068\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0682 - accuracy: 0.0068\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0681 - accuracy: 0.0068\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0681 - accuracy: 0.0068\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0680 - accuracy: 0.0068\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0680 - accuracy: 0.0068\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0679 - accuracy: 0.0068\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0679 - accuracy: 0.0068\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0679 - accuracy: 0.0068\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0678 - accuracy: 0.0068\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0678 - accuracy: 0.0068\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0677 - accuracy: 0.0068\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0677 - accuracy: 0.0068\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0677 - accuracy: 0.0068\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0676 - accuracy: 0.0068\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0676 - accuracy: 0.0068\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0675 - accuracy: 0.0068\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0675 - accuracy: 0.0068\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0675 - accuracy: 0.0068\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0674 - accuracy: 0.0068\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0674 - accuracy: 0.0068\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0674 - accuracy: 0.0068\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0673 - accuracy: 0.0068\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0673 - accuracy: 0.0068\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0672 - accuracy: 0.0068\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0672 - accuracy: 0.0068\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0672 - accuracy: 0.0068\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0671 - accuracy: 0.0068\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0671 - accuracy: 0.0068\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0671 - accuracy: 0.0068\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0670 - accuracy: 0.0068\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0670 - accuracy: 0.0068\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0670 - accuracy: 0.0068\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0670 - accuracy: 0.0068\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0669 - accuracy: 0.0068\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0669 - accuracy: 0.0068\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0669 - accuracy: 0.0068\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0668 - accuracy: 0.0068\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0668 - accuracy: 0.0068\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0668 - accuracy: 0.0068\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0667 - accuracy: 0.0068\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0667 - accuracy: 0.0068\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0667 - accuracy: 0.0068\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0667 - accuracy: 0.0068\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0666 - accuracy: 0.0068\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0666 - accuracy: 0.0068\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0666 - accuracy: 0.0068\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 1s 4ms/step - loss: 0.0721 - accuracy: 0.0000e+00\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0720 - accuracy: 0.0000e+00\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0719 - accuracy: 0.0000e+00\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0718 - accuracy: 0.0000e+00\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0717 - accuracy: 0.0000e+00\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0715 - accuracy: 0.0000e+00\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0714 - accuracy: 0.0000e+00\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0713 - accuracy: 0.0000e+00\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0712 - accuracy: 0.0000e+00\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0711 - accuracy: 0.0000e+00\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0710 - accuracy: 0.0000e+00\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0709 - accuracy: 0.0000e+00\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0708 - accuracy: 0.0000e+00\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0707 - accuracy: 0.0000e+00\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0706 - accuracy: 0.0000e+00\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0705 - accuracy: 0.0000e+00\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0704 - accuracy: 0.0000e+00\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0703 - accuracy: 0.0000e+00\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0702 - accuracy: 0.0000e+00\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0701 - accuracy: 0.0000e+00\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0700 - accuracy: 0.0000e+00\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0699 - accuracy: 0.0000e+00\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0698 - accuracy: 0.0000e+00\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0697 - accuracy: 0.0000e+00\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0696 - accuracy: 0.0000e+00\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0695 - accuracy: 0.0000e+00\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0695 - accuracy: 0.0000e+00\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0694 - accuracy: 0.0000e+00\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0693 - accuracy: 0.0000e+00\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0692 - accuracy: 0.0000e+00\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0691 - accuracy: 0.0000e+00\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0690 - accuracy: 0.0000e+00\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0690 - accuracy: 0.0000e+00\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0689 - accuracy: 0.0000e+00\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0688 - accuracy: 0.0000e+00\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0687 - accuracy: 0.0000e+00\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0686 - accuracy: 0.0000e+00\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0686 - accuracy: 0.0000e+00\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0685 - accuracy: 0.0000e+00\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0684 - accuracy: 0.0000e+00\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0683 - accuracy: 0.0000e+00\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0683 - accuracy: 0.0000e+00\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0682 - accuracy: 0.0000e+00\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0681 - accuracy: 0.0000e+00\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0681 - accuracy: 0.0000e+00\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0680 - accuracy: 0.0000e+00\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0679 - accuracy: 0.0000e+00\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0679 - accuracy: 0.0000e+00\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0678 - accuracy: 0.0000e+00\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0677 - accuracy: 0.0000e+00\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0677 - accuracy: 0.0000e+00\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0676 - accuracy: 0.0000e+00\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0675 - accuracy: 0.0000e+00\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0675 - accuracy: 0.0000e+00\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0674 - accuracy: 0.0000e+00\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0673 - accuracy: 0.0000e+00\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0673 - accuracy: 0.0000e+00\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0672 - accuracy: 0.0000e+00\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0672 - accuracy: 0.0000e+00\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0671 - accuracy: 0.0000e+00\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0671 - accuracy: 0.0000e+00\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0670 - accuracy: 0.0000e+00\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0669 - accuracy: 0.0000e+00\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0669 - accuracy: 0.0000e+00\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0668 - accuracy: 0.0000e+00\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0668 - accuracy: 0.0000e+00\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0667 - accuracy: 0.0000e+00\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0667 - accuracy: 0.0000e+00\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0666 - accuracy: 0.0000e+00\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0666 - accuracy: 0.0000e+00\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0665 - accuracy: 0.0000e+00\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0665 - accuracy: 0.0000e+00\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0664 - accuracy: 0.0000e+00\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0664 - accuracy: 0.0000e+00\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0663 - accuracy: 0.0000e+00\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0663 - accuracy: 0.0000e+00\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0662 - accuracy: 0.0000e+00\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0662 - accuracy: 0.0000e+00\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0661 - accuracy: 0.0000e+00\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0661 - accuracy: 0.0000e+00\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0661 - accuracy: 0.0000e+00\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0660 - accuracy: 0.0000e+00\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0660 - accuracy: 0.0000e+00\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0659 - accuracy: 0.0000e+00\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0659 - accuracy: 0.0000e+00\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0658 - accuracy: 0.0000e+00\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0658 - accuracy: 0.0000e+00\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0658 - accuracy: 0.0000e+00\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0657 - accuracy: 0.0000e+00\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0657 - accuracy: 0.0000e+00\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0656 - accuracy: 0.0000e+00\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0656 - accuracy: 0.0000e+00\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0656 - accuracy: 0.0000e+00\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0655 - accuracy: 0.0000e+00\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0655 - accuracy: 0.0000e+00\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0655 - accuracy: 0.0000e+00\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0654 - accuracy: 0.0000e+00\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0654 - accuracy: 0.0000e+00\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0653 - accuracy: 0.0000e+00\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0653 - accuracy: 0.0000e+00\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 1s 4ms/step - loss: 0.0655 - accuracy: 0.0068\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0654 - accuracy: 0.0068\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0652 - accuracy: 0.0068\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0651 - accuracy: 0.0068\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0648 - accuracy: 0.0068\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0646 - accuracy: 0.0068\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0645 - accuracy: 0.0068\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0643 - accuracy: 0.0068\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0642 - accuracy: 0.0068\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0640 - accuracy: 0.0068\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0639 - accuracy: 0.0068\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0638 - accuracy: 0.0068\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0636 - accuracy: 0.0068\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0635 - accuracy: 0.0068\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0634 - accuracy: 0.0068\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0632 - accuracy: 0.0068\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0631 - accuracy: 0.0068\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0630 - accuracy: 0.0068\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0628 - accuracy: 0.0068\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0627 - accuracy: 0.0068\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0626 - accuracy: 0.0068\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0625 - accuracy: 0.0068\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0624 - accuracy: 0.0068\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0622 - accuracy: 0.0068\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0621 - accuracy: 0.0068\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0620 - accuracy: 0.0068\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0619 - accuracy: 0.0068\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0618 - accuracy: 0.0068\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0617 - accuracy: 0.0068\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0615 - accuracy: 0.0068\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0614 - accuracy: 0.0068\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0613 - accuracy: 0.0068\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0612 - accuracy: 0.0068\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0611 - accuracy: 0.0068\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0610 - accuracy: 0.0068\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0609 - accuracy: 0.0068\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0608 - accuracy: 0.0068\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0607 - accuracy: 0.0068\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0606 - accuracy: 0.0068\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0605 - accuracy: 0.0068\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0604 - accuracy: 0.0068\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0603 - accuracy: 0.0068\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0602 - accuracy: 0.0068\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0601 - accuracy: 0.0068\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0601 - accuracy: 0.0068\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0600 - accuracy: 0.0068\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0599 - accuracy: 0.0068\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0598 - accuracy: 0.0068\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0597 - accuracy: 0.0068\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0596 - accuracy: 0.0068\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0595 - accuracy: 0.0068\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0594 - accuracy: 0.0068\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0594 - accuracy: 0.0068\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0593 - accuracy: 0.0068\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0592 - accuracy: 0.0068\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0591 - accuracy: 0.0068\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0590 - accuracy: 0.0068\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0590 - accuracy: 0.0068\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0589 - accuracy: 0.0068\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0588 - accuracy: 0.0068\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0587 - accuracy: 0.0068\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0587 - accuracy: 0.0068\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0586 - accuracy: 0.0068\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0585 - accuracy: 0.0068\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0585 - accuracy: 0.0068\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0584 - accuracy: 0.0068\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0583 - accuracy: 0.0068\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0582 - accuracy: 0.0068\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0582 - accuracy: 0.0068\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0581 - accuracy: 0.0068\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0580 - accuracy: 0.0068\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0580 - accuracy: 0.0068\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0579 - accuracy: 0.0068\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0579 - accuracy: 0.0068\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0578 - accuracy: 0.0068\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0577 - accuracy: 0.0068\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0577 - accuracy: 0.0068\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0576 - accuracy: 0.0068\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0575 - accuracy: 0.0068\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0575 - accuracy: 0.0068\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0574 - accuracy: 0.0068\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0574 - accuracy: 0.0068\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0573 - accuracy: 0.0068\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0573 - accuracy: 0.0068\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0572 - accuracy: 0.0068\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0572 - accuracy: 0.0068\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0571 - accuracy: 0.0068\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0570 - accuracy: 0.0068\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0570 - accuracy: 0.0068\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0569 - accuracy: 0.0068\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0569 - accuracy: 0.0068\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0568 - accuracy: 0.0068\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0568 - accuracy: 0.0068\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0567 - accuracy: 0.0068\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0567 - accuracy: 0.0068\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0566 - accuracy: 0.0068\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0566 - accuracy: 0.0068\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0566 - accuracy: 0.0068\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0565 - accuracy: 0.0068\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "5/5 [==============================] - 1s 5ms/step - loss: 0.0698 - accuracy: 0.0068\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0697 - accuracy: 0.0068\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0696 - accuracy: 0.0068\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0695 - accuracy: 0.0068\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0694 - accuracy: 0.0068\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0693 - accuracy: 0.0068\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0693 - accuracy: 0.0068\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0692 - accuracy: 0.0068\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0691 - accuracy: 0.0068\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0690 - accuracy: 0.0068\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0689 - accuracy: 0.0068\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0688 - accuracy: 0.0068\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0687 - accuracy: 0.0068\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0686 - accuracy: 0.0068\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0685 - accuracy: 0.0068\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0685 - accuracy: 0.0068\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0684 - accuracy: 0.0068\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0683 - accuracy: 0.0068\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0682 - accuracy: 0.0068\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0681 - accuracy: 0.0068\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0681 - accuracy: 0.0068\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0680 - accuracy: 0.0068\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0679 - accuracy: 0.0068\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0678 - accuracy: 0.0068\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0678 - accuracy: 0.0068\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0677 - accuracy: 0.0068\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0676 - accuracy: 0.0068\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0675 - accuracy: 0.0068\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0675 - accuracy: 0.0068\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.0068\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0673 - accuracy: 0.0068\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0673 - accuracy: 0.0068\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0672 - accuracy: 0.0068\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0671 - accuracy: 0.0068\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0671 - accuracy: 0.0068\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0670 - accuracy: 0.0068\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0669 - accuracy: 0.0068\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0669 - accuracy: 0.0068\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0668 - accuracy: 0.0068\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0667 - accuracy: 0.0068\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0667 - accuracy: 0.0068\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0666 - accuracy: 0.0068\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0666 - accuracy: 0.0068\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0665 - accuracy: 0.0068\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0664 - accuracy: 0.0068\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0664 - accuracy: 0.0068\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0663 - accuracy: 0.0068\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0663 - accuracy: 0.0068\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0662 - accuracy: 0.0068\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0662 - accuracy: 0.0068\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0661 - accuracy: 0.0068\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0661 - accuracy: 0.0068\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0660 - accuracy: 0.0068\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0660 - accuracy: 0.0068\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0659 - accuracy: 0.0068\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0659 - accuracy: 0.0068\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0658 - accuracy: 0.0068\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0658 - accuracy: 0.0068\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0657 - accuracy: 0.0068\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0657 - accuracy: 0.0068\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0656 - accuracy: 0.0068\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0656 - accuracy: 0.0068\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0655 - accuracy: 0.0068\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0655 - accuracy: 0.0068\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0654 - accuracy: 0.0068\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0654 - accuracy: 0.0068\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0653 - accuracy: 0.0068\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0653 - accuracy: 0.0068\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0653 - accuracy: 0.0068\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0652 - accuracy: 0.0068\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0652 - accuracy: 0.0068\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0651 - accuracy: 0.0068\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0651 - accuracy: 0.0068\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0651 - accuracy: 0.0068\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0650 - accuracy: 0.0068\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0650 - accuracy: 0.0068\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0648 - accuracy: 0.0068\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0648 - accuracy: 0.0068\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0646 - accuracy: 0.0068\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0646 - accuracy: 0.0068\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0646 - accuracy: 0.0068\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0645 - accuracy: 0.0068\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0645 - accuracy: 0.0068\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0645 - accuracy: 0.0068\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0644 - accuracy: 0.0068\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0644 - accuracy: 0.0068\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0644 - accuracy: 0.0068\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0643 - accuracy: 0.0068\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0643 - accuracy: 0.0068\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0643 - accuracy: 0.0068\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0643 - accuracy: 0.0068\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0642 - accuracy: 0.0068\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0642 - accuracy: 0.0068\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0642 - accuracy: 0.0068\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 1s 4ms/step - loss: 0.0711 - accuracy: 0.0068\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0709 - accuracy: 0.0068\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0707 - accuracy: 0.0068\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0705 - accuracy: 0.0068\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0704 - accuracy: 0.0068\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0702 - accuracy: 0.0068\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0700 - accuracy: 0.0068\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0699 - accuracy: 0.0068\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0697 - accuracy: 0.0068\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0696 - accuracy: 0.0068\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0694 - accuracy: 0.0068\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0693 - accuracy: 0.0068\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0691 - accuracy: 0.0068\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0690 - accuracy: 0.0068\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0688 - accuracy: 0.0068\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0687 - accuracy: 0.0068\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0685 - accuracy: 0.0068\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0684 - accuracy: 0.0068\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0682 - accuracy: 0.0068\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0681 - accuracy: 0.0068\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0680 - accuracy: 0.0068\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0678 - accuracy: 0.0068\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0677 - accuracy: 0.0068\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0676 - accuracy: 0.0068\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0674 - accuracy: 0.0068\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0673 - accuracy: 0.0068\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0672 - accuracy: 0.0068\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0670 - accuracy: 0.0068\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0669 - accuracy: 0.0068\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0668 - accuracy: 0.0068\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0667 - accuracy: 0.0068\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0666 - accuracy: 0.0068\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0664 - accuracy: 0.0068\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0663 - accuracy: 0.0068\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0662 - accuracy: 0.0068\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0661 - accuracy: 0.0068\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0660 - accuracy: 0.0068\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0659 - accuracy: 0.0068\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0658 - accuracy: 0.0068\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0656 - accuracy: 0.0068\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0655 - accuracy: 0.0068\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0654 - accuracy: 0.0068\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0653 - accuracy: 0.0068\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0652 - accuracy: 0.0068\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0651 - accuracy: 0.0068\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0650 - accuracy: 0.0068\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0648 - accuracy: 0.0068\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0646 - accuracy: 0.0068\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0645 - accuracy: 0.0068\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0645 - accuracy: 0.0068\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0644 - accuracy: 0.0068\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0643 - accuracy: 0.0068\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0642 - accuracy: 0.0068\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0641 - accuracy: 0.0068\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0640 - accuracy: 0.0068\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0639 - accuracy: 0.0068\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0638 - accuracy: 0.0068\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0638 - accuracy: 0.0068\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0637 - accuracy: 0.0068\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0636 - accuracy: 0.0068\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0635 - accuracy: 0.0068\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0634 - accuracy: 0.0068\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0634 - accuracy: 0.0068\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0633 - accuracy: 0.0068\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0632 - accuracy: 0.0068\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0631 - accuracy: 0.0068\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0630 - accuracy: 0.0068\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0630 - accuracy: 0.0068\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0629 - accuracy: 0.0068\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0628 - accuracy: 0.0068\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0628 - accuracy: 0.0068\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0627 - accuracy: 0.0068\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0626 - accuracy: 0.0068\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0625 - accuracy: 0.0068\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0625 - accuracy: 0.0068\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0624 - accuracy: 0.0068\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0624 - accuracy: 0.0068\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0623 - accuracy: 0.0068\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0622 - accuracy: 0.0068\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0622 - accuracy: 0.0068\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0621 - accuracy: 0.0068\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0620 - accuracy: 0.0068\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0620 - accuracy: 0.0068\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0619 - accuracy: 0.0068\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0618 - accuracy: 0.0068\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0618 - accuracy: 0.0068\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0617 - accuracy: 0.0068\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0617 - accuracy: 0.0068\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0616 - accuracy: 0.0068\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0616 - accuracy: 0.0068\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0615 - accuracy: 0.0068\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0615 - accuracy: 0.0068\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0614 - accuracy: 0.0068\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0614 - accuracy: 0.0068\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0613 - accuracy: 0.0068\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0612 - accuracy: 0.0068\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0612 - accuracy: 0.0068\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0611 - accuracy: 0.0068\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "5/5 [==============================] - 1s 4ms/step - loss: 0.0717 - accuracy: 0.0068\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0715 - accuracy: 0.0068\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0713 - accuracy: 0.0068\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0710 - accuracy: 0.0068\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0708 - accuracy: 0.0068\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0706 - accuracy: 0.0068\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0703 - accuracy: 0.0068\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0701 - accuracy: 0.0068\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0699 - accuracy: 0.0068\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0696 - accuracy: 0.0068\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0693 - accuracy: 0.0068\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0690 - accuracy: 0.0068\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0687 - accuracy: 0.0068\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0685 - accuracy: 0.0068\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0681 - accuracy: 0.0068\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0678 - accuracy: 0.0068\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0674 - accuracy: 0.0068\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0671 - accuracy: 0.0068\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0666 - accuracy: 0.0068\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0662 - accuracy: 0.0068\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0657 - accuracy: 0.0068\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0653 - accuracy: 0.0068\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0642 - accuracy: 0.0068\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0636 - accuracy: 0.0068\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0631 - accuracy: 0.0068\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0625 - accuracy: 0.0068\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0618 - accuracy: 0.0068\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0613 - accuracy: 0.0068\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0607 - accuracy: 0.0068\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0602 - accuracy: 0.0068\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0596 - accuracy: 0.0068\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0590 - accuracy: 0.0068\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0584 - accuracy: 0.0068\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0579 - accuracy: 0.0068\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0573 - accuracy: 0.0068\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0567 - accuracy: 0.0068\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0562 - accuracy: 0.0068\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0556 - accuracy: 0.0068\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0551 - accuracy: 0.0068\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0545 - accuracy: 0.0068\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0540 - accuracy: 0.0068\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0534 - accuracy: 0.0068\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0530 - accuracy: 0.0068\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0524 - accuracy: 0.0068\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0519 - accuracy: 0.0068\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0514 - accuracy: 0.0068\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0509 - accuracy: 0.0068\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0504 - accuracy: 0.0068\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0499 - accuracy: 0.0068\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0494 - accuracy: 0.0068\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0489 - accuracy: 0.0068\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0483 - accuracy: 0.0068\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0479 - accuracy: 0.0068\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0473 - accuracy: 0.0068\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0468 - accuracy: 0.0068\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0463 - accuracy: 0.0068\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0458 - accuracy: 0.0068\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0452 - accuracy: 0.0068\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0448 - accuracy: 0.0068\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0442 - accuracy: 0.0068\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0437 - accuracy: 0.0068\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0432 - accuracy: 0.0068\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0427 - accuracy: 0.0068\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0422 - accuracy: 0.0068\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0417 - accuracy: 0.0068\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0412 - accuracy: 0.0068\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0407 - accuracy: 0.0068\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0403 - accuracy: 0.0068\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0400 - accuracy: 0.0068\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0396 - accuracy: 0.0068\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0394 - accuracy: 0.0068\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0390 - accuracy: 0.0068\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0388 - accuracy: 0.0068\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0385 - accuracy: 0.0068\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0382 - accuracy: 0.0068\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0379 - accuracy: 0.0272\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0376 - accuracy: 0.0476\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0374 - accuracy: 0.0476\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0371 - accuracy: 0.0476\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0369 - accuracy: 0.0476\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0366 - accuracy: 0.0476\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0363 - accuracy: 0.0476\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0361 - accuracy: 0.0476\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0358 - accuracy: 0.0476\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0356 - accuracy: 0.0476\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0353 - accuracy: 0.0476\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0351 - accuracy: 0.0476\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0348 - accuracy: 0.0476\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0346 - accuracy: 0.0476\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0343 - accuracy: 0.0476\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0341 - accuracy: 0.0476\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0338 - accuracy: 0.0476\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0336 - accuracy: 0.0476\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0334 - accuracy: 0.0476\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0332 - accuracy: 0.0476\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0329 - accuracy: 0.0476\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0327 - accuracy: 0.0476\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0324 - accuracy: 0.0476\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0322 - accuracy: 0.0476\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "5/5 [==============================] - 1s 7ms/step - loss: 0.0721 - accuracy: 0.0000e+00\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0718 - accuracy: 0.0000e+00\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0715 - accuracy: 0.0000e+00\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0713 - accuracy: 0.0000e+00\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0710 - accuracy: 0.0000e+00\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0707 - accuracy: 0.0000e+00\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0704 - accuracy: 0.0000e+00\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0702 - accuracy: 0.0000e+00\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0698 - accuracy: 0.0000e+00\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0695 - accuracy: 0.0000e+00\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0691 - accuracy: 0.0000e+00\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0688 - accuracy: 0.0000e+00\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0683 - accuracy: 0.0000e+00\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0679 - accuracy: 0.0000e+00\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0675 - accuracy: 0.0000e+00\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0670 - accuracy: 0.0000e+00\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0665 - accuracy: 0.0000e+00\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0660 - accuracy: 0.0000e+00\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0654 - accuracy: 0.0000e+00\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0648 - accuracy: 0.0000e+00\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0642 - accuracy: 0.0000e+00\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0635 - accuracy: 0.0000e+00\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0628 - accuracy: 0.0000e+00\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0622 - accuracy: 0.0000e+00\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0614 - accuracy: 0.0000e+00\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0606 - accuracy: 0.0000e+00\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0598 - accuracy: 0.0000e+00\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0590 - accuracy: 0.0000e+00\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0582 - accuracy: 0.0000e+00\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0573 - accuracy: 0.0000e+00\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0564 - accuracy: 0.0000e+00\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0556 - accuracy: 0.0000e+00\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0547 - accuracy: 0.0000e+00\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0538 - accuracy: 0.0000e+00\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0529 - accuracy: 0.0000e+00\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0521 - accuracy: 0.0000e+00\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0513 - accuracy: 0.0000e+00\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0505 - accuracy: 0.0000e+00\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0497 - accuracy: 0.0000e+00\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0490 - accuracy: 0.0000e+00\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0482 - accuracy: 0.0000e+00\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0475 - accuracy: 0.0000e+00\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0469 - accuracy: 0.0000e+00\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0463 - accuracy: 0.0000e+00\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0457 - accuracy: 0.0000e+00\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0452 - accuracy: 0.0000e+00\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0446 - accuracy: 0.0000e+00\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0441 - accuracy: 0.0000e+00\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0437 - accuracy: 0.0000e+00\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0432 - accuracy: 0.0000e+00\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0428 - accuracy: 0.0000e+00\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0423 - accuracy: 0.0000e+00\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0419 - accuracy: 0.0000e+00\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0415 - accuracy: 0.0000e+00\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0410 - accuracy: 0.0000e+00\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0405 - accuracy: 0.0000e+00\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0400 - accuracy: 0.0000e+00\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0395 - accuracy: 0.0000e+00\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0389 - accuracy: 0.0000e+00\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0384 - accuracy: 0.0000e+00\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0378 - accuracy: 0.0000e+00\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0372 - accuracy: 0.0000e+00\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0365 - accuracy: 0.0000e+00\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0360 - accuracy: 0.0068\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0353 - accuracy: 0.0340\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0347 - accuracy: 0.0340\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0341 - accuracy: 0.0340\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0335 - accuracy: 0.0340\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0328 - accuracy: 0.0340\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0322 - accuracy: 0.0340\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0315 - accuracy: 0.0340\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0309 - accuracy: 0.0340\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0303 - accuracy: 0.0340\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0296 - accuracy: 0.0340\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0290 - accuracy: 0.0340\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0284 - accuracy: 0.0340\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0278 - accuracy: 0.0340\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0271 - accuracy: 0.0340\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0266 - accuracy: 0.0340\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0258 - accuracy: 0.0340\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0253 - accuracy: 0.0340\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0247 - accuracy: 0.0340\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0241 - accuracy: 0.0340\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0235 - accuracy: 0.0340\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0230 - accuracy: 0.0340\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0224 - accuracy: 0.0340\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0218 - accuracy: 0.0340\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0213 - accuracy: 0.0340\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0208 - accuracy: 0.0340\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0202 - accuracy: 0.0340\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0197 - accuracy: 0.0340\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0192 - accuracy: 0.0340\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0188 - accuracy: 0.0340\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0182 - accuracy: 0.0340\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0178 - accuracy: 0.0340\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0174 - accuracy: 0.0340\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0169 - accuracy: 0.0340\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0165 - accuracy: 0.0340\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0161 - accuracy: 0.0340\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0157 - accuracy: 0.0340\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "5/5 [==============================] - 1s 5ms/step - loss: 0.0655 - accuracy: 0.0068\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0652 - accuracy: 0.0068\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0646 - accuracy: 0.0068\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0643 - accuracy: 0.0068\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0640 - accuracy: 0.0068\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0637 - accuracy: 0.0068\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0634 - accuracy: 0.0068\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0631 - accuracy: 0.0068\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0627 - accuracy: 0.0068\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0623 - accuracy: 0.0068\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0620 - accuracy: 0.0068\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0617 - accuracy: 0.0068\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0612 - accuracy: 0.0068\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0609 - accuracy: 0.0068\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0604 - accuracy: 0.0068\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0601 - accuracy: 0.0068\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0596 - accuracy: 0.0068\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0592 - accuracy: 0.0068\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0587 - accuracy: 0.0068\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0583 - accuracy: 0.0068\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0578 - accuracy: 0.0068\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0573 - accuracy: 0.0068\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0569 - accuracy: 0.0068\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0564 - accuracy: 0.0068\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0559 - accuracy: 0.0068\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0554 - accuracy: 0.0068\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0550 - accuracy: 0.0068\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0545 - accuracy: 0.0068\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0540 - accuracy: 0.0068\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0537 - accuracy: 0.0068\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0532 - accuracy: 0.0068\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0527 - accuracy: 0.0068\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0523 - accuracy: 0.0068\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0519 - accuracy: 0.0068\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0515 - accuracy: 0.0068\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0510 - accuracy: 0.0068\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0507 - accuracy: 0.0068\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0502 - accuracy: 0.0068\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0498 - accuracy: 0.0068\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0494 - accuracy: 0.0068\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0491 - accuracy: 0.0068\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0487 - accuracy: 0.0068\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0484 - accuracy: 0.0068\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0480 - accuracy: 0.0068\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0476 - accuracy: 0.0068\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0473 - accuracy: 0.0068\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0469 - accuracy: 0.0068\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0465 - accuracy: 0.0068\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0461 - accuracy: 0.0068\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0457 - accuracy: 0.0068\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0453 - accuracy: 0.0068\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0450 - accuracy: 0.0068\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0445 - accuracy: 0.0068\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0442 - accuracy: 0.0068\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0438 - accuracy: 0.0068\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0434 - accuracy: 0.0068\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0430 - accuracy: 0.0068\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0426 - accuracy: 0.0068\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0422 - accuracy: 0.0068\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0418 - accuracy: 0.0068\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0415 - accuracy: 0.0068\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0411 - accuracy: 0.0068\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0408 - accuracy: 0.0068\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0404 - accuracy: 0.0068\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0400 - accuracy: 0.0068\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0396 - accuracy: 0.0068\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0393 - accuracy: 0.0068\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0389 - accuracy: 0.0068\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0386 - accuracy: 0.0068\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0382 - accuracy: 0.0068\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0378 - accuracy: 0.0068\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0375 - accuracy: 0.0068\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0372 - accuracy: 0.0068\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0368 - accuracy: 0.0068\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0364 - accuracy: 0.0068\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0360 - accuracy: 0.0068\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0357 - accuracy: 0.0068\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0353 - accuracy: 0.0068\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0350 - accuracy: 0.0068\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0346 - accuracy: 0.0068\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0342 - accuracy: 0.0068\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0339 - accuracy: 0.0068\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0335 - accuracy: 0.0068\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0332 - accuracy: 0.0068\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0328 - accuracy: 0.0068\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0324 - accuracy: 0.0068\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0321 - accuracy: 0.0068\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0318 - accuracy: 0.0408\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0315 - accuracy: 0.0476\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0311 - accuracy: 0.0476\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0308 - accuracy: 0.0476\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0304 - accuracy: 0.0476\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0301 - accuracy: 0.0476\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0298 - accuracy: 0.0476\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0294 - accuracy: 0.0476\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0291 - accuracy: 0.0476\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0288 - accuracy: 0.0476\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0285 - accuracy: 0.0476\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0281 - accuracy: 0.0476\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "5/5 [==============================] - 1s 5ms/step - loss: 0.0698 - accuracy: 0.0136\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0696 - accuracy: 0.0068\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0694 - accuracy: 0.0068\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0692 - accuracy: 0.0068\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0690 - accuracy: 0.0068\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0688 - accuracy: 0.0068\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0686 - accuracy: 0.0068\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0684 - accuracy: 0.0068\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0683 - accuracy: 0.0068\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0681 - accuracy: 0.0068\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0679 - accuracy: 0.0068\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0678 - accuracy: 0.0068\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0676 - accuracy: 0.0068\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0675 - accuracy: 0.0068\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0673 - accuracy: 0.0068\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0672 - accuracy: 0.0068\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0670 - accuracy: 0.0068\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0669 - accuracy: 0.0068\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0667 - accuracy: 0.0068\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0666 - accuracy: 0.0068\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0665 - accuracy: 0.0068\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0663 - accuracy: 0.0068\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0662 - accuracy: 0.0068\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0661 - accuracy: 0.0068\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0660 - accuracy: 0.0068\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0658 - accuracy: 0.0068\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0657 - accuracy: 0.0068\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0656 - accuracy: 0.0068\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0655 - accuracy: 0.0068\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0654 - accuracy: 0.0068\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0653 - accuracy: 0.0068\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0652 - accuracy: 0.0068\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0651 - accuracy: 0.0068\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0650 - accuracy: 0.0068\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0648 - accuracy: 0.0068\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0646 - accuracy: 0.0068\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0645 - accuracy: 0.0068\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0645 - accuracy: 0.0068\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0644 - accuracy: 0.0068\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0643 - accuracy: 0.0068\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0642 - accuracy: 0.0068\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0641 - accuracy: 0.0068\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0641 - accuracy: 0.0068\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0640 - accuracy: 0.0068\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0640 - accuracy: 0.0068\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0639 - accuracy: 0.0068\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0638 - accuracy: 0.0068\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0637 - accuracy: 0.0068\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0637 - accuracy: 0.0068\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0636 - accuracy: 0.0068\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0636 - accuracy: 0.0068\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0635 - accuracy: 0.0068\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0635 - accuracy: 0.0068\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0634 - accuracy: 0.0068\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0633 - accuracy: 0.0068\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0633 - accuracy: 0.0068\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0633 - accuracy: 0.0068\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0632 - accuracy: 0.0068\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0632 - accuracy: 0.0068\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0631 - accuracy: 0.0068\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0631 - accuracy: 0.0068\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0630 - accuracy: 0.0068\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0630 - accuracy: 0.0068\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0629 - accuracy: 0.0068\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0629 - accuracy: 0.0068\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0629 - accuracy: 0.0068\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0628 - accuracy: 0.0068\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0628 - accuracy: 0.0068\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0628 - accuracy: 0.0068\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0627 - accuracy: 0.0068\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0627 - accuracy: 0.0068\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0627 - accuracy: 0.0068\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0626 - accuracy: 0.0068\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0626 - accuracy: 0.0068\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0626 - accuracy: 0.0068\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0626 - accuracy: 0.0068\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0625 - accuracy: 0.0068\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0625 - accuracy: 0.0068\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0625 - accuracy: 0.0068\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0625 - accuracy: 0.0068\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0624 - accuracy: 0.0068\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0624 - accuracy: 0.0068\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0624 - accuracy: 0.0068\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0624 - accuracy: 0.0068\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0624 - accuracy: 0.0068\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0623 - accuracy: 0.0068\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0623 - accuracy: 0.0068\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0623 - accuracy: 0.0068\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0623 - accuracy: 0.0068\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0623 - accuracy: 0.0068\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0623 - accuracy: 0.0068\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0622 - accuracy: 0.0068\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0622 - accuracy: 0.0068\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0622 - accuracy: 0.0068\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0622 - accuracy: 0.0068\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0622 - accuracy: 0.0068\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0622 - accuracy: 0.0068\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0622 - accuracy: 0.0068\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 1s 5ms/step - loss: 0.0710 - accuracy: 0.0068\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0707 - accuracy: 0.0068\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0704 - accuracy: 0.0068\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0701 - accuracy: 0.0068\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0698 - accuracy: 0.0068\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0695 - accuracy: 0.0068\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0691 - accuracy: 0.0068\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0688 - accuracy: 0.0068\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0684 - accuracy: 0.0068\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0680 - accuracy: 0.0068\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0675 - accuracy: 0.0068\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0671 - accuracy: 0.0068\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0666 - accuracy: 0.0068\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0661 - accuracy: 0.0068\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0656 - accuracy: 0.0068\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0650 - accuracy: 0.0068\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0645 - accuracy: 0.0068\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0638 - accuracy: 0.0068\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0631 - accuracy: 0.0068\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0625 - accuracy: 0.0068\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0617 - accuracy: 0.0068\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0611 - accuracy: 0.0068\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0603 - accuracy: 0.0068\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0594 - accuracy: 0.0068\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0586 - accuracy: 0.0068\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0577 - accuracy: 0.0068\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0568 - accuracy: 0.0068\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0559 - accuracy: 0.0068\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0549 - accuracy: 0.0068\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0539 - accuracy: 0.0068\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0528 - accuracy: 0.0068\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0518 - accuracy: 0.0068\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0507 - accuracy: 0.0068\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0497 - accuracy: 0.0068\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0487 - accuracy: 0.0068\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0477 - accuracy: 0.0068\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0468 - accuracy: 0.0068\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0459 - accuracy: 0.0068\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0450 - accuracy: 0.0068\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0442 - accuracy: 0.0068\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0434 - accuracy: 0.0068\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0427 - accuracy: 0.0068\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0420 - accuracy: 0.0068\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0414 - accuracy: 0.0068\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0407 - accuracy: 0.0068\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0402 - accuracy: 0.0068\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0396 - accuracy: 0.0068\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0392 - accuracy: 0.0068\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0387 - accuracy: 0.0068\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0383 - accuracy: 0.0068\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0379 - accuracy: 0.0068\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0375 - accuracy: 0.0068\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0371 - accuracy: 0.0068\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0368 - accuracy: 0.0068\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0364 - accuracy: 0.0068\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0361 - accuracy: 0.0068\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0358 - accuracy: 0.0068\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0354 - accuracy: 0.0068\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0351 - accuracy: 0.0068\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0348 - accuracy: 0.0068\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0345 - accuracy: 0.0068\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0343 - accuracy: 0.0068\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0340 - accuracy: 0.0068\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0338 - accuracy: 0.0068\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0335 - accuracy: 0.0068\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0333 - accuracy: 0.0068\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0331 - accuracy: 0.0068\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0328 - accuracy: 0.0068\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0326 - accuracy: 0.0068\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0324 - accuracy: 0.0068\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0322 - accuracy: 0.0068\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0320 - accuracy: 0.0068\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0318 - accuracy: 0.0068\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0316 - accuracy: 0.0068\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0314 - accuracy: 0.0068\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0312 - accuracy: 0.0068\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0310 - accuracy: 0.0068\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0308 - accuracy: 0.0068\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0306 - accuracy: 0.0068\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0304 - accuracy: 0.0068\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0303 - accuracy: 0.0068\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0301 - accuracy: 0.0068\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0299 - accuracy: 0.0068\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0297 - accuracy: 0.0068\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0295 - accuracy: 0.0068\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0294 - accuracy: 0.0068\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0292 - accuracy: 0.0068\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0290 - accuracy: 0.0068\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0288 - accuracy: 0.0068\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0286 - accuracy: 0.0068\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0285 - accuracy: 0.0068\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0283 - accuracy: 0.0068\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0281 - accuracy: 0.0068\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0280 - accuracy: 0.0068\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0278 - accuracy: 0.0068\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0276 - accuracy: 0.0068\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0275 - accuracy: 0.0068\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0273 - accuracy: 0.0338\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0271 - accuracy: 0.0473\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0270 - accuracy: 0.0473\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 1s 4ms/step - loss: 0.0718 - accuracy: 0.0068\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0717 - accuracy: 0.0068\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0716 - accuracy: 0.0068\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0715 - accuracy: 0.0068\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0714 - accuracy: 0.0068\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0713 - accuracy: 0.0068\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0712 - accuracy: 0.0068\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0711 - accuracy: 0.0068\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0711 - accuracy: 0.0068\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0710 - accuracy: 0.0068\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0709 - accuracy: 0.0068\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0708 - accuracy: 0.0068\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0707 - accuracy: 0.0068\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0707 - accuracy: 0.0068\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0706 - accuracy: 0.0068\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0705 - accuracy: 0.0068\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0704 - accuracy: 0.0068\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0704 - accuracy: 0.0068\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0703 - accuracy: 0.0068\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0702 - accuracy: 0.0068\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0701 - accuracy: 0.0068\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0701 - accuracy: 0.0068\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0700 - accuracy: 0.0068\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0699 - accuracy: 0.0068\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0699 - accuracy: 0.0068\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0698 - accuracy: 0.0068\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0697 - accuracy: 0.0068\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0697 - accuracy: 0.0068\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0696 - accuracy: 0.0068\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0695 - accuracy: 0.0068\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0695 - accuracy: 0.0068\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0694 - accuracy: 0.0068\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0693 - accuracy: 0.0068\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0693 - accuracy: 0.0068\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0692 - accuracy: 0.0068\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0692 - accuracy: 0.0068\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0691 - accuracy: 0.0068\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0691 - accuracy: 0.0068\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0690 - accuracy: 0.0068\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0689 - accuracy: 0.0068\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0689 - accuracy: 0.0068\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0688 - accuracy: 0.0068\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0688 - accuracy: 0.0068\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0687 - accuracy: 0.0068\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0687 - accuracy: 0.0068\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0686 - accuracy: 0.0068\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0686 - accuracy: 0.0068\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0685 - accuracy: 0.0068\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0685 - accuracy: 0.0068\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0684 - accuracy: 0.0068\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0684 - accuracy: 0.0068\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0683 - accuracy: 0.0068\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0683 - accuracy: 0.0068\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0682 - accuracy: 0.0068\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0682 - accuracy: 0.0068\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0681 - accuracy: 0.0068\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0681 - accuracy: 0.0068\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0680 - accuracy: 0.0068\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0680 - accuracy: 0.0068\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0680 - accuracy: 0.0068\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0679 - accuracy: 0.0068\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0679 - accuracy: 0.0068\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0678 - accuracy: 0.0068\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0678 - accuracy: 0.0068\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0677 - accuracy: 0.0068\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0677 - accuracy: 0.0068\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0677 - accuracy: 0.0068\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0676 - accuracy: 0.0068\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0676 - accuracy: 0.0068\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0675 - accuracy: 0.0068\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0675 - accuracy: 0.0068\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0675 - accuracy: 0.0068\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0674 - accuracy: 0.0068\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0674 - accuracy: 0.0068\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0674 - accuracy: 0.0068\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0673 - accuracy: 0.0068\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0673 - accuracy: 0.0068\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0673 - accuracy: 0.0068\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0672 - accuracy: 0.0068\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0672 - accuracy: 0.0068\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0671 - accuracy: 0.0068\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0671 - accuracy: 0.0068\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0671 - accuracy: 0.0068\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0671 - accuracy: 0.0068\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0670 - accuracy: 0.0068\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0670 - accuracy: 0.0068\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0670 - accuracy: 0.0068\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0669 - accuracy: 0.0068\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0669 - accuracy: 0.0068\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0669 - accuracy: 0.0068\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0668 - accuracy: 0.0068\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0668 - accuracy: 0.0068\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0668 - accuracy: 0.0068\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0667 - accuracy: 0.0068\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0667 - accuracy: 0.0068\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0667 - accuracy: 0.0068\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0667 - accuracy: 0.0068\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0666 - accuracy: 0.0068\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0666 - accuracy: 0.0068\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0666 - accuracy: 0.0068\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 1s 5ms/step - loss: 0.0721 - accuracy: 0.0204\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0720 - accuracy: 0.0000e+00\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0719 - accuracy: 0.0000e+00\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0718 - accuracy: 0.0000e+00\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0717 - accuracy: 0.0000e+00\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0715 - accuracy: 0.0000e+00\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0714 - accuracy: 0.0000e+00\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0713 - accuracy: 0.0000e+00\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0712 - accuracy: 0.0000e+00\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0711 - accuracy: 0.0000e+00\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0710 - accuracy: 0.0000e+00\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0709 - accuracy: 0.0000e+00\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0708 - accuracy: 0.0000e+00\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0707 - accuracy: 0.0000e+00\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0706 - accuracy: 0.0000e+00\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0705 - accuracy: 0.0000e+00\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0704 - accuracy: 0.0000e+00\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0703 - accuracy: 0.0000e+00\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0702 - accuracy: 0.0000e+00\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0701 - accuracy: 0.0000e+00\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0700 - accuracy: 0.0000e+00\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0699 - accuracy: 0.0000e+00\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0698 - accuracy: 0.0000e+00\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0697 - accuracy: 0.0000e+00\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0696 - accuracy: 0.0000e+00\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0695 - accuracy: 0.0000e+00\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0694 - accuracy: 0.0000e+00\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0694 - accuracy: 0.0000e+00\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0693 - accuracy: 0.0000e+00\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0692 - accuracy: 0.0000e+00\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0691 - accuracy: 0.0000e+00\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0690 - accuracy: 0.0000e+00\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0689 - accuracy: 0.0000e+00\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0689 - accuracy: 0.0000e+00\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0688 - accuracy: 0.0000e+00\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0687 - accuracy: 0.0000e+00\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0686 - accuracy: 0.0000e+00\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0685 - accuracy: 0.0000e+00\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0685 - accuracy: 0.0000e+00\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0684 - accuracy: 0.0000e+00\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0683 - accuracy: 0.0000e+00\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0683 - accuracy: 0.0000e+00\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0682 - accuracy: 0.0000e+00\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0681 - accuracy: 0.0000e+00\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0680 - accuracy: 0.0000e+00\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0680 - accuracy: 0.0000e+00\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0679 - accuracy: 0.0000e+00\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0678 - accuracy: 0.0000e+00\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0678 - accuracy: 0.0000e+00\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0677 - accuracy: 0.0000e+00\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0676 - accuracy: 0.0000e+00\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0676 - accuracy: 0.0000e+00\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0675 - accuracy: 0.0000e+00\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0675 - accuracy: 0.0000e+00\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0674 - accuracy: 0.0000e+00\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0673 - accuracy: 0.0000e+00\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0673 - accuracy: 0.0000e+00\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0672 - accuracy: 0.0000e+00\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0672 - accuracy: 0.0000e+00\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0671 - accuracy: 0.0000e+00\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0670 - accuracy: 0.0000e+00\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0670 - accuracy: 0.0000e+00\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0669 - accuracy: 0.0000e+00\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0669 - accuracy: 0.0000e+00\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0668 - accuracy: 0.0000e+00\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0668 - accuracy: 0.0000e+00\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0667 - accuracy: 0.0000e+00\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0667 - accuracy: 0.0000e+00\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0666 - accuracy: 0.0000e+00\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0666 - accuracy: 0.0000e+00\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0665 - accuracy: 0.0000e+00\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0665 - accuracy: 0.0000e+00\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0664 - accuracy: 0.0000e+00\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0664 - accuracy: 0.0000e+00\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0663 - accuracy: 0.0000e+00\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0663 - accuracy: 0.0000e+00\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0662 - accuracy: 0.0000e+00\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0662 - accuracy: 0.0000e+00\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0661 - accuracy: 0.0000e+00\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0661 - accuracy: 0.0000e+00\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0661 - accuracy: 0.0000e+00\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0660 - accuracy: 0.0000e+00\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0660 - accuracy: 0.0000e+00\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0659 - accuracy: 0.0000e+00\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0659 - accuracy: 0.0000e+00\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0658 - accuracy: 0.0000e+00\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0658 - accuracy: 0.0000e+00\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0658 - accuracy: 0.0000e+00\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0657 - accuracy: 0.0000e+00\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0657 - accuracy: 0.0000e+00\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0656 - accuracy: 0.0000e+00\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0656 - accuracy: 0.0000e+00\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0656 - accuracy: 0.0000e+00\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0655 - accuracy: 0.0000e+00\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0655 - accuracy: 0.0000e+00\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0654 - accuracy: 0.0000e+00\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0654 - accuracy: 0.0000e+00\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0654 - accuracy: 0.0000e+00\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0653 - accuracy: 0.0000e+00\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0653 - accuracy: 0.0000e+00\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 1s 5ms/step - loss: 0.0656 - accuracy: 0.0136\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0654 - accuracy: 0.0068\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0652 - accuracy: 0.0068\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0651 - accuracy: 0.0068\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0648 - accuracy: 0.0068\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0646 - accuracy: 0.0068\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0645 - accuracy: 0.0068\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0643 - accuracy: 0.0068\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0642 - accuracy: 0.0068\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0640 - accuracy: 0.0068\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0639 - accuracy: 0.0068\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0638 - accuracy: 0.0068\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0636 - accuracy: 0.0068\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0635 - accuracy: 0.0068\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0634 - accuracy: 0.0068\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0632 - accuracy: 0.0068\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0631 - accuracy: 0.0068\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0630 - accuracy: 0.0068\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0628 - accuracy: 0.0068\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0627 - accuracy: 0.0068\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0626 - accuracy: 0.0068\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0625 - accuracy: 0.0068\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0623 - accuracy: 0.0068\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0622 - accuracy: 0.0068\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0621 - accuracy: 0.0068\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0620 - accuracy: 0.0068\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0619 - accuracy: 0.0068\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0618 - accuracy: 0.0068\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0617 - accuracy: 0.0068\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0615 - accuracy: 0.0068\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0614 - accuracy: 0.0068\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0613 - accuracy: 0.0068\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0612 - accuracy: 0.0068\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0611 - accuracy: 0.0068\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0610 - accuracy: 0.0068\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0609 - accuracy: 0.0068\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0608 - accuracy: 0.0068\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0607 - accuracy: 0.0068\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0606 - accuracy: 0.0068\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0605 - accuracy: 0.0068\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0604 - accuracy: 0.0068\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0603 - accuracy: 0.0068\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0602 - accuracy: 0.0068\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0601 - accuracy: 0.0068\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0600 - accuracy: 0.0068\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0599 - accuracy: 0.0068\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0599 - accuracy: 0.0068\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0598 - accuracy: 0.0068\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0597 - accuracy: 0.0068\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0596 - accuracy: 0.0068\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0595 - accuracy: 0.0068\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0594 - accuracy: 0.0068\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0594 - accuracy: 0.0068\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0593 - accuracy: 0.0068\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0592 - accuracy: 0.0068\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0591 - accuracy: 0.0068\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0590 - accuracy: 0.0068\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0589 - accuracy: 0.0068\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0589 - accuracy: 0.0068\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0588 - accuracy: 0.0068\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0587 - accuracy: 0.0068\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0586 - accuracy: 0.0068\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0586 - accuracy: 0.0068\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0585 - accuracy: 0.0068\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0584 - accuracy: 0.0068\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0584 - accuracy: 0.0068\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0583 - accuracy: 0.0068\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0582 - accuracy: 0.0068\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0582 - accuracy: 0.0068\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0581 - accuracy: 0.0068\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0580 - accuracy: 0.0068\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0580 - accuracy: 0.0068\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0579 - accuracy: 0.0068\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0578 - accuracy: 0.0068\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0578 - accuracy: 0.0068\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0577 - accuracy: 0.0068\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0577 - accuracy: 0.0068\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0576 - accuracy: 0.0068\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0575 - accuracy: 0.0068\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0575 - accuracy: 0.0068\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0574 - accuracy: 0.0068\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0574 - accuracy: 0.0068\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0573 - accuracy: 0.0068\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0572 - accuracy: 0.0068\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0572 - accuracy: 0.0068\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0571 - accuracy: 0.0068\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0571 - accuracy: 0.0068\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0570 - accuracy: 0.0068\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0570 - accuracy: 0.0068\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0569 - accuracy: 0.0068\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0569 - accuracy: 0.0068\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0568 - accuracy: 0.0068\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0568 - accuracy: 0.0068\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0567 - accuracy: 0.0068\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0567 - accuracy: 0.0068\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0566 - accuracy: 0.0068\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0566 - accuracy: 0.0068\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0565 - accuracy: 0.0068\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0565 - accuracy: 0.0068\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "5/5 [==============================] - 1s 5ms/step - loss: 0.0698 - accuracy: 0.0136\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0697 - accuracy: 0.0068\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0696 - accuracy: 0.0068\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0695 - accuracy: 0.0068\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0694 - accuracy: 0.0068\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0693 - accuracy: 0.0068\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0692 - accuracy: 0.0068\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0692 - accuracy: 0.0068\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0691 - accuracy: 0.0068\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0690 - accuracy: 0.0068\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0689 - accuracy: 0.0068\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0688 - accuracy: 0.0068\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0687 - accuracy: 0.0068\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0686 - accuracy: 0.0068\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0685 - accuracy: 0.0068\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0685 - accuracy: 0.0068\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0684 - accuracy: 0.0068\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0683 - accuracy: 0.0068\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0682 - accuracy: 0.0068\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0681 - accuracy: 0.0068\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0681 - accuracy: 0.0068\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0680 - accuracy: 0.0068\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0679 - accuracy: 0.0068\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0678 - accuracy: 0.0068\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0678 - accuracy: 0.0068\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0677 - accuracy: 0.0068\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0676 - accuracy: 0.0068\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0675 - accuracy: 0.0068\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0675 - accuracy: 0.0068\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0674 - accuracy: 0.0068\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0673 - accuracy: 0.0068\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0673 - accuracy: 0.0068\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0672 - accuracy: 0.0068\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0671 - accuracy: 0.0068\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0671 - accuracy: 0.0068\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0670 - accuracy: 0.0068\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0669 - accuracy: 0.0068\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0669 - accuracy: 0.0068\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0668 - accuracy: 0.0068\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0667 - accuracy: 0.0068\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0667 - accuracy: 0.0068\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0666 - accuracy: 0.0068\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0666 - accuracy: 0.0068\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0665 - accuracy: 0.0068\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0664 - accuracy: 0.0068\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0664 - accuracy: 0.0068\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0663 - accuracy: 0.0068\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0663 - accuracy: 0.0068\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0662 - accuracy: 0.0068\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0662 - accuracy: 0.0068\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0661 - accuracy: 0.0068\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0661 - accuracy: 0.0068\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0660 - accuracy: 0.0068\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0660 - accuracy: 0.0068\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0659 - accuracy: 0.0068\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0659 - accuracy: 0.0068\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0658 - accuracy: 0.0068\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0657 - accuracy: 0.0068\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0657 - accuracy: 0.0068\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0657 - accuracy: 0.0068\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0656 - accuracy: 0.0068\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0656 - accuracy: 0.0068\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0655 - accuracy: 0.0068\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0655 - accuracy: 0.0068\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0654 - accuracy: 0.0068\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0654 - accuracy: 0.0068\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0653 - accuracy: 0.0068\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0653 - accuracy: 0.0068\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0652 - accuracy: 0.0068\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0652 - accuracy: 0.0068\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0652 - accuracy: 0.0068\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0651 - accuracy: 0.0068\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0651 - accuracy: 0.0068\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0650 - accuracy: 0.0068\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0650 - accuracy: 0.0068\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0650 - accuracy: 0.0068\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0648 - accuracy: 0.0068\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0648 - accuracy: 0.0068\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0648 - accuracy: 0.0068\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0646 - accuracy: 0.0068\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0646 - accuracy: 0.0068\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0646 - accuracy: 0.0068\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0645 - accuracy: 0.0068\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0645 - accuracy: 0.0068\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0645 - accuracy: 0.0068\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0644 - accuracy: 0.0068\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0644 - accuracy: 0.0068\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0644 - accuracy: 0.0068\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0643 - accuracy: 0.0068\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0643 - accuracy: 0.0068\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0643 - accuracy: 0.0068\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0642 - accuracy: 0.0068\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0642 - accuracy: 0.0068\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0642 - accuracy: 0.0068\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0642 - accuracy: 0.0068\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 1s 4ms/step - loss: 0.0711 - accuracy: 0.0068\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0709 - accuracy: 0.0068\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0707 - accuracy: 0.0068\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0705 - accuracy: 0.0068\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0704 - accuracy: 0.0068\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0702 - accuracy: 0.0068\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0701 - accuracy: 0.0068\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0699 - accuracy: 0.0068\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0697 - accuracy: 0.0068\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0696 - accuracy: 0.0068\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0694 - accuracy: 0.0068\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0693 - accuracy: 0.0068\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0691 - accuracy: 0.0068\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0690 - accuracy: 0.0068\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0688 - accuracy: 0.0068\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0687 - accuracy: 0.0068\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0685 - accuracy: 0.0068\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0684 - accuracy: 0.0068\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0682 - accuracy: 0.0068\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0681 - accuracy: 0.0068\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0680 - accuracy: 0.0068\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0678 - accuracy: 0.0068\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0677 - accuracy: 0.0068\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0676 - accuracy: 0.0068\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0674 - accuracy: 0.0068\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0673 - accuracy: 0.0068\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0672 - accuracy: 0.0068\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0670 - accuracy: 0.0068\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0669 - accuracy: 0.0068\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0668 - accuracy: 0.0068\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0667 - accuracy: 0.0068\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0666 - accuracy: 0.0068\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0664 - accuracy: 0.0068\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0663 - accuracy: 0.0068\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0662 - accuracy: 0.0068\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0661 - accuracy: 0.0068\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0660 - accuracy: 0.0068\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0659 - accuracy: 0.0068\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0658 - accuracy: 0.0068\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0657 - accuracy: 0.0068\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0655 - accuracy: 0.0068\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0654 - accuracy: 0.0068\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0653 - accuracy: 0.0068\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0652 - accuracy: 0.0068\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0651 - accuracy: 0.0068\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0650 - accuracy: 0.0068\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0649 - accuracy: 0.0068\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0648 - accuracy: 0.0068\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0647 - accuracy: 0.0068\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0646 - accuracy: 0.0068\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0645 - accuracy: 0.0068\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0645 - accuracy: 0.0068\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0644 - accuracy: 0.0068\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0643 - accuracy: 0.0068\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0642 - accuracy: 0.0068\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0641 - accuracy: 0.0068\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0640 - accuracy: 0.0068\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0639 - accuracy: 0.0068\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0638 - accuracy: 0.0068\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0638 - accuracy: 0.0068\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0637 - accuracy: 0.0068\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0636 - accuracy: 0.0068\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0635 - accuracy: 0.0068\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0634 - accuracy: 0.0068\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0634 - accuracy: 0.0068\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0633 - accuracy: 0.0068\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0632 - accuracy: 0.0068\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0631 - accuracy: 0.0068\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0630 - accuracy: 0.0068\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0630 - accuracy: 0.0068\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0629 - accuracy: 0.0068\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0628 - accuracy: 0.0068\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0628 - accuracy: 0.0068\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0627 - accuracy: 0.0068\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0626 - accuracy: 0.0068\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0626 - accuracy: 0.0068\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0625 - accuracy: 0.0068\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0624 - accuracy: 0.0068\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0624 - accuracy: 0.0068\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0623 - accuracy: 0.0068\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0622 - accuracy: 0.0068\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0622 - accuracy: 0.0068\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0621 - accuracy: 0.0068\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0620 - accuracy: 0.0068\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0620 - accuracy: 0.0068\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0619 - accuracy: 0.0068\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0619 - accuracy: 0.0068\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0618 - accuracy: 0.0068\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0617 - accuracy: 0.0068\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0617 - accuracy: 0.0068\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0616 - accuracy: 0.0068\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0616 - accuracy: 0.0068\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0615 - accuracy: 0.0068\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0615 - accuracy: 0.0068\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0614 - accuracy: 0.0068\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0613 - accuracy: 0.0068\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0613 - accuracy: 0.0068\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0612 - accuracy: 0.0068\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0612 - accuracy: 0.0068\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0611 - accuracy: 0.0068\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 211, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: continuous is not supported\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the train scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
            "  category=UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "19/19 [==============================] - 1s 4ms/step - loss: 0.0697 - accuracy: 0.0054\n",
            "Epoch 2/50\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0688 - accuracy: 0.0054\n",
            "Epoch 3/50\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0679 - accuracy: 0.0054\n",
            "Epoch 4/50\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0666 - accuracy: 0.0054\n",
            "Epoch 5/50\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0652 - accuracy: 0.0054\n",
            "Epoch 6/50\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0636 - accuracy: 0.0054\n",
            "Epoch 7/50\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0620 - accuracy: 0.0054\n",
            "Epoch 8/50\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0602 - accuracy: 0.0054\n",
            "Epoch 9/50\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0586 - accuracy: 0.0054\n",
            "Epoch 10/50\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0571 - accuracy: 0.0054\n",
            "Epoch 11/50\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0556 - accuracy: 0.0054\n",
            "Epoch 12/50\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0542 - accuracy: 0.0054\n",
            "Epoch 13/50\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0530 - accuracy: 0.0054\n",
            "Epoch 14/50\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0518 - accuracy: 0.0054\n",
            "Epoch 15/50\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0508 - accuracy: 0.0054\n",
            "Epoch 16/50\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0498 - accuracy: 0.0054\n",
            "Epoch 17/50\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0488 - accuracy: 0.0054\n",
            "Epoch 18/50\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0479 - accuracy: 0.0054\n",
            "Epoch 19/50\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0469 - accuracy: 0.0054\n",
            "Epoch 20/50\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0460 - accuracy: 0.0054\n",
            "Epoch 21/50\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0450 - accuracy: 0.0054\n",
            "Epoch 22/50\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0441 - accuracy: 0.0054\n",
            "Epoch 23/50\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0431 - accuracy: 0.0054\n",
            "Epoch 24/50\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0422 - accuracy: 0.0054\n",
            "Epoch 25/50\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0412 - accuracy: 0.0054\n",
            "Epoch 26/50\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0403 - accuracy: 0.0054\n",
            "Epoch 27/50\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0392 - accuracy: 0.0054\n",
            "Epoch 28/50\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0383 - accuracy: 0.0054\n",
            "Epoch 29/50\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0374 - accuracy: 0.0054\n",
            "Epoch 30/50\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0364 - accuracy: 0.0054\n",
            "Epoch 31/50\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0357 - accuracy: 0.0054\n",
            "Epoch 32/50\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0350 - accuracy: 0.0109\n",
            "Epoch 33/50\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0345 - accuracy: 0.0435\n",
            "Epoch 34/50\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0339 - accuracy: 0.0435\n",
            "Epoch 35/50\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0334 - accuracy: 0.0435\n",
            "Epoch 36/50\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0329 - accuracy: 0.0435\n",
            "Epoch 37/50\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0324 - accuracy: 0.0435\n",
            "Epoch 38/50\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0319 - accuracy: 0.0435\n",
            "Epoch 39/50\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0314 - accuracy: 0.0435\n",
            "Epoch 40/50\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0310 - accuracy: 0.0435\n",
            "Epoch 41/50\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0305 - accuracy: 0.0435\n",
            "Epoch 42/50\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0301 - accuracy: 0.0435\n",
            "Epoch 43/50\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0295 - accuracy: 0.0435\n",
            "Epoch 44/50\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0291 - accuracy: 0.0435\n",
            "Epoch 45/50\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0286 - accuracy: 0.0435\n",
            "Epoch 46/50\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0282 - accuracy: 0.0435\n",
            "Epoch 47/50\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0277 - accuracy: 0.0435\n",
            "Epoch 48/50\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0272 - accuracy: 0.0435\n",
            "Epoch 49/50\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.0268 - accuracy: 0.0435\n",
            "Epoch 50/50\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0263 - accuracy: 0.0435\n",
            "[array([[0.26855124],\n",
            "       [1.        ],\n",
            "       [0.11435914],\n",
            "       [0.54866688],\n",
            "       [0.29810472],\n",
            "       [0.19787986],\n",
            "       [0.63090267],\n",
            "       [0.42659814],\n",
            "       [0.76582075],\n",
            "       [0.29938966],\n",
            "       [0.3610665 ],\n",
            "       [0.03983296],\n",
            "       [0.42788307],\n",
            "       [0.20044973],\n",
            "       [0.24670736],\n",
            "       [0.28268551],\n",
            "       [0.12592355],\n",
            "       [0.19017025],\n",
            "       [0.48442017],\n",
            "       [0.27240604],\n",
            "       [0.34050755],\n",
            "       [0.06938644],\n",
            "       [0.54609701],\n",
            "       [0.82107292],\n",
            "       [0.02698362],\n",
            "       [0.42017347],\n",
            "       [0.30452939],\n",
            "       [0.49084484],\n",
            "       [0.20173466],\n",
            "       [0.2634115 ],\n",
            "       [0.35592676],\n",
            "       [0.32380341],\n",
            "       [0.79794411],\n",
            "       [0.4214584 ],\n",
            "       [0.30966913],\n",
            "       [0.22357854],\n",
            "       [0.214584  ],\n",
            "       [0.35978156],\n",
            "       [0.21586894],\n",
            "       [0.18888532],\n",
            "       [0.44587215],\n",
            "       [0.42017347],\n",
            "       [0.40346932],\n",
            "       [0.29681979],\n",
            "       [0.54738195],\n",
            "       [0.93800193]]), array([0.2663867 , 0.5451902 , 0.1406191 , 0.487872  , 0.2908787 ,\n",
            "       0.28694004, 0.5451902 , 0.30094492, 0.5451902 , 0.36877066,\n",
            "       0.3425089 , 0.12475961, 0.37350187, 0.32324782, 0.18200293,\n",
            "       0.25827307, 0.21004686, 0.33673897, 0.3981804 , 0.407788  ,\n",
            "       0.379913  , 0.1259897 , 0.5451902 , 0.5451902 , 0.12619287,\n",
            "       0.3620699 , 0.38085353, 0.43758342, 0.26514655, 0.2778027 ,\n",
            "       0.3937165 , 0.25235498, 0.5451902 , 0.38996738, 0.32690892,\n",
            "       0.26323318, 0.26812714, 0.40548176, 0.3162896 , 0.2774385 ,\n",
            "       0.5451902 , 0.36013967, 0.36940125, 0.2550636 , 0.5165381 ,\n",
            "       0.5451902 ], dtype=float32)]\n",
            "Best Parameters :  {'batch_size': 10, 'epochs': 50, 'lr': 0.001, 'optimizer': 'adam'}\n"
          ]
        }
      ],
      "source": [
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "def build_regressor(optimizer='adam', lr=0.001):\n",
        "  regressor = Sequential()\n",
        "  regressor.add(Dense(units = 5 , kernel_initializer='random_uniform', activation= 'relu'))\n",
        "  regressor.add(Dense(units = 5 , kernel_initializer='random_uniform', activation= 'relu'))\n",
        "  regressor.add(Dense(units = 1 , kernel_initializer='random_uniform', activation= 'sigmoid'))\n",
        "  regressor.compile(optimizer=optimizer , loss = 'mse', \n",
        "  metrics=['accuracy'])\n",
        "  return regressor\n",
        "KR = KerasRegressor(build_fn=build_regressor)\n",
        "parameters = {'batch_size' : [10,30],\n",
        "              'lr' : [0.001, 0.1],\n",
        "          'epochs' : [50,100],\n",
        "          'optimizer':['adam','SGD']}\n",
        "grid_search = GridSearchCV(estimator = KR, param_grid = parameters, n_jobs=-1, scoring='accuracy',cv=5, return_train_score=True, verbose=0)\n",
        "grid_search.fit(X_train,y_train)\n",
        "\n",
        "grid_search.fit(X_train, np.ravel(y_train))\n",
        "\n",
        "ypred = grid_search.predict(X_test)\n",
        "\n",
        "print ([y_test, ypred])\n",
        "print('Best Parameters : ',grid_search.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ez2f1J1vmxGq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xBHn88A5mxKp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "BagVWWO9mxP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UjfUp644EIXt"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "ML_MVcpo.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPJc0yWHkFTmJ08pCoNFJmB",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}